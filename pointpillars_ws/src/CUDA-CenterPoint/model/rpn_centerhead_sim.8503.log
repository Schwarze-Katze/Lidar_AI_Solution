&&&& RUNNING TensorRT.trtexec [TensorRT v8203] # trtexec --onnx=model/rpn_centerhead_sim.onnx --saveEngine=model/rpn_centerhead_sim.plan.8503 --workspace=4096 --fp16 --outputIOFormats=fp16:chw --inputIOFormats=fp16:chw --verbose --dumpLayerInfo --dumpProfile --separateProfileRun --profilingVerbosity=detailed
[03/24/2023-12:56:13] [I] === Model Options ===
[03/24/2023-12:56:13] [I] Format: ONNX
[03/24/2023-12:56:13] [I] Model: model/rpn_centerhead_sim.onnx
[03/24/2023-12:56:13] [I] Output:
[03/24/2023-12:56:13] [I] === Build Options ===
[03/24/2023-12:56:13] [I] Max batch: explicit batch
[03/24/2023-12:56:13] [I] Workspace: 4096 MiB
[03/24/2023-12:56:13] [I] minTiming: 1
[03/24/2023-12:56:13] [I] avgTiming: 8
[03/24/2023-12:56:13] [I] Precision: FP32+FP16
[03/24/2023-12:56:13] [I] Calibration: 
[03/24/2023-12:56:13] [I] Refit: Disabled
[03/24/2023-12:56:13] [I] Sparsity: Disabled
[03/24/2023-12:56:13] [I] Safe mode: Disabled
[03/24/2023-12:56:13] [I] DirectIO mode: Disabled
[03/24/2023-12:56:13] [I] Restricted mode: Disabled
[03/24/2023-12:56:13] [I] Save engine: model/rpn_centerhead_sim.plan.8503
[03/24/2023-12:56:13] [I] Load engine: 
[03/24/2023-12:56:13] [I] Profiling verbosity: 2
[03/24/2023-12:56:13] [I] Tactic sources: Using default tactic sources
[03/24/2023-12:56:13] [I] timingCacheMode: local
[03/24/2023-12:56:13] [I] timingCacheFile: 
[03/24/2023-12:56:13] [I] Input(s): fp16:chw
[03/24/2023-12:56:13] [I] Output(s): fp16:chw
[03/24/2023-12:56:13] [I] Input build shapes: model
[03/24/2023-12:56:13] [I] Input calibration shapes: model
[03/24/2023-12:56:13] [I] === System Options ===
[03/24/2023-12:56:13] [I] Device: 0
[03/24/2023-12:56:13] [I] DLACore: 
[03/24/2023-12:56:13] [I] Plugins:
[03/24/2023-12:56:13] [I] === Inference Options ===
[03/24/2023-12:56:13] [I] Batch: Explicit
[03/24/2023-12:56:13] [I] Input inference shapes: model
[03/24/2023-12:56:13] [I] Iterations: 10
[03/24/2023-12:56:13] [I] Duration: 3s (+ 200ms warm up)
[03/24/2023-12:56:13] [I] Sleep time: 0ms
[03/24/2023-12:56:13] [I] Idle time: 0ms
[03/24/2023-12:56:13] [I] Streams: 1
[03/24/2023-12:56:13] [I] ExposeDMA: Disabled
[03/24/2023-12:56:13] [I] Data transfers: Enabled
[03/24/2023-12:56:13] [I] Spin-wait: Disabled
[03/24/2023-12:56:13] [I] Multithreading: Disabled
[03/24/2023-12:56:13] [I] CUDA Graph: Disabled
[03/24/2023-12:56:13] [I] Separate profiling: Enabled
[03/24/2023-12:56:13] [I] Time Deserialize: Disabled
[03/24/2023-12:56:13] [I] Time Refit: Disabled
[03/24/2023-12:56:13] [I] Skip inference: Disabled
[03/24/2023-12:56:13] [I] Inputs:
[03/24/2023-12:56:13] [I] === Reporting Options ===
[03/24/2023-12:56:13] [I] Verbose: Enabled
[03/24/2023-12:56:13] [I] Averages: 10 inferences
[03/24/2023-12:56:13] [I] Percentile: 99
[03/24/2023-12:56:13] [I] Dump refittable layers:Disabled
[03/24/2023-12:56:13] [I] Dump output: Disabled
[03/24/2023-12:56:13] [I] Profile: Enabled
[03/24/2023-12:56:13] [I] Export timing to JSON file: 
[03/24/2023-12:56:13] [I] Export output to JSON file: 
[03/24/2023-12:56:13] [I] Export profile to JSON file: 
[03/24/2023-12:56:13] [I] 
[03/24/2023-12:56:13] [I] === Device Information ===
[03/24/2023-12:56:13] [I] Selected Device: NVIDIA A100-PCIE-40GB
[03/24/2023-12:56:13] [I] Compute Capability: 8.0
[03/24/2023-12:56:13] [I] SMs: 108
[03/24/2023-12:56:13] [I] Compute Clock Rate: 1.41 GHz
[03/24/2023-12:56:13] [I] Device Global Memory: 40396 MiB
[03/24/2023-12:56:13] [I] Shared Memory per SM: 164 KiB
[03/24/2023-12:56:13] [I] Memory Bus Width: 5120 bits (ECC enabled)
[03/24/2023-12:56:13] [I] Memory Clock Rate: 1.215 GHz
[03/24/2023-12:56:13] [I] 
[03/24/2023-12:56:13] [I] TensorRT version: 8.2.3
[03/24/2023-12:56:13] [V] [TRT] Registered plugin creator - ::GridAnchor_TRT version 1
[03/24/2023-12:56:13] [V] [TRT] Registered plugin creator - ::GridAnchorRect_TRT version 1
[03/24/2023-12:56:13] [V] [TRT] Registered plugin creator - ::NMS_TRT version 1
[03/24/2023-12:56:13] [V] [TRT] Registered plugin creator - ::Reorg_TRT version 1
[03/24/2023-12:56:13] [V] [TRT] Registered plugin creator - ::Region_TRT version 1
[03/24/2023-12:56:13] [V] [TRT] Registered plugin creator - ::Clip_TRT version 1
[03/24/2023-12:56:13] [V] [TRT] Registered plugin creator - ::LReLU_TRT version 1
[03/24/2023-12:56:13] [V] [TRT] Registered plugin creator - ::PriorBox_TRT version 1
[03/24/2023-12:56:13] [V] [TRT] Registered plugin creator - ::Normalize_TRT version 1
[03/24/2023-12:56:13] [V] [TRT] Registered plugin creator - ::ScatterND version 1
[03/24/2023-12:56:13] [V] [TRT] Registered plugin creator - ::RPROI_TRT version 1
[03/24/2023-12:56:13] [V] [TRT] Registered plugin creator - ::BatchedNMS_TRT version 1
[03/24/2023-12:56:13] [V] [TRT] Registered plugin creator - ::BatchedNMSDynamic_TRT version 1
[03/24/2023-12:56:13] [V] [TRT] Registered plugin creator - ::FlattenConcat_TRT version 1
[03/24/2023-12:56:13] [V] [TRT] Registered plugin creator - ::CropAndResize version 1
[03/24/2023-12:56:13] [V] [TRT] Registered plugin creator - ::DetectionLayer_TRT version 1
[03/24/2023-12:56:13] [V] [TRT] Registered plugin creator - ::EfficientNMS_TRT version 1
[03/24/2023-12:56:13] [V] [TRT] Registered plugin creator - ::EfficientNMS_ONNX_TRT version 1
[03/24/2023-12:56:13] [V] [TRT] Registered plugin creator - ::EfficientNMS_TFTRT_TRT version 1
[03/24/2023-12:56:13] [V] [TRT] Registered plugin creator - ::Proposal version 1
[03/24/2023-12:56:13] [V] [TRT] Registered plugin creator - ::ProposalLayer_TRT version 1
[03/24/2023-12:56:13] [V] [TRT] Registered plugin creator - ::PyramidROIAlign_TRT version 1
[03/24/2023-12:56:13] [V] [TRT] Registered plugin creator - ::ResizeNearest_TRT version 1
[03/24/2023-12:56:13] [V] [TRT] Registered plugin creator - ::Split version 1
[03/24/2023-12:56:13] [V] [TRT] Registered plugin creator - ::SpecialSlice_TRT version 1
[03/24/2023-12:56:13] [V] [TRT] Registered plugin creator - ::InstanceNormalization_TRT version 1
[03/24/2023-12:56:14] [I] [TRT] [MemUsageChange] Init CUDA: CPU +425, GPU +0, now: CPU 437, GPU 690 (MiB)
[03/24/2023-12:56:14] [I] [TRT] [MemUsageSnapshot] Begin constructing builder kernel library: CPU 437 MiB, GPU 690 MiB
[03/24/2023-12:56:14] [I] [TRT] [MemUsageSnapshot] End constructing builder kernel library: CPU 654 MiB, GPU 762 MiB
[03/24/2023-12:56:14] [I] Start parsing network model
[03/24/2023-12:56:14] [I] [TRT] ----------------------------------------------------------------
[03/24/2023-12:56:14] [I] [TRT] Input filename:   model/rpn_centerhead_sim.onnx
[03/24/2023-12:56:14] [I] [TRT] ONNX IR version:  0.0.6
[03/24/2023-12:56:14] [I] [TRT] Opset version:    11
[03/24/2023-12:56:14] [I] [TRT] Producer name:    pytorch
[03/24/2023-12:56:14] [I] [TRT] Producer version: 1.11.0
[03/24/2023-12:56:14] [I] [TRT] Domain:           
[03/24/2023-12:56:14] [I] [TRT] Model version:    0
[03/24/2023-12:56:14] [I] [TRT] Doc string:       
[03/24/2023-12:56:14] [I] [TRT] ----------------------------------------------------------------
[03/24/2023-12:56:14] [V] [TRT] Plugin creator already registered - ::GridAnchor_TRT version 1
[03/24/2023-12:56:14] [V] [TRT] Plugin creator already registered - ::GridAnchorRect_TRT version 1
[03/24/2023-12:56:14] [V] [TRT] Plugin creator already registered - ::NMS_TRT version 1
[03/24/2023-12:56:14] [V] [TRT] Plugin creator already registered - ::Reorg_TRT version 1
[03/24/2023-12:56:14] [V] [TRT] Plugin creator already registered - ::Region_TRT version 1
[03/24/2023-12:56:14] [V] [TRT] Plugin creator already registered - ::Clip_TRT version 1
[03/24/2023-12:56:14] [V] [TRT] Plugin creator already registered - ::LReLU_TRT version 1
[03/24/2023-12:56:14] [V] [TRT] Plugin creator already registered - ::PriorBox_TRT version 1
[03/24/2023-12:56:14] [V] [TRT] Plugin creator already registered - ::Normalize_TRT version 1
[03/24/2023-12:56:14] [V] [TRT] Plugin creator already registered - ::ScatterND version 1
[03/24/2023-12:56:14] [V] [TRT] Plugin creator already registered - ::RPROI_TRT version 1
[03/24/2023-12:56:14] [V] [TRT] Plugin creator already registered - ::BatchedNMS_TRT version 1
[03/24/2023-12:56:14] [V] [TRT] Plugin creator already registered - ::BatchedNMSDynamic_TRT version 1
[03/24/2023-12:56:14] [V] [TRT] Plugin creator already registered - ::FlattenConcat_TRT version 1
[03/24/2023-12:56:14] [V] [TRT] Plugin creator already registered - ::CropAndResize version 1
[03/24/2023-12:56:14] [V] [TRT] Plugin creator already registered - ::DetectionLayer_TRT version 1
[03/24/2023-12:56:14] [V] [TRT] Plugin creator already registered - ::EfficientNMS_TRT version 1
[03/24/2023-12:56:14] [V] [TRT] Plugin creator already registered - ::EfficientNMS_ONNX_TRT version 1
[03/24/2023-12:56:14] [V] [TRT] Plugin creator already registered - ::EfficientNMS_TFTRT_TRT version 1
[03/24/2023-12:56:14] [V] [TRT] Plugin creator already registered - ::Proposal version 1
[03/24/2023-12:56:14] [V] [TRT] Plugin creator already registered - ::ProposalLayer_TRT version 1
[03/24/2023-12:56:14] [V] [TRT] Plugin creator already registered - ::PyramidROIAlign_TRT version 1
[03/24/2023-12:56:14] [V] [TRT] Plugin creator already registered - ::ResizeNearest_TRT version 1
[03/24/2023-12:56:14] [V] [TRT] Plugin creator already registered - ::Split version 1
[03/24/2023-12:56:14] [V] [TRT] Plugin creator already registered - ::SpecialSlice_TRT version 1
[03/24/2023-12:56:14] [V] [TRT] Plugin creator already registered - ::InstanceNormalization_TRT version 1
[03/24/2023-12:56:14] [V] [TRT] Adding network input: input with dtype: float32, dimensions: (1, 256, 180, 180)
[03/24/2023-12:56:14] [V] [TRT] Registering tensor: input for ONNX tensor: input
[03/24/2023-12:56:14] [V] [TRT] Importing initializer: model.neck.deblocks.1.0.weight
[03/24/2023-12:56:14] [V] [TRT] Importing initializer: model.neck.deblocks.1.1.weight
[03/24/2023-12:56:14] [V] [TRT] Importing initializer: model.neck.deblocks.1.1.bias
[03/24/2023-12:56:14] [V] [TRT] Importing initializer: model.neck.deblocks.1.1.running_mean
[03/24/2023-12:56:14] [V] [TRT] Importing initializer: model.neck.deblocks.1.1.running_var
[03/24/2023-12:56:14] [V] [TRT] Importing initializer: model.bbox_head.tasks.0.reg.3.weight
[03/24/2023-12:56:14] [V] [TRT] Importing initializer: model.bbox_head.tasks.0.reg.3.bias
[03/24/2023-12:56:14] [V] [TRT] Importing initializer: model.bbox_head.tasks.0.height.3.weight
[03/24/2023-12:56:14] [V] [TRT] Importing initializer: model.bbox_head.tasks.0.height.3.bias
[03/24/2023-12:56:14] [V] [TRT] Importing initializer: model.bbox_head.tasks.0.dim.3.weight
[03/24/2023-12:56:14] [V] [TRT] Importing initializer: model.bbox_head.tasks.0.dim.3.bias
[03/24/2023-12:56:14] [V] [TRT] Importing initializer: model.bbox_head.tasks.0.rot.3.weight
[03/24/2023-12:56:14] [V] [TRT] Importing initializer: model.bbox_head.tasks.0.rot.3.bias
[03/24/2023-12:56:14] [V] [TRT] Importing initializer: model.bbox_head.tasks.0.vel.3.weight
[03/24/2023-12:56:14] [V] [TRT] Importing initializer: model.bbox_head.tasks.0.vel.3.bias
[03/24/2023-12:56:14] [V] [TRT] Importing initializer: model.bbox_head.tasks.0.hm.3.weight
[03/24/2023-12:56:14] [V] [TRT] Importing initializer: model.bbox_head.tasks.0.hm.3.bias
[03/24/2023-12:56:14] [V] [TRT] Importing initializer: model.bbox_head.tasks.1.reg.3.weight
[03/24/2023-12:56:14] [V] [TRT] Importing initializer: model.bbox_head.tasks.1.reg.3.bias
[03/24/2023-12:56:14] [V] [TRT] Importing initializer: model.bbox_head.tasks.1.height.3.weight
[03/24/2023-12:56:14] [V] [TRT] Importing initializer: model.bbox_head.tasks.1.height.3.bias
[03/24/2023-12:56:14] [V] [TRT] Importing initializer: model.bbox_head.tasks.1.dim.3.weight
[03/24/2023-12:56:14] [V] [TRT] Importing initializer: model.bbox_head.tasks.1.dim.3.bias
[03/24/2023-12:56:14] [V] [TRT] Importing initializer: model.bbox_head.tasks.1.rot.3.weight
[03/24/2023-12:56:14] [V] [TRT] Importing initializer: model.bbox_head.tasks.1.rot.3.bias
[03/24/2023-12:56:14] [V] [TRT] Importing initializer: model.bbox_head.tasks.1.vel.3.weight
[03/24/2023-12:56:14] [V] [TRT] Importing initializer: model.bbox_head.tasks.1.vel.3.bias
[03/24/2023-12:56:14] [V] [TRT] Importing initializer: model.bbox_head.tasks.1.hm.3.weight
[03/24/2023-12:56:14] [V] [TRT] Importing initializer: model.bbox_head.tasks.1.hm.3.bias
[03/24/2023-12:56:14] [V] [TRT] Importing initializer: model.bbox_head.tasks.2.reg.3.weight
[03/24/2023-12:56:14] [V] [TRT] Importing initializer: model.bbox_head.tasks.2.reg.3.bias
[03/24/2023-12:56:14] [V] [TRT] Importing initializer: model.bbox_head.tasks.2.height.3.weight
[03/24/2023-12:56:14] [V] [TRT] Importing initializer: model.bbox_head.tasks.2.height.3.bias
[03/24/2023-12:56:14] [V] [TRT] Importing initializer: model.bbox_head.tasks.2.dim.3.weight
[03/24/2023-12:56:14] [V] [TRT] Importing initializer: model.bbox_head.tasks.2.dim.3.bias
[03/24/2023-12:56:14] [V] [TRT] Importing initializer: model.bbox_head.tasks.2.rot.3.weight
[03/24/2023-12:56:14] [V] [TRT] Importing initializer: model.bbox_head.tasks.2.rot.3.bias
[03/24/2023-12:56:14] [V] [TRT] Importing initializer: model.bbox_head.tasks.2.vel.3.weight
[03/24/2023-12:56:14] [V] [TRT] Importing initializer: model.bbox_head.tasks.2.vel.3.bias
[03/24/2023-12:56:14] [V] [TRT] Importing initializer: model.bbox_head.tasks.2.hm.3.weight
[03/24/2023-12:56:14] [V] [TRT] Importing initializer: model.bbox_head.tasks.2.hm.3.bias
[03/24/2023-12:56:14] [V] [TRT] Importing initializer: model.bbox_head.tasks.3.reg.3.weight
[03/24/2023-12:56:14] [V] [TRT] Importing initializer: model.bbox_head.tasks.3.reg.3.bias
[03/24/2023-12:56:14] [V] [TRT] Importing initializer: model.bbox_head.tasks.3.height.3.weight
[03/24/2023-12:56:14] [V] [TRT] Importing initializer: model.bbox_head.tasks.3.height.3.bias
[03/24/2023-12:56:14] [V] [TRT] Importing initializer: model.bbox_head.tasks.3.dim.3.weight
[03/24/2023-12:56:14] [V] [TRT] Importing initializer: model.bbox_head.tasks.3.dim.3.bias
[03/24/2023-12:56:14] [V] [TRT] Importing initializer: model.bbox_head.tasks.3.rot.3.weight
[03/24/2023-12:56:14] [V] [TRT] Importing initializer: model.bbox_head.tasks.3.rot.3.bias
[03/24/2023-12:56:14] [V] [TRT] Importing initializer: model.bbox_head.tasks.3.vel.3.weight
[03/24/2023-12:56:14] [V] [TRT] Importing initializer: model.bbox_head.tasks.3.vel.3.bias
[03/24/2023-12:56:14] [V] [TRT] Importing initializer: model.bbox_head.tasks.3.hm.3.weight
[03/24/2023-12:56:14] [V] [TRT] Importing initializer: model.bbox_head.tasks.3.hm.3.bias
[03/24/2023-12:56:14] [V] [TRT] Importing initializer: model.bbox_head.tasks.4.reg.3.weight
[03/24/2023-12:56:14] [V] [TRT] Importing initializer: model.bbox_head.tasks.4.reg.3.bias
[03/24/2023-12:56:14] [V] [TRT] Importing initializer: model.bbox_head.tasks.4.height.3.weight
[03/24/2023-12:56:14] [V] [TRT] Importing initializer: model.bbox_head.tasks.4.height.3.bias
[03/24/2023-12:56:14] [V] [TRT] Importing initializer: model.bbox_head.tasks.4.dim.3.weight
[03/24/2023-12:56:14] [V] [TRT] Importing initializer: model.bbox_head.tasks.4.dim.3.bias
[03/24/2023-12:56:14] [V] [TRT] Importing initializer: model.bbox_head.tasks.4.rot.3.weight
[03/24/2023-12:56:14] [V] [TRT] Importing initializer: model.bbox_head.tasks.4.rot.3.bias
[03/24/2023-12:56:14] [V] [TRT] Importing initializer: model.bbox_head.tasks.4.vel.3.weight
[03/24/2023-12:56:14] [V] [TRT] Importing initializer: model.bbox_head.tasks.4.vel.3.bias
[03/24/2023-12:56:14] [V] [TRT] Importing initializer: model.bbox_head.tasks.4.hm.3.weight
[03/24/2023-12:56:14] [V] [TRT] Importing initializer: model.bbox_head.tasks.4.hm.3.bias
[03/24/2023-12:56:14] [V] [TRT] Importing initializer: model.bbox_head.tasks.5.reg.3.weight
[03/24/2023-12:56:14] [V] [TRT] Importing initializer: model.bbox_head.tasks.5.reg.3.bias
[03/24/2023-12:56:14] [V] [TRT] Importing initializer: model.bbox_head.tasks.5.height.3.weight
[03/24/2023-12:56:14] [V] [TRT] Importing initializer: model.bbox_head.tasks.5.height.3.bias
[03/24/2023-12:56:14] [V] [TRT] Importing initializer: model.bbox_head.tasks.5.dim.3.weight
[03/24/2023-12:56:14] [V] [TRT] Importing initializer: model.bbox_head.tasks.5.dim.3.bias
[03/24/2023-12:56:14] [V] [TRT] Importing initializer: model.bbox_head.tasks.5.rot.3.weight
[03/24/2023-12:56:14] [V] [TRT] Importing initializer: model.bbox_head.tasks.5.rot.3.bias
[03/24/2023-12:56:14] [V] [TRT] Importing initializer: model.bbox_head.tasks.5.vel.3.weight
[03/24/2023-12:56:14] [V] [TRT] Importing initializer: model.bbox_head.tasks.5.vel.3.bias
[03/24/2023-12:56:14] [V] [TRT] Importing initializer: model.bbox_head.tasks.5.hm.3.weight
[03/24/2023-12:56:14] [V] [TRT] Importing initializer: model.bbox_head.tasks.5.hm.3.bias
[03/24/2023-12:56:14] [V] [TRT] Importing initializer: onnx::Conv_797
[03/24/2023-12:56:14] [V] [TRT] Importing initializer: onnx::Conv_798
[03/24/2023-12:56:14] [V] [TRT] Importing initializer: onnx::Conv_800
[03/24/2023-12:56:14] [V] [TRT] Importing initializer: onnx::Conv_801
[03/24/2023-12:56:14] [V] [TRT] Importing initializer: onnx::Conv_803
[03/24/2023-12:56:14] [V] [TRT] Importing initializer: onnx::Conv_804
[03/24/2023-12:56:14] [V] [TRT] Importing initializer: onnx::Conv_806
[03/24/2023-12:56:14] [V] [TRT] Importing initializer: onnx::Conv_807
[03/24/2023-12:56:14] [V] [TRT] Importing initializer: onnx::Conv_809
[03/24/2023-12:56:14] [V] [TRT] Importing initializer: onnx::Conv_810
[03/24/2023-12:56:14] [V] [TRT] Importing initializer: onnx::Conv_812
[03/24/2023-12:56:14] [V] [TRT] Importing initializer: onnx::Conv_813
[03/24/2023-12:56:14] [V] [TRT] Importing initializer: onnx::Conv_815
[03/24/2023-12:56:14] [V] [TRT] Importing initializer: onnx::Conv_816
[03/24/2023-12:56:14] [V] [TRT] Importing initializer: onnx::Conv_818
[03/24/2023-12:56:14] [V] [TRT] Importing initializer: onnx::Conv_819
[03/24/2023-12:56:14] [V] [TRT] Importing initializer: onnx::Conv_821
[03/24/2023-12:56:14] [V] [TRT] Importing initializer: onnx::Conv_822
[03/24/2023-12:56:14] [V] [TRT] Importing initializer: onnx::Conv_824
[03/24/2023-12:56:14] [V] [TRT] Importing initializer: onnx::Conv_825
[03/24/2023-12:56:14] [V] [TRT] Importing initializer: onnx::Conv_827
[03/24/2023-12:56:14] [V] [TRT] Importing initializer: onnx::Conv_828
[03/24/2023-12:56:14] [V] [TRT] Importing initializer: onnx::Conv_830
[03/24/2023-12:56:14] [V] [TRT] Importing initializer: onnx::Conv_831
[03/24/2023-12:56:14] [V] [TRT] Importing initializer: onnx::Conv_833
[03/24/2023-12:56:14] [V] [TRT] Importing initializer: onnx::Conv_834
[03/24/2023-12:56:14] [V] [TRT] Importing initializer: onnx::Conv_836
[03/24/2023-12:56:14] [V] [TRT] Importing initializer: onnx::Conv_837
[03/24/2023-12:56:14] [V] [TRT] Importing initializer: onnx::Conv_839
[03/24/2023-12:56:14] [V] [TRT] Importing initializer: onnx::Conv_840
[03/24/2023-12:56:14] [V] [TRT] Importing initializer: onnx::Conv_842
[03/24/2023-12:56:14] [V] [TRT] Importing initializer: onnx::Conv_843
[03/24/2023-12:56:14] [V] [TRT] Importing initializer: onnx::Conv_845
[03/24/2023-12:56:14] [V] [TRT] Importing initializer: onnx::Conv_846
[03/24/2023-12:56:14] [V] [TRT] Importing initializer: onnx::Conv_848
[03/24/2023-12:56:14] [V] [TRT] Importing initializer: onnx::Conv_849
[03/24/2023-12:56:14] [V] [TRT] Importing initializer: onnx::Conv_851
[03/24/2023-12:56:14] [V] [TRT] Importing initializer: onnx::Conv_852
[03/24/2023-12:56:14] [V] [TRT] Importing initializer: onnx::Conv_854
[03/24/2023-12:56:14] [V] [TRT] Importing initializer: onnx::Conv_855
[03/24/2023-12:56:14] [V] [TRT] Importing initializer: onnx::Conv_857
[03/24/2023-12:56:14] [V] [TRT] Importing initializer: onnx::Conv_858
[03/24/2023-12:56:14] [V] [TRT] Importing initializer: onnx::Conv_860
[03/24/2023-12:56:14] [V] [TRT] Importing initializer: onnx::Conv_861
[03/24/2023-12:56:14] [V] [TRT] Importing initializer: onnx::Conv_863
[03/24/2023-12:56:14] [V] [TRT] Importing initializer: onnx::Conv_864
[03/24/2023-12:56:14] [V] [TRT] Importing initializer: onnx::Conv_866
[03/24/2023-12:56:14] [V] [TRT] Importing initializer: onnx::Conv_867
[03/24/2023-12:56:14] [V] [TRT] Importing initializer: onnx::Conv_869
[03/24/2023-12:56:14] [V] [TRT] Importing initializer: onnx::Conv_870
[03/24/2023-12:56:14] [V] [TRT] Importing initializer: onnx::Conv_872
[03/24/2023-12:56:14] [V] [TRT] Importing initializer: onnx::Conv_873
[03/24/2023-12:56:14] [V] [TRT] Importing initializer: onnx::Conv_875
[03/24/2023-12:56:14] [V] [TRT] Importing initializer: onnx::Conv_876
[03/24/2023-12:56:14] [V] [TRT] Importing initializer: onnx::Conv_878
[03/24/2023-12:56:14] [V] [TRT] Importing initializer: onnx::Conv_879
[03/24/2023-12:56:14] [V] [TRT] Importing initializer: onnx::Conv_881
[03/24/2023-12:56:14] [V] [TRT] Importing initializer: onnx::Conv_882
[03/24/2023-12:56:14] [V] [TRT] Importing initializer: onnx::Conv_884
[03/24/2023-12:56:14] [V] [TRT] Importing initializer: onnx::Conv_885
[03/24/2023-12:56:14] [V] [TRT] Importing initializer: onnx::Conv_887
[03/24/2023-12:56:14] [V] [TRT] Importing initializer: onnx::Conv_888
[03/24/2023-12:56:14] [V] [TRT] Importing initializer: onnx::Conv_890
[03/24/2023-12:56:14] [V] [TRT] Importing initializer: onnx::Conv_891
[03/24/2023-12:56:14] [V] [TRT] Importing initializer: onnx::Conv_893
[03/24/2023-12:56:14] [V] [TRT] Importing initializer: onnx::Conv_894
[03/24/2023-12:56:14] [V] [TRT] Importing initializer: onnx::Conv_896
[03/24/2023-12:56:14] [V] [TRT] Importing initializer: onnx::Conv_897
[03/24/2023-12:56:14] [V] [TRT] Importing initializer: onnx::Conv_899
[03/24/2023-12:56:14] [V] [TRT] Importing initializer: onnx::Conv_900
[03/24/2023-12:56:14] [V] [TRT] Importing initializer: onnx::Conv_902
[03/24/2023-12:56:14] [V] [TRT] Importing initializer: onnx::Conv_903
[03/24/2023-12:56:14] [V] [TRT] Importing initializer: onnx::Conv_905
[03/24/2023-12:56:14] [V] [TRT] Importing initializer: onnx::Conv_906
[03/24/2023-12:56:14] [V] [TRT] Importing initializer: onnx::Conv_908
[03/24/2023-12:56:14] [V] [TRT] Importing initializer: onnx::Conv_909
[03/24/2023-12:56:14] [V] [TRT] Importing initializer: onnx::Conv_911
[03/24/2023-12:56:14] [V] [TRT] Importing initializer: onnx::Conv_912
[03/24/2023-12:56:14] [V] [TRT] Importing initializer: onnx::Conv_914
[03/24/2023-12:56:14] [V] [TRT] Importing initializer: onnx::Conv_915
[03/24/2023-12:56:14] [V] [TRT] Importing initializer: onnx::Conv_917
[03/24/2023-12:56:14] [V] [TRT] Importing initializer: onnx::Conv_918
[03/24/2023-12:56:14] [V] [TRT] Importing initializer: onnx::Conv_920
[03/24/2023-12:56:14] [V] [TRT] Importing initializer: onnx::Conv_921
[03/24/2023-12:56:14] [V] [TRT] Importing initializer: onnx::Conv_923
[03/24/2023-12:56:14] [V] [TRT] Importing initializer: onnx::Conv_924
[03/24/2023-12:56:14] [V] [TRT] Importing initializer: onnx::Conv_926
[03/24/2023-12:56:14] [V] [TRT] Importing initializer: onnx::Conv_927
[03/24/2023-12:56:14] [V] [TRT] Importing initializer: onnx::Conv_929
[03/24/2023-12:56:14] [V] [TRT] Importing initializer: onnx::Conv_930
[03/24/2023-12:56:14] [V] [TRT] Importing initializer: onnx::Conv_932
[03/24/2023-12:56:14] [V] [TRT] Importing initializer: onnx::Conv_933
[03/24/2023-12:56:14] [V] [TRT] Importing initializer: onnx::Conv_935
[03/24/2023-12:56:14] [V] [TRT] Importing initializer: onnx::Conv_936
[03/24/2023-12:56:14] [V] [TRT] Importing initializer: onnx::Conv_938
[03/24/2023-12:56:14] [V] [TRT] Importing initializer: onnx::Conv_939
[03/24/2023-12:56:14] [V] [TRT] Importing initializer: onnx::Conv_941
[03/24/2023-12:56:14] [V] [TRT] Importing initializer: onnx::Conv_942
[03/24/2023-12:56:14] [V] [TRT] Importing initializer: onnx::Conv_944
[03/24/2023-12:56:14] [V] [TRT] Importing initializer: onnx::Conv_945
[03/24/2023-12:56:14] [V] [TRT] Parsing node: Conv_15 [Conv]
[03/24/2023-12:56:14] [V] [TRT] Searching for input: input
[03/24/2023-12:56:14] [V] [TRT] Searching for input: onnx::Conv_797
[03/24/2023-12:56:14] [V] [TRT] Searching for input: onnx::Conv_798
[03/24/2023-12:56:14] [V] [TRT] Conv_15 [Conv] inputs: [input -> (1, 256, 180, 180)[FLOAT]], [onnx::Conv_797 -> (128, 256, 3, 3)[FLOAT]], [onnx::Conv_798 -> (128)[FLOAT]], 
[03/24/2023-12:56:14] [V] [TRT] Convolution input dimensions: (1, 256, 180, 180)
[03/24/2023-12:56:14] [V] [TRT] Registering layer: Conv_15 for ONNX node: Conv_15
[03/24/2023-12:56:14] [V] [TRT] Using kernel: (3, 3), strides: (1, 1), prepadding: (1, 1), postpadding: (1, 1), dilations: (1, 1), numOutputs: 128
[03/24/2023-12:56:14] [V] [TRT] Convolution output dimensions: (1, 128, 180, 180)
[03/24/2023-12:56:14] [V] [TRT] Registering tensor: input.8 for ONNX tensor: input.8
[03/24/2023-12:56:14] [V] [TRT] Conv_15 [Conv] outputs: [input.8 -> (1, 128, 180, 180)[FLOAT]], 
[03/24/2023-12:56:14] [V] [TRT] Parsing node: Relu_16 [Relu]
[03/24/2023-12:56:14] [V] [TRT] Searching for input: input.8
[03/24/2023-12:56:14] [V] [TRT] Relu_16 [Relu] inputs: [input.8 -> (1, 128, 180, 180)[FLOAT]], 
[03/24/2023-12:56:14] [V] [TRT] Registering layer: Relu_16 for ONNX node: Relu_16
[03/24/2023-12:56:14] [V] [TRT] Registering tensor: input.12 for ONNX tensor: input.12
[03/24/2023-12:56:14] [V] [TRT] Relu_16 [Relu] outputs: [input.12 -> (1, 128, 180, 180)[FLOAT]], 
[03/24/2023-12:56:14] [V] [TRT] Parsing node: Conv_17 [Conv]
[03/24/2023-12:56:14] [V] [TRT] Searching for input: input.12
[03/24/2023-12:56:14] [V] [TRT] Searching for input: onnx::Conv_800
[03/24/2023-12:56:14] [V] [TRT] Searching for input: onnx::Conv_801
[03/24/2023-12:56:14] [V] [TRT] Conv_17 [Conv] inputs: [input.12 -> (1, 128, 180, 180)[FLOAT]], [onnx::Conv_800 -> (128, 128, 3, 3)[FLOAT]], [onnx::Conv_801 -> (128)[FLOAT]], 
[03/24/2023-12:56:14] [V] [TRT] Convolution input dimensions: (1, 128, 180, 180)
[03/24/2023-12:56:14] [V] [TRT] Registering layer: Conv_17 for ONNX node: Conv_17
[03/24/2023-12:56:14] [V] [TRT] Using kernel: (3, 3), strides: (1, 1), prepadding: (1, 1), postpadding: (1, 1), dilations: (1, 1), numOutputs: 128
[03/24/2023-12:56:14] [V] [TRT] Convolution output dimensions: (1, 128, 180, 180)
[03/24/2023-12:56:14] [V] [TRT] Registering tensor: input.20 for ONNX tensor: input.20
[03/24/2023-12:56:14] [V] [TRT] Conv_17 [Conv] outputs: [input.20 -> (1, 128, 180, 180)[FLOAT]], 
[03/24/2023-12:56:14] [V] [TRT] Parsing node: Relu_18 [Relu]
[03/24/2023-12:56:14] [V] [TRT] Searching for input: input.20
[03/24/2023-12:56:14] [V] [TRT] Relu_18 [Relu] inputs: [input.20 -> (1, 128, 180, 180)[FLOAT]], 
[03/24/2023-12:56:14] [V] [TRT] Registering layer: Relu_18 for ONNX node: Relu_18
[03/24/2023-12:56:14] [V] [TRT] Registering tensor: input.24 for ONNX tensor: input.24
[03/24/2023-12:56:14] [V] [TRT] Relu_18 [Relu] outputs: [input.24 -> (1, 128, 180, 180)[FLOAT]], 
[03/24/2023-12:56:14] [V] [TRT] Parsing node: Conv_19 [Conv]
[03/24/2023-12:56:14] [V] [TRT] Searching for input: input.24
[03/24/2023-12:56:14] [V] [TRT] Searching for input: onnx::Conv_803
[03/24/2023-12:56:14] [V] [TRT] Searching for input: onnx::Conv_804
[03/24/2023-12:56:14] [V] [TRT] Conv_19 [Conv] inputs: [input.24 -> (1, 128, 180, 180)[FLOAT]], [onnx::Conv_803 -> (128, 128, 3, 3)[FLOAT]], [onnx::Conv_804 -> (128)[FLOAT]], 
[03/24/2023-12:56:14] [V] [TRT] Convolution input dimensions: (1, 128, 180, 180)
[03/24/2023-12:56:14] [V] [TRT] Registering layer: Conv_19 for ONNX node: Conv_19
[03/24/2023-12:56:14] [V] [TRT] Using kernel: (3, 3), strides: (1, 1), prepadding: (1, 1), postpadding: (1, 1), dilations: (1, 1), numOutputs: 128
[03/24/2023-12:56:14] [V] [TRT] Convolution output dimensions: (1, 128, 180, 180)
[03/24/2023-12:56:14] [V] [TRT] Registering tensor: input.32 for ONNX tensor: input.32
[03/24/2023-12:56:14] [V] [TRT] Conv_19 [Conv] outputs: [input.32 -> (1, 128, 180, 180)[FLOAT]], 
[03/24/2023-12:56:14] [V] [TRT] Parsing node: Relu_20 [Relu]
[03/24/2023-12:56:14] [V] [TRT] Searching for input: input.32
[03/24/2023-12:56:14] [V] [TRT] Relu_20 [Relu] inputs: [input.32 -> (1, 128, 180, 180)[FLOAT]], 
[03/24/2023-12:56:14] [V] [TRT] Registering layer: Relu_20 for ONNX node: Relu_20
[03/24/2023-12:56:14] [V] [TRT] Registering tensor: input.36 for ONNX tensor: input.36
[03/24/2023-12:56:14] [V] [TRT] Relu_20 [Relu] outputs: [input.36 -> (1, 128, 180, 180)[FLOAT]], 
[03/24/2023-12:56:14] [V] [TRT] Parsing node: Conv_21 [Conv]
[03/24/2023-12:56:14] [V] [TRT] Searching for input: input.36
[03/24/2023-12:56:14] [V] [TRT] Searching for input: onnx::Conv_806
[03/24/2023-12:56:14] [V] [TRT] Searching for input: onnx::Conv_807
[03/24/2023-12:56:14] [V] [TRT] Conv_21 [Conv] inputs: [input.36 -> (1, 128, 180, 180)[FLOAT]], [onnx::Conv_806 -> (128, 128, 3, 3)[FLOAT]], [onnx::Conv_807 -> (128)[FLOAT]], 
[03/24/2023-12:56:14] [V] [TRT] Convolution input dimensions: (1, 128, 180, 180)
[03/24/2023-12:56:14] [V] [TRT] Registering layer: Conv_21 for ONNX node: Conv_21
[03/24/2023-12:56:14] [V] [TRT] Using kernel: (3, 3), strides: (1, 1), prepadding: (1, 1), postpadding: (1, 1), dilations: (1, 1), numOutputs: 128
[03/24/2023-12:56:14] [V] [TRT] Convolution output dimensions: (1, 128, 180, 180)
[03/24/2023-12:56:14] [V] [TRT] Registering tensor: input.44 for ONNX tensor: input.44
[03/24/2023-12:56:14] [V] [TRT] Conv_21 [Conv] outputs: [input.44 -> (1, 128, 180, 180)[FLOAT]], 
[03/24/2023-12:56:14] [V] [TRT] Parsing node: Relu_22 [Relu]
[03/24/2023-12:56:14] [V] [TRT] Searching for input: input.44
[03/24/2023-12:56:14] [V] [TRT] Relu_22 [Relu] inputs: [input.44 -> (1, 128, 180, 180)[FLOAT]], 
[03/24/2023-12:56:14] [V] [TRT] Registering layer: Relu_22 for ONNX node: Relu_22
[03/24/2023-12:56:14] [V] [TRT] Registering tensor: input.48 for ONNX tensor: input.48
[03/24/2023-12:56:14] [V] [TRT] Relu_22 [Relu] outputs: [input.48 -> (1, 128, 180, 180)[FLOAT]], 
[03/24/2023-12:56:14] [V] [TRT] Parsing node: Conv_23 [Conv]
[03/24/2023-12:56:14] [V] [TRT] Searching for input: input.48
[03/24/2023-12:56:14] [V] [TRT] Searching for input: onnx::Conv_809
[03/24/2023-12:56:14] [V] [TRT] Searching for input: onnx::Conv_810
[03/24/2023-12:56:14] [V] [TRT] Conv_23 [Conv] inputs: [input.48 -> (1, 128, 180, 180)[FLOAT]], [onnx::Conv_809 -> (128, 128, 3, 3)[FLOAT]], [onnx::Conv_810 -> (128)[FLOAT]], 
[03/24/2023-12:56:14] [V] [TRT] Convolution input dimensions: (1, 128, 180, 180)
[03/24/2023-12:56:14] [V] [TRT] Registering layer: Conv_23 for ONNX node: Conv_23
[03/24/2023-12:56:14] [V] [TRT] Using kernel: (3, 3), strides: (1, 1), prepadding: (1, 1), postpadding: (1, 1), dilations: (1, 1), numOutputs: 128
[03/24/2023-12:56:14] [V] [TRT] Convolution output dimensions: (1, 128, 180, 180)
[03/24/2023-12:56:14] [V] [TRT] Registering tensor: input.56 for ONNX tensor: input.56
[03/24/2023-12:56:14] [V] [TRT] Conv_23 [Conv] outputs: [input.56 -> (1, 128, 180, 180)[FLOAT]], 
[03/24/2023-12:56:14] [V] [TRT] Parsing node: Relu_24 [Relu]
[03/24/2023-12:56:14] [V] [TRT] Searching for input: input.56
[03/24/2023-12:56:14] [V] [TRT] Relu_24 [Relu] inputs: [input.56 -> (1, 128, 180, 180)[FLOAT]], 
[03/24/2023-12:56:14] [V] [TRT] Registering layer: Relu_24 for ONNX node: Relu_24
[03/24/2023-12:56:14] [V] [TRT] Registering tensor: input.60 for ONNX tensor: input.60
[03/24/2023-12:56:14] [V] [TRT] Relu_24 [Relu] outputs: [input.60 -> (1, 128, 180, 180)[FLOAT]], 
[03/24/2023-12:56:14] [V] [TRT] Parsing node: Conv_25 [Conv]
[03/24/2023-12:56:14] [V] [TRT] Searching for input: input.60
[03/24/2023-12:56:14] [V] [TRT] Searching for input: onnx::Conv_812
[03/24/2023-12:56:14] [V] [TRT] Searching for input: onnx::Conv_813
[03/24/2023-12:56:14] [V] [TRT] Conv_25 [Conv] inputs: [input.60 -> (1, 128, 180, 180)[FLOAT]], [onnx::Conv_812 -> (128, 128, 3, 3)[FLOAT]], [onnx::Conv_813 -> (128)[FLOAT]], 
[03/24/2023-12:56:14] [V] [TRT] Convolution input dimensions: (1, 128, 180, 180)
[03/24/2023-12:56:14] [V] [TRT] Registering layer: Conv_25 for ONNX node: Conv_25
[03/24/2023-12:56:14] [V] [TRT] Using kernel: (3, 3), strides: (1, 1), prepadding: (1, 1), postpadding: (1, 1), dilations: (1, 1), numOutputs: 128
[03/24/2023-12:56:14] [V] [TRT] Convolution output dimensions: (1, 128, 180, 180)
[03/24/2023-12:56:14] [V] [TRT] Registering tensor: input.68 for ONNX tensor: input.68
[03/24/2023-12:56:14] [V] [TRT] Conv_25 [Conv] outputs: [input.68 -> (1, 128, 180, 180)[FLOAT]], 
[03/24/2023-12:56:14] [V] [TRT] Parsing node: Relu_26 [Relu]
[03/24/2023-12:56:14] [V] [TRT] Searching for input: input.68
[03/24/2023-12:56:14] [V] [TRT] Relu_26 [Relu] inputs: [input.68 -> (1, 128, 180, 180)[FLOAT]], 
[03/24/2023-12:56:14] [V] [TRT] Registering layer: Relu_26 for ONNX node: Relu_26
[03/24/2023-12:56:14] [V] [TRT] Registering tensor: input.72 for ONNX tensor: input.72
[03/24/2023-12:56:14] [V] [TRT] Relu_26 [Relu] outputs: [input.72 -> (1, 128, 180, 180)[FLOAT]], 
[03/24/2023-12:56:14] [V] [TRT] Parsing node: Conv_27 [Conv]
[03/24/2023-12:56:14] [V] [TRT] Searching for input: input.72
[03/24/2023-12:56:14] [V] [TRT] Searching for input: onnx::Conv_815
[03/24/2023-12:56:14] [V] [TRT] Searching for input: onnx::Conv_816
[03/24/2023-12:56:14] [V] [TRT] Conv_27 [Conv] inputs: [input.72 -> (1, 128, 180, 180)[FLOAT]], [onnx::Conv_815 -> (256, 128, 1, 1)[FLOAT]], [onnx::Conv_816 -> (256)[FLOAT]], 
[03/24/2023-12:56:14] [V] [TRT] Convolution input dimensions: (1, 128, 180, 180)
[03/24/2023-12:56:14] [V] [TRT] Registering layer: Conv_27 for ONNX node: Conv_27
[03/24/2023-12:56:14] [V] [TRT] Using kernel: (1, 1), strides: (1, 1), prepadding: (0, 0), postpadding: (0, 0), dilations: (1, 1), numOutputs: 256
[03/24/2023-12:56:14] [V] [TRT] Convolution output dimensions: (1, 256, 180, 180)
[03/24/2023-12:56:14] [V] [TRT] Registering tensor: input.80 for ONNX tensor: input.80
[03/24/2023-12:56:14] [V] [TRT] Conv_27 [Conv] outputs: [input.80 -> (1, 256, 180, 180)[FLOAT]], 
[03/24/2023-12:56:14] [V] [TRT] Parsing node: Relu_28 [Relu]
[03/24/2023-12:56:14] [V] [TRT] Searching for input: input.80
[03/24/2023-12:56:14] [V] [TRT] Relu_28 [Relu] inputs: [input.80 -> (1, 256, 180, 180)[FLOAT]], 
[03/24/2023-12:56:14] [V] [TRT] Registering layer: Relu_28 for ONNX node: Relu_28
[03/24/2023-12:56:14] [V] [TRT] Registering tensor: onnx::Concat_602 for ONNX tensor: onnx::Concat_602
[03/24/2023-12:56:14] [V] [TRT] Relu_28 [Relu] outputs: [onnx::Concat_602 -> (1, 256, 180, 180)[FLOAT]], 
[03/24/2023-12:56:14] [V] [TRT] Parsing node: Conv_44 [Conv]
[03/24/2023-12:56:14] [V] [TRT] Searching for input: input.72
[03/24/2023-12:56:14] [V] [TRT] Searching for input: onnx::Conv_818
[03/24/2023-12:56:14] [V] [TRT] Searching for input: onnx::Conv_819
[03/24/2023-12:56:14] [V] [TRT] Conv_44 [Conv] inputs: [input.72 -> (1, 128, 180, 180)[FLOAT]], [onnx::Conv_818 -> (256, 128, 3, 3)[FLOAT]], [onnx::Conv_819 -> (256)[FLOAT]], 
[03/24/2023-12:56:14] [V] [TRT] Convolution input dimensions: (1, 128, 180, 180)
[03/24/2023-12:56:14] [V] [TRT] Registering layer: Conv_44 for ONNX node: Conv_44
[03/24/2023-12:56:14] [V] [TRT] Using kernel: (3, 3), strides: (2, 2), prepadding: (1, 1), postpadding: (1, 1), dilations: (1, 1), numOutputs: 256
[03/24/2023-12:56:14] [V] [TRT] Convolution output dimensions: (1, 256, 90, 90)
[03/24/2023-12:56:14] [V] [TRT] Registering tensor: input.92 for ONNX tensor: input.92
[03/24/2023-12:56:14] [V] [TRT] Conv_44 [Conv] outputs: [input.92 -> (1, 256, 90, 90)[FLOAT]], 
[03/24/2023-12:56:14] [V] [TRT] Parsing node: Relu_45 [Relu]
[03/24/2023-12:56:14] [V] [TRT] Searching for input: input.92
[03/24/2023-12:56:14] [V] [TRT] Relu_45 [Relu] inputs: [input.92 -> (1, 256, 90, 90)[FLOAT]], 
[03/24/2023-12:56:14] [V] [TRT] Registering layer: Relu_45 for ONNX node: Relu_45
[03/24/2023-12:56:14] [V] [TRT] Registering tensor: input.96 for ONNX tensor: input.96
[03/24/2023-12:56:14] [V] [TRT] Relu_45 [Relu] outputs: [input.96 -> (1, 256, 90, 90)[FLOAT]], 
[03/24/2023-12:56:14] [V] [TRT] Parsing node: Conv_46 [Conv]
[03/24/2023-12:56:14] [V] [TRT] Searching for input: input.96
[03/24/2023-12:56:14] [V] [TRT] Searching for input: onnx::Conv_821
[03/24/2023-12:56:14] [V] [TRT] Searching for input: onnx::Conv_822
[03/24/2023-12:56:14] [V] [TRT] Conv_46 [Conv] inputs: [input.96 -> (1, 256, 90, 90)[FLOAT]], [onnx::Conv_821 -> (256, 256, 3, 3)[FLOAT]], [onnx::Conv_822 -> (256)[FLOAT]], 
[03/24/2023-12:56:14] [V] [TRT] Convolution input dimensions: (1, 256, 90, 90)
[03/24/2023-12:56:14] [V] [TRT] Registering layer: Conv_46 for ONNX node: Conv_46
[03/24/2023-12:56:14] [V] [TRT] Using kernel: (3, 3), strides: (1, 1), prepadding: (1, 1), postpadding: (1, 1), dilations: (1, 1), numOutputs: 256
[03/24/2023-12:56:14] [V] [TRT] Convolution output dimensions: (1, 256, 90, 90)
[03/24/2023-12:56:14] [V] [TRT] Registering tensor: input.104 for ONNX tensor: input.104
[03/24/2023-12:56:14] [V] [TRT] Conv_46 [Conv] outputs: [input.104 -> (1, 256, 90, 90)[FLOAT]], 
[03/24/2023-12:56:14] [V] [TRT] Parsing node: Relu_47 [Relu]
[03/24/2023-12:56:14] [V] [TRT] Searching for input: input.104
[03/24/2023-12:56:14] [V] [TRT] Relu_47 [Relu] inputs: [input.104 -> (1, 256, 90, 90)[FLOAT]], 
[03/24/2023-12:56:14] [V] [TRT] Registering layer: Relu_47 for ONNX node: Relu_47
[03/24/2023-12:56:14] [V] [TRT] Registering tensor: input.108 for ONNX tensor: input.108
[03/24/2023-12:56:14] [V] [TRT] Relu_47 [Relu] outputs: [input.108 -> (1, 256, 90, 90)[FLOAT]], 
[03/24/2023-12:56:14] [V] [TRT] Parsing node: Conv_48 [Conv]
[03/24/2023-12:56:14] [V] [TRT] Searching for input: input.108
[03/24/2023-12:56:14] [V] [TRT] Searching for input: onnx::Conv_824
[03/24/2023-12:56:14] [V] [TRT] Searching for input: onnx::Conv_825
[03/24/2023-12:56:14] [V] [TRT] Conv_48 [Conv] inputs: [input.108 -> (1, 256, 90, 90)[FLOAT]], [onnx::Conv_824 -> (256, 256, 3, 3)[FLOAT]], [onnx::Conv_825 -> (256)[FLOAT]], 
[03/24/2023-12:56:14] [V] [TRT] Convolution input dimensions: (1, 256, 90, 90)
[03/24/2023-12:56:14] [V] [TRT] Registering layer: Conv_48 for ONNX node: Conv_48
[03/24/2023-12:56:14] [V] [TRT] Using kernel: (3, 3), strides: (1, 1), prepadding: (1, 1), postpadding: (1, 1), dilations: (1, 1), numOutputs: 256
[03/24/2023-12:56:14] [V] [TRT] Convolution output dimensions: (1, 256, 90, 90)
[03/24/2023-12:56:14] [V] [TRT] Registering tensor: input.116 for ONNX tensor: input.116
[03/24/2023-12:56:14] [V] [TRT] Conv_48 [Conv] outputs: [input.116 -> (1, 256, 90, 90)[FLOAT]], 
[03/24/2023-12:56:14] [V] [TRT] Parsing node: Relu_49 [Relu]
[03/24/2023-12:56:14] [V] [TRT] Searching for input: input.116
[03/24/2023-12:56:14] [V] [TRT] Relu_49 [Relu] inputs: [input.116 -> (1, 256, 90, 90)[FLOAT]], 
[03/24/2023-12:56:14] [V] [TRT] Registering layer: Relu_49 for ONNX node: Relu_49
[03/24/2023-12:56:14] [V] [TRT] Registering tensor: input.120 for ONNX tensor: input.120
[03/24/2023-12:56:14] [V] [TRT] Relu_49 [Relu] outputs: [input.120 -> (1, 256, 90, 90)[FLOAT]], 
[03/24/2023-12:56:14] [V] [TRT] Parsing node: Conv_50 [Conv]
[03/24/2023-12:56:14] [V] [TRT] Searching for input: input.120
[03/24/2023-12:56:14] [V] [TRT] Searching for input: onnx::Conv_827
[03/24/2023-12:56:14] [V] [TRT] Searching for input: onnx::Conv_828
[03/24/2023-12:56:14] [V] [TRT] Conv_50 [Conv] inputs: [input.120 -> (1, 256, 90, 90)[FLOAT]], [onnx::Conv_827 -> (256, 256, 3, 3)[FLOAT]], [onnx::Conv_828 -> (256)[FLOAT]], 
[03/24/2023-12:56:14] [V] [TRT] Convolution input dimensions: (1, 256, 90, 90)
[03/24/2023-12:56:14] [V] [TRT] Registering layer: Conv_50 for ONNX node: Conv_50
[03/24/2023-12:56:14] [V] [TRT] Using kernel: (3, 3), strides: (1, 1), prepadding: (1, 1), postpadding: (1, 1), dilations: (1, 1), numOutputs: 256
[03/24/2023-12:56:14] [V] [TRT] Convolution output dimensions: (1, 256, 90, 90)
[03/24/2023-12:56:14] [V] [TRT] Registering tensor: input.128 for ONNX tensor: input.128
[03/24/2023-12:56:14] [V] [TRT] Conv_50 [Conv] outputs: [input.128 -> (1, 256, 90, 90)[FLOAT]], 
[03/24/2023-12:56:14] [V] [TRT] Parsing node: Relu_51 [Relu]
[03/24/2023-12:56:14] [V] [TRT] Searching for input: input.128
[03/24/2023-12:56:14] [V] [TRT] Relu_51 [Relu] inputs: [input.128 -> (1, 256, 90, 90)[FLOAT]], 
[03/24/2023-12:56:14] [V] [TRT] Registering layer: Relu_51 for ONNX node: Relu_51
[03/24/2023-12:56:14] [V] [TRT] Registering tensor: input.132 for ONNX tensor: input.132
[03/24/2023-12:56:14] [V] [TRT] Relu_51 [Relu] outputs: [input.132 -> (1, 256, 90, 90)[FLOAT]], 
[03/24/2023-12:56:14] [V] [TRT] Parsing node: Conv_52 [Conv]
[03/24/2023-12:56:14] [V] [TRT] Searching for input: input.132
[03/24/2023-12:56:14] [V] [TRT] Searching for input: onnx::Conv_830
[03/24/2023-12:56:14] [V] [TRT] Searching for input: onnx::Conv_831
[03/24/2023-12:56:14] [V] [TRT] Conv_52 [Conv] inputs: [input.132 -> (1, 256, 90, 90)[FLOAT]], [onnx::Conv_830 -> (256, 256, 3, 3)[FLOAT]], [onnx::Conv_831 -> (256)[FLOAT]], 
[03/24/2023-12:56:14] [V] [TRT] Convolution input dimensions: (1, 256, 90, 90)
[03/24/2023-12:56:14] [V] [TRT] Registering layer: Conv_52 for ONNX node: Conv_52
[03/24/2023-12:56:14] [V] [TRT] Using kernel: (3, 3), strides: (1, 1), prepadding: (1, 1), postpadding: (1, 1), dilations: (1, 1), numOutputs: 256
[03/24/2023-12:56:14] [V] [TRT] Convolution output dimensions: (1, 256, 90, 90)
[03/24/2023-12:56:14] [V] [TRT] Registering tensor: input.140 for ONNX tensor: input.140
[03/24/2023-12:56:14] [V] [TRT] Conv_52 [Conv] outputs: [input.140 -> (1, 256, 90, 90)[FLOAT]], 
[03/24/2023-12:56:14] [V] [TRT] Parsing node: Relu_53 [Relu]
[03/24/2023-12:56:14] [V] [TRT] Searching for input: input.140
[03/24/2023-12:56:14] [V] [TRT] Relu_53 [Relu] inputs: [input.140 -> (1, 256, 90, 90)[FLOAT]], 
[03/24/2023-12:56:14] [V] [TRT] Registering layer: Relu_53 for ONNX node: Relu_53
[03/24/2023-12:56:14] [V] [TRT] Registering tensor: input.144 for ONNX tensor: input.144
[03/24/2023-12:56:14] [V] [TRT] Relu_53 [Relu] outputs: [input.144 -> (1, 256, 90, 90)[FLOAT]], 
[03/24/2023-12:56:14] [V] [TRT] Parsing node: Conv_54 [Conv]
[03/24/2023-12:56:14] [V] [TRT] Searching for input: input.144
[03/24/2023-12:56:14] [V] [TRT] Searching for input: onnx::Conv_833
[03/24/2023-12:56:14] [V] [TRT] Searching for input: onnx::Conv_834
[03/24/2023-12:56:14] [V] [TRT] Conv_54 [Conv] inputs: [input.144 -> (1, 256, 90, 90)[FLOAT]], [onnx::Conv_833 -> (256, 256, 3, 3)[FLOAT]], [onnx::Conv_834 -> (256)[FLOAT]], 
[03/24/2023-12:56:14] [V] [TRT] Convolution input dimensions: (1, 256, 90, 90)
[03/24/2023-12:56:14] [V] [TRT] Registering layer: Conv_54 for ONNX node: Conv_54
[03/24/2023-12:56:14] [V] [TRT] Using kernel: (3, 3), strides: (1, 1), prepadding: (1, 1), postpadding: (1, 1), dilations: (1, 1), numOutputs: 256
[03/24/2023-12:56:14] [V] [TRT] Convolution output dimensions: (1, 256, 90, 90)
[03/24/2023-12:56:14] [V] [TRT] Registering tensor: input.152 for ONNX tensor: input.152
[03/24/2023-12:56:14] [V] [TRT] Conv_54 [Conv] outputs: [input.152 -> (1, 256, 90, 90)[FLOAT]], 
[03/24/2023-12:56:14] [V] [TRT] Parsing node: Relu_55 [Relu]
[03/24/2023-12:56:14] [V] [TRT] Searching for input: input.152
[03/24/2023-12:56:14] [V] [TRT] Relu_55 [Relu] inputs: [input.152 -> (1, 256, 90, 90)[FLOAT]], 
[03/24/2023-12:56:14] [V] [TRT] Registering layer: Relu_55 for ONNX node: Relu_55
[03/24/2023-12:56:14] [V] [TRT] Registering tensor: onnx::ConvTranspose_644 for ONNX tensor: onnx::ConvTranspose_644
[03/24/2023-12:56:14] [V] [TRT] Relu_55 [Relu] outputs: [onnx::ConvTranspose_644 -> (1, 256, 90, 90)[FLOAT]], 
[03/24/2023-12:56:14] [V] [TRT] Parsing node: ConvTranspose_56 [ConvTranspose]
[03/24/2023-12:56:14] [V] [TRT] Searching for input: onnx::ConvTranspose_644
[03/24/2023-12:56:14] [V] [TRT] Searching for input: model.neck.deblocks.1.0.weight
[03/24/2023-12:56:14] [V] [TRT] ConvTranspose_56 [ConvTranspose] inputs: [onnx::ConvTranspose_644 -> (1, 256, 90, 90)[FLOAT]], [model.neck.deblocks.1.0.weight -> (256, 256, 2, 2)[FLOAT]], 
[03/24/2023-12:56:14] [V] [TRT] Running deconvolution with: 
Padding mode: NOTSET
Pre-padding: (0, 0)
Post-padding: (0, 0)
[03/24/2023-12:56:14] [V] [TRT] Registering layer: ConvTranspose_56 for ONNX node: ConvTranspose_56
[03/24/2023-12:56:14] [V] [TRT] Registering tensor: input.156 for ONNX tensor: input.156
[03/24/2023-12:56:14] [V] [TRT] ConvTranspose_56 [ConvTranspose] outputs: [input.156 -> (1, 256, 180, 180)[FLOAT]], 
[03/24/2023-12:56:14] [V] [TRT] Parsing node: BatchNormalization_57 [BatchNormalization]
[03/24/2023-12:56:14] [V] [TRT] Searching for input: input.156
[03/24/2023-12:56:14] [V] [TRT] Searching for input: model.neck.deblocks.1.1.weight
[03/24/2023-12:56:14] [V] [TRT] Searching for input: model.neck.deblocks.1.1.bias
[03/24/2023-12:56:14] [V] [TRT] Searching for input: model.neck.deblocks.1.1.running_mean
[03/24/2023-12:56:14] [V] [TRT] Searching for input: model.neck.deblocks.1.1.running_var
[03/24/2023-12:56:14] [V] [TRT] BatchNormalization_57 [BatchNormalization] inputs: [input.156 -> (1, 256, 180, 180)[FLOAT]], [model.neck.deblocks.1.1.weight -> (256)[FLOAT]], [model.neck.deblocks.1.1.bias -> (256)[FLOAT]], [model.neck.deblocks.1.1.running_mean -> (256)[FLOAT]], [model.neck.deblocks.1.1.running_var -> (256)[FLOAT]], 
[03/24/2023-12:56:14] [V] [TRT] Registering layer: BatchNormalization_57 for ONNX node: BatchNormalization_57
[03/24/2023-12:56:14] [V] [TRT] Registering tensor: input.160 for ONNX tensor: input.160
[03/24/2023-12:56:14] [V] [TRT] BatchNormalization_57 [BatchNormalization] outputs: [input.160 -> (1, 256, 180, 180)[FLOAT]], 
[03/24/2023-12:56:14] [V] [TRT] Parsing node: Relu_58 [Relu]
[03/24/2023-12:56:14] [V] [TRT] Searching for input: input.160
[03/24/2023-12:56:14] [V] [TRT] Relu_58 [Relu] inputs: [input.160 -> (1, 256, 180, 180)[FLOAT]], 
[03/24/2023-12:56:14] [V] [TRT] Registering layer: Relu_58 for ONNX node: Relu_58
[03/24/2023-12:56:14] [V] [TRT] Registering tensor: onnx::Concat_647 for ONNX tensor: onnx::Concat_647
[03/24/2023-12:56:14] [V] [TRT] Relu_58 [Relu] outputs: [onnx::Concat_647 -> (1, 256, 180, 180)[FLOAT]], 
[03/24/2023-12:56:14] [V] [TRT] Parsing node: Concat_59 [Concat]
[03/24/2023-12:56:14] [V] [TRT] Searching for input: onnx::Concat_602
[03/24/2023-12:56:14] [V] [TRT] Searching for input: onnx::Concat_647
[03/24/2023-12:56:14] [V] [TRT] Concat_59 [Concat] inputs: [onnx::Concat_602 -> (1, 256, 180, 180)[FLOAT]], [onnx::Concat_647 -> (1, 256, 180, 180)[FLOAT]], 
[03/24/2023-12:56:14] [V] [TRT] Registering layer: Concat_59 for ONNX node: Concat_59
[03/24/2023-12:56:14] [V] [TRT] Registering tensor: input.164 for ONNX tensor: input.164
[03/24/2023-12:56:14] [V] [TRT] Concat_59 [Concat] outputs: [input.164 -> (1, 512, 180, 180)[FLOAT]], 
[03/24/2023-12:56:14] [V] [TRT] Parsing node: Conv_60 [Conv]
[03/24/2023-12:56:14] [V] [TRT] Searching for input: input.164
[03/24/2023-12:56:14] [V] [TRT] Searching for input: onnx::Conv_836
[03/24/2023-12:56:14] [V] [TRT] Searching for input: onnx::Conv_837
[03/24/2023-12:56:14] [V] [TRT] Conv_60 [Conv] inputs: [input.164 -> (1, 512, 180, 180)[FLOAT]], [onnx::Conv_836 -> (64, 512, 3, 3)[FLOAT]], [onnx::Conv_837 -> (64)[FLOAT]], 
[03/24/2023-12:56:14] [V] [TRT] Convolution input dimensions: (1, 512, 180, 180)
[03/24/2023-12:56:14] [V] [TRT] Registering layer: Conv_60 for ONNX node: Conv_60
[03/24/2023-12:56:14] [V] [TRT] Using kernel: (3, 3), strides: (1, 1), prepadding: (1, 1), postpadding: (1, 1), dilations: (1, 1), numOutputs: 64
[03/24/2023-12:56:14] [V] [TRT] Convolution output dimensions: (1, 64, 180, 180)
[03/24/2023-12:56:14] [V] [TRT] Registering tensor: input.172 for ONNX tensor: input.172
[03/24/2023-12:56:14] [V] [TRT] Conv_60 [Conv] outputs: [input.172 -> (1, 64, 180, 180)[FLOAT]], 
[03/24/2023-12:56:14] [V] [TRT] Parsing node: Relu_61 [Relu]
[03/24/2023-12:56:14] [V] [TRT] Searching for input: input.172
[03/24/2023-12:56:14] [V] [TRT] Relu_61 [Relu] inputs: [input.172 -> (1, 64, 180, 180)[FLOAT]], 
[03/24/2023-12:56:14] [V] [TRT] Registering layer: Relu_61 for ONNX node: Relu_61
[03/24/2023-12:56:14] [V] [TRT] Registering tensor: onnx::Conv_651 for ONNX tensor: onnx::Conv_651
[03/24/2023-12:56:14] [V] [TRT] Relu_61 [Relu] outputs: [onnx::Conv_651 -> (1, 64, 180, 180)[FLOAT]], 
[03/24/2023-12:56:14] [V] [TRT] Parsing node: Conv_62 [Conv]
[03/24/2023-12:56:14] [V] [TRT] Searching for input: onnx::Conv_651
[03/24/2023-12:56:14] [V] [TRT] Searching for input: onnx::Conv_839
[03/24/2023-12:56:14] [V] [TRT] Searching for input: onnx::Conv_840
[03/24/2023-12:56:14] [V] [TRT] Conv_62 [Conv] inputs: [onnx::Conv_651 -> (1, 64, 180, 180)[FLOAT]], [onnx::Conv_839 -> (64, 64, 3, 3)[FLOAT]], [onnx::Conv_840 -> (64)[FLOAT]], 
[03/24/2023-12:56:14] [V] [TRT] Convolution input dimensions: (1, 64, 180, 180)
[03/24/2023-12:56:14] [V] [TRT] Registering layer: Conv_62 for ONNX node: Conv_62
[03/24/2023-12:56:14] [V] [TRT] Using kernel: (3, 3), strides: (1, 1), prepadding: (1, 1), postpadding: (1, 1), dilations: (1, 1), numOutputs: 64
[03/24/2023-12:56:14] [V] [TRT] Convolution output dimensions: (1, 64, 180, 180)
[03/24/2023-12:56:14] [V] [TRT] Registering tensor: input.180 for ONNX tensor: input.180
[03/24/2023-12:56:14] [V] [TRT] Conv_62 [Conv] outputs: [input.180 -> (1, 64, 180, 180)[FLOAT]], 
[03/24/2023-12:56:14] [V] [TRT] Parsing node: Relu_63 [Relu]
[03/24/2023-12:56:14] [V] [TRT] Searching for input: input.180
[03/24/2023-12:56:14] [V] [TRT] Relu_63 [Relu] inputs: [input.180 -> (1, 64, 180, 180)[FLOAT]], 
[03/24/2023-12:56:14] [V] [TRT] Registering layer: Relu_63 for ONNX node: Relu_63
[03/24/2023-12:56:14] [V] [TRT] Registering tensor: input.184 for ONNX tensor: input.184
[03/24/2023-12:56:14] [V] [TRT] Relu_63 [Relu] outputs: [input.184 -> (1, 64, 180, 180)[FLOAT]], 
[03/24/2023-12:56:14] [V] [TRT] Parsing node: Conv_64 [Conv]
[03/24/2023-12:56:14] [V] [TRT] Searching for input: input.184
[03/24/2023-12:56:14] [V] [TRT] Searching for input: model.bbox_head.tasks.0.reg.3.weight
[03/24/2023-12:56:14] [V] [TRT] Searching for input: model.bbox_head.tasks.0.reg.3.bias
[03/24/2023-12:56:14] [V] [TRT] Conv_64 [Conv] inputs: [input.184 -> (1, 64, 180, 180)[FLOAT]], [model.bbox_head.tasks.0.reg.3.weight -> (2, 64, 3, 3)[FLOAT]], [model.bbox_head.tasks.0.reg.3.bias -> (2)[FLOAT]], 
[03/24/2023-12:56:14] [V] [TRT] Convolution input dimensions: (1, 64, 180, 180)
[03/24/2023-12:56:14] [V] [TRT] Registering layer: Conv_64 for ONNX node: Conv_64
[03/24/2023-12:56:14] [V] [TRT] Using kernel: (3, 3), strides: (1, 1), prepadding: (1, 1), postpadding: (1, 1), dilations: (1, 1), numOutputs: 2
[03/24/2023-12:56:14] [V] [TRT] Convolution output dimensions: (1, 2, 180, 180)
[03/24/2023-12:56:14] [V] [TRT] Registering tensor: reg_0_0 for ONNX tensor: reg_0
[03/24/2023-12:56:14] [V] [TRT] Conv_64 [Conv] outputs: [reg_0 -> (1, 2, 180, 180)[FLOAT]], 
[03/24/2023-12:56:14] [V] [TRT] Parsing node: Conv_65 [Conv]
[03/24/2023-12:56:14] [V] [TRT] Searching for input: onnx::Conv_651
[03/24/2023-12:56:14] [V] [TRT] Searching for input: onnx::Conv_842
[03/24/2023-12:56:14] [V] [TRT] Searching for input: onnx::Conv_843
[03/24/2023-12:56:14] [V] [TRT] Conv_65 [Conv] inputs: [onnx::Conv_651 -> (1, 64, 180, 180)[FLOAT]], [onnx::Conv_842 -> (64, 64, 3, 3)[FLOAT]], [onnx::Conv_843 -> (64)[FLOAT]], 
[03/24/2023-12:56:14] [V] [TRT] Convolution input dimensions: (1, 64, 180, 180)
[03/24/2023-12:56:14] [V] [TRT] Registering layer: Conv_65 for ONNX node: Conv_65
[03/24/2023-12:56:14] [V] [TRT] Using kernel: (3, 3), strides: (1, 1), prepadding: (1, 1), postpadding: (1, 1), dilations: (1, 1), numOutputs: 64
[03/24/2023-12:56:14] [V] [TRT] Convolution output dimensions: (1, 64, 180, 180)
[03/24/2023-12:56:14] [V] [TRT] Registering tensor: input.192 for ONNX tensor: input.192
[03/24/2023-12:56:14] [V] [TRT] Conv_65 [Conv] outputs: [input.192 -> (1, 64, 180, 180)[FLOAT]], 
[03/24/2023-12:56:14] [V] [TRT] Parsing node: Relu_66 [Relu]
[03/24/2023-12:56:14] [V] [TRT] Searching for input: input.192
[03/24/2023-12:56:14] [V] [TRT] Relu_66 [Relu] inputs: [input.192 -> (1, 64, 180, 180)[FLOAT]], 
[03/24/2023-12:56:14] [V] [TRT] Registering layer: Relu_66 for ONNX node: Relu_66
[03/24/2023-12:56:14] [V] [TRT] Registering tensor: input.196 for ONNX tensor: input.196
[03/24/2023-12:56:14] [V] [TRT] Relu_66 [Relu] outputs: [input.196 -> (1, 64, 180, 180)[FLOAT]], 
[03/24/2023-12:56:14] [V] [TRT] Parsing node: Conv_67 [Conv]
[03/24/2023-12:56:14] [V] [TRT] Searching for input: input.196
[03/24/2023-12:56:14] [V] [TRT] Searching for input: model.bbox_head.tasks.0.height.3.weight
[03/24/2023-12:56:14] [V] [TRT] Searching for input: model.bbox_head.tasks.0.height.3.bias
[03/24/2023-12:56:14] [V] [TRT] Conv_67 [Conv] inputs: [input.196 -> (1, 64, 180, 180)[FLOAT]], [model.bbox_head.tasks.0.height.3.weight -> (1, 64, 3, 3)[FLOAT]], [model.bbox_head.tasks.0.height.3.bias -> (1)[FLOAT]], 
[03/24/2023-12:56:14] [V] [TRT] Convolution input dimensions: (1, 64, 180, 180)
[03/24/2023-12:56:14] [V] [TRT] Registering layer: Conv_67 for ONNX node: Conv_67
[03/24/2023-12:56:14] [V] [TRT] Using kernel: (3, 3), strides: (1, 1), prepadding: (1, 1), postpadding: (1, 1), dilations: (1, 1), numOutputs: 1
[03/24/2023-12:56:14] [V] [TRT] Convolution output dimensions: (1, 1, 180, 180)
[03/24/2023-12:56:14] [V] [TRT] Registering tensor: height_0_1 for ONNX tensor: height_0
[03/24/2023-12:56:14] [V] [TRT] Conv_67 [Conv] outputs: [height_0 -> (1, 1, 180, 180)[FLOAT]], 
[03/24/2023-12:56:14] [V] [TRT] Parsing node: Conv_68 [Conv]
[03/24/2023-12:56:14] [V] [TRT] Searching for input: onnx::Conv_651
[03/24/2023-12:56:14] [V] [TRT] Searching for input: onnx::Conv_845
[03/24/2023-12:56:14] [V] [TRT] Searching for input: onnx::Conv_846
[03/24/2023-12:56:14] [V] [TRT] Conv_68 [Conv] inputs: [onnx::Conv_651 -> (1, 64, 180, 180)[FLOAT]], [onnx::Conv_845 -> (64, 64, 3, 3)[FLOAT]], [onnx::Conv_846 -> (64)[FLOAT]], 
[03/24/2023-12:56:14] [V] [TRT] Convolution input dimensions: (1, 64, 180, 180)
[03/24/2023-12:56:14] [V] [TRT] Registering layer: Conv_68 for ONNX node: Conv_68
[03/24/2023-12:56:14] [V] [TRT] Using kernel: (3, 3), strides: (1, 1), prepadding: (1, 1), postpadding: (1, 1), dilations: (1, 1), numOutputs: 64
[03/24/2023-12:56:14] [V] [TRT] Convolution output dimensions: (1, 64, 180, 180)
[03/24/2023-12:56:14] [V] [TRT] Registering tensor: input.204 for ONNX tensor: input.204
[03/24/2023-12:56:14] [V] [TRT] Conv_68 [Conv] outputs: [input.204 -> (1, 64, 180, 180)[FLOAT]], 
[03/24/2023-12:56:14] [V] [TRT] Parsing node: Relu_69 [Relu]
[03/24/2023-12:56:14] [V] [TRT] Searching for input: input.204
[03/24/2023-12:56:14] [V] [TRT] Relu_69 [Relu] inputs: [input.204 -> (1, 64, 180, 180)[FLOAT]], 
[03/24/2023-12:56:14] [V] [TRT] Registering layer: Relu_69 for ONNX node: Relu_69
[03/24/2023-12:56:14] [V] [TRT] Registering tensor: input.208 for ONNX tensor: input.208
[03/24/2023-12:56:14] [V] [TRT] Relu_69 [Relu] outputs: [input.208 -> (1, 64, 180, 180)[FLOAT]], 
[03/24/2023-12:56:14] [V] [TRT] Parsing node: Conv_70 [Conv]
[03/24/2023-12:56:14] [V] [TRT] Searching for input: input.208
[03/24/2023-12:56:14] [V] [TRT] Searching for input: model.bbox_head.tasks.0.dim.3.weight
[03/24/2023-12:56:14] [V] [TRT] Searching for input: model.bbox_head.tasks.0.dim.3.bias
[03/24/2023-12:56:14] [V] [TRT] Conv_70 [Conv] inputs: [input.208 -> (1, 64, 180, 180)[FLOAT]], [model.bbox_head.tasks.0.dim.3.weight -> (3, 64, 3, 3)[FLOAT]], [model.bbox_head.tasks.0.dim.3.bias -> (3)[FLOAT]], 
[03/24/2023-12:56:14] [V] [TRT] Convolution input dimensions: (1, 64, 180, 180)
[03/24/2023-12:56:14] [V] [TRT] Registering layer: Conv_70 for ONNX node: Conv_70
[03/24/2023-12:56:14] [V] [TRT] Using kernel: (3, 3), strides: (1, 1), prepadding: (1, 1), postpadding: (1, 1), dilations: (1, 1), numOutputs: 3
[03/24/2023-12:56:14] [V] [TRT] Convolution output dimensions: (1, 3, 180, 180)
[03/24/2023-12:56:14] [V] [TRT] Registering tensor: dim_0_2 for ONNX tensor: dim_0
[03/24/2023-12:56:14] [V] [TRT] Conv_70 [Conv] outputs: [dim_0 -> (1, 3, 180, 180)[FLOAT]], 
[03/24/2023-12:56:14] [V] [TRT] Parsing node: Conv_71 [Conv]
[03/24/2023-12:56:14] [V] [TRT] Searching for input: onnx::Conv_651
[03/24/2023-12:56:14] [V] [TRT] Searching for input: onnx::Conv_848
[03/24/2023-12:56:14] [V] [TRT] Searching for input: onnx::Conv_849
[03/24/2023-12:56:14] [V] [TRT] Conv_71 [Conv] inputs: [onnx::Conv_651 -> (1, 64, 180, 180)[FLOAT]], [onnx::Conv_848 -> (64, 64, 3, 3)[FLOAT]], [onnx::Conv_849 -> (64)[FLOAT]], 
[03/24/2023-12:56:14] [V] [TRT] Convolution input dimensions: (1, 64, 180, 180)
[03/24/2023-12:56:14] [V] [TRT] Registering layer: Conv_71 for ONNX node: Conv_71
[03/24/2023-12:56:14] [V] [TRT] Using kernel: (3, 3), strides: (1, 1), prepadding: (1, 1), postpadding: (1, 1), dilations: (1, 1), numOutputs: 64
[03/24/2023-12:56:14] [V] [TRT] Convolution output dimensions: (1, 64, 180, 180)
[03/24/2023-12:56:14] [V] [TRT] Registering tensor: input.216 for ONNX tensor: input.216
[03/24/2023-12:56:14] [V] [TRT] Conv_71 [Conv] outputs: [input.216 -> (1, 64, 180, 180)[FLOAT]], 
[03/24/2023-12:56:14] [V] [TRT] Parsing node: Relu_72 [Relu]
[03/24/2023-12:56:14] [V] [TRT] Searching for input: input.216
[03/24/2023-12:56:14] [V] [TRT] Relu_72 [Relu] inputs: [input.216 -> (1, 64, 180, 180)[FLOAT]], 
[03/24/2023-12:56:14] [V] [TRT] Registering layer: Relu_72 for ONNX node: Relu_72
[03/24/2023-12:56:14] [V] [TRT] Registering tensor: input.220 for ONNX tensor: input.220
[03/24/2023-12:56:14] [V] [TRT] Relu_72 [Relu] outputs: [input.220 -> (1, 64, 180, 180)[FLOAT]], 
[03/24/2023-12:56:14] [V] [TRT] Parsing node: Conv_73 [Conv]
[03/24/2023-12:56:14] [V] [TRT] Searching for input: input.220
[03/24/2023-12:56:14] [V] [TRT] Searching for input: model.bbox_head.tasks.0.rot.3.weight
[03/24/2023-12:56:14] [V] [TRT] Searching for input: model.bbox_head.tasks.0.rot.3.bias
[03/24/2023-12:56:14] [V] [TRT] Conv_73 [Conv] inputs: [input.220 -> (1, 64, 180, 180)[FLOAT]], [model.bbox_head.tasks.0.rot.3.weight -> (2, 64, 3, 3)[FLOAT]], [model.bbox_head.tasks.0.rot.3.bias -> (2)[FLOAT]], 
[03/24/2023-12:56:14] [V] [TRT] Convolution input dimensions: (1, 64, 180, 180)
[03/24/2023-12:56:14] [V] [TRT] Registering layer: Conv_73 for ONNX node: Conv_73
[03/24/2023-12:56:14] [V] [TRT] Using kernel: (3, 3), strides: (1, 1), prepadding: (1, 1), postpadding: (1, 1), dilations: (1, 1), numOutputs: 2
[03/24/2023-12:56:14] [V] [TRT] Convolution output dimensions: (1, 2, 180, 180)
[03/24/2023-12:56:14] [V] [TRT] Registering tensor: rot_0_3 for ONNX tensor: rot_0
[03/24/2023-12:56:14] [V] [TRT] Conv_73 [Conv] outputs: [rot_0 -> (1, 2, 180, 180)[FLOAT]], 
[03/24/2023-12:56:14] [V] [TRT] Parsing node: Conv_74 [Conv]
[03/24/2023-12:56:14] [V] [TRT] Searching for input: onnx::Conv_651
[03/24/2023-12:56:14] [V] [TRT] Searching for input: onnx::Conv_851
[03/24/2023-12:56:14] [V] [TRT] Searching for input: onnx::Conv_852
[03/24/2023-12:56:14] [V] [TRT] Conv_74 [Conv] inputs: [onnx::Conv_651 -> (1, 64, 180, 180)[FLOAT]], [onnx::Conv_851 -> (64, 64, 3, 3)[FLOAT]], [onnx::Conv_852 -> (64)[FLOAT]], 
[03/24/2023-12:56:14] [V] [TRT] Convolution input dimensions: (1, 64, 180, 180)
[03/24/2023-12:56:14] [V] [TRT] Registering layer: Conv_74 for ONNX node: Conv_74
[03/24/2023-12:56:14] [V] [TRT] Using kernel: (3, 3), strides: (1, 1), prepadding: (1, 1), postpadding: (1, 1), dilations: (1, 1), numOutputs: 64
[03/24/2023-12:56:14] [V] [TRT] Convolution output dimensions: (1, 64, 180, 180)
[03/24/2023-12:56:14] [V] [TRT] Registering tensor: input.228 for ONNX tensor: input.228
[03/24/2023-12:56:14] [V] [TRT] Conv_74 [Conv] outputs: [input.228 -> (1, 64, 180, 180)[FLOAT]], 
[03/24/2023-12:56:14] [V] [TRT] Parsing node: Relu_75 [Relu]
[03/24/2023-12:56:14] [V] [TRT] Searching for input: input.228
[03/24/2023-12:56:14] [V] [TRT] Relu_75 [Relu] inputs: [input.228 -> (1, 64, 180, 180)[FLOAT]], 
[03/24/2023-12:56:14] [V] [TRT] Registering layer: Relu_75 for ONNX node: Relu_75
[03/24/2023-12:56:14] [V] [TRT] Registering tensor: input.232 for ONNX tensor: input.232
[03/24/2023-12:56:14] [V] [TRT] Relu_75 [Relu] outputs: [input.232 -> (1, 64, 180, 180)[FLOAT]], 
[03/24/2023-12:56:14] [V] [TRT] Parsing node: Conv_76 [Conv]
[03/24/2023-12:56:14] [V] [TRT] Searching for input: input.232
[03/24/2023-12:56:14] [V] [TRT] Searching for input: model.bbox_head.tasks.0.vel.3.weight
[03/24/2023-12:56:14] [V] [TRT] Searching for input: model.bbox_head.tasks.0.vel.3.bias
[03/24/2023-12:56:14] [V] [TRT] Conv_76 [Conv] inputs: [input.232 -> (1, 64, 180, 180)[FLOAT]], [model.bbox_head.tasks.0.vel.3.weight -> (2, 64, 3, 3)[FLOAT]], [model.bbox_head.tasks.0.vel.3.bias -> (2)[FLOAT]], 
[03/24/2023-12:56:14] [V] [TRT] Convolution input dimensions: (1, 64, 180, 180)
[03/24/2023-12:56:14] [V] [TRT] Registering layer: Conv_76 for ONNX node: Conv_76
[03/24/2023-12:56:14] [V] [TRT] Using kernel: (3, 3), strides: (1, 1), prepadding: (1, 1), postpadding: (1, 1), dilations: (1, 1), numOutputs: 2
[03/24/2023-12:56:14] [V] [TRT] Convolution output dimensions: (1, 2, 180, 180)
[03/24/2023-12:56:14] [V] [TRT] Registering tensor: vel_0_4 for ONNX tensor: vel_0
[03/24/2023-12:56:14] [V] [TRT] Conv_76 [Conv] outputs: [vel_0 -> (1, 2, 180, 180)[FLOAT]], 
[03/24/2023-12:56:14] [V] [TRT] Parsing node: Conv_77 [Conv]
[03/24/2023-12:56:14] [V] [TRT] Searching for input: onnx::Conv_651
[03/24/2023-12:56:14] [V] [TRT] Searching for input: onnx::Conv_854
[03/24/2023-12:56:14] [V] [TRT] Searching for input: onnx::Conv_855
[03/24/2023-12:56:14] [V] [TRT] Conv_77 [Conv] inputs: [onnx::Conv_651 -> (1, 64, 180, 180)[FLOAT]], [onnx::Conv_854 -> (64, 64, 3, 3)[FLOAT]], [onnx::Conv_855 -> (64)[FLOAT]], 
[03/24/2023-12:56:14] [V] [TRT] Convolution input dimensions: (1, 64, 180, 180)
[03/24/2023-12:56:14] [V] [TRT] Registering layer: Conv_77 for ONNX node: Conv_77
[03/24/2023-12:56:14] [V] [TRT] Using kernel: (3, 3), strides: (1, 1), prepadding: (1, 1), postpadding: (1, 1), dilations: (1, 1), numOutputs: 64
[03/24/2023-12:56:14] [V] [TRT] Convolution output dimensions: (1, 64, 180, 180)
[03/24/2023-12:56:14] [V] [TRT] Registering tensor: input.240 for ONNX tensor: input.240
[03/24/2023-12:56:14] [V] [TRT] Conv_77 [Conv] outputs: [input.240 -> (1, 64, 180, 180)[FLOAT]], 
[03/24/2023-12:56:14] [V] [TRT] Parsing node: Relu_78 [Relu]
[03/24/2023-12:56:14] [V] [TRT] Searching for input: input.240
[03/24/2023-12:56:14] [V] [TRT] Relu_78 [Relu] inputs: [input.240 -> (1, 64, 180, 180)[FLOAT]], 
[03/24/2023-12:56:14] [V] [TRT] Registering layer: Relu_78 for ONNX node: Relu_78
[03/24/2023-12:56:14] [V] [TRT] Registering tensor: input.244 for ONNX tensor: input.244
[03/24/2023-12:56:14] [V] [TRT] Relu_78 [Relu] outputs: [input.244 -> (1, 64, 180, 180)[FLOAT]], 
[03/24/2023-12:56:14] [V] [TRT] Parsing node: Conv_79 [Conv]
[03/24/2023-12:56:14] [V] [TRT] Searching for input: input.244
[03/24/2023-12:56:14] [V] [TRT] Searching for input: model.bbox_head.tasks.0.hm.3.weight
[03/24/2023-12:56:14] [V] [TRT] Searching for input: model.bbox_head.tasks.0.hm.3.bias
[03/24/2023-12:56:14] [V] [TRT] Conv_79 [Conv] inputs: [input.244 -> (1, 64, 180, 180)[FLOAT]], [model.bbox_head.tasks.0.hm.3.weight -> (1, 64, 3, 3)[FLOAT]], [model.bbox_head.tasks.0.hm.3.bias -> (1)[FLOAT]], 
[03/24/2023-12:56:14] [V] [TRT] Convolution input dimensions: (1, 64, 180, 180)
[03/24/2023-12:56:14] [V] [TRT] Registering layer: Conv_79 for ONNX node: Conv_79
[03/24/2023-12:56:14] [V] [TRT] Using kernel: (3, 3), strides: (1, 1), prepadding: (1, 1), postpadding: (1, 1), dilations: (1, 1), numOutputs: 1
[03/24/2023-12:56:14] [V] [TRT] Convolution output dimensions: (1, 1, 180, 180)
[03/24/2023-12:56:14] [V] [TRT] Registering tensor: hm_0_5 for ONNX tensor: hm_0
[03/24/2023-12:56:14] [V] [TRT] Conv_79 [Conv] outputs: [hm_0 -> (1, 1, 180, 180)[FLOAT]], 
[03/24/2023-12:56:14] [V] [TRT] Parsing node: Conv_80 [Conv]
[03/24/2023-12:56:14] [V] [TRT] Searching for input: onnx::Conv_651
[03/24/2023-12:56:14] [V] [TRT] Searching for input: onnx::Conv_857
[03/24/2023-12:56:14] [V] [TRT] Searching for input: onnx::Conv_858
[03/24/2023-12:56:14] [V] [TRT] Conv_80 [Conv] inputs: [onnx::Conv_651 -> (1, 64, 180, 180)[FLOAT]], [onnx::Conv_857 -> (64, 64, 3, 3)[FLOAT]], [onnx::Conv_858 -> (64)[FLOAT]], 
[03/24/2023-12:56:14] [V] [TRT] Convolution input dimensions: (1, 64, 180, 180)
[03/24/2023-12:56:14] [V] [TRT] Registering layer: Conv_80 for ONNX node: Conv_80
[03/24/2023-12:56:14] [V] [TRT] Using kernel: (3, 3), strides: (1, 1), prepadding: (1, 1), postpadding: (1, 1), dilations: (1, 1), numOutputs: 64
[03/24/2023-12:56:14] [V] [TRT] Convolution output dimensions: (1, 64, 180, 180)
[03/24/2023-12:56:14] [V] [TRT] Registering tensor: input.252 for ONNX tensor: input.252
[03/24/2023-12:56:14] [V] [TRT] Conv_80 [Conv] outputs: [input.252 -> (1, 64, 180, 180)[FLOAT]], 
[03/24/2023-12:56:14] [V] [TRT] Parsing node: Relu_81 [Relu]
[03/24/2023-12:56:14] [V] [TRT] Searching for input: input.252
[03/24/2023-12:56:14] [V] [TRT] Relu_81 [Relu] inputs: [input.252 -> (1, 64, 180, 180)[FLOAT]], 
[03/24/2023-12:56:14] [V] [TRT] Registering layer: Relu_81 for ONNX node: Relu_81
[03/24/2023-12:56:14] [V] [TRT] Registering tensor: input.256 for ONNX tensor: input.256
[03/24/2023-12:56:14] [V] [TRT] Relu_81 [Relu] outputs: [input.256 -> (1, 64, 180, 180)[FLOAT]], 
[03/24/2023-12:56:14] [V] [TRT] Parsing node: Conv_82 [Conv]
[03/24/2023-12:56:14] [V] [TRT] Searching for input: input.256
[03/24/2023-12:56:14] [V] [TRT] Searching for input: model.bbox_head.tasks.1.reg.3.weight
[03/24/2023-12:56:14] [V] [TRT] Searching for input: model.bbox_head.tasks.1.reg.3.bias
[03/24/2023-12:56:14] [V] [TRT] Conv_82 [Conv] inputs: [input.256 -> (1, 64, 180, 180)[FLOAT]], [model.bbox_head.tasks.1.reg.3.weight -> (2, 64, 3, 3)[FLOAT]], [model.bbox_head.tasks.1.reg.3.bias -> (2)[FLOAT]], 
[03/24/2023-12:56:14] [V] [TRT] Convolution input dimensions: (1, 64, 180, 180)
[03/24/2023-12:56:14] [V] [TRT] Registering layer: Conv_82 for ONNX node: Conv_82
[03/24/2023-12:56:14] [V] [TRT] Using kernel: (3, 3), strides: (1, 1), prepadding: (1, 1), postpadding: (1, 1), dilations: (1, 1), numOutputs: 2
[03/24/2023-12:56:14] [V] [TRT] Convolution output dimensions: (1, 2, 180, 180)
[03/24/2023-12:56:14] [V] [TRT] Registering tensor: reg_1_6 for ONNX tensor: reg_1
[03/24/2023-12:56:14] [V] [TRT] Conv_82 [Conv] outputs: [reg_1 -> (1, 2, 180, 180)[FLOAT]], 
[03/24/2023-12:56:14] [V] [TRT] Parsing node: Conv_83 [Conv]
[03/24/2023-12:56:14] [V] [TRT] Searching for input: onnx::Conv_651
[03/24/2023-12:56:14] [V] [TRT] Searching for input: onnx::Conv_860
[03/24/2023-12:56:14] [V] [TRT] Searching for input: onnx::Conv_861
[03/24/2023-12:56:14] [V] [TRT] Conv_83 [Conv] inputs: [onnx::Conv_651 -> (1, 64, 180, 180)[FLOAT]], [onnx::Conv_860 -> (64, 64, 3, 3)[FLOAT]], [onnx::Conv_861 -> (64)[FLOAT]], 
[03/24/2023-12:56:14] [V] [TRT] Convolution input dimensions: (1, 64, 180, 180)
[03/24/2023-12:56:14] [V] [TRT] Registering layer: Conv_83 for ONNX node: Conv_83
[03/24/2023-12:56:14] [V] [TRT] Using kernel: (3, 3), strides: (1, 1), prepadding: (1, 1), postpadding: (1, 1), dilations: (1, 1), numOutputs: 64
[03/24/2023-12:56:14] [V] [TRT] Convolution output dimensions: (1, 64, 180, 180)
[03/24/2023-12:56:14] [V] [TRT] Registering tensor: input.264 for ONNX tensor: input.264
[03/24/2023-12:56:14] [V] [TRT] Conv_83 [Conv] outputs: [input.264 -> (1, 64, 180, 180)[FLOAT]], 
[03/24/2023-12:56:14] [V] [TRT] Parsing node: Relu_84 [Relu]
[03/24/2023-12:56:14] [V] [TRT] Searching for input: input.264
[03/24/2023-12:56:14] [V] [TRT] Relu_84 [Relu] inputs: [input.264 -> (1, 64, 180, 180)[FLOAT]], 
[03/24/2023-12:56:14] [V] [TRT] Registering layer: Relu_84 for ONNX node: Relu_84
[03/24/2023-12:56:14] [V] [TRT] Registering tensor: input.268 for ONNX tensor: input.268
[03/24/2023-12:56:14] [V] [TRT] Relu_84 [Relu] outputs: [input.268 -> (1, 64, 180, 180)[FLOAT]], 
[03/24/2023-12:56:14] [V] [TRT] Parsing node: Conv_85 [Conv]
[03/24/2023-12:56:14] [V] [TRT] Searching for input: input.268
[03/24/2023-12:56:14] [V] [TRT] Searching for input: model.bbox_head.tasks.1.height.3.weight
[03/24/2023-12:56:14] [V] [TRT] Searching for input: model.bbox_head.tasks.1.height.3.bias
[03/24/2023-12:56:14] [V] [TRT] Conv_85 [Conv] inputs: [input.268 -> (1, 64, 180, 180)[FLOAT]], [model.bbox_head.tasks.1.height.3.weight -> (1, 64, 3, 3)[FLOAT]], [model.bbox_head.tasks.1.height.3.bias -> (1)[FLOAT]], 
[03/24/2023-12:56:14] [V] [TRT] Convolution input dimensions: (1, 64, 180, 180)
[03/24/2023-12:56:14] [V] [TRT] Registering layer: Conv_85 for ONNX node: Conv_85
[03/24/2023-12:56:14] [V] [TRT] Using kernel: (3, 3), strides: (1, 1), prepadding: (1, 1), postpadding: (1, 1), dilations: (1, 1), numOutputs: 1
[03/24/2023-12:56:14] [V] [TRT] Convolution output dimensions: (1, 1, 180, 180)
[03/24/2023-12:56:14] [V] [TRT] Registering tensor: height_1_7 for ONNX tensor: height_1
[03/24/2023-12:56:14] [V] [TRT] Conv_85 [Conv] outputs: [height_1 -> (1, 1, 180, 180)[FLOAT]], 
[03/24/2023-12:56:14] [V] [TRT] Parsing node: Conv_86 [Conv]
[03/24/2023-12:56:14] [V] [TRT] Searching for input: onnx::Conv_651
[03/24/2023-12:56:14] [V] [TRT] Searching for input: onnx::Conv_863
[03/24/2023-12:56:14] [V] [TRT] Searching for input: onnx::Conv_864
[03/24/2023-12:56:14] [V] [TRT] Conv_86 [Conv] inputs: [onnx::Conv_651 -> (1, 64, 180, 180)[FLOAT]], [onnx::Conv_863 -> (64, 64, 3, 3)[FLOAT]], [onnx::Conv_864 -> (64)[FLOAT]], 
[03/24/2023-12:56:14] [V] [TRT] Convolution input dimensions: (1, 64, 180, 180)
[03/24/2023-12:56:14] [V] [TRT] Registering layer: Conv_86 for ONNX node: Conv_86
[03/24/2023-12:56:14] [V] [TRT] Using kernel: (3, 3), strides: (1, 1), prepadding: (1, 1), postpadding: (1, 1), dilations: (1, 1), numOutputs: 64
[03/24/2023-12:56:14] [V] [TRT] Convolution output dimensions: (1, 64, 180, 180)
[03/24/2023-12:56:14] [V] [TRT] Registering tensor: input.276 for ONNX tensor: input.276
[03/24/2023-12:56:14] [V] [TRT] Conv_86 [Conv] outputs: [input.276 -> (1, 64, 180, 180)[FLOAT]], 
[03/24/2023-12:56:14] [V] [TRT] Parsing node: Relu_87 [Relu]
[03/24/2023-12:56:14] [V] [TRT] Searching for input: input.276
[03/24/2023-12:56:14] [V] [TRT] Relu_87 [Relu] inputs: [input.276 -> (1, 64, 180, 180)[FLOAT]], 
[03/24/2023-12:56:14] [V] [TRT] Registering layer: Relu_87 for ONNX node: Relu_87
[03/24/2023-12:56:14] [V] [TRT] Registering tensor: input.280 for ONNX tensor: input.280
[03/24/2023-12:56:14] [V] [TRT] Relu_87 [Relu] outputs: [input.280 -> (1, 64, 180, 180)[FLOAT]], 
[03/24/2023-12:56:14] [V] [TRT] Parsing node: Conv_88 [Conv]
[03/24/2023-12:56:14] [V] [TRT] Searching for input: input.280
[03/24/2023-12:56:14] [V] [TRT] Searching for input: model.bbox_head.tasks.1.dim.3.weight
[03/24/2023-12:56:14] [V] [TRT] Searching for input: model.bbox_head.tasks.1.dim.3.bias
[03/24/2023-12:56:14] [V] [TRT] Conv_88 [Conv] inputs: [input.280 -> (1, 64, 180, 180)[FLOAT]], [model.bbox_head.tasks.1.dim.3.weight -> (3, 64, 3, 3)[FLOAT]], [model.bbox_head.tasks.1.dim.3.bias -> (3)[FLOAT]], 
[03/24/2023-12:56:14] [V] [TRT] Convolution input dimensions: (1, 64, 180, 180)
[03/24/2023-12:56:14] [V] [TRT] Registering layer: Conv_88 for ONNX node: Conv_88
[03/24/2023-12:56:14] [V] [TRT] Using kernel: (3, 3), strides: (1, 1), prepadding: (1, 1), postpadding: (1, 1), dilations: (1, 1), numOutputs: 3
[03/24/2023-12:56:14] [V] [TRT] Convolution output dimensions: (1, 3, 180, 180)
[03/24/2023-12:56:14] [V] [TRT] Registering tensor: dim_1_8 for ONNX tensor: dim_1
[03/24/2023-12:56:14] [V] [TRT] Conv_88 [Conv] outputs: [dim_1 -> (1, 3, 180, 180)[FLOAT]], 
[03/24/2023-12:56:14] [V] [TRT] Parsing node: Conv_89 [Conv]
[03/24/2023-12:56:14] [V] [TRT] Searching for input: onnx::Conv_651
[03/24/2023-12:56:14] [V] [TRT] Searching for input: onnx::Conv_866
[03/24/2023-12:56:14] [V] [TRT] Searching for input: onnx::Conv_867
[03/24/2023-12:56:14] [V] [TRT] Conv_89 [Conv] inputs: [onnx::Conv_651 -> (1, 64, 180, 180)[FLOAT]], [onnx::Conv_866 -> (64, 64, 3, 3)[FLOAT]], [onnx::Conv_867 -> (64)[FLOAT]], 
[03/24/2023-12:56:14] [V] [TRT] Convolution input dimensions: (1, 64, 180, 180)
[03/24/2023-12:56:14] [V] [TRT] Registering layer: Conv_89 for ONNX node: Conv_89
[03/24/2023-12:56:14] [V] [TRT] Using kernel: (3, 3), strides: (1, 1), prepadding: (1, 1), postpadding: (1, 1), dilations: (1, 1), numOutputs: 64
[03/24/2023-12:56:14] [V] [TRT] Convolution output dimensions: (1, 64, 180, 180)
[03/24/2023-12:56:14] [V] [TRT] Registering tensor: input.288 for ONNX tensor: input.288
[03/24/2023-12:56:14] [V] [TRT] Conv_89 [Conv] outputs: [input.288 -> (1, 64, 180, 180)[FLOAT]], 
[03/24/2023-12:56:14] [V] [TRT] Parsing node: Relu_90 [Relu]
[03/24/2023-12:56:14] [V] [TRT] Searching for input: input.288
[03/24/2023-12:56:14] [V] [TRT] Relu_90 [Relu] inputs: [input.288 -> (1, 64, 180, 180)[FLOAT]], 
[03/24/2023-12:56:14] [V] [TRT] Registering layer: Relu_90 for ONNX node: Relu_90
[03/24/2023-12:56:14] [V] [TRT] Registering tensor: input.292 for ONNX tensor: input.292
[03/24/2023-12:56:14] [V] [TRT] Relu_90 [Relu] outputs: [input.292 -> (1, 64, 180, 180)[FLOAT]], 
[03/24/2023-12:56:14] [V] [TRT] Parsing node: Conv_91 [Conv]
[03/24/2023-12:56:14] [V] [TRT] Searching for input: input.292
[03/24/2023-12:56:14] [V] [TRT] Searching for input: model.bbox_head.tasks.1.rot.3.weight
[03/24/2023-12:56:14] [V] [TRT] Searching for input: model.bbox_head.tasks.1.rot.3.bias
[03/24/2023-12:56:14] [V] [TRT] Conv_91 [Conv] inputs: [input.292 -> (1, 64, 180, 180)[FLOAT]], [model.bbox_head.tasks.1.rot.3.weight -> (2, 64, 3, 3)[FLOAT]], [model.bbox_head.tasks.1.rot.3.bias -> (2)[FLOAT]], 
[03/24/2023-12:56:14] [V] [TRT] Convolution input dimensions: (1, 64, 180, 180)
[03/24/2023-12:56:14] [V] [TRT] Registering layer: Conv_91 for ONNX node: Conv_91
[03/24/2023-12:56:14] [V] [TRT] Using kernel: (3, 3), strides: (1, 1), prepadding: (1, 1), postpadding: (1, 1), dilations: (1, 1), numOutputs: 2
[03/24/2023-12:56:14] [V] [TRT] Convolution output dimensions: (1, 2, 180, 180)
[03/24/2023-12:56:14] [V] [TRT] Registering tensor: rot_1_9 for ONNX tensor: rot_1
[03/24/2023-12:56:14] [V] [TRT] Conv_91 [Conv] outputs: [rot_1 -> (1, 2, 180, 180)[FLOAT]], 
[03/24/2023-12:56:14] [V] [TRT] Parsing node: Conv_92 [Conv]
[03/24/2023-12:56:14] [V] [TRT] Searching for input: onnx::Conv_651
[03/24/2023-12:56:14] [V] [TRT] Searching for input: onnx::Conv_869
[03/24/2023-12:56:14] [V] [TRT] Searching for input: onnx::Conv_870
[03/24/2023-12:56:14] [V] [TRT] Conv_92 [Conv] inputs: [onnx::Conv_651 -> (1, 64, 180, 180)[FLOAT]], [onnx::Conv_869 -> (64, 64, 3, 3)[FLOAT]], [onnx::Conv_870 -> (64)[FLOAT]], 
[03/24/2023-12:56:14] [V] [TRT] Convolution input dimensions: (1, 64, 180, 180)
[03/24/2023-12:56:14] [V] [TRT] Registering layer: Conv_92 for ONNX node: Conv_92
[03/24/2023-12:56:14] [V] [TRT] Using kernel: (3, 3), strides: (1, 1), prepadding: (1, 1), postpadding: (1, 1), dilations: (1, 1), numOutputs: 64
[03/24/2023-12:56:14] [V] [TRT] Convolution output dimensions: (1, 64, 180, 180)
[03/24/2023-12:56:14] [V] [TRT] Registering tensor: input.300 for ONNX tensor: input.300
[03/24/2023-12:56:14] [V] [TRT] Conv_92 [Conv] outputs: [input.300 -> (1, 64, 180, 180)[FLOAT]], 
[03/24/2023-12:56:14] [V] [TRT] Parsing node: Relu_93 [Relu]
[03/24/2023-12:56:14] [V] [TRT] Searching for input: input.300
[03/24/2023-12:56:14] [V] [TRT] Relu_93 [Relu] inputs: [input.300 -> (1, 64, 180, 180)[FLOAT]], 
[03/24/2023-12:56:14] [V] [TRT] Registering layer: Relu_93 for ONNX node: Relu_93
[03/24/2023-12:56:14] [V] [TRT] Registering tensor: input.304 for ONNX tensor: input.304
[03/24/2023-12:56:14] [V] [TRT] Relu_93 [Relu] outputs: [input.304 -> (1, 64, 180, 180)[FLOAT]], 
[03/24/2023-12:56:14] [V] [TRT] Parsing node: Conv_94 [Conv]
[03/24/2023-12:56:14] [V] [TRT] Searching for input: input.304
[03/24/2023-12:56:14] [V] [TRT] Searching for input: model.bbox_head.tasks.1.vel.3.weight
[03/24/2023-12:56:14] [V] [TRT] Searching for input: model.bbox_head.tasks.1.vel.3.bias
[03/24/2023-12:56:14] [V] [TRT] Conv_94 [Conv] inputs: [input.304 -> (1, 64, 180, 180)[FLOAT]], [model.bbox_head.tasks.1.vel.3.weight -> (2, 64, 3, 3)[FLOAT]], [model.bbox_head.tasks.1.vel.3.bias -> (2)[FLOAT]], 
[03/24/2023-12:56:14] [V] [TRT] Convolution input dimensions: (1, 64, 180, 180)
[03/24/2023-12:56:14] [V] [TRT] Registering layer: Conv_94 for ONNX node: Conv_94
[03/24/2023-12:56:14] [V] [TRT] Using kernel: (3, 3), strides: (1, 1), prepadding: (1, 1), postpadding: (1, 1), dilations: (1, 1), numOutputs: 2
[03/24/2023-12:56:14] [V] [TRT] Convolution output dimensions: (1, 2, 180, 180)
[03/24/2023-12:56:14] [V] [TRT] Registering tensor: vel_1_10 for ONNX tensor: vel_1
[03/24/2023-12:56:14] [V] [TRT] Conv_94 [Conv] outputs: [vel_1 -> (1, 2, 180, 180)[FLOAT]], 
[03/24/2023-12:56:14] [V] [TRT] Parsing node: Conv_95 [Conv]
[03/24/2023-12:56:14] [V] [TRT] Searching for input: onnx::Conv_651
[03/24/2023-12:56:14] [V] [TRT] Searching for input: onnx::Conv_872
[03/24/2023-12:56:14] [V] [TRT] Searching for input: onnx::Conv_873
[03/24/2023-12:56:14] [V] [TRT] Conv_95 [Conv] inputs: [onnx::Conv_651 -> (1, 64, 180, 180)[FLOAT]], [onnx::Conv_872 -> (64, 64, 3, 3)[FLOAT]], [onnx::Conv_873 -> (64)[FLOAT]], 
[03/24/2023-12:56:14] [V] [TRT] Convolution input dimensions: (1, 64, 180, 180)
[03/24/2023-12:56:14] [V] [TRT] Registering layer: Conv_95 for ONNX node: Conv_95
[03/24/2023-12:56:14] [V] [TRT] Using kernel: (3, 3), strides: (1, 1), prepadding: (1, 1), postpadding: (1, 1), dilations: (1, 1), numOutputs: 64
[03/24/2023-12:56:14] [V] [TRT] Convolution output dimensions: (1, 64, 180, 180)
[03/24/2023-12:56:14] [V] [TRT] Registering tensor: input.312 for ONNX tensor: input.312
[03/24/2023-12:56:14] [V] [TRT] Conv_95 [Conv] outputs: [input.312 -> (1, 64, 180, 180)[FLOAT]], 
[03/24/2023-12:56:14] [V] [TRT] Parsing node: Relu_96 [Relu]
[03/24/2023-12:56:14] [V] [TRT] Searching for input: input.312
[03/24/2023-12:56:14] [V] [TRT] Relu_96 [Relu] inputs: [input.312 -> (1, 64, 180, 180)[FLOAT]], 
[03/24/2023-12:56:14] [V] [TRT] Registering layer: Relu_96 for ONNX node: Relu_96
[03/24/2023-12:56:14] [V] [TRT] Registering tensor: input.316 for ONNX tensor: input.316
[03/24/2023-12:56:14] [V] [TRT] Relu_96 [Relu] outputs: [input.316 -> (1, 64, 180, 180)[FLOAT]], 
[03/24/2023-12:56:14] [V] [TRT] Parsing node: Conv_97 [Conv]
[03/24/2023-12:56:14] [V] [TRT] Searching for input: input.316
[03/24/2023-12:56:14] [V] [TRT] Searching for input: model.bbox_head.tasks.1.hm.3.weight
[03/24/2023-12:56:14] [V] [TRT] Searching for input: model.bbox_head.tasks.1.hm.3.bias
[03/24/2023-12:56:14] [V] [TRT] Conv_97 [Conv] inputs: [input.316 -> (1, 64, 180, 180)[FLOAT]], [model.bbox_head.tasks.1.hm.3.weight -> (2, 64, 3, 3)[FLOAT]], [model.bbox_head.tasks.1.hm.3.bias -> (2)[FLOAT]], 
[03/24/2023-12:56:14] [V] [TRT] Convolution input dimensions: (1, 64, 180, 180)
[03/24/2023-12:56:14] [V] [TRT] Registering layer: Conv_97 for ONNX node: Conv_97
[03/24/2023-12:56:14] [V] [TRT] Using kernel: (3, 3), strides: (1, 1), prepadding: (1, 1), postpadding: (1, 1), dilations: (1, 1), numOutputs: 2
[03/24/2023-12:56:14] [V] [TRT] Convolution output dimensions: (1, 2, 180, 180)
[03/24/2023-12:56:14] [V] [TRT] Registering tensor: hm_1_11 for ONNX tensor: hm_1
[03/24/2023-12:56:14] [V] [TRT] Conv_97 [Conv] outputs: [hm_1 -> (1, 2, 180, 180)[FLOAT]], 
[03/24/2023-12:56:14] [V] [TRT] Parsing node: Conv_98 [Conv]
[03/24/2023-12:56:14] [V] [TRT] Searching for input: onnx::Conv_651
[03/24/2023-12:56:14] [V] [TRT] Searching for input: onnx::Conv_875
[03/24/2023-12:56:14] [V] [TRT] Searching for input: onnx::Conv_876
[03/24/2023-12:56:14] [V] [TRT] Conv_98 [Conv] inputs: [onnx::Conv_651 -> (1, 64, 180, 180)[FLOAT]], [onnx::Conv_875 -> (64, 64, 3, 3)[FLOAT]], [onnx::Conv_876 -> (64)[FLOAT]], 
[03/24/2023-12:56:14] [V] [TRT] Convolution input dimensions: (1, 64, 180, 180)
[03/24/2023-12:56:14] [V] [TRT] Registering layer: Conv_98 for ONNX node: Conv_98
[03/24/2023-12:56:14] [V] [TRT] Using kernel: (3, 3), strides: (1, 1), prepadding: (1, 1), postpadding: (1, 1), dilations: (1, 1), numOutputs: 64
[03/24/2023-12:56:14] [V] [TRT] Convolution output dimensions: (1, 64, 180, 180)
[03/24/2023-12:56:14] [V] [TRT] Registering tensor: input.324 for ONNX tensor: input.324
[03/24/2023-12:56:14] [V] [TRT] Conv_98 [Conv] outputs: [input.324 -> (1, 64, 180, 180)[FLOAT]], 
[03/24/2023-12:56:14] [V] [TRT] Parsing node: Relu_99 [Relu]
[03/24/2023-12:56:14] [V] [TRT] Searching for input: input.324
[03/24/2023-12:56:14] [V] [TRT] Relu_99 [Relu] inputs: [input.324 -> (1, 64, 180, 180)[FLOAT]], 
[03/24/2023-12:56:14] [V] [TRT] Registering layer: Relu_99 for ONNX node: Relu_99
[03/24/2023-12:56:14] [V] [TRT] Registering tensor: input.328 for ONNX tensor: input.328
[03/24/2023-12:56:14] [V] [TRT] Relu_99 [Relu] outputs: [input.328 -> (1, 64, 180, 180)[FLOAT]], 
[03/24/2023-12:56:14] [V] [TRT] Parsing node: Conv_100 [Conv]
[03/24/2023-12:56:14] [V] [TRT] Searching for input: input.328
[03/24/2023-12:56:14] [V] [TRT] Searching for input: model.bbox_head.tasks.2.reg.3.weight
[03/24/2023-12:56:14] [V] [TRT] Searching for input: model.bbox_head.tasks.2.reg.3.bias
[03/24/2023-12:56:14] [V] [TRT] Conv_100 [Conv] inputs: [input.328 -> (1, 64, 180, 180)[FLOAT]], [model.bbox_head.tasks.2.reg.3.weight -> (2, 64, 3, 3)[FLOAT]], [model.bbox_head.tasks.2.reg.3.bias -> (2)[FLOAT]], 
[03/24/2023-12:56:14] [V] [TRT] Convolution input dimensions: (1, 64, 180, 180)
[03/24/2023-12:56:14] [V] [TRT] Registering layer: Conv_100 for ONNX node: Conv_100
[03/24/2023-12:56:14] [V] [TRT] Using kernel: (3, 3), strides: (1, 1), prepadding: (1, 1), postpadding: (1, 1), dilations: (1, 1), numOutputs: 2
[03/24/2023-12:56:14] [V] [TRT] Convolution output dimensions: (1, 2, 180, 180)
[03/24/2023-12:56:14] [V] [TRT] Registering tensor: reg_2_12 for ONNX tensor: reg_2
[03/24/2023-12:56:14] [V] [TRT] Conv_100 [Conv] outputs: [reg_2 -> (1, 2, 180, 180)[FLOAT]], 
[03/24/2023-12:56:14] [V] [TRT] Parsing node: Conv_101 [Conv]
[03/24/2023-12:56:14] [V] [TRT] Searching for input: onnx::Conv_651
[03/24/2023-12:56:14] [V] [TRT] Searching for input: onnx::Conv_878
[03/24/2023-12:56:14] [V] [TRT] Searching for input: onnx::Conv_879
[03/24/2023-12:56:14] [V] [TRT] Conv_101 [Conv] inputs: [onnx::Conv_651 -> (1, 64, 180, 180)[FLOAT]], [onnx::Conv_878 -> (64, 64, 3, 3)[FLOAT]], [onnx::Conv_879 -> (64)[FLOAT]], 
[03/24/2023-12:56:14] [V] [TRT] Convolution input dimensions: (1, 64, 180, 180)
[03/24/2023-12:56:14] [V] [TRT] Registering layer: Conv_101 for ONNX node: Conv_101
[03/24/2023-12:56:14] [V] [TRT] Using kernel: (3, 3), strides: (1, 1), prepadding: (1, 1), postpadding: (1, 1), dilations: (1, 1), numOutputs: 64
[03/24/2023-12:56:14] [V] [TRT] Convolution output dimensions: (1, 64, 180, 180)
[03/24/2023-12:56:14] [V] [TRT] Registering tensor: input.336 for ONNX tensor: input.336
[03/24/2023-12:56:14] [V] [TRT] Conv_101 [Conv] outputs: [input.336 -> (1, 64, 180, 180)[FLOAT]], 
[03/24/2023-12:56:14] [V] [TRT] Parsing node: Relu_102 [Relu]
[03/24/2023-12:56:14] [V] [TRT] Searching for input: input.336
[03/24/2023-12:56:14] [V] [TRT] Relu_102 [Relu] inputs: [input.336 -> (1, 64, 180, 180)[FLOAT]], 
[03/24/2023-12:56:14] [V] [TRT] Registering layer: Relu_102 for ONNX node: Relu_102
[03/24/2023-12:56:14] [V] [TRT] Registering tensor: input.340 for ONNX tensor: input.340
[03/24/2023-12:56:14] [V] [TRT] Relu_102 [Relu] outputs: [input.340 -> (1, 64, 180, 180)[FLOAT]], 
[03/24/2023-12:56:14] [V] [TRT] Parsing node: Conv_103 [Conv]
[03/24/2023-12:56:14] [V] [TRT] Searching for input: input.340
[03/24/2023-12:56:14] [V] [TRT] Searching for input: model.bbox_head.tasks.2.height.3.weight
[03/24/2023-12:56:14] [V] [TRT] Searching for input: model.bbox_head.tasks.2.height.3.bias
[03/24/2023-12:56:14] [V] [TRT] Conv_103 [Conv] inputs: [input.340 -> (1, 64, 180, 180)[FLOAT]], [model.bbox_head.tasks.2.height.3.weight -> (1, 64, 3, 3)[FLOAT]], [model.bbox_head.tasks.2.height.3.bias -> (1)[FLOAT]], 
[03/24/2023-12:56:14] [V] [TRT] Convolution input dimensions: (1, 64, 180, 180)
[03/24/2023-12:56:14] [V] [TRT] Registering layer: Conv_103 for ONNX node: Conv_103
[03/24/2023-12:56:14] [V] [TRT] Using kernel: (3, 3), strides: (1, 1), prepadding: (1, 1), postpadding: (1, 1), dilations: (1, 1), numOutputs: 1
[03/24/2023-12:56:14] [V] [TRT] Convolution output dimensions: (1, 1, 180, 180)
[03/24/2023-12:56:14] [V] [TRT] Registering tensor: height_2_13 for ONNX tensor: height_2
[03/24/2023-12:56:14] [V] [TRT] Conv_103 [Conv] outputs: [height_2 -> (1, 1, 180, 180)[FLOAT]], 
[03/24/2023-12:56:14] [V] [TRT] Parsing node: Conv_104 [Conv]
[03/24/2023-12:56:14] [V] [TRT] Searching for input: onnx::Conv_651
[03/24/2023-12:56:14] [V] [TRT] Searching for input: onnx::Conv_881
[03/24/2023-12:56:14] [V] [TRT] Searching for input: onnx::Conv_882
[03/24/2023-12:56:14] [V] [TRT] Conv_104 [Conv] inputs: [onnx::Conv_651 -> (1, 64, 180, 180)[FLOAT]], [onnx::Conv_881 -> (64, 64, 3, 3)[FLOAT]], [onnx::Conv_882 -> (64)[FLOAT]], 
[03/24/2023-12:56:14] [V] [TRT] Convolution input dimensions: (1, 64, 180, 180)
[03/24/2023-12:56:14] [V] [TRT] Registering layer: Conv_104 for ONNX node: Conv_104
[03/24/2023-12:56:14] [V] [TRT] Using kernel: (3, 3), strides: (1, 1), prepadding: (1, 1), postpadding: (1, 1), dilations: (1, 1), numOutputs: 64
[03/24/2023-12:56:14] [V] [TRT] Convolution output dimensions: (1, 64, 180, 180)
[03/24/2023-12:56:14] [V] [TRT] Registering tensor: input.348 for ONNX tensor: input.348
[03/24/2023-12:56:14] [V] [TRT] Conv_104 [Conv] outputs: [input.348 -> (1, 64, 180, 180)[FLOAT]], 
[03/24/2023-12:56:14] [V] [TRT] Parsing node: Relu_105 [Relu]
[03/24/2023-12:56:14] [V] [TRT] Searching for input: input.348
[03/24/2023-12:56:14] [V] [TRT] Relu_105 [Relu] inputs: [input.348 -> (1, 64, 180, 180)[FLOAT]], 
[03/24/2023-12:56:14] [V] [TRT] Registering layer: Relu_105 for ONNX node: Relu_105
[03/24/2023-12:56:14] [V] [TRT] Registering tensor: input.352 for ONNX tensor: input.352
[03/24/2023-12:56:14] [V] [TRT] Relu_105 [Relu] outputs: [input.352 -> (1, 64, 180, 180)[FLOAT]], 
[03/24/2023-12:56:14] [V] [TRT] Parsing node: Conv_106 [Conv]
[03/24/2023-12:56:14] [V] [TRT] Searching for input: input.352
[03/24/2023-12:56:14] [V] [TRT] Searching for input: model.bbox_head.tasks.2.dim.3.weight
[03/24/2023-12:56:14] [V] [TRT] Searching for input: model.bbox_head.tasks.2.dim.3.bias
[03/24/2023-12:56:14] [V] [TRT] Conv_106 [Conv] inputs: [input.352 -> (1, 64, 180, 180)[FLOAT]], [model.bbox_head.tasks.2.dim.3.weight -> (3, 64, 3, 3)[FLOAT]], [model.bbox_head.tasks.2.dim.3.bias -> (3)[FLOAT]], 
[03/24/2023-12:56:14] [V] [TRT] Convolution input dimensions: (1, 64, 180, 180)
[03/24/2023-12:56:14] [V] [TRT] Registering layer: Conv_106 for ONNX node: Conv_106
[03/24/2023-12:56:14] [V] [TRT] Using kernel: (3, 3), strides: (1, 1), prepadding: (1, 1), postpadding: (1, 1), dilations: (1, 1), numOutputs: 3
[03/24/2023-12:56:14] [V] [TRT] Convolution output dimensions: (1, 3, 180, 180)
[03/24/2023-12:56:14] [V] [TRT] Registering tensor: dim_2_14 for ONNX tensor: dim_2
[03/24/2023-12:56:14] [V] [TRT] Conv_106 [Conv] outputs: [dim_2 -> (1, 3, 180, 180)[FLOAT]], 
[03/24/2023-12:56:14] [V] [TRT] Parsing node: Conv_107 [Conv]
[03/24/2023-12:56:14] [V] [TRT] Searching for input: onnx::Conv_651
[03/24/2023-12:56:14] [V] [TRT] Searching for input: onnx::Conv_884
[03/24/2023-12:56:14] [V] [TRT] Searching for input: onnx::Conv_885
[03/24/2023-12:56:14] [V] [TRT] Conv_107 [Conv] inputs: [onnx::Conv_651 -> (1, 64, 180, 180)[FLOAT]], [onnx::Conv_884 -> (64, 64, 3, 3)[FLOAT]], [onnx::Conv_885 -> (64)[FLOAT]], 
[03/24/2023-12:56:14] [V] [TRT] Convolution input dimensions: (1, 64, 180, 180)
[03/24/2023-12:56:14] [V] [TRT] Registering layer: Conv_107 for ONNX node: Conv_107
[03/24/2023-12:56:14] [V] [TRT] Using kernel: (3, 3), strides: (1, 1), prepadding: (1, 1), postpadding: (1, 1), dilations: (1, 1), numOutputs: 64
[03/24/2023-12:56:14] [V] [TRT] Convolution output dimensions: (1, 64, 180, 180)
[03/24/2023-12:56:14] [V] [TRT] Registering tensor: input.360 for ONNX tensor: input.360
[03/24/2023-12:56:14] [V] [TRT] Conv_107 [Conv] outputs: [input.360 -> (1, 64, 180, 180)[FLOAT]], 
[03/24/2023-12:56:14] [V] [TRT] Parsing node: Relu_108 [Relu]
[03/24/2023-12:56:14] [V] [TRT] Searching for input: input.360
[03/24/2023-12:56:14] [V] [TRT] Relu_108 [Relu] inputs: [input.360 -> (1, 64, 180, 180)[FLOAT]], 
[03/24/2023-12:56:14] [V] [TRT] Registering layer: Relu_108 for ONNX node: Relu_108
[03/24/2023-12:56:14] [V] [TRT] Registering tensor: input.364 for ONNX tensor: input.364
[03/24/2023-12:56:14] [V] [TRT] Relu_108 [Relu] outputs: [input.364 -> (1, 64, 180, 180)[FLOAT]], 
[03/24/2023-12:56:14] [V] [TRT] Parsing node: Conv_109 [Conv]
[03/24/2023-12:56:14] [V] [TRT] Searching for input: input.364
[03/24/2023-12:56:14] [V] [TRT] Searching for input: model.bbox_head.tasks.2.rot.3.weight
[03/24/2023-12:56:14] [V] [TRT] Searching for input: model.bbox_head.tasks.2.rot.3.bias
[03/24/2023-12:56:14] [V] [TRT] Conv_109 [Conv] inputs: [input.364 -> (1, 64, 180, 180)[FLOAT]], [model.bbox_head.tasks.2.rot.3.weight -> (2, 64, 3, 3)[FLOAT]], [model.bbox_head.tasks.2.rot.3.bias -> (2)[FLOAT]], 
[03/24/2023-12:56:14] [V] [TRT] Convolution input dimensions: (1, 64, 180, 180)
[03/24/2023-12:56:14] [V] [TRT] Registering layer: Conv_109 for ONNX node: Conv_109
[03/24/2023-12:56:14] [V] [TRT] Using kernel: (3, 3), strides: (1, 1), prepadding: (1, 1), postpadding: (1, 1), dilations: (1, 1), numOutputs: 2
[03/24/2023-12:56:14] [V] [TRT] Convolution output dimensions: (1, 2, 180, 180)
[03/24/2023-12:56:14] [V] [TRT] Registering tensor: rot_2_15 for ONNX tensor: rot_2
[03/24/2023-12:56:14] [V] [TRT] Conv_109 [Conv] outputs: [rot_2 -> (1, 2, 180, 180)[FLOAT]], 
[03/24/2023-12:56:14] [V] [TRT] Parsing node: Conv_110 [Conv]
[03/24/2023-12:56:14] [V] [TRT] Searching for input: onnx::Conv_651
[03/24/2023-12:56:14] [V] [TRT] Searching for input: onnx::Conv_887
[03/24/2023-12:56:14] [V] [TRT] Searching for input: onnx::Conv_888
[03/24/2023-12:56:14] [V] [TRT] Conv_110 [Conv] inputs: [onnx::Conv_651 -> (1, 64, 180, 180)[FLOAT]], [onnx::Conv_887 -> (64, 64, 3, 3)[FLOAT]], [onnx::Conv_888 -> (64)[FLOAT]], 
[03/24/2023-12:56:14] [V] [TRT] Convolution input dimensions: (1, 64, 180, 180)
[03/24/2023-12:56:14] [V] [TRT] Registering layer: Conv_110 for ONNX node: Conv_110
[03/24/2023-12:56:14] [V] [TRT] Using kernel: (3, 3), strides: (1, 1), prepadding: (1, 1), postpadding: (1, 1), dilations: (1, 1), numOutputs: 64
[03/24/2023-12:56:14] [V] [TRT] Convolution output dimensions: (1, 64, 180, 180)
[03/24/2023-12:56:14] [V] [TRT] Registering tensor: input.372 for ONNX tensor: input.372
[03/24/2023-12:56:14] [V] [TRT] Conv_110 [Conv] outputs: [input.372 -> (1, 64, 180, 180)[FLOAT]], 
[03/24/2023-12:56:14] [V] [TRT] Parsing node: Relu_111 [Relu]
[03/24/2023-12:56:14] [V] [TRT] Searching for input: input.372
[03/24/2023-12:56:14] [V] [TRT] Relu_111 [Relu] inputs: [input.372 -> (1, 64, 180, 180)[FLOAT]], 
[03/24/2023-12:56:14] [V] [TRT] Registering layer: Relu_111 for ONNX node: Relu_111
[03/24/2023-12:56:14] [V] [TRT] Registering tensor: input.376 for ONNX tensor: input.376
[03/24/2023-12:56:14] [V] [TRT] Relu_111 [Relu] outputs: [input.376 -> (1, 64, 180, 180)[FLOAT]], 
[03/24/2023-12:56:14] [V] [TRT] Parsing node: Conv_112 [Conv]
[03/24/2023-12:56:14] [V] [TRT] Searching for input: input.376
[03/24/2023-12:56:14] [V] [TRT] Searching for input: model.bbox_head.tasks.2.vel.3.weight
[03/24/2023-12:56:14] [V] [TRT] Searching for input: model.bbox_head.tasks.2.vel.3.bias
[03/24/2023-12:56:14] [V] [TRT] Conv_112 [Conv] inputs: [input.376 -> (1, 64, 180, 180)[FLOAT]], [model.bbox_head.tasks.2.vel.3.weight -> (2, 64, 3, 3)[FLOAT]], [model.bbox_head.tasks.2.vel.3.bias -> (2)[FLOAT]], 
[03/24/2023-12:56:14] [V] [TRT] Convolution input dimensions: (1, 64, 180, 180)
[03/24/2023-12:56:14] [V] [TRT] Registering layer: Conv_112 for ONNX node: Conv_112
[03/24/2023-12:56:14] [V] [TRT] Using kernel: (3, 3), strides: (1, 1), prepadding: (1, 1), postpadding: (1, 1), dilations: (1, 1), numOutputs: 2
[03/24/2023-12:56:14] [V] [TRT] Convolution output dimensions: (1, 2, 180, 180)
[03/24/2023-12:56:14] [V] [TRT] Registering tensor: vel_2_16 for ONNX tensor: vel_2
[03/24/2023-12:56:14] [V] [TRT] Conv_112 [Conv] outputs: [vel_2 -> (1, 2, 180, 180)[FLOAT]], 
[03/24/2023-12:56:14] [V] [TRT] Parsing node: Conv_113 [Conv]
[03/24/2023-12:56:14] [V] [TRT] Searching for input: onnx::Conv_651
[03/24/2023-12:56:14] [V] [TRT] Searching for input: onnx::Conv_890
[03/24/2023-12:56:14] [V] [TRT] Searching for input: onnx::Conv_891
[03/24/2023-12:56:14] [V] [TRT] Conv_113 [Conv] inputs: [onnx::Conv_651 -> (1, 64, 180, 180)[FLOAT]], [onnx::Conv_890 -> (64, 64, 3, 3)[FLOAT]], [onnx::Conv_891 -> (64)[FLOAT]], 
[03/24/2023-12:56:14] [V] [TRT] Convolution input dimensions: (1, 64, 180, 180)
[03/24/2023-12:56:14] [V] [TRT] Registering layer: Conv_113 for ONNX node: Conv_113
[03/24/2023-12:56:14] [V] [TRT] Using kernel: (3, 3), strides: (1, 1), prepadding: (1, 1), postpadding: (1, 1), dilations: (1, 1), numOutputs: 64
[03/24/2023-12:56:14] [V] [TRT] Convolution output dimensions: (1, 64, 180, 180)
[03/24/2023-12:56:14] [V] [TRT] Registering tensor: input.384 for ONNX tensor: input.384
[03/24/2023-12:56:14] [V] [TRT] Conv_113 [Conv] outputs: [input.384 -> (1, 64, 180, 180)[FLOAT]], 
[03/24/2023-12:56:14] [V] [TRT] Parsing node: Relu_114 [Relu]
[03/24/2023-12:56:14] [V] [TRT] Searching for input: input.384
[03/24/2023-12:56:14] [V] [TRT] Relu_114 [Relu] inputs: [input.384 -> (1, 64, 180, 180)[FLOAT]], 
[03/24/2023-12:56:14] [V] [TRT] Registering layer: Relu_114 for ONNX node: Relu_114
[03/24/2023-12:56:14] [V] [TRT] Registering tensor: input.388 for ONNX tensor: input.388
[03/24/2023-12:56:14] [V] [TRT] Relu_114 [Relu] outputs: [input.388 -> (1, 64, 180, 180)[FLOAT]], 
[03/24/2023-12:56:14] [V] [TRT] Parsing node: Conv_115 [Conv]
[03/24/2023-12:56:14] [V] [TRT] Searching for input: input.388
[03/24/2023-12:56:14] [V] [TRT] Searching for input: model.bbox_head.tasks.2.hm.3.weight
[03/24/2023-12:56:14] [V] [TRT] Searching for input: model.bbox_head.tasks.2.hm.3.bias
[03/24/2023-12:56:14] [V] [TRT] Conv_115 [Conv] inputs: [input.388 -> (1, 64, 180, 180)[FLOAT]], [model.bbox_head.tasks.2.hm.3.weight -> (2, 64, 3, 3)[FLOAT]], [model.bbox_head.tasks.2.hm.3.bias -> (2)[FLOAT]], 
[03/24/2023-12:56:14] [V] [TRT] Convolution input dimensions: (1, 64, 180, 180)
[03/24/2023-12:56:14] [V] [TRT] Registering layer: Conv_115 for ONNX node: Conv_115
[03/24/2023-12:56:14] [V] [TRT] Using kernel: (3, 3), strides: (1, 1), prepadding: (1, 1), postpadding: (1, 1), dilations: (1, 1), numOutputs: 2
[03/24/2023-12:56:14] [V] [TRT] Convolution output dimensions: (1, 2, 180, 180)
[03/24/2023-12:56:14] [V] [TRT] Registering tensor: hm_2_17 for ONNX tensor: hm_2
[03/24/2023-12:56:14] [V] [TRT] Conv_115 [Conv] outputs: [hm_2 -> (1, 2, 180, 180)[FLOAT]], 
[03/24/2023-12:56:14] [V] [TRT] Parsing node: Conv_116 [Conv]
[03/24/2023-12:56:14] [V] [TRT] Searching for input: onnx::Conv_651
[03/24/2023-12:56:14] [V] [TRT] Searching for input: onnx::Conv_893
[03/24/2023-12:56:14] [V] [TRT] Searching for input: onnx::Conv_894
[03/24/2023-12:56:14] [V] [TRT] Conv_116 [Conv] inputs: [onnx::Conv_651 -> (1, 64, 180, 180)[FLOAT]], [onnx::Conv_893 -> (64, 64, 3, 3)[FLOAT]], [onnx::Conv_894 -> (64)[FLOAT]], 
[03/24/2023-12:56:14] [V] [TRT] Convolution input dimensions: (1, 64, 180, 180)
[03/24/2023-12:56:14] [V] [TRT] Registering layer: Conv_116 for ONNX node: Conv_116
[03/24/2023-12:56:14] [V] [TRT] Using kernel: (3, 3), strides: (1, 1), prepadding: (1, 1), postpadding: (1, 1), dilations: (1, 1), numOutputs: 64
[03/24/2023-12:56:14] [V] [TRT] Convolution output dimensions: (1, 64, 180, 180)
[03/24/2023-12:56:14] [V] [TRT] Registering tensor: input.396 for ONNX tensor: input.396
[03/24/2023-12:56:14] [V] [TRT] Conv_116 [Conv] outputs: [input.396 -> (1, 64, 180, 180)[FLOAT]], 
[03/24/2023-12:56:14] [V] [TRT] Parsing node: Relu_117 [Relu]
[03/24/2023-12:56:14] [V] [TRT] Searching for input: input.396
[03/24/2023-12:56:14] [V] [TRT] Relu_117 [Relu] inputs: [input.396 -> (1, 64, 180, 180)[FLOAT]], 
[03/24/2023-12:56:14] [V] [TRT] Registering layer: Relu_117 for ONNX node: Relu_117
[03/24/2023-12:56:14] [V] [TRT] Registering tensor: input.400 for ONNX tensor: input.400
[03/24/2023-12:56:14] [V] [TRT] Relu_117 [Relu] outputs: [input.400 -> (1, 64, 180, 180)[FLOAT]], 
[03/24/2023-12:56:14] [V] [TRT] Parsing node: Conv_118 [Conv]
[03/24/2023-12:56:14] [V] [TRT] Searching for input: input.400
[03/24/2023-12:56:14] [V] [TRT] Searching for input: model.bbox_head.tasks.3.reg.3.weight
[03/24/2023-12:56:14] [V] [TRT] Searching for input: model.bbox_head.tasks.3.reg.3.bias
[03/24/2023-12:56:14] [V] [TRT] Conv_118 [Conv] inputs: [input.400 -> (1, 64, 180, 180)[FLOAT]], [model.bbox_head.tasks.3.reg.3.weight -> (2, 64, 3, 3)[FLOAT]], [model.bbox_head.tasks.3.reg.3.bias -> (2)[FLOAT]], 
[03/24/2023-12:56:14] [V] [TRT] Convolution input dimensions: (1, 64, 180, 180)
[03/24/2023-12:56:14] [V] [TRT] Registering layer: Conv_118 for ONNX node: Conv_118
[03/24/2023-12:56:14] [V] [TRT] Using kernel: (3, 3), strides: (1, 1), prepadding: (1, 1), postpadding: (1, 1), dilations: (1, 1), numOutputs: 2
[03/24/2023-12:56:14] [V] [TRT] Convolution output dimensions: (1, 2, 180, 180)
[03/24/2023-12:56:14] [V] [TRT] Registering tensor: reg_3_18 for ONNX tensor: reg_3
[03/24/2023-12:56:14] [V] [TRT] Conv_118 [Conv] outputs: [reg_3 -> (1, 2, 180, 180)[FLOAT]], 
[03/24/2023-12:56:14] [V] [TRT] Parsing node: Conv_119 [Conv]
[03/24/2023-12:56:14] [V] [TRT] Searching for input: onnx::Conv_651
[03/24/2023-12:56:14] [V] [TRT] Searching for input: onnx::Conv_896
[03/24/2023-12:56:14] [V] [TRT] Searching for input: onnx::Conv_897
[03/24/2023-12:56:14] [V] [TRT] Conv_119 [Conv] inputs: [onnx::Conv_651 -> (1, 64, 180, 180)[FLOAT]], [onnx::Conv_896 -> (64, 64, 3, 3)[FLOAT]], [onnx::Conv_897 -> (64)[FLOAT]], 
[03/24/2023-12:56:14] [V] [TRT] Convolution input dimensions: (1, 64, 180, 180)
[03/24/2023-12:56:14] [V] [TRT] Registering layer: Conv_119 for ONNX node: Conv_119
[03/24/2023-12:56:14] [V] [TRT] Using kernel: (3, 3), strides: (1, 1), prepadding: (1, 1), postpadding: (1, 1), dilations: (1, 1), numOutputs: 64
[03/24/2023-12:56:14] [V] [TRT] Convolution output dimensions: (1, 64, 180, 180)
[03/24/2023-12:56:14] [V] [TRT] Registering tensor: input.408 for ONNX tensor: input.408
[03/24/2023-12:56:14] [V] [TRT] Conv_119 [Conv] outputs: [input.408 -> (1, 64, 180, 180)[FLOAT]], 
[03/24/2023-12:56:14] [V] [TRT] Parsing node: Relu_120 [Relu]
[03/24/2023-12:56:14] [V] [TRT] Searching for input: input.408
[03/24/2023-12:56:14] [V] [TRT] Relu_120 [Relu] inputs: [input.408 -> (1, 64, 180, 180)[FLOAT]], 
[03/24/2023-12:56:14] [V] [TRT] Registering layer: Relu_120 for ONNX node: Relu_120
[03/24/2023-12:56:14] [V] [TRT] Registering tensor: input.412 for ONNX tensor: input.412
[03/24/2023-12:56:14] [V] [TRT] Relu_120 [Relu] outputs: [input.412 -> (1, 64, 180, 180)[FLOAT]], 
[03/24/2023-12:56:14] [V] [TRT] Parsing node: Conv_121 [Conv]
[03/24/2023-12:56:14] [V] [TRT] Searching for input: input.412
[03/24/2023-12:56:14] [V] [TRT] Searching for input: model.bbox_head.tasks.3.height.3.weight
[03/24/2023-12:56:14] [V] [TRT] Searching for input: model.bbox_head.tasks.3.height.3.bias
[03/24/2023-12:56:14] [V] [TRT] Conv_121 [Conv] inputs: [input.412 -> (1, 64, 180, 180)[FLOAT]], [model.bbox_head.tasks.3.height.3.weight -> (1, 64, 3, 3)[FLOAT]], [model.bbox_head.tasks.3.height.3.bias -> (1)[FLOAT]], 
[03/24/2023-12:56:14] [V] [TRT] Convolution input dimensions: (1, 64, 180, 180)
[03/24/2023-12:56:14] [V] [TRT] Registering layer: Conv_121 for ONNX node: Conv_121
[03/24/2023-12:56:14] [V] [TRT] Using kernel: (3, 3), strides: (1, 1), prepadding: (1, 1), postpadding: (1, 1), dilations: (1, 1), numOutputs: 1
[03/24/2023-12:56:14] [V] [TRT] Convolution output dimensions: (1, 1, 180, 180)
[03/24/2023-12:56:14] [V] [TRT] Registering tensor: height_3_19 for ONNX tensor: height_3
[03/24/2023-12:56:14] [V] [TRT] Conv_121 [Conv] outputs: [height_3 -> (1, 1, 180, 180)[FLOAT]], 
[03/24/2023-12:56:14] [V] [TRT] Parsing node: Conv_122 [Conv]
[03/24/2023-12:56:14] [V] [TRT] Searching for input: onnx::Conv_651
[03/24/2023-12:56:14] [V] [TRT] Searching for input: onnx::Conv_899
[03/24/2023-12:56:14] [V] [TRT] Searching for input: onnx::Conv_900
[03/24/2023-12:56:14] [V] [TRT] Conv_122 [Conv] inputs: [onnx::Conv_651 -> (1, 64, 180, 180)[FLOAT]], [onnx::Conv_899 -> (64, 64, 3, 3)[FLOAT]], [onnx::Conv_900 -> (64)[FLOAT]], 
[03/24/2023-12:56:14] [V] [TRT] Convolution input dimensions: (1, 64, 180, 180)
[03/24/2023-12:56:14] [V] [TRT] Registering layer: Conv_122 for ONNX node: Conv_122
[03/24/2023-12:56:14] [V] [TRT] Using kernel: (3, 3), strides: (1, 1), prepadding: (1, 1), postpadding: (1, 1), dilations: (1, 1), numOutputs: 64
[03/24/2023-12:56:14] [V] [TRT] Convolution output dimensions: (1, 64, 180, 180)
[03/24/2023-12:56:14] [V] [TRT] Registering tensor: input.420 for ONNX tensor: input.420
[03/24/2023-12:56:14] [V] [TRT] Conv_122 [Conv] outputs: [input.420 -> (1, 64, 180, 180)[FLOAT]], 
[03/24/2023-12:56:14] [V] [TRT] Parsing node: Relu_123 [Relu]
[03/24/2023-12:56:14] [V] [TRT] Searching for input: input.420
[03/24/2023-12:56:14] [V] [TRT] Relu_123 [Relu] inputs: [input.420 -> (1, 64, 180, 180)[FLOAT]], 
[03/24/2023-12:56:14] [V] [TRT] Registering layer: Relu_123 for ONNX node: Relu_123
[03/24/2023-12:56:14] [V] [TRT] Registering tensor: input.424 for ONNX tensor: input.424
[03/24/2023-12:56:14] [V] [TRT] Relu_123 [Relu] outputs: [input.424 -> (1, 64, 180, 180)[FLOAT]], 
[03/24/2023-12:56:14] [V] [TRT] Parsing node: Conv_124 [Conv]
[03/24/2023-12:56:14] [V] [TRT] Searching for input: input.424
[03/24/2023-12:56:14] [V] [TRT] Searching for input: model.bbox_head.tasks.3.dim.3.weight
[03/24/2023-12:56:14] [V] [TRT] Searching for input: model.bbox_head.tasks.3.dim.3.bias
[03/24/2023-12:56:14] [V] [TRT] Conv_124 [Conv] inputs: [input.424 -> (1, 64, 180, 180)[FLOAT]], [model.bbox_head.tasks.3.dim.3.weight -> (3, 64, 3, 3)[FLOAT]], [model.bbox_head.tasks.3.dim.3.bias -> (3)[FLOAT]], 
[03/24/2023-12:56:14] [V] [TRT] Convolution input dimensions: (1, 64, 180, 180)
[03/24/2023-12:56:14] [V] [TRT] Registering layer: Conv_124 for ONNX node: Conv_124
[03/24/2023-12:56:14] [V] [TRT] Using kernel: (3, 3), strides: (1, 1), prepadding: (1, 1), postpadding: (1, 1), dilations: (1, 1), numOutputs: 3
[03/24/2023-12:56:14] [V] [TRT] Convolution output dimensions: (1, 3, 180, 180)
[03/24/2023-12:56:14] [V] [TRT] Registering tensor: dim_3_20 for ONNX tensor: dim_3
[03/24/2023-12:56:14] [V] [TRT] Conv_124 [Conv] outputs: [dim_3 -> (1, 3, 180, 180)[FLOAT]], 
[03/24/2023-12:56:14] [V] [TRT] Parsing node: Conv_125 [Conv]
[03/24/2023-12:56:14] [V] [TRT] Searching for input: onnx::Conv_651
[03/24/2023-12:56:14] [V] [TRT] Searching for input: onnx::Conv_902
[03/24/2023-12:56:14] [V] [TRT] Searching for input: onnx::Conv_903
[03/24/2023-12:56:14] [V] [TRT] Conv_125 [Conv] inputs: [onnx::Conv_651 -> (1, 64, 180, 180)[FLOAT]], [onnx::Conv_902 -> (64, 64, 3, 3)[FLOAT]], [onnx::Conv_903 -> (64)[FLOAT]], 
[03/24/2023-12:56:14] [V] [TRT] Convolution input dimensions: (1, 64, 180, 180)
[03/24/2023-12:56:14] [V] [TRT] Registering layer: Conv_125 for ONNX node: Conv_125
[03/24/2023-12:56:14] [V] [TRT] Using kernel: (3, 3), strides: (1, 1), prepadding: (1, 1), postpadding: (1, 1), dilations: (1, 1), numOutputs: 64
[03/24/2023-12:56:14] [V] [TRT] Convolution output dimensions: (1, 64, 180, 180)
[03/24/2023-12:56:14] [V] [TRT] Registering tensor: input.432 for ONNX tensor: input.432
[03/24/2023-12:56:14] [V] [TRT] Conv_125 [Conv] outputs: [input.432 -> (1, 64, 180, 180)[FLOAT]], 
[03/24/2023-12:56:14] [V] [TRT] Parsing node: Relu_126 [Relu]
[03/24/2023-12:56:14] [V] [TRT] Searching for input: input.432
[03/24/2023-12:56:14] [V] [TRT] Relu_126 [Relu] inputs: [input.432 -> (1, 64, 180, 180)[FLOAT]], 
[03/24/2023-12:56:14] [V] [TRT] Registering layer: Relu_126 for ONNX node: Relu_126
[03/24/2023-12:56:14] [V] [TRT] Registering tensor: input.436 for ONNX tensor: input.436
[03/24/2023-12:56:14] [V] [TRT] Relu_126 [Relu] outputs: [input.436 -> (1, 64, 180, 180)[FLOAT]], 
[03/24/2023-12:56:14] [V] [TRT] Parsing node: Conv_127 [Conv]
[03/24/2023-12:56:14] [V] [TRT] Searching for input: input.436
[03/24/2023-12:56:14] [V] [TRT] Searching for input: model.bbox_head.tasks.3.rot.3.weight
[03/24/2023-12:56:14] [V] [TRT] Searching for input: model.bbox_head.tasks.3.rot.3.bias
[03/24/2023-12:56:14] [V] [TRT] Conv_127 [Conv] inputs: [input.436 -> (1, 64, 180, 180)[FLOAT]], [model.bbox_head.tasks.3.rot.3.weight -> (2, 64, 3, 3)[FLOAT]], [model.bbox_head.tasks.3.rot.3.bias -> (2)[FLOAT]], 
[03/24/2023-12:56:14] [V] [TRT] Convolution input dimensions: (1, 64, 180, 180)
[03/24/2023-12:56:14] [V] [TRT] Registering layer: Conv_127 for ONNX node: Conv_127
[03/24/2023-12:56:14] [V] [TRT] Using kernel: (3, 3), strides: (1, 1), prepadding: (1, 1), postpadding: (1, 1), dilations: (1, 1), numOutputs: 2
[03/24/2023-12:56:14] [V] [TRT] Convolution output dimensions: (1, 2, 180, 180)
[03/24/2023-12:56:14] [V] [TRT] Registering tensor: rot_3_21 for ONNX tensor: rot_3
[03/24/2023-12:56:14] [V] [TRT] Conv_127 [Conv] outputs: [rot_3 -> (1, 2, 180, 180)[FLOAT]], 
[03/24/2023-12:56:14] [V] [TRT] Parsing node: Conv_128 [Conv]
[03/24/2023-12:56:14] [V] [TRT] Searching for input: onnx::Conv_651
[03/24/2023-12:56:14] [V] [TRT] Searching for input: onnx::Conv_905
[03/24/2023-12:56:14] [V] [TRT] Searching for input: onnx::Conv_906
[03/24/2023-12:56:14] [V] [TRT] Conv_128 [Conv] inputs: [onnx::Conv_651 -> (1, 64, 180, 180)[FLOAT]], [onnx::Conv_905 -> (64, 64, 3, 3)[FLOAT]], [onnx::Conv_906 -> (64)[FLOAT]], 
[03/24/2023-12:56:14] [V] [TRT] Convolution input dimensions: (1, 64, 180, 180)
[03/24/2023-12:56:14] [V] [TRT] Registering layer: Conv_128 for ONNX node: Conv_128
[03/24/2023-12:56:14] [V] [TRT] Using kernel: (3, 3), strides: (1, 1), prepadding: (1, 1), postpadding: (1, 1), dilations: (1, 1), numOutputs: 64
[03/24/2023-12:56:14] [V] [TRT] Convolution output dimensions: (1, 64, 180, 180)
[03/24/2023-12:56:14] [V] [TRT] Registering tensor: input.444 for ONNX tensor: input.444
[03/24/2023-12:56:14] [V] [TRT] Conv_128 [Conv] outputs: [input.444 -> (1, 64, 180, 180)[FLOAT]], 
[03/24/2023-12:56:14] [V] [TRT] Parsing node: Relu_129 [Relu]
[03/24/2023-12:56:14] [V] [TRT] Searching for input: input.444
[03/24/2023-12:56:14] [V] [TRT] Relu_129 [Relu] inputs: [input.444 -> (1, 64, 180, 180)[FLOAT]], 
[03/24/2023-12:56:14] [V] [TRT] Registering layer: Relu_129 for ONNX node: Relu_129
[03/24/2023-12:56:14] [V] [TRT] Registering tensor: input.448 for ONNX tensor: input.448
[03/24/2023-12:56:14] [V] [TRT] Relu_129 [Relu] outputs: [input.448 -> (1, 64, 180, 180)[FLOAT]], 
[03/24/2023-12:56:14] [V] [TRT] Parsing node: Conv_130 [Conv]
[03/24/2023-12:56:14] [V] [TRT] Searching for input: input.448
[03/24/2023-12:56:14] [V] [TRT] Searching for input: model.bbox_head.tasks.3.vel.3.weight
[03/24/2023-12:56:14] [V] [TRT] Searching for input: model.bbox_head.tasks.3.vel.3.bias
[03/24/2023-12:56:14] [V] [TRT] Conv_130 [Conv] inputs: [input.448 -> (1, 64, 180, 180)[FLOAT]], [model.bbox_head.tasks.3.vel.3.weight -> (2, 64, 3, 3)[FLOAT]], [model.bbox_head.tasks.3.vel.3.bias -> (2)[FLOAT]], 
[03/24/2023-12:56:14] [V] [TRT] Convolution input dimensions: (1, 64, 180, 180)
[03/24/2023-12:56:14] [V] [TRT] Registering layer: Conv_130 for ONNX node: Conv_130
[03/24/2023-12:56:14] [V] [TRT] Using kernel: (3, 3), strides: (1, 1), prepadding: (1, 1), postpadding: (1, 1), dilations: (1, 1), numOutputs: 2
[03/24/2023-12:56:14] [V] [TRT] Convolution output dimensions: (1, 2, 180, 180)
[03/24/2023-12:56:14] [V] [TRT] Registering tensor: vel_3_22 for ONNX tensor: vel_3
[03/24/2023-12:56:14] [V] [TRT] Conv_130 [Conv] outputs: [vel_3 -> (1, 2, 180, 180)[FLOAT]], 
[03/24/2023-12:56:14] [V] [TRT] Parsing node: Conv_131 [Conv]
[03/24/2023-12:56:14] [V] [TRT] Searching for input: onnx::Conv_651
[03/24/2023-12:56:14] [V] [TRT] Searching for input: onnx::Conv_908
[03/24/2023-12:56:14] [V] [TRT] Searching for input: onnx::Conv_909
[03/24/2023-12:56:14] [V] [TRT] Conv_131 [Conv] inputs: [onnx::Conv_651 -> (1, 64, 180, 180)[FLOAT]], [onnx::Conv_908 -> (64, 64, 3, 3)[FLOAT]], [onnx::Conv_909 -> (64)[FLOAT]], 
[03/24/2023-12:56:14] [V] [TRT] Convolution input dimensions: (1, 64, 180, 180)
[03/24/2023-12:56:14] [V] [TRT] Registering layer: Conv_131 for ONNX node: Conv_131
[03/24/2023-12:56:14] [V] [TRT] Using kernel: (3, 3), strides: (1, 1), prepadding: (1, 1), postpadding: (1, 1), dilations: (1, 1), numOutputs: 64
[03/24/2023-12:56:14] [V] [TRT] Convolution output dimensions: (1, 64, 180, 180)
[03/24/2023-12:56:14] [V] [TRT] Registering tensor: input.456 for ONNX tensor: input.456
[03/24/2023-12:56:14] [V] [TRT] Conv_131 [Conv] outputs: [input.456 -> (1, 64, 180, 180)[FLOAT]], 
[03/24/2023-12:56:14] [V] [TRT] Parsing node: Relu_132 [Relu]
[03/24/2023-12:56:14] [V] [TRT] Searching for input: input.456
[03/24/2023-12:56:14] [V] [TRT] Relu_132 [Relu] inputs: [input.456 -> (1, 64, 180, 180)[FLOAT]], 
[03/24/2023-12:56:14] [V] [TRT] Registering layer: Relu_132 for ONNX node: Relu_132
[03/24/2023-12:56:14] [V] [TRT] Registering tensor: input.460 for ONNX tensor: input.460
[03/24/2023-12:56:14] [V] [TRT] Relu_132 [Relu] outputs: [input.460 -> (1, 64, 180, 180)[FLOAT]], 
[03/24/2023-12:56:14] [V] [TRT] Parsing node: Conv_133 [Conv]
[03/24/2023-12:56:14] [V] [TRT] Searching for input: input.460
[03/24/2023-12:56:14] [V] [TRT] Searching for input: model.bbox_head.tasks.3.hm.3.weight
[03/24/2023-12:56:14] [V] [TRT] Searching for input: model.bbox_head.tasks.3.hm.3.bias
[03/24/2023-12:56:14] [V] [TRT] Conv_133 [Conv] inputs: [input.460 -> (1, 64, 180, 180)[FLOAT]], [model.bbox_head.tasks.3.hm.3.weight -> (1, 64, 3, 3)[FLOAT]], [model.bbox_head.tasks.3.hm.3.bias -> (1)[FLOAT]], 
[03/24/2023-12:56:14] [V] [TRT] Convolution input dimensions: (1, 64, 180, 180)
[03/24/2023-12:56:14] [V] [TRT] Registering layer: Conv_133 for ONNX node: Conv_133
[03/24/2023-12:56:14] [V] [TRT] Using kernel: (3, 3), strides: (1, 1), prepadding: (1, 1), postpadding: (1, 1), dilations: (1, 1), numOutputs: 1
[03/24/2023-12:56:14] [V] [TRT] Convolution output dimensions: (1, 1, 180, 180)
[03/24/2023-12:56:14] [V] [TRT] Registering tensor: hm_3_23 for ONNX tensor: hm_3
[03/24/2023-12:56:14] [V] [TRT] Conv_133 [Conv] outputs: [hm_3 -> (1, 1, 180, 180)[FLOAT]], 
[03/24/2023-12:56:14] [V] [TRT] Parsing node: Conv_134 [Conv]
[03/24/2023-12:56:14] [V] [TRT] Searching for input: onnx::Conv_651
[03/24/2023-12:56:14] [V] [TRT] Searching for input: onnx::Conv_911
[03/24/2023-12:56:14] [V] [TRT] Searching for input: onnx::Conv_912
[03/24/2023-12:56:14] [V] [TRT] Conv_134 [Conv] inputs: [onnx::Conv_651 -> (1, 64, 180, 180)[FLOAT]], [onnx::Conv_911 -> (64, 64, 3, 3)[FLOAT]], [onnx::Conv_912 -> (64)[FLOAT]], 
[03/24/2023-12:56:14] [V] [TRT] Convolution input dimensions: (1, 64, 180, 180)
[03/24/2023-12:56:14] [V] [TRT] Registering layer: Conv_134 for ONNX node: Conv_134
[03/24/2023-12:56:14] [V] [TRT] Using kernel: (3, 3), strides: (1, 1), prepadding: (1, 1), postpadding: (1, 1), dilations: (1, 1), numOutputs: 64
[03/24/2023-12:56:14] [V] [TRT] Convolution output dimensions: (1, 64, 180, 180)
[03/24/2023-12:56:14] [V] [TRT] Registering tensor: input.468 for ONNX tensor: input.468
[03/24/2023-12:56:14] [V] [TRT] Conv_134 [Conv] outputs: [input.468 -> (1, 64, 180, 180)[FLOAT]], 
[03/24/2023-12:56:14] [V] [TRT] Parsing node: Relu_135 [Relu]
[03/24/2023-12:56:14] [V] [TRT] Searching for input: input.468
[03/24/2023-12:56:14] [V] [TRT] Relu_135 [Relu] inputs: [input.468 -> (1, 64, 180, 180)[FLOAT]], 
[03/24/2023-12:56:14] [V] [TRT] Registering layer: Relu_135 for ONNX node: Relu_135
[03/24/2023-12:56:14] [V] [TRT] Registering tensor: input.472 for ONNX tensor: input.472
[03/24/2023-12:56:14] [V] [TRT] Relu_135 [Relu] outputs: [input.472 -> (1, 64, 180, 180)[FLOAT]], 
[03/24/2023-12:56:14] [V] [TRT] Parsing node: Conv_136 [Conv]
[03/24/2023-12:56:14] [V] [TRT] Searching for input: input.472
[03/24/2023-12:56:14] [V] [TRT] Searching for input: model.bbox_head.tasks.4.reg.3.weight
[03/24/2023-12:56:14] [V] [TRT] Searching for input: model.bbox_head.tasks.4.reg.3.bias
[03/24/2023-12:56:14] [V] [TRT] Conv_136 [Conv] inputs: [input.472 -> (1, 64, 180, 180)[FLOAT]], [model.bbox_head.tasks.4.reg.3.weight -> (2, 64, 3, 3)[FLOAT]], [model.bbox_head.tasks.4.reg.3.bias -> (2)[FLOAT]], 
[03/24/2023-12:56:14] [V] [TRT] Convolution input dimensions: (1, 64, 180, 180)
[03/24/2023-12:56:14] [V] [TRT] Registering layer: Conv_136 for ONNX node: Conv_136
[03/24/2023-12:56:14] [V] [TRT] Using kernel: (3, 3), strides: (1, 1), prepadding: (1, 1), postpadding: (1, 1), dilations: (1, 1), numOutputs: 2
[03/24/2023-12:56:14] [V] [TRT] Convolution output dimensions: (1, 2, 180, 180)
[03/24/2023-12:56:14] [V] [TRT] Registering tensor: reg_4_24 for ONNX tensor: reg_4
[03/24/2023-12:56:14] [V] [TRT] Conv_136 [Conv] outputs: [reg_4 -> (1, 2, 180, 180)[FLOAT]], 
[03/24/2023-12:56:14] [V] [TRT] Parsing node: Conv_137 [Conv]
[03/24/2023-12:56:14] [V] [TRT] Searching for input: onnx::Conv_651
[03/24/2023-12:56:14] [V] [TRT] Searching for input: onnx::Conv_914
[03/24/2023-12:56:14] [V] [TRT] Searching for input: onnx::Conv_915
[03/24/2023-12:56:14] [V] [TRT] Conv_137 [Conv] inputs: [onnx::Conv_651 -> (1, 64, 180, 180)[FLOAT]], [onnx::Conv_914 -> (64, 64, 3, 3)[FLOAT]], [onnx::Conv_915 -> (64)[FLOAT]], 
[03/24/2023-12:56:14] [V] [TRT] Convolution input dimensions: (1, 64, 180, 180)
[03/24/2023-12:56:14] [V] [TRT] Registering layer: Conv_137 for ONNX node: Conv_137
[03/24/2023-12:56:14] [V] [TRT] Using kernel: (3, 3), strides: (1, 1), prepadding: (1, 1), postpadding: (1, 1), dilations: (1, 1), numOutputs: 64
[03/24/2023-12:56:14] [V] [TRT] Convolution output dimensions: (1, 64, 180, 180)
[03/24/2023-12:56:14] [V] [TRT] Registering tensor: input.480 for ONNX tensor: input.480
[03/24/2023-12:56:14] [V] [TRT] Conv_137 [Conv] outputs: [input.480 -> (1, 64, 180, 180)[FLOAT]], 
[03/24/2023-12:56:14] [V] [TRT] Parsing node: Relu_138 [Relu]
[03/24/2023-12:56:14] [V] [TRT] Searching for input: input.480
[03/24/2023-12:56:14] [V] [TRT] Relu_138 [Relu] inputs: [input.480 -> (1, 64, 180, 180)[FLOAT]], 
[03/24/2023-12:56:14] [V] [TRT] Registering layer: Relu_138 for ONNX node: Relu_138
[03/24/2023-12:56:14] [V] [TRT] Registering tensor: input.484 for ONNX tensor: input.484
[03/24/2023-12:56:14] [V] [TRT] Relu_138 [Relu] outputs: [input.484 -> (1, 64, 180, 180)[FLOAT]], 
[03/24/2023-12:56:14] [V] [TRT] Parsing node: Conv_139 [Conv]
[03/24/2023-12:56:14] [V] [TRT] Searching for input: input.484
[03/24/2023-12:56:14] [V] [TRT] Searching for input: model.bbox_head.tasks.4.height.3.weight
[03/24/2023-12:56:14] [V] [TRT] Searching for input: model.bbox_head.tasks.4.height.3.bias
[03/24/2023-12:56:14] [V] [TRT] Conv_139 [Conv] inputs: [input.484 -> (1, 64, 180, 180)[FLOAT]], [model.bbox_head.tasks.4.height.3.weight -> (1, 64, 3, 3)[FLOAT]], [model.bbox_head.tasks.4.height.3.bias -> (1)[FLOAT]], 
[03/24/2023-12:56:14] [V] [TRT] Convolution input dimensions: (1, 64, 180, 180)
[03/24/2023-12:56:14] [V] [TRT] Registering layer: Conv_139 for ONNX node: Conv_139
[03/24/2023-12:56:14] [V] [TRT] Using kernel: (3, 3), strides: (1, 1), prepadding: (1, 1), postpadding: (1, 1), dilations: (1, 1), numOutputs: 1
[03/24/2023-12:56:14] [V] [TRT] Convolution output dimensions: (1, 1, 180, 180)
[03/24/2023-12:56:14] [V] [TRT] Registering tensor: height_4_25 for ONNX tensor: height_4
[03/24/2023-12:56:14] [V] [TRT] Conv_139 [Conv] outputs: [height_4 -> (1, 1, 180, 180)[FLOAT]], 
[03/24/2023-12:56:14] [V] [TRT] Parsing node: Conv_140 [Conv]
[03/24/2023-12:56:14] [V] [TRT] Searching for input: onnx::Conv_651
[03/24/2023-12:56:14] [V] [TRT] Searching for input: onnx::Conv_917
[03/24/2023-12:56:14] [V] [TRT] Searching for input: onnx::Conv_918
[03/24/2023-12:56:14] [V] [TRT] Conv_140 [Conv] inputs: [onnx::Conv_651 -> (1, 64, 180, 180)[FLOAT]], [onnx::Conv_917 -> (64, 64, 3, 3)[FLOAT]], [onnx::Conv_918 -> (64)[FLOAT]], 
[03/24/2023-12:56:14] [V] [TRT] Convolution input dimensions: (1, 64, 180, 180)
[03/24/2023-12:56:14] [V] [TRT] Registering layer: Conv_140 for ONNX node: Conv_140
[03/24/2023-12:56:14] [V] [TRT] Using kernel: (3, 3), strides: (1, 1), prepadding: (1, 1), postpadding: (1, 1), dilations: (1, 1), numOutputs: 64
[03/24/2023-12:56:14] [V] [TRT] Convolution output dimensions: (1, 64, 180, 180)
[03/24/2023-12:56:14] [V] [TRT] Registering tensor: input.492 for ONNX tensor: input.492
[03/24/2023-12:56:14] [V] [TRT] Conv_140 [Conv] outputs: [input.492 -> (1, 64, 180, 180)[FLOAT]], 
[03/24/2023-12:56:14] [V] [TRT] Parsing node: Relu_141 [Relu]
[03/24/2023-12:56:14] [V] [TRT] Searching for input: input.492
[03/24/2023-12:56:14] [V] [TRT] Relu_141 [Relu] inputs: [input.492 -> (1, 64, 180, 180)[FLOAT]], 
[03/24/2023-12:56:14] [V] [TRT] Registering layer: Relu_141 for ONNX node: Relu_141
[03/24/2023-12:56:14] [V] [TRT] Registering tensor: input.496 for ONNX tensor: input.496
[03/24/2023-12:56:14] [V] [TRT] Relu_141 [Relu] outputs: [input.496 -> (1, 64, 180, 180)[FLOAT]], 
[03/24/2023-12:56:14] [V] [TRT] Parsing node: Conv_142 [Conv]
[03/24/2023-12:56:14] [V] [TRT] Searching for input: input.496
[03/24/2023-12:56:14] [V] [TRT] Searching for input: model.bbox_head.tasks.4.dim.3.weight
[03/24/2023-12:56:14] [V] [TRT] Searching for input: model.bbox_head.tasks.4.dim.3.bias
[03/24/2023-12:56:14] [V] [TRT] Conv_142 [Conv] inputs: [input.496 -> (1, 64, 180, 180)[FLOAT]], [model.bbox_head.tasks.4.dim.3.weight -> (3, 64, 3, 3)[FLOAT]], [model.bbox_head.tasks.4.dim.3.bias -> (3)[FLOAT]], 
[03/24/2023-12:56:14] [V] [TRT] Convolution input dimensions: (1, 64, 180, 180)
[03/24/2023-12:56:14] [V] [TRT] Registering layer: Conv_142 for ONNX node: Conv_142
[03/24/2023-12:56:14] [V] [TRT] Using kernel: (3, 3), strides: (1, 1), prepadding: (1, 1), postpadding: (1, 1), dilations: (1, 1), numOutputs: 3
[03/24/2023-12:56:14] [V] [TRT] Convolution output dimensions: (1, 3, 180, 180)
[03/24/2023-12:56:14] [V] [TRT] Registering tensor: dim_4_26 for ONNX tensor: dim_4
[03/24/2023-12:56:14] [V] [TRT] Conv_142 [Conv] outputs: [dim_4 -> (1, 3, 180, 180)[FLOAT]], 
[03/24/2023-12:56:14] [V] [TRT] Parsing node: Conv_143 [Conv]
[03/24/2023-12:56:14] [V] [TRT] Searching for input: onnx::Conv_651
[03/24/2023-12:56:14] [V] [TRT] Searching for input: onnx::Conv_920
[03/24/2023-12:56:14] [V] [TRT] Searching for input: onnx::Conv_921
[03/24/2023-12:56:14] [V] [TRT] Conv_143 [Conv] inputs: [onnx::Conv_651 -> (1, 64, 180, 180)[FLOAT]], [onnx::Conv_920 -> (64, 64, 3, 3)[FLOAT]], [onnx::Conv_921 -> (64)[FLOAT]], 
[03/24/2023-12:56:14] [V] [TRT] Convolution input dimensions: (1, 64, 180, 180)
[03/24/2023-12:56:14] [V] [TRT] Registering layer: Conv_143 for ONNX node: Conv_143
[03/24/2023-12:56:14] [V] [TRT] Using kernel: (3, 3), strides: (1, 1), prepadding: (1, 1), postpadding: (1, 1), dilations: (1, 1), numOutputs: 64
[03/24/2023-12:56:14] [V] [TRT] Convolution output dimensions: (1, 64, 180, 180)
[03/24/2023-12:56:14] [V] [TRT] Registering tensor: input.504 for ONNX tensor: input.504
[03/24/2023-12:56:14] [V] [TRT] Conv_143 [Conv] outputs: [input.504 -> (1, 64, 180, 180)[FLOAT]], 
[03/24/2023-12:56:14] [V] [TRT] Parsing node: Relu_144 [Relu]
[03/24/2023-12:56:14] [V] [TRT] Searching for input: input.504
[03/24/2023-12:56:14] [V] [TRT] Relu_144 [Relu] inputs: [input.504 -> (1, 64, 180, 180)[FLOAT]], 
[03/24/2023-12:56:14] [V] [TRT] Registering layer: Relu_144 for ONNX node: Relu_144
[03/24/2023-12:56:14] [V] [TRT] Registering tensor: input.508 for ONNX tensor: input.508
[03/24/2023-12:56:14] [V] [TRT] Relu_144 [Relu] outputs: [input.508 -> (1, 64, 180, 180)[FLOAT]], 
[03/24/2023-12:56:14] [V] [TRT] Parsing node: Conv_145 [Conv]
[03/24/2023-12:56:14] [V] [TRT] Searching for input: input.508
[03/24/2023-12:56:14] [V] [TRT] Searching for input: model.bbox_head.tasks.4.rot.3.weight
[03/24/2023-12:56:14] [V] [TRT] Searching for input: model.bbox_head.tasks.4.rot.3.bias
[03/24/2023-12:56:14] [V] [TRT] Conv_145 [Conv] inputs: [input.508 -> (1, 64, 180, 180)[FLOAT]], [model.bbox_head.tasks.4.rot.3.weight -> (2, 64, 3, 3)[FLOAT]], [model.bbox_head.tasks.4.rot.3.bias -> (2)[FLOAT]], 
[03/24/2023-12:56:14] [V] [TRT] Convolution input dimensions: (1, 64, 180, 180)
[03/24/2023-12:56:14] [V] [TRT] Registering layer: Conv_145 for ONNX node: Conv_145
[03/24/2023-12:56:14] [V] [TRT] Using kernel: (3, 3), strides: (1, 1), prepadding: (1, 1), postpadding: (1, 1), dilations: (1, 1), numOutputs: 2
[03/24/2023-12:56:14] [V] [TRT] Convolution output dimensions: (1, 2, 180, 180)
[03/24/2023-12:56:14] [V] [TRT] Registering tensor: rot_4_27 for ONNX tensor: rot_4
[03/24/2023-12:56:14] [V] [TRT] Conv_145 [Conv] outputs: [rot_4 -> (1, 2, 180, 180)[FLOAT]], 
[03/24/2023-12:56:14] [V] [TRT] Parsing node: Conv_146 [Conv]
[03/24/2023-12:56:14] [V] [TRT] Searching for input: onnx::Conv_651
[03/24/2023-12:56:14] [V] [TRT] Searching for input: onnx::Conv_923
[03/24/2023-12:56:14] [V] [TRT] Searching for input: onnx::Conv_924
[03/24/2023-12:56:14] [V] [TRT] Conv_146 [Conv] inputs: [onnx::Conv_651 -> (1, 64, 180, 180)[FLOAT]], [onnx::Conv_923 -> (64, 64, 3, 3)[FLOAT]], [onnx::Conv_924 -> (64)[FLOAT]], 
[03/24/2023-12:56:14] [V] [TRT] Convolution input dimensions: (1, 64, 180, 180)
[03/24/2023-12:56:14] [V] [TRT] Registering layer: Conv_146 for ONNX node: Conv_146
[03/24/2023-12:56:14] [V] [TRT] Using kernel: (3, 3), strides: (1, 1), prepadding: (1, 1), postpadding: (1, 1), dilations: (1, 1), numOutputs: 64
[03/24/2023-12:56:14] [V] [TRT] Convolution output dimensions: (1, 64, 180, 180)
[03/24/2023-12:56:14] [V] [TRT] Registering tensor: input.516 for ONNX tensor: input.516
[03/24/2023-12:56:14] [V] [TRT] Conv_146 [Conv] outputs: [input.516 -> (1, 64, 180, 180)[FLOAT]], 
[03/24/2023-12:56:14] [V] [TRT] Parsing node: Relu_147 [Relu]
[03/24/2023-12:56:14] [V] [TRT] Searching for input: input.516
[03/24/2023-12:56:14] [V] [TRT] Relu_147 [Relu] inputs: [input.516 -> (1, 64, 180, 180)[FLOAT]], 
[03/24/2023-12:56:14] [V] [TRT] Registering layer: Relu_147 for ONNX node: Relu_147
[03/24/2023-12:56:14] [V] [TRT] Registering tensor: input.520 for ONNX tensor: input.520
[03/24/2023-12:56:14] [V] [TRT] Relu_147 [Relu] outputs: [input.520 -> (1, 64, 180, 180)[FLOAT]], 
[03/24/2023-12:56:14] [V] [TRT] Parsing node: Conv_148 [Conv]
[03/24/2023-12:56:14] [V] [TRT] Searching for input: input.520
[03/24/2023-12:56:14] [V] [TRT] Searching for input: model.bbox_head.tasks.4.vel.3.weight
[03/24/2023-12:56:14] [V] [TRT] Searching for input: model.bbox_head.tasks.4.vel.3.bias
[03/24/2023-12:56:14] [V] [TRT] Conv_148 [Conv] inputs: [input.520 -> (1, 64, 180, 180)[FLOAT]], [model.bbox_head.tasks.4.vel.3.weight -> (2, 64, 3, 3)[FLOAT]], [model.bbox_head.tasks.4.vel.3.bias -> (2)[FLOAT]], 
[03/24/2023-12:56:14] [V] [TRT] Convolution input dimensions: (1, 64, 180, 180)
[03/24/2023-12:56:14] [V] [TRT] Registering layer: Conv_148 for ONNX node: Conv_148
[03/24/2023-12:56:14] [V] [TRT] Using kernel: (3, 3), strides: (1, 1), prepadding: (1, 1), postpadding: (1, 1), dilations: (1, 1), numOutputs: 2
[03/24/2023-12:56:14] [V] [TRT] Convolution output dimensions: (1, 2, 180, 180)
[03/24/2023-12:56:14] [V] [TRT] Registering tensor: vel_4_28 for ONNX tensor: vel_4
[03/24/2023-12:56:14] [V] [TRT] Conv_148 [Conv] outputs: [vel_4 -> (1, 2, 180, 180)[FLOAT]], 
[03/24/2023-12:56:14] [V] [TRT] Parsing node: Conv_149 [Conv]
[03/24/2023-12:56:14] [V] [TRT] Searching for input: onnx::Conv_651
[03/24/2023-12:56:14] [V] [TRT] Searching for input: onnx::Conv_926
[03/24/2023-12:56:14] [V] [TRT] Searching for input: onnx::Conv_927
[03/24/2023-12:56:14] [V] [TRT] Conv_149 [Conv] inputs: [onnx::Conv_651 -> (1, 64, 180, 180)[FLOAT]], [onnx::Conv_926 -> (64, 64, 3, 3)[FLOAT]], [onnx::Conv_927 -> (64)[FLOAT]], 
[03/24/2023-12:56:14] [V] [TRT] Convolution input dimensions: (1, 64, 180, 180)
[03/24/2023-12:56:14] [V] [TRT] Registering layer: Conv_149 for ONNX node: Conv_149
[03/24/2023-12:56:14] [V] [TRT] Using kernel: (3, 3), strides: (1, 1), prepadding: (1, 1), postpadding: (1, 1), dilations: (1, 1), numOutputs: 64
[03/24/2023-12:56:14] [V] [TRT] Convolution output dimensions: (1, 64, 180, 180)
[03/24/2023-12:56:14] [V] [TRT] Registering tensor: input.528 for ONNX tensor: input.528
[03/24/2023-12:56:14] [V] [TRT] Conv_149 [Conv] outputs: [input.528 -> (1, 64, 180, 180)[FLOAT]], 
[03/24/2023-12:56:14] [V] [TRT] Parsing node: Relu_150 [Relu]
[03/24/2023-12:56:14] [V] [TRT] Searching for input: input.528
[03/24/2023-12:56:14] [V] [TRT] Relu_150 [Relu] inputs: [input.528 -> (1, 64, 180, 180)[FLOAT]], 
[03/24/2023-12:56:14] [V] [TRT] Registering layer: Relu_150 for ONNX node: Relu_150
[03/24/2023-12:56:14] [V] [TRT] Registering tensor: input.532 for ONNX tensor: input.532
[03/24/2023-12:56:14] [V] [TRT] Relu_150 [Relu] outputs: [input.532 -> (1, 64, 180, 180)[FLOAT]], 
[03/24/2023-12:56:14] [V] [TRT] Parsing node: Conv_151 [Conv]
[03/24/2023-12:56:14] [V] [TRT] Searching for input: input.532
[03/24/2023-12:56:14] [V] [TRT] Searching for input: model.bbox_head.tasks.4.hm.3.weight
[03/24/2023-12:56:14] [V] [TRT] Searching for input: model.bbox_head.tasks.4.hm.3.bias
[03/24/2023-12:56:14] [V] [TRT] Conv_151 [Conv] inputs: [input.532 -> (1, 64, 180, 180)[FLOAT]], [model.bbox_head.tasks.4.hm.3.weight -> (2, 64, 3, 3)[FLOAT]], [model.bbox_head.tasks.4.hm.3.bias -> (2)[FLOAT]], 
[03/24/2023-12:56:14] [V] [TRT] Convolution input dimensions: (1, 64, 180, 180)
[03/24/2023-12:56:14] [V] [TRT] Registering layer: Conv_151 for ONNX node: Conv_151
[03/24/2023-12:56:14] [V] [TRT] Using kernel: (3, 3), strides: (1, 1), prepadding: (1, 1), postpadding: (1, 1), dilations: (1, 1), numOutputs: 2
[03/24/2023-12:56:14] [V] [TRT] Convolution output dimensions: (1, 2, 180, 180)
[03/24/2023-12:56:14] [V] [TRT] Registering tensor: hm_4_29 for ONNX tensor: hm_4
[03/24/2023-12:56:14] [V] [TRT] Conv_151 [Conv] outputs: [hm_4 -> (1, 2, 180, 180)[FLOAT]], 
[03/24/2023-12:56:14] [V] [TRT] Parsing node: Conv_152 [Conv]
[03/24/2023-12:56:14] [V] [TRT] Searching for input: onnx::Conv_651
[03/24/2023-12:56:14] [V] [TRT] Searching for input: onnx::Conv_929
[03/24/2023-12:56:14] [V] [TRT] Searching for input: onnx::Conv_930
[03/24/2023-12:56:14] [V] [TRT] Conv_152 [Conv] inputs: [onnx::Conv_651 -> (1, 64, 180, 180)[FLOAT]], [onnx::Conv_929 -> (64, 64, 3, 3)[FLOAT]], [onnx::Conv_930 -> (64)[FLOAT]], 
[03/24/2023-12:56:14] [V] [TRT] Convolution input dimensions: (1, 64, 180, 180)
[03/24/2023-12:56:14] [V] [TRT] Registering layer: Conv_152 for ONNX node: Conv_152
[03/24/2023-12:56:14] [V] [TRT] Using kernel: (3, 3), strides: (1, 1), prepadding: (1, 1), postpadding: (1, 1), dilations: (1, 1), numOutputs: 64
[03/24/2023-12:56:14] [V] [TRT] Convolution output dimensions: (1, 64, 180, 180)
[03/24/2023-12:56:14] [V] [TRT] Registering tensor: input.540 for ONNX tensor: input.540
[03/24/2023-12:56:14] [V] [TRT] Conv_152 [Conv] outputs: [input.540 -> (1, 64, 180, 180)[FLOAT]], 
[03/24/2023-12:56:14] [V] [TRT] Parsing node: Relu_153 [Relu]
[03/24/2023-12:56:14] [V] [TRT] Searching for input: input.540
[03/24/2023-12:56:14] [V] [TRT] Relu_153 [Relu] inputs: [input.540 -> (1, 64, 180, 180)[FLOAT]], 
[03/24/2023-12:56:14] [V] [TRT] Registering layer: Relu_153 for ONNX node: Relu_153
[03/24/2023-12:56:14] [V] [TRT] Registering tensor: input.544 for ONNX tensor: input.544
[03/24/2023-12:56:14] [V] [TRT] Relu_153 [Relu] outputs: [input.544 -> (1, 64, 180, 180)[FLOAT]], 
[03/24/2023-12:56:14] [V] [TRT] Parsing node: Conv_154 [Conv]
[03/24/2023-12:56:14] [V] [TRT] Searching for input: input.544
[03/24/2023-12:56:14] [V] [TRT] Searching for input: model.bbox_head.tasks.5.reg.3.weight
[03/24/2023-12:56:14] [V] [TRT] Searching for input: model.bbox_head.tasks.5.reg.3.bias
[03/24/2023-12:56:14] [V] [TRT] Conv_154 [Conv] inputs: [input.544 -> (1, 64, 180, 180)[FLOAT]], [model.bbox_head.tasks.5.reg.3.weight -> (2, 64, 3, 3)[FLOAT]], [model.bbox_head.tasks.5.reg.3.bias -> (2)[FLOAT]], 
[03/24/2023-12:56:14] [V] [TRT] Convolution input dimensions: (1, 64, 180, 180)
[03/24/2023-12:56:14] [V] [TRT] Registering layer: Conv_154 for ONNX node: Conv_154
[03/24/2023-12:56:14] [V] [TRT] Using kernel: (3, 3), strides: (1, 1), prepadding: (1, 1), postpadding: (1, 1), dilations: (1, 1), numOutputs: 2
[03/24/2023-12:56:14] [V] [TRT] Convolution output dimensions: (1, 2, 180, 180)
[03/24/2023-12:56:14] [V] [TRT] Registering tensor: reg_5_30 for ONNX tensor: reg_5
[03/24/2023-12:56:14] [V] [TRT] Conv_154 [Conv] outputs: [reg_5 -> (1, 2, 180, 180)[FLOAT]], 
[03/24/2023-12:56:14] [V] [TRT] Parsing node: Conv_155 [Conv]
[03/24/2023-12:56:14] [V] [TRT] Searching for input: onnx::Conv_651
[03/24/2023-12:56:14] [V] [TRT] Searching for input: onnx::Conv_932
[03/24/2023-12:56:14] [V] [TRT] Searching for input: onnx::Conv_933
[03/24/2023-12:56:14] [V] [TRT] Conv_155 [Conv] inputs: [onnx::Conv_651 -> (1, 64, 180, 180)[FLOAT]], [onnx::Conv_932 -> (64, 64, 3, 3)[FLOAT]], [onnx::Conv_933 -> (64)[FLOAT]], 
[03/24/2023-12:56:14] [V] [TRT] Convolution input dimensions: (1, 64, 180, 180)
[03/24/2023-12:56:14] [V] [TRT] Registering layer: Conv_155 for ONNX node: Conv_155
[03/24/2023-12:56:14] [V] [TRT] Using kernel: (3, 3), strides: (1, 1), prepadding: (1, 1), postpadding: (1, 1), dilations: (1, 1), numOutputs: 64
[03/24/2023-12:56:14] [V] [TRT] Convolution output dimensions: (1, 64, 180, 180)
[03/24/2023-12:56:14] [V] [TRT] Registering tensor: input.552 for ONNX tensor: input.552
[03/24/2023-12:56:14] [V] [TRT] Conv_155 [Conv] outputs: [input.552 -> (1, 64, 180, 180)[FLOAT]], 
[03/24/2023-12:56:14] [V] [TRT] Parsing node: Relu_156 [Relu]
[03/24/2023-12:56:14] [V] [TRT] Searching for input: input.552
[03/24/2023-12:56:14] [V] [TRT] Relu_156 [Relu] inputs: [input.552 -> (1, 64, 180, 180)[FLOAT]], 
[03/24/2023-12:56:14] [V] [TRT] Registering layer: Relu_156 for ONNX node: Relu_156
[03/24/2023-12:56:14] [V] [TRT] Registering tensor: input.556 for ONNX tensor: input.556
[03/24/2023-12:56:14] [V] [TRT] Relu_156 [Relu] outputs: [input.556 -> (1, 64, 180, 180)[FLOAT]], 
[03/24/2023-12:56:14] [V] [TRT] Parsing node: Conv_157 [Conv]
[03/24/2023-12:56:14] [V] [TRT] Searching for input: input.556
[03/24/2023-12:56:14] [V] [TRT] Searching for input: model.bbox_head.tasks.5.height.3.weight
[03/24/2023-12:56:14] [V] [TRT] Searching for input: model.bbox_head.tasks.5.height.3.bias
[03/24/2023-12:56:14] [V] [TRT] Conv_157 [Conv] inputs: [input.556 -> (1, 64, 180, 180)[FLOAT]], [model.bbox_head.tasks.5.height.3.weight -> (1, 64, 3, 3)[FLOAT]], [model.bbox_head.tasks.5.height.3.bias -> (1)[FLOAT]], 
[03/24/2023-12:56:14] [V] [TRT] Convolution input dimensions: (1, 64, 180, 180)
[03/24/2023-12:56:14] [V] [TRT] Registering layer: Conv_157 for ONNX node: Conv_157
[03/24/2023-12:56:14] [V] [TRT] Using kernel: (3, 3), strides: (1, 1), prepadding: (1, 1), postpadding: (1, 1), dilations: (1, 1), numOutputs: 1
[03/24/2023-12:56:14] [V] [TRT] Convolution output dimensions: (1, 1, 180, 180)
[03/24/2023-12:56:14] [V] [TRT] Registering tensor: height_5_31 for ONNX tensor: height_5
[03/24/2023-12:56:14] [V] [TRT] Conv_157 [Conv] outputs: [height_5 -> (1, 1, 180, 180)[FLOAT]], 
[03/24/2023-12:56:14] [V] [TRT] Parsing node: Conv_158 [Conv]
[03/24/2023-12:56:14] [V] [TRT] Searching for input: onnx::Conv_651
[03/24/2023-12:56:14] [V] [TRT] Searching for input: onnx::Conv_935
[03/24/2023-12:56:14] [V] [TRT] Searching for input: onnx::Conv_936
[03/24/2023-12:56:14] [V] [TRT] Conv_158 [Conv] inputs: [onnx::Conv_651 -> (1, 64, 180, 180)[FLOAT]], [onnx::Conv_935 -> (64, 64, 3, 3)[FLOAT]], [onnx::Conv_936 -> (64)[FLOAT]], 
[03/24/2023-12:56:14] [V] [TRT] Convolution input dimensions: (1, 64, 180, 180)
[03/24/2023-12:56:14] [V] [TRT] Registering layer: Conv_158 for ONNX node: Conv_158
[03/24/2023-12:56:14] [V] [TRT] Using kernel: (3, 3), strides: (1, 1), prepadding: (1, 1), postpadding: (1, 1), dilations: (1, 1), numOutputs: 64
[03/24/2023-12:56:14] [V] [TRT] Convolution output dimensions: (1, 64, 180, 180)
[03/24/2023-12:56:14] [V] [TRT] Registering tensor: input.564 for ONNX tensor: input.564
[03/24/2023-12:56:14] [V] [TRT] Conv_158 [Conv] outputs: [input.564 -> (1, 64, 180, 180)[FLOAT]], 
[03/24/2023-12:56:14] [V] [TRT] Parsing node: Relu_159 [Relu]
[03/24/2023-12:56:14] [V] [TRT] Searching for input: input.564
[03/24/2023-12:56:14] [V] [TRT] Relu_159 [Relu] inputs: [input.564 -> (1, 64, 180, 180)[FLOAT]], 
[03/24/2023-12:56:14] [V] [TRT] Registering layer: Relu_159 for ONNX node: Relu_159
[03/24/2023-12:56:14] [V] [TRT] Registering tensor: input.568 for ONNX tensor: input.568
[03/24/2023-12:56:14] [V] [TRT] Relu_159 [Relu] outputs: [input.568 -> (1, 64, 180, 180)[FLOAT]], 
[03/24/2023-12:56:14] [V] [TRT] Parsing node: Conv_160 [Conv]
[03/24/2023-12:56:14] [V] [TRT] Searching for input: input.568
[03/24/2023-12:56:14] [V] [TRT] Searching for input: model.bbox_head.tasks.5.dim.3.weight
[03/24/2023-12:56:14] [V] [TRT] Searching for input: model.bbox_head.tasks.5.dim.3.bias
[03/24/2023-12:56:14] [V] [TRT] Conv_160 [Conv] inputs: [input.568 -> (1, 64, 180, 180)[FLOAT]], [model.bbox_head.tasks.5.dim.3.weight -> (3, 64, 3, 3)[FLOAT]], [model.bbox_head.tasks.5.dim.3.bias -> (3)[FLOAT]], 
[03/24/2023-12:56:14] [V] [TRT] Convolution input dimensions: (1, 64, 180, 180)
[03/24/2023-12:56:14] [V] [TRT] Registering layer: Conv_160 for ONNX node: Conv_160
[03/24/2023-12:56:14] [V] [TRT] Using kernel: (3, 3), strides: (1, 1), prepadding: (1, 1), postpadding: (1, 1), dilations: (1, 1), numOutputs: 3
[03/24/2023-12:56:14] [V] [TRT] Convolution output dimensions: (1, 3, 180, 180)
[03/24/2023-12:56:14] [V] [TRT] Registering tensor: dim_5_32 for ONNX tensor: dim_5
[03/24/2023-12:56:14] [V] [TRT] Conv_160 [Conv] outputs: [dim_5 -> (1, 3, 180, 180)[FLOAT]], 
[03/24/2023-12:56:14] [V] [TRT] Parsing node: Conv_161 [Conv]
[03/24/2023-12:56:14] [V] [TRT] Searching for input: onnx::Conv_651
[03/24/2023-12:56:14] [V] [TRT] Searching for input: onnx::Conv_938
[03/24/2023-12:56:14] [V] [TRT] Searching for input: onnx::Conv_939
[03/24/2023-12:56:14] [V] [TRT] Conv_161 [Conv] inputs: [onnx::Conv_651 -> (1, 64, 180, 180)[FLOAT]], [onnx::Conv_938 -> (64, 64, 3, 3)[FLOAT]], [onnx::Conv_939 -> (64)[FLOAT]], 
[03/24/2023-12:56:14] [V] [TRT] Convolution input dimensions: (1, 64, 180, 180)
[03/24/2023-12:56:14] [V] [TRT] Registering layer: Conv_161 for ONNX node: Conv_161
[03/24/2023-12:56:14] [V] [TRT] Using kernel: (3, 3), strides: (1, 1), prepadding: (1, 1), postpadding: (1, 1), dilations: (1, 1), numOutputs: 64
[03/24/2023-12:56:14] [V] [TRT] Convolution output dimensions: (1, 64, 180, 180)
[03/24/2023-12:56:14] [V] [TRT] Registering tensor: input.576 for ONNX tensor: input.576
[03/24/2023-12:56:14] [V] [TRT] Conv_161 [Conv] outputs: [input.576 -> (1, 64, 180, 180)[FLOAT]], 
[03/24/2023-12:56:14] [V] [TRT] Parsing node: Relu_162 [Relu]
[03/24/2023-12:56:14] [V] [TRT] Searching for input: input.576
[03/24/2023-12:56:14] [V] [TRT] Relu_162 [Relu] inputs: [input.576 -> (1, 64, 180, 180)[FLOAT]], 
[03/24/2023-12:56:14] [V] [TRT] Registering layer: Relu_162 for ONNX node: Relu_162
[03/24/2023-12:56:14] [V] [TRT] Registering tensor: input.580 for ONNX tensor: input.580
[03/24/2023-12:56:14] [V] [TRT] Relu_162 [Relu] outputs: [input.580 -> (1, 64, 180, 180)[FLOAT]], 
[03/24/2023-12:56:14] [V] [TRT] Parsing node: Conv_163 [Conv]
[03/24/2023-12:56:14] [V] [TRT] Searching for input: input.580
[03/24/2023-12:56:14] [V] [TRT] Searching for input: model.bbox_head.tasks.5.rot.3.weight
[03/24/2023-12:56:14] [V] [TRT] Searching for input: model.bbox_head.tasks.5.rot.3.bias
[03/24/2023-12:56:14] [V] [TRT] Conv_163 [Conv] inputs: [input.580 -> (1, 64, 180, 180)[FLOAT]], [model.bbox_head.tasks.5.rot.3.weight -> (2, 64, 3, 3)[FLOAT]], [model.bbox_head.tasks.5.rot.3.bias -> (2)[FLOAT]], 
[03/24/2023-12:56:14] [V] [TRT] Convolution input dimensions: (1, 64, 180, 180)
[03/24/2023-12:56:14] [V] [TRT] Registering layer: Conv_163 for ONNX node: Conv_163
[03/24/2023-12:56:14] [V] [TRT] Using kernel: (3, 3), strides: (1, 1), prepadding: (1, 1), postpadding: (1, 1), dilations: (1, 1), numOutputs: 2
[03/24/2023-12:56:14] [V] [TRT] Convolution output dimensions: (1, 2, 180, 180)
[03/24/2023-12:56:14] [V] [TRT] Registering tensor: rot_5_33 for ONNX tensor: rot_5
[03/24/2023-12:56:14] [V] [TRT] Conv_163 [Conv] outputs: [rot_5 -> (1, 2, 180, 180)[FLOAT]], 
[03/24/2023-12:56:14] [V] [TRT] Parsing node: Conv_164 [Conv]
[03/24/2023-12:56:14] [V] [TRT] Searching for input: onnx::Conv_651
[03/24/2023-12:56:14] [V] [TRT] Searching for input: onnx::Conv_941
[03/24/2023-12:56:14] [V] [TRT] Searching for input: onnx::Conv_942
[03/24/2023-12:56:14] [V] [TRT] Conv_164 [Conv] inputs: [onnx::Conv_651 -> (1, 64, 180, 180)[FLOAT]], [onnx::Conv_941 -> (64, 64, 3, 3)[FLOAT]], [onnx::Conv_942 -> (64)[FLOAT]], 
[03/24/2023-12:56:14] [V] [TRT] Convolution input dimensions: (1, 64, 180, 180)
[03/24/2023-12:56:14] [V] [TRT] Registering layer: Conv_164 for ONNX node: Conv_164
[03/24/2023-12:56:14] [V] [TRT] Using kernel: (3, 3), strides: (1, 1), prepadding: (1, 1), postpadding: (1, 1), dilations: (1, 1), numOutputs: 64
[03/24/2023-12:56:14] [V] [TRT] Convolution output dimensions: (1, 64, 180, 180)
[03/24/2023-12:56:14] [V] [TRT] Registering tensor: input.588 for ONNX tensor: input.588
[03/24/2023-12:56:14] [V] [TRT] Conv_164 [Conv] outputs: [input.588 -> (1, 64, 180, 180)[FLOAT]], 
[03/24/2023-12:56:14] [V] [TRT] Parsing node: Relu_165 [Relu]
[03/24/2023-12:56:14] [V] [TRT] Searching for input: input.588
[03/24/2023-12:56:14] [V] [TRT] Relu_165 [Relu] inputs: [input.588 -> (1, 64, 180, 180)[FLOAT]], 
[03/24/2023-12:56:14] [V] [TRT] Registering layer: Relu_165 for ONNX node: Relu_165
[03/24/2023-12:56:14] [V] [TRT] Registering tensor: input.592 for ONNX tensor: input.592
[03/24/2023-12:56:14] [V] [TRT] Relu_165 [Relu] outputs: [input.592 -> (1, 64, 180, 180)[FLOAT]], 
[03/24/2023-12:56:14] [V] [TRT] Parsing node: Conv_166 [Conv]
[03/24/2023-12:56:14] [V] [TRT] Searching for input: input.592
[03/24/2023-12:56:14] [V] [TRT] Searching for input: model.bbox_head.tasks.5.vel.3.weight
[03/24/2023-12:56:14] [V] [TRT] Searching for input: model.bbox_head.tasks.5.vel.3.bias
[03/24/2023-12:56:14] [V] [TRT] Conv_166 [Conv] inputs: [input.592 -> (1, 64, 180, 180)[FLOAT]], [model.bbox_head.tasks.5.vel.3.weight -> (2, 64, 3, 3)[FLOAT]], [model.bbox_head.tasks.5.vel.3.bias -> (2)[FLOAT]], 
[03/24/2023-12:56:14] [V] [TRT] Convolution input dimensions: (1, 64, 180, 180)
[03/24/2023-12:56:14] [V] [TRT] Registering layer: Conv_166 for ONNX node: Conv_166
[03/24/2023-12:56:14] [V] [TRT] Using kernel: (3, 3), strides: (1, 1), prepadding: (1, 1), postpadding: (1, 1), dilations: (1, 1), numOutputs: 2
[03/24/2023-12:56:14] [V] [TRT] Convolution output dimensions: (1, 2, 180, 180)
[03/24/2023-12:56:14] [V] [TRT] Registering tensor: vel_5_34 for ONNX tensor: vel_5
[03/24/2023-12:56:14] [V] [TRT] Conv_166 [Conv] outputs: [vel_5 -> (1, 2, 180, 180)[FLOAT]], 
[03/24/2023-12:56:14] [V] [TRT] Parsing node: Conv_167 [Conv]
[03/24/2023-12:56:14] [V] [TRT] Searching for input: onnx::Conv_651
[03/24/2023-12:56:14] [V] [TRT] Searching for input: onnx::Conv_944
[03/24/2023-12:56:14] [V] [TRT] Searching for input: onnx::Conv_945
[03/24/2023-12:56:14] [V] [TRT] Conv_167 [Conv] inputs: [onnx::Conv_651 -> (1, 64, 180, 180)[FLOAT]], [onnx::Conv_944 -> (64, 64, 3, 3)[FLOAT]], [onnx::Conv_945 -> (64)[FLOAT]], 
[03/24/2023-12:56:14] [V] [TRT] Convolution input dimensions: (1, 64, 180, 180)
[03/24/2023-12:56:14] [V] [TRT] Registering layer: Conv_167 for ONNX node: Conv_167
[03/24/2023-12:56:14] [V] [TRT] Using kernel: (3, 3), strides: (1, 1), prepadding: (1, 1), postpadding: (1, 1), dilations: (1, 1), numOutputs: 64
[03/24/2023-12:56:14] [V] [TRT] Convolution output dimensions: (1, 64, 180, 180)
[03/24/2023-12:56:14] [V] [TRT] Registering tensor: input.600 for ONNX tensor: input.600
[03/24/2023-12:56:14] [V] [TRT] Conv_167 [Conv] outputs: [input.600 -> (1, 64, 180, 180)[FLOAT]], 
[03/24/2023-12:56:14] [V] [TRT] Parsing node: Relu_168 [Relu]
[03/24/2023-12:56:14] [V] [TRT] Searching for input: input.600
[03/24/2023-12:56:14] [V] [TRT] Relu_168 [Relu] inputs: [input.600 -> (1, 64, 180, 180)[FLOAT]], 
[03/24/2023-12:56:14] [V] [TRT] Registering layer: Relu_168 for ONNX node: Relu_168
[03/24/2023-12:56:14] [V] [TRT] Registering tensor: input.604 for ONNX tensor: input.604
[03/24/2023-12:56:14] [V] [TRT] Relu_168 [Relu] outputs: [input.604 -> (1, 64, 180, 180)[FLOAT]], 
[03/24/2023-12:56:14] [V] [TRT] Parsing node: Conv_169 [Conv]
[03/24/2023-12:56:14] [V] [TRT] Searching for input: input.604
[03/24/2023-12:56:14] [V] [TRT] Searching for input: model.bbox_head.tasks.5.hm.3.weight
[03/24/2023-12:56:14] [V] [TRT] Searching for input: model.bbox_head.tasks.5.hm.3.bias
[03/24/2023-12:56:14] [V] [TRT] Conv_169 [Conv] inputs: [input.604 -> (1, 64, 180, 180)[FLOAT]], [model.bbox_head.tasks.5.hm.3.weight -> (2, 64, 3, 3)[FLOAT]], [model.bbox_head.tasks.5.hm.3.bias -> (2)[FLOAT]], 
[03/24/2023-12:56:14] [V] [TRT] Convolution input dimensions: (1, 64, 180, 180)
[03/24/2023-12:56:14] [V] [TRT] Registering layer: Conv_169 for ONNX node: Conv_169
[03/24/2023-12:56:14] [V] [TRT] Using kernel: (3, 3), strides: (1, 1), prepadding: (1, 1), postpadding: (1, 1), dilations: (1, 1), numOutputs: 2
[03/24/2023-12:56:14] [V] [TRT] Convolution output dimensions: (1, 2, 180, 180)
[03/24/2023-12:56:14] [V] [TRT] Registering tensor: hm_5_35 for ONNX tensor: hm_5
[03/24/2023-12:56:14] [V] [TRT] Conv_169 [Conv] outputs: [hm_5 -> (1, 2, 180, 180)[FLOAT]], 
[03/24/2023-12:56:14] [V] [TRT] Marking reg_0_0 as output: reg_0
[03/24/2023-12:56:14] [V] [TRT] Marking height_0_1 as output: height_0
[03/24/2023-12:56:14] [V] [TRT] Marking dim_0_2 as output: dim_0
[03/24/2023-12:56:14] [V] [TRT] Marking rot_0_3 as output: rot_0
[03/24/2023-12:56:14] [V] [TRT] Marking vel_0_4 as output: vel_0
[03/24/2023-12:56:14] [V] [TRT] Marking hm_0_5 as output: hm_0
[03/24/2023-12:56:14] [V] [TRT] Marking reg_1_6 as output: reg_1
[03/24/2023-12:56:14] [V] [TRT] Marking height_1_7 as output: height_1
[03/24/2023-12:56:14] [V] [TRT] Marking dim_1_8 as output: dim_1
[03/24/2023-12:56:14] [V] [TRT] Marking rot_1_9 as output: rot_1
[03/24/2023-12:56:14] [V] [TRT] Marking vel_1_10 as output: vel_1
[03/24/2023-12:56:14] [V] [TRT] Marking hm_1_11 as output: hm_1
[03/24/2023-12:56:14] [V] [TRT] Marking reg_2_12 as output: reg_2
[03/24/2023-12:56:14] [V] [TRT] Marking height_2_13 as output: height_2
[03/24/2023-12:56:14] [V] [TRT] Marking dim_2_14 as output: dim_2
[03/24/2023-12:56:14] [V] [TRT] Marking rot_2_15 as output: rot_2
[03/24/2023-12:56:14] [V] [TRT] Marking vel_2_16 as output: vel_2
[03/24/2023-12:56:14] [V] [TRT] Marking hm_2_17 as output: hm_2
[03/24/2023-12:56:14] [V] [TRT] Marking reg_3_18 as output: reg_3
[03/24/2023-12:56:14] [V] [TRT] Marking height_3_19 as output: height_3
[03/24/2023-12:56:14] [V] [TRT] Marking dim_3_20 as output: dim_3
[03/24/2023-12:56:14] [V] [TRT] Marking rot_3_21 as output: rot_3
[03/24/2023-12:56:14] [V] [TRT] Marking vel_3_22 as output: vel_3
[03/24/2023-12:56:14] [V] [TRT] Marking hm_3_23 as output: hm_3
[03/24/2023-12:56:14] [V] [TRT] Marking reg_4_24 as output: reg_4
[03/24/2023-12:56:14] [V] [TRT] Marking height_4_25 as output: height_4
[03/24/2023-12:56:14] [V] [TRT] Marking dim_4_26 as output: dim_4
[03/24/2023-12:56:14] [V] [TRT] Marking rot_4_27 as output: rot_4
[03/24/2023-12:56:14] [V] [TRT] Marking vel_4_28 as output: vel_4
[03/24/2023-12:56:14] [V] [TRT] Marking hm_4_29 as output: hm_4
[03/24/2023-12:56:14] [V] [TRT] Marking reg_5_30 as output: reg_5
[03/24/2023-12:56:14] [V] [TRT] Marking height_5_31 as output: height_5
[03/24/2023-12:56:14] [V] [TRT] Marking dim_5_32 as output: dim_5
[03/24/2023-12:56:14] [V] [TRT] Marking rot_5_33 as output: rot_5
[03/24/2023-12:56:14] [V] [TRT] Marking vel_5_34 as output: vel_5
[03/24/2023-12:56:14] [V] [TRT] Marking hm_5_35 as output: hm_5
[03/24/2023-12:56:14] [I] Finish parsing network model
[03/24/2023-12:56:14] [V] [TRT] Applying generic optimizations to the graph for inference.
[03/24/2023-12:56:14] [V] [TRT] Original: 140 layers
[03/24/2023-12:56:14] [V] [TRT] After dead-layer removal: 140 layers
[03/24/2023-12:56:14] [V] [TRT] After Myelin optimization: 140 layers
[03/24/2023-12:56:14] [V] [TRT] Applying ScaleNodes fusions.
[03/24/2023-12:56:14] [V] [TRT] After scale fusion: 140 layers
[03/24/2023-12:56:14] [V] [TRT] Running: ConvReluFusion
[03/24/2023-12:56:14] [V] [TRT] ConvReluFusion: Fusing Conv_15 with Relu_16
[03/24/2023-12:56:14] [V] [TRT] Running: ConvReluFusion
[03/24/2023-12:56:14] [V] [TRT] ConvReluFusion: Fusing Conv_17 with Relu_18
[03/24/2023-12:56:14] [V] [TRT] Running: ConvReluFusion
[03/24/2023-12:56:14] [V] [TRT] ConvReluFusion: Fusing Conv_19 with Relu_20
[03/24/2023-12:56:14] [V] [TRT] Running: ConvReluFusion
[03/24/2023-12:56:14] [V] [TRT] ConvReluFusion: Fusing Conv_21 with Relu_22
[03/24/2023-12:56:14] [V] [TRT] Running: ConvReluFusion
[03/24/2023-12:56:14] [V] [TRT] ConvReluFusion: Fusing Conv_23 with Relu_24
[03/24/2023-12:56:14] [V] [TRT] Running: ConvReluFusion
[03/24/2023-12:56:14] [V] [TRT] ConvReluFusion: Fusing Conv_25 with Relu_26
[03/24/2023-12:56:14] [V] [TRT] Running: ConvReluFusion
[03/24/2023-12:56:14] [V] [TRT] ConvReluFusion: Fusing Conv_27 with Relu_28
[03/24/2023-12:56:14] [V] [TRT] Running: ConvReluFusion
[03/24/2023-12:56:14] [V] [TRT] ConvReluFusion: Fusing Conv_44 with Relu_45
[03/24/2023-12:56:14] [V] [TRT] Running: ConvReluFusion
[03/24/2023-12:56:14] [V] [TRT] ConvReluFusion: Fusing Conv_46 with Relu_47
[03/24/2023-12:56:14] [V] [TRT] Running: ConvReluFusion
[03/24/2023-12:56:14] [V] [TRT] ConvReluFusion: Fusing Conv_48 with Relu_49
[03/24/2023-12:56:14] [V] [TRT] Running: ConvReluFusion
[03/24/2023-12:56:14] [V] [TRT] ConvReluFusion: Fusing Conv_50 with Relu_51
[03/24/2023-12:56:14] [V] [TRT] Running: ConvReluFusion
[03/24/2023-12:56:14] [V] [TRT] ConvReluFusion: Fusing Conv_52 with Relu_53
[03/24/2023-12:56:14] [V] [TRT] Running: ConvReluFusion
[03/24/2023-12:56:14] [V] [TRT] ConvReluFusion: Fusing Conv_54 with Relu_55
[03/24/2023-12:56:14] [V] [TRT] Running: DeconvScaleFusion
[03/24/2023-12:56:14] [V] [TRT] DeconvScaleFusion: Fusing ConvTranspose_56 with BatchNormalization_57
[03/24/2023-12:56:14] [V] [TRT] Running: DeconvReluFusion
[03/24/2023-12:56:14] [V] [TRT] DeconvReluFusion: Fusing ConvTranspose_56 + BatchNormalization_57 with Relu_58
[03/24/2023-12:56:14] [V] [TRT] Running: ConvReluFusion
[03/24/2023-12:56:14] [V] [TRT] ConvReluFusion: Fusing Conv_60 with Relu_61
[03/24/2023-12:56:14] [V] [TRT] Running: ConvReluFusion
[03/24/2023-12:56:14] [V] [TRT] ConvReluFusion: Fusing Conv_62 with Relu_63
[03/24/2023-12:56:14] [V] [TRT] Running: ConvReluFusion
[03/24/2023-12:56:14] [V] [TRT] ConvReluFusion: Fusing Conv_65 with Relu_66
[03/24/2023-12:56:14] [V] [TRT] Running: ConvReluFusion
[03/24/2023-12:56:14] [V] [TRT] ConvReluFusion: Fusing Conv_68 with Relu_69
[03/24/2023-12:56:14] [V] [TRT] Running: ConvReluFusion
[03/24/2023-12:56:14] [V] [TRT] ConvReluFusion: Fusing Conv_71 with Relu_72
[03/24/2023-12:56:14] [V] [TRT] Running: ConvReluFusion
[03/24/2023-12:56:14] [V] [TRT] ConvReluFusion: Fusing Conv_74 with Relu_75
[03/24/2023-12:56:14] [V] [TRT] Running: ConvReluFusion
[03/24/2023-12:56:14] [V] [TRT] ConvReluFusion: Fusing Conv_77 with Relu_78
[03/24/2023-12:56:14] [V] [TRT] Running: ConvReluFusion
[03/24/2023-12:56:14] [V] [TRT] ConvReluFusion: Fusing Conv_80 with Relu_81
[03/24/2023-12:56:14] [V] [TRT] Running: ConvReluFusion
[03/24/2023-12:56:14] [V] [TRT] ConvReluFusion: Fusing Conv_83 with Relu_84
[03/24/2023-12:56:14] [V] [TRT] Running: ConvReluFusion
[03/24/2023-12:56:14] [V] [TRT] ConvReluFusion: Fusing Conv_86 with Relu_87
[03/24/2023-12:56:14] [V] [TRT] Running: ConvReluFusion
[03/24/2023-12:56:14] [V] [TRT] ConvReluFusion: Fusing Conv_89 with Relu_90
[03/24/2023-12:56:14] [V] [TRT] Running: ConvReluFusion
[03/24/2023-12:56:14] [V] [TRT] ConvReluFusion: Fusing Conv_92 with Relu_93
[03/24/2023-12:56:14] [V] [TRT] Running: ConvReluFusion
[03/24/2023-12:56:14] [V] [TRT] ConvReluFusion: Fusing Conv_95 with Relu_96
[03/24/2023-12:56:14] [V] [TRT] Running: ConvReluFusion
[03/24/2023-12:56:14] [V] [TRT] ConvReluFusion: Fusing Conv_98 with Relu_99
[03/24/2023-12:56:14] [V] [TRT] Running: ConvReluFusion
[03/24/2023-12:56:14] [V] [TRT] ConvReluFusion: Fusing Conv_101 with Relu_102
[03/24/2023-12:56:14] [V] [TRT] Running: ConvReluFusion
[03/24/2023-12:56:14] [V] [TRT] ConvReluFusion: Fusing Conv_104 with Relu_105
[03/24/2023-12:56:14] [V] [TRT] Running: ConvReluFusion
[03/24/2023-12:56:14] [V] [TRT] ConvReluFusion: Fusing Conv_107 with Relu_108
[03/24/2023-12:56:14] [V] [TRT] Running: ConvReluFusion
[03/24/2023-12:56:14] [V] [TRT] ConvReluFusion: Fusing Conv_110 with Relu_111
[03/24/2023-12:56:14] [V] [TRT] Running: ConvReluFusion
[03/24/2023-12:56:14] [V] [TRT] ConvReluFusion: Fusing Conv_113 with Relu_114
[03/24/2023-12:56:14] [V] [TRT] Running: ConvReluFusion
[03/24/2023-12:56:14] [V] [TRT] ConvReluFusion: Fusing Conv_116 with Relu_117
[03/24/2023-12:56:14] [V] [TRT] Running: ConvReluFusion
[03/24/2023-12:56:14] [V] [TRT] ConvReluFusion: Fusing Conv_119 with Relu_120
[03/24/2023-12:56:14] [V] [TRT] Running: ConvReluFusion
[03/24/2023-12:56:14] [V] [TRT] ConvReluFusion: Fusing Conv_122 with Relu_123
[03/24/2023-12:56:14] [V] [TRT] Running: ConvReluFusion
[03/24/2023-12:56:14] [V] [TRT] ConvReluFusion: Fusing Conv_125 with Relu_126
[03/24/2023-12:56:14] [V] [TRT] Running: ConvReluFusion
[03/24/2023-12:56:14] [V] [TRT] ConvReluFusion: Fusing Conv_128 with Relu_129
[03/24/2023-12:56:14] [V] [TRT] Running: ConvReluFusion
[03/24/2023-12:56:14] [V] [TRT] ConvReluFusion: Fusing Conv_131 with Relu_132
[03/24/2023-12:56:14] [V] [TRT] Running: ConvReluFusion
[03/24/2023-12:56:14] [V] [TRT] ConvReluFusion: Fusing Conv_134 with Relu_135
[03/24/2023-12:56:14] [V] [TRT] Running: ConvReluFusion
[03/24/2023-12:56:14] [V] [TRT] ConvReluFusion: Fusing Conv_137 with Relu_138
[03/24/2023-12:56:14] [V] [TRT] Running: ConvReluFusion
[03/24/2023-12:56:14] [V] [TRT] ConvReluFusion: Fusing Conv_140 with Relu_141
[03/24/2023-12:56:14] [V] [TRT] Running: ConvReluFusion
[03/24/2023-12:56:14] [V] [TRT] ConvReluFusion: Fusing Conv_143 with Relu_144
[03/24/2023-12:56:14] [V] [TRT] Running: ConvReluFusion
[03/24/2023-12:56:14] [V] [TRT] ConvReluFusion: Fusing Conv_146 with Relu_147
[03/24/2023-12:56:14] [V] [TRT] Running: ConvReluFusion
[03/24/2023-12:56:14] [V] [TRT] ConvReluFusion: Fusing Conv_149 with Relu_150
[03/24/2023-12:56:14] [V] [TRT] Running: ConvReluFusion
[03/24/2023-12:56:14] [V] [TRT] ConvReluFusion: Fusing Conv_152 with Relu_153
[03/24/2023-12:56:14] [V] [TRT] Running: ConvReluFusion
[03/24/2023-12:56:14] [V] [TRT] ConvReluFusion: Fusing Conv_155 with Relu_156
[03/24/2023-12:56:14] [V] [TRT] Running: ConvReluFusion
[03/24/2023-12:56:14] [V] [TRT] ConvReluFusion: Fusing Conv_158 with Relu_159
[03/24/2023-12:56:14] [V] [TRT] Running: ConvReluFusion
[03/24/2023-12:56:14] [V] [TRT] ConvReluFusion: Fusing Conv_161 with Relu_162
[03/24/2023-12:56:14] [V] [TRT] Running: ConvReluFusion
[03/24/2023-12:56:14] [V] [TRT] ConvReluFusion: Fusing Conv_164 with Relu_165
[03/24/2023-12:56:14] [V] [TRT] Running: ConvReluFusion
[03/24/2023-12:56:14] [V] [TRT] ConvReluFusion: Fusing Conv_167 with Relu_168
[03/24/2023-12:56:15] [V] [TRT] After vertical fusions: 88 layers
[03/24/2023-12:56:15] [V] [TRT] After dupe layer removal: 88 layers
[03/24/2023-12:56:15] [V] [TRT] After final dead-layer removal: 88 layers
[03/24/2023-12:56:15] [V] [TRT] Merging layers: Conv_62 + Relu_63 || Conv_65 + Relu_66 || Conv_68 + Relu_69 || Conv_71 + Relu_72 || Conv_74 + Relu_75 || Conv_77 + Relu_78 || Conv_80 + Relu_81 || Conv_83 + Relu_84
[03/24/2023-12:56:15] [V] [TRT] Merging layers: Conv_86 + Relu_87 || Conv_89 + Relu_90 || Conv_92 + Relu_93 || Conv_95 + Relu_96 || Conv_98 + Relu_99 || Conv_101 + Relu_102 || Conv_104 + Relu_105 || Conv_107 + Relu_108
[03/24/2023-12:56:15] [V] [TRT] Merging layers: Conv_110 + Relu_111 || Conv_113 + Relu_114 || Conv_116 + Relu_117 || Conv_119 + Relu_120 || Conv_122 + Relu_123 || Conv_125 + Relu_126 || Conv_128 + Relu_129 || Conv_131 + Relu_132
[03/24/2023-12:56:15] [V] [TRT] Merging layers: Conv_134 + Relu_135 || Conv_137 + Relu_138 || Conv_140 + Relu_141 || Conv_143 + Relu_144 || Conv_146 + Relu_147 || Conv_149 + Relu_150 || Conv_152 + Relu_153 || Conv_155 + Relu_156
[03/24/2023-12:56:15] [V] [TRT] Merging layers: Conv_158 + Relu_159 || Conv_161 + Relu_162 || Conv_164 + Relu_165 || Conv_167 + Relu_168
[03/24/2023-12:56:15] [V] [TRT] After tensor merging: 57 layers
[03/24/2023-12:56:15] [V] [TRT] Eliminating concatenation Concat_59
[03/24/2023-12:56:15] [V] [TRT] Retargeting onnx::Concat_602 to input.164
[03/24/2023-12:56:15] [V] [TRT] Generating copy for onnx::Concat_647 to input.164 because input does not support striding.
[03/24/2023-12:56:15] [V] [TRT] After concat removal: 57 layers
[03/24/2023-12:56:15] [V] [TRT] Graph construction and optimization completed in 0.863356 seconds.
[03/24/2023-12:56:16] [V] [TRT] Using cublasLt as a tactic source
[03/24/2023-12:56:16] [I] [TRT] [MemUsageChange] Init cuBLAS/cuBLASLt: CPU +815, GPU +352, now: CPU 1500, GPU 1114 (MiB)
[03/24/2023-12:56:16] [V] [TRT] Using cuDNN as a tactic source
[03/24/2023-12:56:16] [I] [TRT] [MemUsageChange] Init cuDNN: CPU +126, GPU +60, now: CPU 1626, GPU 1174 (MiB)
[03/24/2023-12:56:16] [I] [TRT] Local timing cache in use. Profiling results in this builder pass will not be stored.
[03/24/2023-12:56:16] [V] [TRT] Constructing optimization profile number 0 [1/1].
[03/24/2023-12:56:16] [V] [TRT] Reserving memory for activation tensors. Host: 0 bytes Device: 42249600 bytes
[03/24/2023-12:56:16] [V] [TRT] =============== Computing reformatting costs
[03/24/2023-12:56:16] [V] [TRT] *************** Autotuning Reformat: Half(8294400,32400,180,1) -> Float(8294400,32400,180,1) ***************
[03/24/2023-12:56:16] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(input -> <out>) (Reformat)
[03/24/2023-12:56:16] [V] [TRT] Tactic: 1002 Time: 0.058368
[03/24/2023-12:56:16] [V] [TRT] Tactic: 0 Time: 0.07424
[03/24/2023-12:56:16] [V] [TRT] Fastest Tactic: 1002 Time: 0.058368
[03/24/2023-12:56:16] [V] [TRT] *************** Autotuning Reformat: Half(8294400,32400,180,1) -> Float(8294400,1,46080,256) ***************
[03/24/2023-12:56:16] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(input -> <out>) (Reformat)
[03/24/2023-12:56:16] [V] [TRT] Tactic: 1002 Time: 0.048128
[03/24/2023-12:56:16] [V] [TRT] Tactic: 0 Time: 0.103424
[03/24/2023-12:56:16] [V] [TRT] Fastest Tactic: 1002 Time: 0.048128
[03/24/2023-12:56:16] [V] [TRT] *************** Autotuning Reformat: Half(8294400,32400,180,1) -> Float(2073600,1:4,11520,64) ***************
[03/24/2023-12:56:16] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(input -> <out>) (Reformat)
[03/24/2023-12:56:16] [V] [TRT] Tactic: 1002 Time: 0.048
[03/24/2023-12:56:16] [V] [TRT] Tactic: 0 Time: 0.105344
[03/24/2023-12:56:16] [V] [TRT] Fastest Tactic: 1002 Time: 0.048
[03/24/2023-12:56:16] [V] [TRT] *************** Autotuning Reformat: Half(8294400,32400,180,1) -> Half(4147200,32400:2,180,1) ***************
[03/24/2023-12:56:16] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(input -> <out>) (Reformat)
[03/24/2023-12:56:16] [V] [TRT] Tactic: 1002 Time: 0.049152
[03/24/2023-12:56:16] [V] [TRT] Tactic: 0 Time: 0.056064
[03/24/2023-12:56:16] [V] [TRT] Fastest Tactic: 1002 Time: 0.049152
[03/24/2023-12:56:16] [V] [TRT] *************** Autotuning Reformat: Half(8294400,32400,180,1) -> Half(1036800,1:8,5760,32) ***************
[03/24/2023-12:56:16] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(input -> <out>) (Reformat)
[03/24/2023-12:56:16] [V] [TRT] Tactic: 1002 Time: 0.052096
[03/24/2023-12:56:16] [V] [TRT] Tactic: 0 Time: 0.037888
[03/24/2023-12:56:16] [V] [TRT] Fastest Tactic: 0 Time: 0.037888
[03/24/2023-12:56:16] [V] [TRT] *************** Autotuning Reformat: Half(8294400,32400,180,1) -> Half(518400,1:16,2880,16) ***************
[03/24/2023-12:56:16] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(input -> <out>) (Reformat)
[03/24/2023-12:56:16] [V] [TRT] Tactic: 1002 Time: 0.05184
[03/24/2023-12:56:16] [V] [TRT] Tactic: 0 Time: 0.102144
[03/24/2023-12:56:16] [V] [TRT] Fastest Tactic: 1002 Time: 0.05184
[03/24/2023-12:56:16] [V] [TRT] =============== Computing reformatting costs
[03/24/2023-12:56:16] [V] [TRT] *************** Autotuning Reformat: Float(4147200,32400,180,1) -> Float(4147200,1,23040,128) ***************
[03/24/2023-12:56:16] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(input.12 -> <out>) (Reformat)
[03/24/2023-12:56:16] [V] [TRT] Tactic: 1002 Time: 0.034048
[03/24/2023-12:56:16] [V] [TRT] Tactic: 0 Time: 0.052096
[03/24/2023-12:56:16] [V] [TRT] Fastest Tactic: 1002 Time: 0.034048
[03/24/2023-12:56:16] [V] [TRT] *************** Autotuning Reformat: Float(4147200,32400,180,1) -> Float(1036800,1:4,5760,32) ***************
[03/24/2023-12:56:16] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(input.12 -> <out>) (Reformat)
[03/24/2023-12:56:16] [V] [TRT] Tactic: 1002 Time: 0.034304
[03/24/2023-12:56:16] [V] [TRT] Tactic: 0 Time: 0.053248
[03/24/2023-12:56:16] [V] [TRT] Fastest Tactic: 1002 Time: 0.034304
[03/24/2023-12:56:16] [V] [TRT] *************** Autotuning Reformat: Float(4147200,32400,180,1) -> Half(4147200,32400,180,1) ***************
[03/24/2023-12:56:16] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(input.12 -> <out>) (Reformat)
[03/24/2023-12:56:16] [V] [TRT] Tactic: 1002 Time: 0.033024
[03/24/2023-12:56:16] [V] [TRT] Tactic: 0 Time: 0.042112
[03/24/2023-12:56:16] [V] [TRT] Fastest Tactic: 1002 Time: 0.033024
[03/24/2023-12:56:16] [V] [TRT] *************** Autotuning Reformat: Float(4147200,32400,180,1) -> Half(2073600,32400:2,180,1) ***************
[03/24/2023-12:56:16] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(input.12 -> <out>) (Reformat)
[03/24/2023-12:56:16] [V] [TRT] Tactic: 1002 Time: 0.036608
[03/24/2023-12:56:16] [V] [TRT] Tactic: 0 Time: 0.031104
[03/24/2023-12:56:16] [V] [TRT] Fastest Tactic: 0 Time: 0.031104
[03/24/2023-12:56:16] [V] [TRT] *************** Autotuning Reformat: Float(4147200,32400,180,1) -> Half(518400,1:8,2880,16) ***************
[03/24/2023-12:56:16] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(input.12 -> <out>) (Reformat)
[03/24/2023-12:56:16] [V] [TRT] Tactic: 1002 Time: 0.027264
[03/24/2023-12:56:16] [V] [TRT] Tactic: 0 Time: 0.020224
[03/24/2023-12:56:16] [V] [TRT] Fastest Tactic: 0 Time: 0.020224
[03/24/2023-12:56:16] [V] [TRT] *************** Autotuning Reformat: Float(4147200,32400,180,1) -> Half(259200,1:16,1440,8) ***************
[03/24/2023-12:56:16] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(input.12 -> <out>) (Reformat)
[03/24/2023-12:56:16] [V] [TRT] Tactic: 1002 Time: 0.02752
[03/24/2023-12:56:16] [V] [TRT] Tactic: 0 Time: 0.04992
[03/24/2023-12:56:16] [V] [TRT] Fastest Tactic: 1002 Time: 0.02752
[03/24/2023-12:56:16] [V] [TRT] *************** Autotuning Reformat: Float(4147200,1,23040,128) -> Float(4147200,32400,180,1) ***************
[03/24/2023-12:56:16] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(input.12 -> <out>) (Reformat)
[03/24/2023-12:56:16] [V] [TRT] Tactic: 1002 Time: 0.032256
[03/24/2023-12:56:16] [V] [TRT] Tactic: 0 Time: 0.061056
[03/24/2023-12:56:16] [V] [TRT] Fastest Tactic: 1002 Time: 0.032256
[03/24/2023-12:56:16] [V] [TRT] *************** Autotuning Reformat: Float(4147200,1,23040,128) -> Float(1036800,1:4,5760,32) ***************
[03/24/2023-12:56:16] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(input.12 -> <out>) (Reformat)
[03/24/2023-12:56:16] [V] [TRT] Tactic: 1002 Time: 0.031104
[03/24/2023-12:56:16] [V] [TRT] Tactic: 0 Time: 0.039936
[03/24/2023-12:56:16] [V] [TRT] Fastest Tactic: 1002 Time: 0.031104
[03/24/2023-12:56:16] [V] [TRT] *************** Autotuning Reformat: Float(4147200,1,23040,128) -> Half(4147200,32400,180,1) ***************
[03/24/2023-12:56:16] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(input.12 -> <out>) (Reformat)
[03/24/2023-12:56:16] [V] [TRT] Tactic: 1002 Time: 0.027904
[03/24/2023-12:56:16] [V] [TRT] Tactic: 0 Time: 0.051072
[03/24/2023-12:56:16] [V] [TRT] Fastest Tactic: 1002 Time: 0.027904
[03/24/2023-12:56:16] [V] [TRT] *************** Autotuning Reformat: Float(4147200,1,23040,128) -> Half(2073600,32400:2,180,1) ***************
[03/24/2023-12:56:16] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(input.12 -> <out>) (Reformat)
[03/24/2023-12:56:16] [V] [TRT] Tactic: 1002 Time: 0.034944
[03/24/2023-12:56:16] [V] [TRT] Tactic: 0 Time: 0.051456
[03/24/2023-12:56:16] [V] [TRT] Fastest Tactic: 1002 Time: 0.034944
[03/24/2023-12:56:16] [V] [TRT] *************** Autotuning Reformat: Float(4147200,1,23040,128) -> Half(518400,1:8,2880,16) ***************
[03/24/2023-12:56:16] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(input.12 -> <out>) (Reformat)
[03/24/2023-12:56:16] [V] [TRT] Tactic: 1002 Time: 0.024576
[03/24/2023-12:56:16] [V] [TRT] Tactic: 0 Time: 0.03904
[03/24/2023-12:56:16] [V] [TRT] Fastest Tactic: 1002 Time: 0.024576
[03/24/2023-12:56:16] [V] [TRT] *************** Autotuning Reformat: Float(4147200,1,23040,128) -> Half(259200,1:16,1440,8) ***************
[03/24/2023-12:56:16] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(input.12 -> <out>) (Reformat)
[03/24/2023-12:56:16] [V] [TRT] Tactic: 1002 Time: 0.024576
[03/24/2023-12:56:16] [V] [TRT] Tactic: 0 Time: 0.03904
[03/24/2023-12:56:16] [V] [TRT] Fastest Tactic: 1002 Time: 0.024576
[03/24/2023-12:56:16] [V] [TRT] *************** Autotuning Reformat: Float(1036800,1:4,5760,32) -> Float(4147200,32400,180,1) ***************
[03/24/2023-12:56:16] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(input.12 -> <out>) (Reformat)
[03/24/2023-12:56:16] [V] [TRT] Tactic: 1002 Time: 0.032512
[03/24/2023-12:56:16] [V] [TRT] Tactic: 0 Time: 0.061696
[03/24/2023-12:56:16] [V] [TRT] Fastest Tactic: 1002 Time: 0.032512
[03/24/2023-12:56:16] [V] [TRT] *************** Autotuning Reformat: Float(1036800,1:4,5760,32) -> Float(4147200,1,23040,128) ***************
[03/24/2023-12:56:16] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(input.12 -> <out>) (Reformat)
[03/24/2023-12:56:17] [V] [TRT] Tactic: 1002 Time: 0.031104
[03/24/2023-12:56:17] [V] [TRT] Tactic: 0 Time: 0.039808
[03/24/2023-12:56:17] [V] [TRT] Fastest Tactic: 1002 Time: 0.031104
[03/24/2023-12:56:17] [V] [TRT] *************** Autotuning Reformat: Float(1036800,1:4,5760,32) -> Half(4147200,32400,180,1) ***************
[03/24/2023-12:56:17] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(input.12 -> <out>) (Reformat)
[03/24/2023-12:56:17] [V] [TRT] Tactic: 1002 Time: 0.02816
[03/24/2023-12:56:17] [V] [TRT] Tactic: 0 Time: 0.051328
[03/24/2023-12:56:17] [V] [TRT] Fastest Tactic: 1002 Time: 0.02816
[03/24/2023-12:56:17] [V] [TRT] *************** Autotuning Reformat: Float(1036800,1:4,5760,32) -> Half(2073600,32400:2,180,1) ***************
[03/24/2023-12:56:17] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(input.12 -> <out>) (Reformat)
[03/24/2023-12:56:17] [V] [TRT] Tactic: 1002 Time: 0.034944
[03/24/2023-12:56:17] [V] [TRT] Tactic: 0 Time: 0.0512
[03/24/2023-12:56:17] [V] [TRT] Fastest Tactic: 1002 Time: 0.034944
[03/24/2023-12:56:17] [V] [TRT] *************** Autotuning Reformat: Float(1036800,1:4,5760,32) -> Half(518400,1:8,2880,16) ***************
[03/24/2023-12:56:17] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(input.12 -> <out>) (Reformat)
[03/24/2023-12:56:17] [V] [TRT] Tactic: 1002 Time: 0.024704
[03/24/2023-12:56:17] [V] [TRT] Tactic: 0 Time: 0.045056
[03/24/2023-12:56:17] [V] [TRT] Fastest Tactic: 1002 Time: 0.024704
[03/24/2023-12:56:17] [V] [TRT] *************** Autotuning Reformat: Float(1036800,1:4,5760,32) -> Half(259200,1:16,1440,8) ***************
[03/24/2023-12:56:17] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(input.12 -> <out>) (Reformat)
[03/24/2023-12:56:17] [V] [TRT] Tactic: 1002 Time: 0.02432
[03/24/2023-12:56:17] [V] [TRT] Tactic: 0 Time: 0.045056
[03/24/2023-12:56:17] [V] [TRT] Fastest Tactic: 1002 Time: 0.02432
[03/24/2023-12:56:17] [V] [TRT] *************** Autotuning Reformat: Half(4147200,32400,180,1) -> Float(4147200,32400,180,1) ***************
[03/24/2023-12:56:17] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(input.12 -> <out>) (Reformat)
[03/24/2023-12:56:17] [V] [TRT] Tactic: 1002 Time: 0.032896
[03/24/2023-12:56:17] [V] [TRT] Tactic: 0 Time: 0.040576
[03/24/2023-12:56:17] [V] [TRT] Fastest Tactic: 1002 Time: 0.032896
[03/24/2023-12:56:17] [V] [TRT] *************** Autotuning Reformat: Half(4147200,32400,180,1) -> Float(4147200,1,23040,128) ***************
[03/24/2023-12:56:17] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(input.12 -> <out>) (Reformat)
[03/24/2023-12:56:17] [V] [TRT] Tactic: 1002 Time: 0.027264
[03/24/2023-12:56:17] [V] [TRT] Tactic: 0 Time: 0.048768
[03/24/2023-12:56:17] [V] [TRT] Fastest Tactic: 1002 Time: 0.027264
[03/24/2023-12:56:17] [V] [TRT] *************** Autotuning Reformat: Half(4147200,32400,180,1) -> Float(1036800,1:4,5760,32) ***************
[03/24/2023-12:56:17] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(input.12 -> <out>) (Reformat)
[03/24/2023-12:56:17] [V] [TRT] Tactic: 1002 Time: 0.027392
[03/24/2023-12:56:17] [V] [TRT] Tactic: 0 Time: 0.050816
[03/24/2023-12:56:17] [V] [TRT] Fastest Tactic: 1002 Time: 0.027392
[03/24/2023-12:56:17] [V] [TRT] *************** Autotuning Reformat: Half(4147200,32400,180,1) -> Half(2073600,32400:2,180,1) ***************
[03/24/2023-12:56:17] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(input.12 -> <out>) (Reformat)
[03/24/2023-12:56:17] [V] [TRT] Tactic: 1002 Time: 0.025728
[03/24/2023-12:56:17] [V] [TRT] Tactic: 0 Time: 0.03072
[03/24/2023-12:56:17] [V] [TRT] Fastest Tactic: 1002 Time: 0.025728
[03/24/2023-12:56:17] [V] [TRT] *************** Autotuning Reformat: Half(4147200,32400,180,1) -> Half(518400,1:8,2880,16) ***************
[03/24/2023-12:56:17] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(input.12 -> <out>) (Reformat)
[03/24/2023-12:56:17] [V] [TRT] Tactic: 1002 Time: 0.025984
[03/24/2023-12:56:17] [V] [TRT] Tactic: 0 Time: 0.019456
[03/24/2023-12:56:17] [V] [TRT] Fastest Tactic: 0 Time: 0.019456
[03/24/2023-12:56:17] [V] [TRT] *************** Autotuning Reformat: Half(4147200,32400,180,1) -> Half(259200,1:16,1440,8) ***************
[03/24/2023-12:56:17] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(input.12 -> <out>) (Reformat)
[03/24/2023-12:56:17] [V] [TRT] Tactic: 1002 Time: 0.025728
[03/24/2023-12:56:17] [V] [TRT] Tactic: 0 Time: 0.046848
[03/24/2023-12:56:17] [V] [TRT] Fastest Tactic: 1002 Time: 0.025728
[03/24/2023-12:56:17] [V] [TRT] *************** Autotuning Reformat: Half(2073600,32400:2,180,1) -> Float(4147200,32400,180,1) ***************
[03/24/2023-12:56:17] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(input.12 -> <out>) (Reformat)
[03/24/2023-12:56:17] [V] [TRT] Tactic: 1002 Time: 0.031488
[03/24/2023-12:56:17] [V] [TRT] Tactic: 0 Time: 0.03072
[03/24/2023-12:56:17] [V] [TRT] Fastest Tactic: 0 Time: 0.03072
[03/24/2023-12:56:17] [V] [TRT] *************** Autotuning Reformat: Half(2073600,32400:2,180,1) -> Float(4147200,1,23040,128) ***************
[03/24/2023-12:56:17] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(input.12 -> <out>) (Reformat)
[03/24/2023-12:56:17] [V] [TRT] Tactic: 1002 Time: 0.027648
[03/24/2023-12:56:17] [V] [TRT] Tactic: 0 Time: 0.040192
[03/24/2023-12:56:17] [V] [TRT] Fastest Tactic: 1002 Time: 0.027648
[03/24/2023-12:56:17] [V] [TRT] *************** Autotuning Reformat: Half(2073600,32400:2,180,1) -> Float(1036800,1:4,5760,32) ***************
[03/24/2023-12:56:17] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(input.12 -> <out>) (Reformat)
[03/24/2023-12:56:17] [V] [TRT] Tactic: 1002 Time: 0.02752
[03/24/2023-12:56:17] [V] [TRT] Tactic: 0 Time: 0.045568
[03/24/2023-12:56:17] [V] [TRT] Fastest Tactic: 1002 Time: 0.02752
[03/24/2023-12:56:17] [V] [TRT] *************** Autotuning Reformat: Half(2073600,32400:2,180,1) -> Half(4147200,32400,180,1) ***************
[03/24/2023-12:56:17] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(input.12 -> <out>) (Reformat)
[03/24/2023-12:56:17] [V] [TRT] Tactic: 1002 Time: 0.078208
[03/24/2023-12:56:17] [V] [TRT] Tactic: 0 Time: 0.030592
[03/24/2023-12:56:17] [V] [TRT] Fastest Tactic: 0 Time: 0.030592
[03/24/2023-12:56:17] [V] [TRT] *************** Autotuning Reformat: Half(2073600,32400:2,180,1) -> Half(518400,1:8,2880,16) ***************
[03/24/2023-12:56:17] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(input.12 -> <out>) (Reformat)
[03/24/2023-12:56:17] [V] [TRT] Tactic: 1002 Time: 0.026624
[03/24/2023-12:56:17] [V] [TRT] Tactic: 0 Time: 0.01408
[03/24/2023-12:56:17] [V] [TRT] Fastest Tactic: 0 Time: 0.01408
[03/24/2023-12:56:17] [V] [TRT] *************** Autotuning Reformat: Half(2073600,32400:2,180,1) -> Half(259200,1:16,1440,8) ***************
[03/24/2023-12:56:17] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(input.12 -> <out>) (Reformat)
[03/24/2023-12:56:17] [V] [TRT] Tactic: 1002 Time: 0.026368
[03/24/2023-12:56:17] [V] [TRT] Tactic: 0 Time: 0.041728
[03/24/2023-12:56:17] [V] [TRT] Fastest Tactic: 1002 Time: 0.026368
[03/24/2023-12:56:17] [V] [TRT] *************** Autotuning Reformat: Half(518400,1:8,2880,16) -> Float(4147200,32400,180,1) ***************
[03/24/2023-12:56:17] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(input.12 -> <out>) (Reformat)
[03/24/2023-12:56:17] [V] [TRT] Tactic: 1002 Time: 0.028544
[03/24/2023-12:56:17] [V] [TRT] Tactic: 0 Time: 0.016256
[03/24/2023-12:56:17] [V] [TRT] Fastest Tactic: 0 Time: 0.016256
[03/24/2023-12:56:17] [V] [TRT] *************** Autotuning Reformat: Half(518400,1:8,2880,16) -> Float(4147200,1,23040,128) ***************
[03/24/2023-12:56:17] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(input.12 -> <out>) (Reformat)
[03/24/2023-12:56:17] [V] [TRT] Tactic: 1002 Time: 0.024576
[03/24/2023-12:56:17] [V] [TRT] Tactic: 0 Time: 0.039552
[03/24/2023-12:56:17] [V] [TRT] Fastest Tactic: 1002 Time: 0.024576
[03/24/2023-12:56:17] [V] [TRT] *************** Autotuning Reformat: Half(518400,1:8,2880,16) -> Float(1036800,1:4,5760,32) ***************
[03/24/2023-12:56:17] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(input.12 -> <out>) (Reformat)
[03/24/2023-12:56:17] [V] [TRT] Tactic: 1002 Time: 0.024576
[03/24/2023-12:56:17] [V] [TRT] Tactic: 0 Time: 0.044672
[03/24/2023-12:56:17] [V] [TRT] Fastest Tactic: 1002 Time: 0.024576
[03/24/2023-12:56:17] [V] [TRT] *************** Autotuning Reformat: Half(518400,1:8,2880,16) -> Half(4147200,32400,180,1) ***************
[03/24/2023-12:56:17] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(input.12 -> <out>) (Reformat)
[03/24/2023-12:56:17] [V] [TRT] Tactic: 1002 Time: 0.062976
[03/24/2023-12:56:17] [V] [TRT] Tactic: 0 Time: 0.014208
[03/24/2023-12:56:17] [V] [TRT] Fastest Tactic: 0 Time: 0.014208
[03/24/2023-12:56:17] [V] [TRT] *************** Autotuning Reformat: Half(518400,1:8,2880,16) -> Half(2073600,32400:2,180,1) ***************
[03/24/2023-12:56:17] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(input.12 -> <out>) (Reformat)
[03/24/2023-12:56:17] [V] [TRT] Tactic: 1002 Time: 0.03456
[03/24/2023-12:56:17] [V] [TRT] Tactic: 0 Time: 0.01408
[03/24/2023-12:56:17] [V] [TRT] Fastest Tactic: 0 Time: 0.01408
[03/24/2023-12:56:17] [V] [TRT] *************** Autotuning Reformat: Half(518400,1:8,2880,16) -> Half(259200,1:16,1440,8) ***************
[03/24/2023-12:56:17] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(input.12 -> <out>) (Reformat)
[03/24/2023-12:56:17] [V] [TRT] Tactic: 1002 Time: 0.02368
[03/24/2023-12:56:17] [V] [TRT] Tactic: 0 Time: 0.041728
[03/24/2023-12:56:17] [V] [TRT] Fastest Tactic: 1002 Time: 0.02368
[03/24/2023-12:56:17] [V] [TRT] *************** Autotuning Reformat: Half(259200,1:16,1440,8) -> Float(4147200,32400,180,1) ***************
[03/24/2023-12:56:17] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(input.12 -> <out>) (Reformat)
[03/24/2023-12:56:17] [V] [TRT] Tactic: 1002 Time: 0.028672
[03/24/2023-12:56:17] [V] [TRT] Tactic: 0 Time: 0.050048
[03/24/2023-12:56:17] [V] [TRT] Fastest Tactic: 1002 Time: 0.028672
[03/24/2023-12:56:17] [V] [TRT] *************** Autotuning Reformat: Half(259200,1:16,1440,8) -> Float(4147200,1,23040,128) ***************
[03/24/2023-12:56:17] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(input.12 -> <out>) (Reformat)
[03/24/2023-12:56:17] [V] [TRT] Tactic: 1002 Time: 0.024576
[03/24/2023-12:56:17] [V] [TRT] Tactic: 0 Time: 0.03968
[03/24/2023-12:56:17] [V] [TRT] Fastest Tactic: 1002 Time: 0.024576
[03/24/2023-12:56:17] [V] [TRT] *************** Autotuning Reformat: Half(259200,1:16,1440,8) -> Float(1036800,1:4,5760,32) ***************
[03/24/2023-12:56:17] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(input.12 -> <out>) (Reformat)
[03/24/2023-12:56:17] [V] [TRT] Tactic: 1002 Time: 0.024448
[03/24/2023-12:56:17] [V] [TRT] Tactic: 0 Time: 0.044928
[03/24/2023-12:56:17] [V] [TRT] Fastest Tactic: 1002 Time: 0.024448
[03/24/2023-12:56:17] [V] [TRT] *************** Autotuning Reformat: Half(259200,1:16,1440,8) -> Half(4147200,32400,180,1) ***************
[03/24/2023-12:56:17] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(input.12 -> <out>) (Reformat)
[03/24/2023-12:56:17] [V] [TRT] Tactic: 1002 Time: 0.063104
[03/24/2023-12:56:17] [V] [TRT] Tactic: 0 Time: 0.049024
[03/24/2023-12:56:17] [V] [TRT] Fastest Tactic: 0 Time: 0.049024
[03/24/2023-12:56:17] [V] [TRT] *************** Autotuning Reformat: Half(259200,1:16,1440,8) -> Half(2073600,32400:2,180,1) ***************
[03/24/2023-12:56:17] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(input.12 -> <out>) (Reformat)
[03/24/2023-12:56:17] [V] [TRT] Tactic: 1002 Time: 0.034816
[03/24/2023-12:56:17] [V] [TRT] Tactic: 0 Time: 0.0512
[03/24/2023-12:56:17] [V] [TRT] Fastest Tactic: 1002 Time: 0.034816
[03/24/2023-12:56:17] [V] [TRT] *************** Autotuning Reformat: Half(259200,1:16,1440,8) -> Half(518400,1:8,2880,16) ***************
[03/24/2023-12:56:17] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(input.12 -> <out>) (Reformat)
[03/24/2023-12:56:17] [V] [TRT] Tactic: 1002 Time: 0.023808
[03/24/2023-12:56:17] [V] [TRT] Tactic: 0 Time: 0.041856
[03/24/2023-12:56:17] [V] [TRT] Fastest Tactic: 1002 Time: 0.023808
[03/24/2023-12:56:17] [V] [TRT] =============== Computing reformatting costs
[03/24/2023-12:56:17] [V] [TRT] *************** Autotuning Reformat: Float(4147200,32400,180,1) -> Float(4147200,1,23040,128) ***************
[03/24/2023-12:56:17] [V] [TRT] *************** Autotuning Reformat: Float(4147200,32400,180,1) -> Float(1036800,1:4,5760,32) ***************
[03/24/2023-12:56:17] [V] [TRT] *************** Autotuning Reformat: Float(4147200,32400,180,1) -> Half(4147200,32400,180,1) ***************
[03/24/2023-12:56:17] [V] [TRT] *************** Autotuning Reformat: Float(4147200,32400,180,1) -> Half(2073600,32400:2,180,1) ***************
[03/24/2023-12:56:17] [V] [TRT] *************** Autotuning Reformat: Float(4147200,32400,180,1) -> Half(518400,1:8,2880,16) ***************
[03/24/2023-12:56:17] [V] [TRT] *************** Autotuning Reformat: Float(4147200,32400,180,1) -> Half(259200,1:16,1440,8) ***************
[03/24/2023-12:56:17] [V] [TRT] *************** Autotuning Reformat: Float(4147200,1,23040,128) -> Float(4147200,32400,180,1) ***************
[03/24/2023-12:56:17] [V] [TRT] *************** Autotuning Reformat: Float(4147200,1,23040,128) -> Float(1036800,1:4,5760,32) ***************
[03/24/2023-12:56:17] [V] [TRT] *************** Autotuning Reformat: Float(4147200,1,23040,128) -> Half(4147200,32400,180,1) ***************
[03/24/2023-12:56:17] [V] [TRT] *************** Autotuning Reformat: Float(4147200,1,23040,128) -> Half(2073600,32400:2,180,1) ***************
[03/24/2023-12:56:17] [V] [TRT] *************** Autotuning Reformat: Float(4147200,1,23040,128) -> Half(518400,1:8,2880,16) ***************
[03/24/2023-12:56:17] [V] [TRT] *************** Autotuning Reformat: Float(4147200,1,23040,128) -> Half(259200,1:16,1440,8) ***************
[03/24/2023-12:56:17] [V] [TRT] *************** Autotuning Reformat: Float(1036800,1:4,5760,32) -> Float(4147200,32400,180,1) ***************
[03/24/2023-12:56:17] [V] [TRT] *************** Autotuning Reformat: Float(1036800,1:4,5760,32) -> Float(4147200,1,23040,128) ***************
[03/24/2023-12:56:17] [V] [TRT] *************** Autotuning Reformat: Float(1036800,1:4,5760,32) -> Half(4147200,32400,180,1) ***************
[03/24/2023-12:56:17] [V] [TRT] *************** Autotuning Reformat: Float(1036800,1:4,5760,32) -> Half(2073600,32400:2,180,1) ***************
[03/24/2023-12:56:17] [V] [TRT] *************** Autotuning Reformat: Float(1036800,1:4,5760,32) -> Half(518400,1:8,2880,16) ***************
[03/24/2023-12:56:17] [V] [TRT] *************** Autotuning Reformat: Float(1036800,1:4,5760,32) -> Half(259200,1:16,1440,8) ***************
[03/24/2023-12:56:17] [V] [TRT] *************** Autotuning Reformat: Half(4147200,32400,180,1) -> Float(4147200,32400,180,1) ***************
[03/24/2023-12:56:17] [V] [TRT] *************** Autotuning Reformat: Half(4147200,32400,180,1) -> Float(4147200,1,23040,128) ***************
[03/24/2023-12:56:17] [V] [TRT] *************** Autotuning Reformat: Half(4147200,32400,180,1) -> Float(1036800,1:4,5760,32) ***************
[03/24/2023-12:56:17] [V] [TRT] *************** Autotuning Reformat: Half(4147200,32400,180,1) -> Half(2073600,32400:2,180,1) ***************
[03/24/2023-12:56:17] [V] [TRT] *************** Autotuning Reformat: Half(4147200,32400,180,1) -> Half(518400,1:8,2880,16) ***************
[03/24/2023-12:56:17] [V] [TRT] *************** Autotuning Reformat: Half(4147200,32400,180,1) -> Half(259200,1:16,1440,8) ***************
[03/24/2023-12:56:17] [V] [TRT] *************** Autotuning Reformat: Half(2073600,32400:2,180,1) -> Float(4147200,32400,180,1) ***************
[03/24/2023-12:56:17] [V] [TRT] *************** Autotuning Reformat: Half(2073600,32400:2,180,1) -> Float(4147200,1,23040,128) ***************
[03/24/2023-12:56:17] [V] [TRT] *************** Autotuning Reformat: Half(2073600,32400:2,180,1) -> Float(1036800,1:4,5760,32) ***************
[03/24/2023-12:56:17] [V] [TRT] *************** Autotuning Reformat: Half(2073600,32400:2,180,1) -> Half(4147200,32400,180,1) ***************
[03/24/2023-12:56:17] [V] [TRT] *************** Autotuning Reformat: Half(2073600,32400:2,180,1) -> Half(518400,1:8,2880,16) ***************
[03/24/2023-12:56:17] [V] [TRT] *************** Autotuning Reformat: Half(2073600,32400:2,180,1) -> Half(259200,1:16,1440,8) ***************
[03/24/2023-12:56:17] [V] [TRT] *************** Autotuning Reformat: Half(518400,1:8,2880,16) -> Float(4147200,32400,180,1) ***************
[03/24/2023-12:56:17] [V] [TRT] *************** Autotuning Reformat: Half(518400,1:8,2880,16) -> Float(4147200,1,23040,128) ***************
[03/24/2023-12:56:17] [V] [TRT] *************** Autotuning Reformat: Half(518400,1:8,2880,16) -> Float(1036800,1:4,5760,32) ***************
[03/24/2023-12:56:17] [V] [TRT] *************** Autotuning Reformat: Half(518400,1:8,2880,16) -> Half(4147200,32400,180,1) ***************
[03/24/2023-12:56:17] [V] [TRT] *************** Autotuning Reformat: Half(518400,1:8,2880,16) -> Half(2073600,32400:2,180,1) ***************
[03/24/2023-12:56:17] [V] [TRT] *************** Autotuning Reformat: Half(518400,1:8,2880,16) -> Half(259200,1:16,1440,8) ***************
[03/24/2023-12:56:17] [V] [TRT] *************** Autotuning Reformat: Half(259200,1:16,1440,8) -> Float(4147200,32400,180,1) ***************
[03/24/2023-12:56:17] [V] [TRT] *************** Autotuning Reformat: Half(259200,1:16,1440,8) -> Float(4147200,1,23040,128) ***************
[03/24/2023-12:56:17] [V] [TRT] *************** Autotuning Reformat: Half(259200,1:16,1440,8) -> Float(1036800,1:4,5760,32) ***************
[03/24/2023-12:56:17] [V] [TRT] *************** Autotuning Reformat: Half(259200,1:16,1440,8) -> Half(4147200,32400,180,1) ***************
[03/24/2023-12:56:17] [V] [TRT] *************** Autotuning Reformat: Half(259200,1:16,1440,8) -> Half(2073600,32400:2,180,1) ***************
[03/24/2023-12:56:17] [V] [TRT] *************** Autotuning Reformat: Half(259200,1:16,1440,8) -> Half(518400,1:8,2880,16) ***************
[03/24/2023-12:56:17] [V] [TRT] =============== Computing reformatting costs
[03/24/2023-12:56:17] [V] [TRT] *************** Autotuning Reformat: Float(4147200,32400,180,1) -> Float(4147200,1,23040,128) ***************
[03/24/2023-12:56:17] [V] [TRT] *************** Autotuning Reformat: Float(4147200,32400,180,1) -> Float(1036800,1:4,5760,32) ***************
[03/24/2023-12:56:17] [V] [TRT] *************** Autotuning Reformat: Float(4147200,32400,180,1) -> Half(4147200,32400,180,1) ***************
[03/24/2023-12:56:17] [V] [TRT] *************** Autotuning Reformat: Float(4147200,32400,180,1) -> Half(2073600,32400:2,180,1) ***************
[03/24/2023-12:56:17] [V] [TRT] *************** Autotuning Reformat: Float(4147200,32400,180,1) -> Half(518400,1:8,2880,16) ***************
[03/24/2023-12:56:17] [V] [TRT] *************** Autotuning Reformat: Float(4147200,32400,180,1) -> Half(259200,1:16,1440,8) ***************
[03/24/2023-12:56:17] [V] [TRT] *************** Autotuning Reformat: Float(4147200,1,23040,128) -> Float(4147200,32400,180,1) ***************
[03/24/2023-12:56:17] [V] [TRT] *************** Autotuning Reformat: Float(4147200,1,23040,128) -> Float(1036800,1:4,5760,32) ***************
[03/24/2023-12:56:17] [V] [TRT] *************** Autotuning Reformat: Float(4147200,1,23040,128) -> Half(4147200,32400,180,1) ***************
[03/24/2023-12:56:17] [V] [TRT] *************** Autotuning Reformat: Float(4147200,1,23040,128) -> Half(2073600,32400:2,180,1) ***************
[03/24/2023-12:56:17] [V] [TRT] *************** Autotuning Reformat: Float(4147200,1,23040,128) -> Half(518400,1:8,2880,16) ***************
[03/24/2023-12:56:17] [V] [TRT] *************** Autotuning Reformat: Float(4147200,1,23040,128) -> Half(259200,1:16,1440,8) ***************
[03/24/2023-12:56:17] [V] [TRT] *************** Autotuning Reformat: Float(1036800,1:4,5760,32) -> Float(4147200,32400,180,1) ***************
[03/24/2023-12:56:17] [V] [TRT] *************** Autotuning Reformat: Float(1036800,1:4,5760,32) -> Float(4147200,1,23040,128) ***************
[03/24/2023-12:56:17] [V] [TRT] *************** Autotuning Reformat: Float(1036800,1:4,5760,32) -> Half(4147200,32400,180,1) ***************
[03/24/2023-12:56:17] [V] [TRT] *************** Autotuning Reformat: Float(1036800,1:4,5760,32) -> Half(2073600,32400:2,180,1) ***************
[03/24/2023-12:56:17] [V] [TRT] *************** Autotuning Reformat: Float(1036800,1:4,5760,32) -> Half(518400,1:8,2880,16) ***************
[03/24/2023-12:56:17] [V] [TRT] *************** Autotuning Reformat: Float(1036800,1:4,5760,32) -> Half(259200,1:16,1440,8) ***************
[03/24/2023-12:56:17] [V] [TRT] *************** Autotuning Reformat: Half(4147200,32400,180,1) -> Float(4147200,32400,180,1) ***************
[03/24/2023-12:56:17] [V] [TRT] *************** Autotuning Reformat: Half(4147200,32400,180,1) -> Float(4147200,1,23040,128) ***************
[03/24/2023-12:56:17] [V] [TRT] *************** Autotuning Reformat: Half(4147200,32400,180,1) -> Float(1036800,1:4,5760,32) ***************
[03/24/2023-12:56:17] [V] [TRT] *************** Autotuning Reformat: Half(4147200,32400,180,1) -> Half(2073600,32400:2,180,1) ***************
[03/24/2023-12:56:17] [V] [TRT] *************** Autotuning Reformat: Half(4147200,32400,180,1) -> Half(518400,1:8,2880,16) ***************
[03/24/2023-12:56:17] [V] [TRT] *************** Autotuning Reformat: Half(4147200,32400,180,1) -> Half(259200,1:16,1440,8) ***************
[03/24/2023-12:56:17] [V] [TRT] *************** Autotuning Reformat: Half(2073600,32400:2,180,1) -> Float(4147200,32400,180,1) ***************
[03/24/2023-12:56:17] [V] [TRT] *************** Autotuning Reformat: Half(2073600,32400:2,180,1) -> Float(4147200,1,23040,128) ***************
[03/24/2023-12:56:17] [V] [TRT] *************** Autotuning Reformat: Half(2073600,32400:2,180,1) -> Float(1036800,1:4,5760,32) ***************
[03/24/2023-12:56:17] [V] [TRT] *************** Autotuning Reformat: Half(2073600,32400:2,180,1) -> Half(4147200,32400,180,1) ***************
[03/24/2023-12:56:17] [V] [TRT] *************** Autotuning Reformat: Half(2073600,32400:2,180,1) -> Half(518400,1:8,2880,16) ***************
[03/24/2023-12:56:17] [V] [TRT] *************** Autotuning Reformat: Half(2073600,32400:2,180,1) -> Half(259200,1:16,1440,8) ***************
[03/24/2023-12:56:17] [V] [TRT] *************** Autotuning Reformat: Half(518400,1:8,2880,16) -> Float(4147200,32400,180,1) ***************
[03/24/2023-12:56:17] [V] [TRT] *************** Autotuning Reformat: Half(518400,1:8,2880,16) -> Float(4147200,1,23040,128) ***************
[03/24/2023-12:56:17] [V] [TRT] *************** Autotuning Reformat: Half(518400,1:8,2880,16) -> Float(1036800,1:4,5760,32) ***************
[03/24/2023-12:56:17] [V] [TRT] *************** Autotuning Reformat: Half(518400,1:8,2880,16) -> Half(4147200,32400,180,1) ***************
[03/24/2023-12:56:17] [V] [TRT] *************** Autotuning Reformat: Half(518400,1:8,2880,16) -> Half(2073600,32400:2,180,1) ***************
[03/24/2023-12:56:17] [V] [TRT] *************** Autotuning Reformat: Half(518400,1:8,2880,16) -> Half(259200,1:16,1440,8) ***************
[03/24/2023-12:56:17] [V] [TRT] *************** Autotuning Reformat: Half(259200,1:16,1440,8) -> Float(4147200,32400,180,1) ***************
[03/24/2023-12:56:17] [V] [TRT] *************** Autotuning Reformat: Half(259200,1:16,1440,8) -> Float(4147200,1,23040,128) ***************
[03/24/2023-12:56:17] [V] [TRT] *************** Autotuning Reformat: Half(259200,1:16,1440,8) -> Float(1036800,1:4,5760,32) ***************
[03/24/2023-12:56:17] [V] [TRT] *************** Autotuning Reformat: Half(259200,1:16,1440,8) -> Half(4147200,32400,180,1) ***************
[03/24/2023-12:56:17] [V] [TRT] *************** Autotuning Reformat: Half(259200,1:16,1440,8) -> Half(2073600,32400:2,180,1) ***************
[03/24/2023-12:56:17] [V] [TRT] *************** Autotuning Reformat: Half(259200,1:16,1440,8) -> Half(518400,1:8,2880,16) ***************
[03/24/2023-12:56:17] [V] [TRT] =============== Computing reformatting costs
[03/24/2023-12:56:17] [V] [TRT] *************** Autotuning Reformat: Float(4147200,32400,180,1) -> Float(4147200,1,23040,128) ***************
[03/24/2023-12:56:17] [V] [TRT] *************** Autotuning Reformat: Float(4147200,32400,180,1) -> Float(1036800,1:4,5760,32) ***************
[03/24/2023-12:56:17] [V] [TRT] *************** Autotuning Reformat: Float(4147200,32400,180,1) -> Half(4147200,32400,180,1) ***************
[03/24/2023-12:56:17] [V] [TRT] *************** Autotuning Reformat: Float(4147200,32400,180,1) -> Half(2073600,32400:2,180,1) ***************
[03/24/2023-12:56:17] [V] [TRT] *************** Autotuning Reformat: Float(4147200,32400,180,1) -> Half(518400,1:8,2880,16) ***************
[03/24/2023-12:56:17] [V] [TRT] *************** Autotuning Reformat: Float(4147200,32400,180,1) -> Half(259200,1:16,1440,8) ***************
[03/24/2023-12:56:17] [V] [TRT] *************** Autotuning Reformat: Float(4147200,1,23040,128) -> Float(4147200,32400,180,1) ***************
[03/24/2023-12:56:17] [V] [TRT] *************** Autotuning Reformat: Float(4147200,1,23040,128) -> Float(1036800,1:4,5760,32) ***************
[03/24/2023-12:56:17] [V] [TRT] *************** Autotuning Reformat: Float(4147200,1,23040,128) -> Half(4147200,32400,180,1) ***************
[03/24/2023-12:56:17] [V] [TRT] *************** Autotuning Reformat: Float(4147200,1,23040,128) -> Half(2073600,32400:2,180,1) ***************
[03/24/2023-12:56:17] [V] [TRT] *************** Autotuning Reformat: Float(4147200,1,23040,128) -> Half(518400,1:8,2880,16) ***************
[03/24/2023-12:56:17] [V] [TRT] *************** Autotuning Reformat: Float(4147200,1,23040,128) -> Half(259200,1:16,1440,8) ***************
[03/24/2023-12:56:17] [V] [TRT] *************** Autotuning Reformat: Float(1036800,1:4,5760,32) -> Float(4147200,32400,180,1) ***************
[03/24/2023-12:56:17] [V] [TRT] *************** Autotuning Reformat: Float(1036800,1:4,5760,32) -> Float(4147200,1,23040,128) ***************
[03/24/2023-12:56:17] [V] [TRT] *************** Autotuning Reformat: Float(1036800,1:4,5760,32) -> Half(4147200,32400,180,1) ***************
[03/24/2023-12:56:17] [V] [TRT] *************** Autotuning Reformat: Float(1036800,1:4,5760,32) -> Half(2073600,32400:2,180,1) ***************
[03/24/2023-12:56:17] [V] [TRT] *************** Autotuning Reformat: Float(1036800,1:4,5760,32) -> Half(518400,1:8,2880,16) ***************
[03/24/2023-12:56:17] [V] [TRT] *************** Autotuning Reformat: Float(1036800,1:4,5760,32) -> Half(259200,1:16,1440,8) ***************
[03/24/2023-12:56:17] [V] [TRT] *************** Autotuning Reformat: Half(4147200,32400,180,1) -> Float(4147200,32400,180,1) ***************
[03/24/2023-12:56:17] [V] [TRT] *************** Autotuning Reformat: Half(4147200,32400,180,1) -> Float(4147200,1,23040,128) ***************
[03/24/2023-12:56:17] [V] [TRT] *************** Autotuning Reformat: Half(4147200,32400,180,1) -> Float(1036800,1:4,5760,32) ***************
[03/24/2023-12:56:17] [V] [TRT] *************** Autotuning Reformat: Half(4147200,32400,180,1) -> Half(2073600,32400:2,180,1) ***************
[03/24/2023-12:56:17] [V] [TRT] *************** Autotuning Reformat: Half(4147200,32400,180,1) -> Half(518400,1:8,2880,16) ***************
[03/24/2023-12:56:17] [V] [TRT] *************** Autotuning Reformat: Half(4147200,32400,180,1) -> Half(259200,1:16,1440,8) ***************
[03/24/2023-12:56:17] [V] [TRT] *************** Autotuning Reformat: Half(2073600,32400:2,180,1) -> Float(4147200,32400,180,1) ***************
[03/24/2023-12:56:17] [V] [TRT] *************** Autotuning Reformat: Half(2073600,32400:2,180,1) -> Float(4147200,1,23040,128) ***************
[03/24/2023-12:56:17] [V] [TRT] *************** Autotuning Reformat: Half(2073600,32400:2,180,1) -> Float(1036800,1:4,5760,32) ***************
[03/24/2023-12:56:17] [V] [TRT] *************** Autotuning Reformat: Half(2073600,32400:2,180,1) -> Half(4147200,32400,180,1) ***************
[03/24/2023-12:56:17] [V] [TRT] *************** Autotuning Reformat: Half(2073600,32400:2,180,1) -> Half(518400,1:8,2880,16) ***************
[03/24/2023-12:56:17] [V] [TRT] *************** Autotuning Reformat: Half(2073600,32400:2,180,1) -> Half(259200,1:16,1440,8) ***************
[03/24/2023-12:56:17] [V] [TRT] *************** Autotuning Reformat: Half(518400,1:8,2880,16) -> Float(4147200,32400,180,1) ***************
[03/24/2023-12:56:17] [V] [TRT] *************** Autotuning Reformat: Half(518400,1:8,2880,16) -> Float(4147200,1,23040,128) ***************
[03/24/2023-12:56:17] [V] [TRT] *************** Autotuning Reformat: Half(518400,1:8,2880,16) -> Float(1036800,1:4,5760,32) ***************
[03/24/2023-12:56:17] [V] [TRT] *************** Autotuning Reformat: Half(518400,1:8,2880,16) -> Half(4147200,32400,180,1) ***************
[03/24/2023-12:56:17] [V] [TRT] *************** Autotuning Reformat: Half(518400,1:8,2880,16) -> Half(2073600,32400:2,180,1) ***************
[03/24/2023-12:56:17] [V] [TRT] *************** Autotuning Reformat: Half(518400,1:8,2880,16) -> Half(259200,1:16,1440,8) ***************
[03/24/2023-12:56:17] [V] [TRT] *************** Autotuning Reformat: Half(259200,1:16,1440,8) -> Float(4147200,32400,180,1) ***************
[03/24/2023-12:56:17] [V] [TRT] *************** Autotuning Reformat: Half(259200,1:16,1440,8) -> Float(4147200,1,23040,128) ***************
[03/24/2023-12:56:17] [V] [TRT] *************** Autotuning Reformat: Half(259200,1:16,1440,8) -> Float(1036800,1:4,5760,32) ***************
[03/24/2023-12:56:17] [V] [TRT] *************** Autotuning Reformat: Half(259200,1:16,1440,8) -> Half(4147200,32400,180,1) ***************
[03/24/2023-12:56:17] [V] [TRT] *************** Autotuning Reformat: Half(259200,1:16,1440,8) -> Half(2073600,32400:2,180,1) ***************
[03/24/2023-12:56:17] [V] [TRT] *************** Autotuning Reformat: Half(259200,1:16,1440,8) -> Half(518400,1:8,2880,16) ***************
[03/24/2023-12:56:17] [V] [TRT] =============== Computing reformatting costs
[03/24/2023-12:56:17] [V] [TRT] *************** Autotuning Reformat: Float(4147200,32400,180,1) -> Float(4147200,1,23040,128) ***************
[03/24/2023-12:56:17] [V] [TRT] *************** Autotuning Reformat: Float(4147200,32400,180,1) -> Float(1036800,1:4,5760,32) ***************
[03/24/2023-12:56:17] [V] [TRT] *************** Autotuning Reformat: Float(4147200,32400,180,1) -> Half(4147200,32400,180,1) ***************
[03/24/2023-12:56:17] [V] [TRT] *************** Autotuning Reformat: Float(4147200,32400,180,1) -> Half(2073600,32400:2,180,1) ***************
[03/24/2023-12:56:17] [V] [TRT] *************** Autotuning Reformat: Float(4147200,32400,180,1) -> Half(518400,1:8,2880,16) ***************
[03/24/2023-12:56:17] [V] [TRT] *************** Autotuning Reformat: Float(4147200,32400,180,1) -> Half(259200,1:16,1440,8) ***************
[03/24/2023-12:56:17] [V] [TRT] *************** Autotuning Reformat: Float(4147200,1,23040,128) -> Float(4147200,32400,180,1) ***************
[03/24/2023-12:56:17] [V] [TRT] *************** Autotuning Reformat: Float(4147200,1,23040,128) -> Float(1036800,1:4,5760,32) ***************
[03/24/2023-12:56:17] [V] [TRT] *************** Autotuning Reformat: Float(4147200,1,23040,128) -> Half(4147200,32400,180,1) ***************
[03/24/2023-12:56:17] [V] [TRT] *************** Autotuning Reformat: Float(4147200,1,23040,128) -> Half(2073600,32400:2,180,1) ***************
[03/24/2023-12:56:17] [V] [TRT] *************** Autotuning Reformat: Float(4147200,1,23040,128) -> Half(518400,1:8,2880,16) ***************
[03/24/2023-12:56:17] [V] [TRT] *************** Autotuning Reformat: Float(4147200,1,23040,128) -> Half(259200,1:16,1440,8) ***************
[03/24/2023-12:56:17] [V] [TRT] *************** Autotuning Reformat: Float(1036800,1:4,5760,32) -> Float(4147200,32400,180,1) ***************
[03/24/2023-12:56:17] [V] [TRT] *************** Autotuning Reformat: Float(1036800,1:4,5760,32) -> Float(4147200,1,23040,128) ***************
[03/24/2023-12:56:17] [V] [TRT] *************** Autotuning Reformat: Float(1036800,1:4,5760,32) -> Half(4147200,32400,180,1) ***************
[03/24/2023-12:56:17] [V] [TRT] *************** Autotuning Reformat: Float(1036800,1:4,5760,32) -> Half(2073600,32400:2,180,1) ***************
[03/24/2023-12:56:17] [V] [TRT] *************** Autotuning Reformat: Float(1036800,1:4,5760,32) -> Half(518400,1:8,2880,16) ***************
[03/24/2023-12:56:17] [V] [TRT] *************** Autotuning Reformat: Float(1036800,1:4,5760,32) -> Half(259200,1:16,1440,8) ***************
[03/24/2023-12:56:17] [V] [TRT] *************** Autotuning Reformat: Half(4147200,32400,180,1) -> Float(4147200,32400,180,1) ***************
[03/24/2023-12:56:17] [V] [TRT] *************** Autotuning Reformat: Half(4147200,32400,180,1) -> Float(4147200,1,23040,128) ***************
[03/24/2023-12:56:17] [V] [TRT] *************** Autotuning Reformat: Half(4147200,32400,180,1) -> Float(1036800,1:4,5760,32) ***************
[03/24/2023-12:56:17] [V] [TRT] *************** Autotuning Reformat: Half(4147200,32400,180,1) -> Half(2073600,32400:2,180,1) ***************
[03/24/2023-12:56:17] [V] [TRT] *************** Autotuning Reformat: Half(4147200,32400,180,1) -> Half(518400,1:8,2880,16) ***************
[03/24/2023-12:56:17] [V] [TRT] *************** Autotuning Reformat: Half(4147200,32400,180,1) -> Half(259200,1:16,1440,8) ***************
[03/24/2023-12:56:17] [V] [TRT] *************** Autotuning Reformat: Half(2073600,32400:2,180,1) -> Float(4147200,32400,180,1) ***************
[03/24/2023-12:56:17] [V] [TRT] *************** Autotuning Reformat: Half(2073600,32400:2,180,1) -> Float(4147200,1,23040,128) ***************
[03/24/2023-12:56:17] [V] [TRT] *************** Autotuning Reformat: Half(2073600,32400:2,180,1) -> Float(1036800,1:4,5760,32) ***************
[03/24/2023-12:56:17] [V] [TRT] *************** Autotuning Reformat: Half(2073600,32400:2,180,1) -> Half(4147200,32400,180,1) ***************
[03/24/2023-12:56:17] [V] [TRT] *************** Autotuning Reformat: Half(2073600,32400:2,180,1) -> Half(518400,1:8,2880,16) ***************
[03/24/2023-12:56:17] [V] [TRT] *************** Autotuning Reformat: Half(2073600,32400:2,180,1) -> Half(259200,1:16,1440,8) ***************
[03/24/2023-12:56:17] [V] [TRT] *************** Autotuning Reformat: Half(518400,1:8,2880,16) -> Float(4147200,32400,180,1) ***************
[03/24/2023-12:56:17] [V] [TRT] *************** Autotuning Reformat: Half(518400,1:8,2880,16) -> Float(4147200,1,23040,128) ***************
[03/24/2023-12:56:17] [V] [TRT] *************** Autotuning Reformat: Half(518400,1:8,2880,16) -> Float(1036800,1:4,5760,32) ***************
[03/24/2023-12:56:17] [V] [TRT] *************** Autotuning Reformat: Half(518400,1:8,2880,16) -> Half(4147200,32400,180,1) ***************
[03/24/2023-12:56:17] [V] [TRT] *************** Autotuning Reformat: Half(518400,1:8,2880,16) -> Half(2073600,32400:2,180,1) ***************
[03/24/2023-12:56:17] [V] [TRT] *************** Autotuning Reformat: Half(518400,1:8,2880,16) -> Half(259200,1:16,1440,8) ***************
[03/24/2023-12:56:17] [V] [TRT] *************** Autotuning Reformat: Half(259200,1:16,1440,8) -> Float(4147200,32400,180,1) ***************
[03/24/2023-12:56:17] [V] [TRT] *************** Autotuning Reformat: Half(259200,1:16,1440,8) -> Float(4147200,1,23040,128) ***************
[03/24/2023-12:56:17] [V] [TRT] *************** Autotuning Reformat: Half(259200,1:16,1440,8) -> Float(1036800,1:4,5760,32) ***************
[03/24/2023-12:56:17] [V] [TRT] *************** Autotuning Reformat: Half(259200,1:16,1440,8) -> Half(4147200,32400,180,1) ***************
[03/24/2023-12:56:17] [V] [TRT] *************** Autotuning Reformat: Half(259200,1:16,1440,8) -> Half(2073600,32400:2,180,1) ***************
[03/24/2023-12:56:17] [V] [TRT] *************** Autotuning Reformat: Half(259200,1:16,1440,8) -> Half(518400,1:8,2880,16) ***************
[03/24/2023-12:56:17] [V] [TRT] =============== Computing reformatting costs
[03/24/2023-12:56:17] [V] [TRT] *************** Autotuning Reformat: Float(4147200,32400,180,1) -> Float(4147200,1,23040,128) ***************
[03/24/2023-12:56:17] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> input.72) (Reformat)
[03/24/2023-12:56:17] [V] [TRT] Tactic: 1002 Time: 0.03392
[03/24/2023-12:56:17] [V] [TRT] Tactic: 0 Time: 0.052224
[03/24/2023-12:56:17] [V] [TRT] Fastest Tactic: 1002 Time: 0.03392
[03/24/2023-12:56:17] [V] [TRT] *************** Autotuning Reformat: Float(4147200,32400,180,1) -> Float(1036800,1:4,5760,32) ***************
[03/24/2023-12:56:17] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> input.72) (Reformat)
[03/24/2023-12:56:17] [V] [TRT] Tactic: 1002 Time: 0.03392
[03/24/2023-12:56:17] [V] [TRT] Tactic: 0 Time: 0.053248
[03/24/2023-12:56:17] [V] [TRT] Fastest Tactic: 1002 Time: 0.03392
[03/24/2023-12:56:17] [V] [TRT] *************** Autotuning Reformat: Float(4147200,32400,180,1) -> Half(4147200,32400,180,1) ***************
[03/24/2023-12:56:17] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> input.72) (Reformat)
[03/24/2023-12:56:17] [V] [TRT] Tactic: 1002 Time: 0.033152
[03/24/2023-12:56:17] [V] [TRT] Tactic: 0 Time: 0.042112
[03/24/2023-12:56:17] [V] [TRT] Fastest Tactic: 1002 Time: 0.033152
[03/24/2023-12:56:17] [V] [TRT] *************** Autotuning Reformat: Float(4147200,32400,180,1) -> Half(2073600,32400:2,180,1) ***************
[03/24/2023-12:56:17] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> input.72) (Reformat)
[03/24/2023-12:56:17] [V] [TRT] Tactic: 1002 Time: 0.036096
[03/24/2023-12:56:17] [V] [TRT] Tactic: 0 Time: 0.030976
[03/24/2023-12:56:17] [V] [TRT] Fastest Tactic: 0 Time: 0.030976
[03/24/2023-12:56:17] [V] [TRT] *************** Autotuning Reformat: Float(4147200,32400,180,1) -> Half(518400,1:8,2880,16) ***************
[03/24/2023-12:56:17] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> input.72) (Reformat)
[03/24/2023-12:56:17] [V] [TRT] Tactic: 1002 Time: 0.027264
[03/24/2023-12:56:17] [V] [TRT] Tactic: 0 Time: 0.020096
[03/24/2023-12:56:17] [V] [TRT] Fastest Tactic: 0 Time: 0.020096
[03/24/2023-12:56:17] [V] [TRT] *************** Autotuning Reformat: Float(4147200,32400,180,1) -> Half(259200,1:16,1440,8) ***************
[03/24/2023-12:56:17] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> input.72) (Reformat)
[03/24/2023-12:56:17] [V] [TRT] Tactic: 1002 Time: 0.02752
[03/24/2023-12:56:17] [V] [TRT] Tactic: 0 Time: 0.04992
[03/24/2023-12:56:17] [V] [TRT] Fastest Tactic: 1002 Time: 0.02752
[03/24/2023-12:56:17] [V] [TRT] *************** Autotuning Reformat: Float(4147200,1,23040,128) -> Float(4147200,32400,180,1) ***************
[03/24/2023-12:56:17] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> input.72) (Reformat)
[03/24/2023-12:56:17] [V] [TRT] Tactic: 1002 Time: 0.032
[03/24/2023-12:56:17] [V] [TRT] Tactic: 0 Time: 0.0608
[03/24/2023-12:56:17] [V] [TRT] Fastest Tactic: 1002 Time: 0.032
[03/24/2023-12:56:17] [V] [TRT] *************** Autotuning Reformat: Float(4147200,1,23040,128) -> Float(1036800,1:4,5760,32) ***************
[03/24/2023-12:56:17] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> input.72) (Reformat)
[03/24/2023-12:56:17] [V] [TRT] Tactic: 1002 Time: 0.030848
[03/24/2023-12:56:17] [V] [TRT] Tactic: 0 Time: 0.069632
[03/24/2023-12:56:17] [V] [TRT] Fastest Tactic: 1002 Time: 0.030848
[03/24/2023-12:56:17] [V] [TRT] *************** Autotuning Reformat: Float(4147200,1,23040,128) -> Half(4147200,32400,180,1) ***************
[03/24/2023-12:56:17] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> input.72) (Reformat)
[03/24/2023-12:56:17] [V] [TRT] Tactic: 1002 Time: 0.049536
[03/24/2023-12:56:17] [V] [TRT] Tactic: 0 Time: 0.09152
[03/24/2023-12:56:17] [V] [TRT] Fastest Tactic: 1002 Time: 0.049536
[03/24/2023-12:56:17] [V] [TRT] *************** Autotuning Reformat: Float(4147200,1,23040,128) -> Half(2073600,32400:2,180,1) ***************
[03/24/2023-12:56:17] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> input.72) (Reformat)
[03/24/2023-12:56:17] [V] [TRT] Tactic: 1002 Time: 0.062464
[03/24/2023-12:56:17] [V] [TRT] Tactic: 0 Time: 0.092928
[03/24/2023-12:56:17] [V] [TRT] Fastest Tactic: 1002 Time: 0.062464
[03/24/2023-12:56:17] [V] [TRT] *************** Autotuning Reformat: Float(4147200,1,23040,128) -> Half(518400,1:8,2880,16) ***************
[03/24/2023-12:56:17] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> input.72) (Reformat)
[03/24/2023-12:56:17] [V] [TRT] Tactic: 1002 Time: 0.04288
[03/24/2023-12:56:17] [V] [TRT] Tactic: 0 Time: 0.069248
[03/24/2023-12:56:17] [V] [TRT] Fastest Tactic: 1002 Time: 0.04288
[03/24/2023-12:56:17] [V] [TRT] *************** Autotuning Reformat: Float(4147200,1,23040,128) -> Half(259200,1:16,1440,8) ***************
[03/24/2023-12:56:17] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> input.72) (Reformat)
[03/24/2023-12:56:17] [V] [TRT] Tactic: 1002 Time: 0.043008
[03/24/2023-12:56:17] [V] [TRT] Tactic: 0 Time: 0.069376
[03/24/2023-12:56:17] [V] [TRT] Fastest Tactic: 1002 Time: 0.043008
[03/24/2023-12:56:17] [V] [TRT] *************** Autotuning Reformat: Float(1036800,1:4,5760,32) -> Float(4147200,32400,180,1) ***************
[03/24/2023-12:56:17] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> input.72) (Reformat)
[03/24/2023-12:56:17] [V] [TRT] Tactic: 1002 Time: 0.055552
[03/24/2023-12:56:17] [V] [TRT] Tactic: 0 Time: 0.098816
[03/24/2023-12:56:17] [V] [TRT] Fastest Tactic: 1002 Time: 0.055552
[03/24/2023-12:56:17] [V] [TRT] *************** Autotuning Reformat: Float(1036800,1:4,5760,32) -> Float(4147200,1,23040,128) ***************
[03/24/2023-12:56:17] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> input.72) (Reformat)
[03/24/2023-12:56:17] [V] [TRT] Tactic: 1002 Time: 0.04672
[03/24/2023-12:56:17] [V] [TRT] Tactic: 0 Time: 0.069888
[03/24/2023-12:56:17] [V] [TRT] Fastest Tactic: 1002 Time: 0.04672
[03/24/2023-12:56:17] [V] [TRT] *************** Autotuning Reformat: Float(1036800,1:4,5760,32) -> Half(4147200,32400,180,1) ***************
[03/24/2023-12:56:17] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> input.72) (Reformat)
[03/24/2023-12:56:17] [V] [TRT] Tactic: 1002 Time: 0.049408
[03/24/2023-12:56:17] [V] [TRT] Tactic: 0 Time: 0.09152
[03/24/2023-12:56:17] [V] [TRT] Fastest Tactic: 1002 Time: 0.049408
[03/24/2023-12:56:17] [V] [TRT] *************** Autotuning Reformat: Float(1036800,1:4,5760,32) -> Half(2073600,32400:2,180,1) ***************
[03/24/2023-12:56:17] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> input.72) (Reformat)
[03/24/2023-12:56:17] [V] [TRT] Tactic: 1002 Time: 0.062464
[03/24/2023-12:56:17] [V] [TRT] Tactic: 0 Time: 0.092672
[03/24/2023-12:56:17] [V] [TRT] Fastest Tactic: 1002 Time: 0.062464
[03/24/2023-12:56:17] [V] [TRT] *************** Autotuning Reformat: Float(1036800,1:4,5760,32) -> Half(518400,1:8,2880,16) ***************
[03/24/2023-12:56:17] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> input.72) (Reformat)
[03/24/2023-12:56:17] [V] [TRT] Tactic: 1002 Time: 0.043008
[03/24/2023-12:56:17] [V] [TRT] Tactic: 0 Time: 0.079872
[03/24/2023-12:56:17] [V] [TRT] Fastest Tactic: 1002 Time: 0.043008
[03/24/2023-12:56:17] [V] [TRT] *************** Autotuning Reformat: Float(1036800,1:4,5760,32) -> Half(259200,1:16,1440,8) ***************
[03/24/2023-12:56:17] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> input.72) (Reformat)
[03/24/2023-12:56:17] [V] [TRT] Tactic: 1002 Time: 0.043136
[03/24/2023-12:56:17] [V] [TRT] Tactic: 0 Time: 0.079872
[03/24/2023-12:56:17] [V] [TRT] Fastest Tactic: 1002 Time: 0.043136
[03/24/2023-12:56:17] [V] [TRT] *************** Autotuning Reformat: Half(4147200,32400,180,1) -> Float(4147200,32400,180,1) ***************
[03/24/2023-12:56:17] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> input.72) (Reformat)
[03/24/2023-12:56:17] [V] [TRT] Tactic: 1002 Time: 0.058752
[03/24/2023-12:56:17] [V] [TRT] Tactic: 0 Time: 0.073728
[03/24/2023-12:56:17] [V] [TRT] Fastest Tactic: 1002 Time: 0.058752
[03/24/2023-12:56:17] [V] [TRT] *************** Autotuning Reformat: Half(4147200,32400,180,1) -> Float(4147200,1,23040,128) ***************
[03/24/2023-12:56:17] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> input.72) (Reformat)
[03/24/2023-12:56:17] [V] [TRT] Tactic: 1002 Time: 0.047488
[03/24/2023-12:56:17] [V] [TRT] Tactic: 0 Time: 0.088576
[03/24/2023-12:56:17] [V] [TRT] Fastest Tactic: 1002 Time: 0.047488
[03/24/2023-12:56:17] [V] [TRT] *************** Autotuning Reformat: Half(4147200,32400,180,1) -> Float(1036800,1:4,5760,32) ***************
[03/24/2023-12:56:17] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> input.72) (Reformat)
[03/24/2023-12:56:17] [V] [TRT] Tactic: 1002 Time: 0.04736
[03/24/2023-12:56:17] [V] [TRT] Tactic: 0 Time: 0.093056
[03/24/2023-12:56:17] [V] [TRT] Fastest Tactic: 1002 Time: 0.04736
[03/24/2023-12:56:17] [V] [TRT] *************** Autotuning Reformat: Half(4147200,32400,180,1) -> Half(2073600,32400:2,180,1) ***************
[03/24/2023-12:56:17] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> input.72) (Reformat)
[03/24/2023-12:56:17] [V] [TRT] Tactic: 1002 Time: 0.04608
[03/24/2023-12:56:17] [V] [TRT] Tactic: 0 Time: 0.055936
[03/24/2023-12:56:17] [V] [TRT] Fastest Tactic: 1002 Time: 0.04608
[03/24/2023-12:56:17] [V] [TRT] *************** Autotuning Reformat: Half(4147200,32400,180,1) -> Half(518400,1:8,2880,16) ***************
[03/24/2023-12:56:17] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> input.72) (Reformat)
[03/24/2023-12:56:17] [V] [TRT] Tactic: 1002 Time: 0.046336
[03/24/2023-12:56:17] [V] [TRT] Tactic: 0 Time: 0.033792
[03/24/2023-12:56:17] [V] [TRT] Fastest Tactic: 0 Time: 0.033792
[03/24/2023-12:56:17] [V] [TRT] *************** Autotuning Reformat: Half(4147200,32400,180,1) -> Half(259200,1:16,1440,8) ***************
[03/24/2023-12:56:17] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> input.72) (Reformat)
[03/24/2023-12:56:17] [V] [TRT] Tactic: 1002 Time: 0.046208
[03/24/2023-12:56:17] [V] [TRT] Tactic: 0 Time: 0.083328
[03/24/2023-12:56:17] [V] [TRT] Fastest Tactic: 1002 Time: 0.046208
[03/24/2023-12:56:17] [V] [TRT] *************** Autotuning Reformat: Half(2073600,32400:2,180,1) -> Float(4147200,32400,180,1) ***************
[03/24/2023-12:56:17] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> input.72) (Reformat)
[03/24/2023-12:56:17] [V] [TRT] Tactic: 1002 Time: 0.056704
[03/24/2023-12:56:17] [V] [TRT] Tactic: 0 Time: 0.055424
[03/24/2023-12:56:17] [V] [TRT] Fastest Tactic: 0 Time: 0.055424
[03/24/2023-12:56:17] [V] [TRT] *************** Autotuning Reformat: Half(2073600,32400:2,180,1) -> Float(4147200,1,23040,128) ***************
[03/24/2023-12:56:17] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> input.72) (Reformat)
[03/24/2023-12:56:17] [V] [TRT] Tactic: 1002 Time: 0.048
[03/24/2023-12:56:17] [V] [TRT] Tactic: 0 Time: 0.070912
[03/24/2023-12:56:17] [V] [TRT] Fastest Tactic: 1002 Time: 0.048
[03/24/2023-12:56:17] [V] [TRT] *************** Autotuning Reformat: Half(2073600,32400:2,180,1) -> Float(1036800,1:4,5760,32) ***************
[03/24/2023-12:56:17] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> input.72) (Reformat)
[03/24/2023-12:56:17] [V] [TRT] Tactic: 1002 Time: 0.047872
[03/24/2023-12:56:17] [V] [TRT] Tactic: 0 Time: 0.080768
[03/24/2023-12:56:17] [V] [TRT] Fastest Tactic: 1002 Time: 0.047872
[03/24/2023-12:56:17] [V] [TRT] *************** Autotuning Reformat: Half(2073600,32400:2,180,1) -> Half(4147200,32400,180,1) ***************
[03/24/2023-12:56:17] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> input.72) (Reformat)
[03/24/2023-12:56:17] [V] [TRT] Tactic: 1002 Time: 0.144
[03/24/2023-12:56:17] [V] [TRT] Tactic: 0 Time: 0.055168
[03/24/2023-12:56:17] [V] [TRT] Fastest Tactic: 0 Time: 0.055168
[03/24/2023-12:56:17] [V] [TRT] *************** Autotuning Reformat: Half(2073600,32400:2,180,1) -> Half(518400,1:8,2880,16) ***************
[03/24/2023-12:56:17] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> input.72) (Reformat)
[03/24/2023-12:56:17] [V] [TRT] Tactic: 1002 Time: 0.046976
[03/24/2023-12:56:17] [V] [TRT] Tactic: 0 Time: 0.024192
[03/24/2023-12:56:17] [V] [TRT] Fastest Tactic: 0 Time: 0.024192
[03/24/2023-12:56:17] [V] [TRT] *************** Autotuning Reformat: Half(2073600,32400:2,180,1) -> Half(259200,1:16,1440,8) ***************
[03/24/2023-12:56:17] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> input.72) (Reformat)
[03/24/2023-12:56:17] [V] [TRT] Tactic: 1002 Time: 0.047104
[03/24/2023-12:56:17] [V] [TRT] Tactic: 0 Time: 0.074752
[03/24/2023-12:56:17] [V] [TRT] Fastest Tactic: 1002 Time: 0.047104
[03/24/2023-12:56:17] [V] [TRT] *************** Autotuning Reformat: Half(518400,1:8,2880,16) -> Float(4147200,32400,180,1) ***************
[03/24/2023-12:56:17] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> input.72) (Reformat)
[03/24/2023-12:56:17] [V] [TRT] Tactic: 1002 Time: 0.051584
[03/24/2023-12:56:17] [V] [TRT] Tactic: 0 Time: 0.028288
[03/24/2023-12:56:17] [V] [TRT] Fastest Tactic: 0 Time: 0.028288
[03/24/2023-12:56:17] [V] [TRT] *************** Autotuning Reformat: Half(518400,1:8,2880,16) -> Float(4147200,1,23040,128) ***************
[03/24/2023-12:56:17] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> input.72) (Reformat)
[03/24/2023-12:56:17] [V] [TRT] Tactic: 1002 Time: 0.043008
[03/24/2023-12:56:17] [V] [TRT] Tactic: 0 Time: 0.0704
[03/24/2023-12:56:17] [V] [TRT] Fastest Tactic: 1002 Time: 0.043008
[03/24/2023-12:56:17] [V] [TRT] *************** Autotuning Reformat: Half(518400,1:8,2880,16) -> Float(1036800,1:4,5760,32) ***************
[03/24/2023-12:56:17] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> input.72) (Reformat)
[03/24/2023-12:56:17] [V] [TRT] Tactic: 1002 Time: 0.04288
[03/24/2023-12:56:17] [V] [TRT] Tactic: 0 Time: 0.080128
[03/24/2023-12:56:17] [V] [TRT] Fastest Tactic: 1002 Time: 0.04288
[03/24/2023-12:56:17] [V] [TRT] *************** Autotuning Reformat: Half(518400,1:8,2880,16) -> Half(4147200,32400,180,1) ***************
[03/24/2023-12:56:17] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> input.72) (Reformat)
[03/24/2023-12:56:17] [V] [TRT] Tactic: 1002 Time: 0.115456
[03/24/2023-12:56:17] [V] [TRT] Tactic: 0 Time: 0.024576
[03/24/2023-12:56:17] [V] [TRT] Fastest Tactic: 0 Time: 0.024576
[03/24/2023-12:56:17] [V] [TRT] *************** Autotuning Reformat: Half(518400,1:8,2880,16) -> Half(2073600,32400:2,180,1) ***************
[03/24/2023-12:56:17] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> input.72) (Reformat)
[03/24/2023-12:56:17] [V] [TRT] Tactic: 1002 Time: 0.062336
[03/24/2023-12:56:17] [V] [TRT] Tactic: 0 Time: 0.02432
[03/24/2023-12:56:17] [V] [TRT] Fastest Tactic: 0 Time: 0.02432
[03/24/2023-12:56:17] [V] [TRT] *************** Autotuning Reformat: Half(518400,1:8,2880,16) -> Half(259200,1:16,1440,8) ***************
[03/24/2023-12:56:17] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> input.72) (Reformat)
[03/24/2023-12:56:17] [V] [TRT] Tactic: 1002 Time: 0.041984
[03/24/2023-12:56:17] [V] [TRT] Tactic: 0 Time: 0.074752
[03/24/2023-12:56:17] [V] [TRT] Fastest Tactic: 1002 Time: 0.041984
[03/24/2023-12:56:17] [V] [TRT] *************** Autotuning Reformat: Half(259200,1:16,1440,8) -> Float(4147200,32400,180,1) ***************
[03/24/2023-12:56:17] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> input.72) (Reformat)
[03/24/2023-12:56:17] [V] [TRT] Tactic: 1002 Time: 0.051328
[03/24/2023-12:56:17] [V] [TRT] Tactic: 0 Time: 0.09024
[03/24/2023-12:56:17] [V] [TRT] Fastest Tactic: 1002 Time: 0.051328
[03/24/2023-12:56:17] [V] [TRT] *************** Autotuning Reformat: Half(259200,1:16,1440,8) -> Float(4147200,1,23040,128) ***************
[03/24/2023-12:56:17] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> input.72) (Reformat)
[03/24/2023-12:56:17] [V] [TRT] Tactic: 1002 Time: 0.043136
[03/24/2023-12:56:17] [V] [TRT] Tactic: 0 Time: 0.070656
[03/24/2023-12:56:17] [V] [TRT] Fastest Tactic: 1002 Time: 0.043136
[03/24/2023-12:56:17] [V] [TRT] *************** Autotuning Reformat: Half(259200,1:16,1440,8) -> Float(1036800,1:4,5760,32) ***************
[03/24/2023-12:56:17] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> input.72) (Reformat)
[03/24/2023-12:56:17] [V] [TRT] Tactic: 1002 Time: 0.043008
[03/24/2023-12:56:17] [V] [TRT] Tactic: 0 Time: 0.08
[03/24/2023-12:56:17] [V] [TRT] Fastest Tactic: 1002 Time: 0.043008
[03/24/2023-12:56:17] [V] [TRT] *************** Autotuning Reformat: Half(259200,1:16,1440,8) -> Half(4147200,32400,180,1) ***************
[03/24/2023-12:56:17] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> input.72) (Reformat)
[03/24/2023-12:56:17] [V] [TRT] Tactic: 1002 Time: 0.115072
[03/24/2023-12:56:17] [V] [TRT] Tactic: 0 Time: 0.089088
[03/24/2023-12:56:17] [V] [TRT] Fastest Tactic: 0 Time: 0.089088
[03/24/2023-12:56:17] [V] [TRT] *************** Autotuning Reformat: Half(259200,1:16,1440,8) -> Half(2073600,32400:2,180,1) ***************
[03/24/2023-12:56:17] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> input.72) (Reformat)
[03/24/2023-12:56:17] [V] [TRT] Tactic: 1002 Time: 0.062208
[03/24/2023-12:56:17] [V] [TRT] Tactic: 0 Time: 0.093312
[03/24/2023-12:56:17] [V] [TRT] Fastest Tactic: 1002 Time: 0.062208
[03/24/2023-12:56:17] [V] [TRT] *************** Autotuning Reformat: Half(259200,1:16,1440,8) -> Half(518400,1:8,2880,16) ***************
[03/24/2023-12:56:17] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> input.72) (Reformat)
[03/24/2023-12:56:17] [V] [TRT] Tactic: 1002 Time: 0.04224
[03/24/2023-12:56:17] [V] [TRT] Tactic: 0 Time: 0.07488
[03/24/2023-12:56:17] [V] [TRT] Fastest Tactic: 1002 Time: 0.04224
[03/24/2023-12:56:17] [V] [TRT] =============== Computing reformatting costs
[03/24/2023-12:56:17] [V] [TRT] *************** Autotuning Reformat: Float(4147200,32400,180,1) -> Float(4147200,1,23040,128) ***************
[03/24/2023-12:56:17] [V] [TRT] *************** Autotuning Reformat: Float(4147200,32400,180,1) -> Float(1036800,1:4,5760,32) ***************
[03/24/2023-12:56:17] [V] [TRT] *************** Autotuning Reformat: Float(4147200,32400,180,1) -> Half(4147200,32400,180,1) ***************
[03/24/2023-12:56:17] [V] [TRT] *************** Autotuning Reformat: Float(4147200,32400,180,1) -> Half(2073600,32400:2,180,1) ***************
[03/24/2023-12:56:17] [V] [TRT] *************** Autotuning Reformat: Float(4147200,32400,180,1) -> Half(518400,1:8,2880,16) ***************
[03/24/2023-12:56:17] [V] [TRT] *************** Autotuning Reformat: Float(4147200,32400,180,1) -> Half(259200,1:16,1440,8) ***************
[03/24/2023-12:56:17] [V] [TRT] *************** Autotuning Reformat: Float(4147200,1,23040,128) -> Float(4147200,32400,180,1) ***************
[03/24/2023-12:56:17] [V] [TRT] *************** Autotuning Reformat: Float(4147200,1,23040,128) -> Float(1036800,1:4,5760,32) ***************
[03/24/2023-12:56:17] [V] [TRT] *************** Autotuning Reformat: Float(4147200,1,23040,128) -> Half(4147200,32400,180,1) ***************
[03/24/2023-12:56:17] [V] [TRT] *************** Autotuning Reformat: Float(4147200,1,23040,128) -> Half(2073600,32400:2,180,1) ***************
[03/24/2023-12:56:17] [V] [TRT] *************** Autotuning Reformat: Float(4147200,1,23040,128) -> Half(518400,1:8,2880,16) ***************
[03/24/2023-12:56:17] [V] [TRT] *************** Autotuning Reformat: Float(4147200,1,23040,128) -> Half(259200,1:16,1440,8) ***************
[03/24/2023-12:56:17] [V] [TRT] *************** Autotuning Reformat: Float(1036800,1:4,5760,32) -> Float(4147200,32400,180,1) ***************
[03/24/2023-12:56:17] [V] [TRT] *************** Autotuning Reformat: Float(1036800,1:4,5760,32) -> Float(4147200,1,23040,128) ***************
[03/24/2023-12:56:17] [V] [TRT] *************** Autotuning Reformat: Float(1036800,1:4,5760,32) -> Half(4147200,32400,180,1) ***************
[03/24/2023-12:56:17] [V] [TRT] *************** Autotuning Reformat: Float(1036800,1:4,5760,32) -> Half(2073600,32400:2,180,1) ***************
[03/24/2023-12:56:17] [V] [TRT] *************** Autotuning Reformat: Float(1036800,1:4,5760,32) -> Half(518400,1:8,2880,16) ***************
[03/24/2023-12:56:17] [V] [TRT] *************** Autotuning Reformat: Float(1036800,1:4,5760,32) -> Half(259200,1:16,1440,8) ***************
[03/24/2023-12:56:17] [V] [TRT] *************** Autotuning Reformat: Half(4147200,32400,180,1) -> Float(4147200,32400,180,1) ***************
[03/24/2023-12:56:17] [V] [TRT] *************** Autotuning Reformat: Half(4147200,32400,180,1) -> Float(4147200,1,23040,128) ***************
[03/24/2023-12:56:17] [V] [TRT] *************** Autotuning Reformat: Half(4147200,32400,180,1) -> Float(1036800,1:4,5760,32) ***************
[03/24/2023-12:56:17] [V] [TRT] *************** Autotuning Reformat: Half(4147200,32400,180,1) -> Half(2073600,32400:2,180,1) ***************
[03/24/2023-12:56:17] [V] [TRT] *************** Autotuning Reformat: Half(4147200,32400,180,1) -> Half(518400,1:8,2880,16) ***************
[03/24/2023-12:56:17] [V] [TRT] *************** Autotuning Reformat: Half(4147200,32400,180,1) -> Half(259200,1:16,1440,8) ***************
[03/24/2023-12:56:17] [V] [TRT] *************** Autotuning Reformat: Half(2073600,32400:2,180,1) -> Float(4147200,32400,180,1) ***************
[03/24/2023-12:56:17] [V] [TRT] *************** Autotuning Reformat: Half(2073600,32400:2,180,1) -> Float(4147200,1,23040,128) ***************
[03/24/2023-12:56:17] [V] [TRT] *************** Autotuning Reformat: Half(2073600,32400:2,180,1) -> Float(1036800,1:4,5760,32) ***************
[03/24/2023-12:56:17] [V] [TRT] *************** Autotuning Reformat: Half(2073600,32400:2,180,1) -> Half(4147200,32400,180,1) ***************
[03/24/2023-12:56:17] [V] [TRT] *************** Autotuning Reformat: Half(2073600,32400:2,180,1) -> Half(518400,1:8,2880,16) ***************
[03/24/2023-12:56:17] [V] [TRT] *************** Autotuning Reformat: Half(2073600,32400:2,180,1) -> Half(259200,1:16,1440,8) ***************
[03/24/2023-12:56:17] [V] [TRT] *************** Autotuning Reformat: Half(518400,1:8,2880,16) -> Float(4147200,32400,180,1) ***************
[03/24/2023-12:56:17] [V] [TRT] *************** Autotuning Reformat: Half(518400,1:8,2880,16) -> Float(4147200,1,23040,128) ***************
[03/24/2023-12:56:17] [V] [TRT] *************** Autotuning Reformat: Half(518400,1:8,2880,16) -> Float(1036800,1:4,5760,32) ***************
[03/24/2023-12:56:17] [V] [TRT] *************** Autotuning Reformat: Half(518400,1:8,2880,16) -> Half(4147200,32400,180,1) ***************
[03/24/2023-12:56:17] [V] [TRT] *************** Autotuning Reformat: Half(518400,1:8,2880,16) -> Half(2073600,32400:2,180,1) ***************
[03/24/2023-12:56:17] [V] [TRT] *************** Autotuning Reformat: Half(518400,1:8,2880,16) -> Half(259200,1:16,1440,8) ***************
[03/24/2023-12:56:17] [V] [TRT] *************** Autotuning Reformat: Half(259200,1:16,1440,8) -> Float(4147200,32400,180,1) ***************
[03/24/2023-12:56:17] [V] [TRT] *************** Autotuning Reformat: Half(259200,1:16,1440,8) -> Float(4147200,1,23040,128) ***************
[03/24/2023-12:56:17] [V] [TRT] *************** Autotuning Reformat: Half(259200,1:16,1440,8) -> Float(1036800,1:4,5760,32) ***************
[03/24/2023-12:56:17] [V] [TRT] *************** Autotuning Reformat: Half(259200,1:16,1440,8) -> Half(4147200,32400,180,1) ***************
[03/24/2023-12:56:17] [V] [TRT] *************** Autotuning Reformat: Half(259200,1:16,1440,8) -> Half(2073600,32400:2,180,1) ***************
[03/24/2023-12:56:17] [V] [TRT] *************** Autotuning Reformat: Half(259200,1:16,1440,8) -> Half(518400,1:8,2880,16) ***************
[03/24/2023-12:56:17] [V] [TRT] =============== Computing reformatting costs
[03/24/2023-12:56:17] [V] [TRT] *************** Autotuning Reformat: Float(16588800,32400,180,1) -> Float(16588800,1,92160,512) ***************
[03/24/2023-12:56:17] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> onnx::Concat_602) (Reformat)
[03/24/2023-12:56:17] [V] [TRT] Tactic: 1002 Time: 0.089088
[03/24/2023-12:56:17] [V] [TRT] Tactic: 0 Time: 0.237312
[03/24/2023-12:56:17] [V] [TRT] Fastest Tactic: 1002 Time: 0.089088
[03/24/2023-12:56:17] [V] [TRT] *************** Autotuning Reformat: Float(16588800,32400,180,1) -> Float(4147200,1:4,23040,128) ***************
[03/24/2023-12:56:17] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> onnx::Concat_602) (Reformat)
[03/24/2023-12:56:18] [V] [TRT] Tactic: 1002 Time: 0.089344
[03/24/2023-12:56:18] [V] [TRT] Tactic: 0 Time: 0.237312
[03/24/2023-12:56:18] [V] [TRT] Fastest Tactic: 1002 Time: 0.089344
[03/24/2023-12:56:18] [V] [TRT] *************** Autotuning Reformat: Float(16588800,32400,180,1) -> Half(16588800,32400,180,1) ***************
[03/24/2023-12:56:18] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> onnx::Concat_602) (Reformat)
[03/24/2023-12:56:18] [V] [TRT] Tactic: 1002 Time: 0.123136
[03/24/2023-12:56:18] [V] [TRT] Tactic: 0 Time: 0.106752
[03/24/2023-12:56:18] [V] [TRT] Fastest Tactic: 0 Time: 0.106752
[03/24/2023-12:56:18] [V] [TRT] *************** Autotuning Reformat: Float(16588800,32400,180,1) -> Half(8294400,32400:2,180,1) ***************
[03/24/2023-12:56:18] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> onnx::Concat_602) (Reformat)
[03/24/2023-12:56:18] [V] [TRT] Tactic: 1002 Time: 0.114432
[03/24/2023-12:56:18] [V] [TRT] Tactic: 0 Time: 0.101504
[03/24/2023-12:56:18] [V] [TRT] Fastest Tactic: 0 Time: 0.101504
[03/24/2023-12:56:18] [V] [TRT] *************** Autotuning Reformat: Float(16588800,32400,180,1) -> Half(2073600,1:8,11520,64) ***************
[03/24/2023-12:56:18] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> onnx::Concat_602) (Reformat)
[03/24/2023-12:56:18] [V] [TRT] Tactic: 1002 Time: 0.081152
[03/24/2023-12:56:18] [V] [TRT] Tactic: 0 Time: 0.06208
[03/24/2023-12:56:18] [V] [TRT] Fastest Tactic: 0 Time: 0.06208
[03/24/2023-12:56:18] [V] [TRT] *************** Autotuning Reformat: Float(16588800,32400,180,1) -> Half(1036800,1:16,5760,32) ***************
[03/24/2023-12:56:18] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> onnx::Concat_602) (Reformat)
[03/24/2023-12:56:18] [V] [TRT] Tactic: 1002 Time: 0.081408
[03/24/2023-12:56:18] [V] [TRT] Tactic: 0 Time: 0.236544
[03/24/2023-12:56:18] [V] [TRT] Fastest Tactic: 1002 Time: 0.081408
[03/24/2023-12:56:18] [V] [TRT] *************** Autotuning Reformat: Float(16588800,1,92160,512) -> Float(16588800,32400,180,1) ***************
[03/24/2023-12:56:18] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> onnx::Concat_602) (Reformat)
[03/24/2023-12:56:18] [V] [TRT] Tactic: 1002 Time: 0.094848
[03/24/2023-12:56:18] [V] [TRT] Tactic: 0 Time: 0.203008
[03/24/2023-12:56:18] [V] [TRT] Fastest Tactic: 1002 Time: 0.094848
[03/24/2023-12:56:18] [V] [TRT] *************** Autotuning Reformat: Float(16588800,1,92160,512) -> Float(4147200,1:4,23040,128) ***************
[03/24/2023-12:56:18] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> onnx::Concat_602) (Reformat)
[03/24/2023-12:56:18] [V] [TRT] Tactic: 1002 Time: 0.0768
[03/24/2023-12:56:18] [V] [TRT] Tactic: 0 Time: 0.127232
[03/24/2023-12:56:18] [V] [TRT] Fastest Tactic: 1002 Time: 0.0768
[03/24/2023-12:56:18] [V] [TRT] *************** Autotuning Reformat: Float(16588800,1,92160,512) -> Half(16588800,32400,180,1) ***************
[03/24/2023-12:56:18] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> onnx::Concat_602) (Reformat)
[03/24/2023-12:56:18] [V] [TRT] Tactic: 1002 Time: 0.08896
[03/24/2023-12:56:18] [V] [TRT] Tactic: 0 Time: 0.190592
[03/24/2023-12:56:18] [V] [TRT] Fastest Tactic: 1002 Time: 0.08896
[03/24/2023-12:56:18] [V] [TRT] *************** Autotuning Reformat: Float(16588800,1,92160,512) -> Half(8294400,32400:2,180,1) ***************
[03/24/2023-12:56:18] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> onnx::Concat_602) (Reformat)
[03/24/2023-12:56:18] [V] [TRT] Tactic: 1002 Time: 0.11008
[03/24/2023-12:56:18] [V] [TRT] Tactic: 0 Time: 0.203776
[03/24/2023-12:56:18] [V] [TRT] Fastest Tactic: 1002 Time: 0.11008
[03/24/2023-12:56:18] [V] [TRT] *************** Autotuning Reformat: Float(16588800,1,92160,512) -> Half(2073600,1:8,11520,64) ***************
[03/24/2023-12:56:18] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> onnx::Concat_602) (Reformat)
[03/24/2023-12:56:18] [V] [TRT] Tactic: 1002 Time: 0.07296
[03/24/2023-12:56:18] [V] [TRT] Tactic: 0 Time: 0.128
[03/24/2023-12:56:18] [V] [TRT] Fastest Tactic: 1002 Time: 0.07296
[03/24/2023-12:56:18] [V] [TRT] *************** Autotuning Reformat: Float(16588800,1,92160,512) -> Half(1036800,1:16,5760,32) ***************
[03/24/2023-12:56:18] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> onnx::Concat_602) (Reformat)
[03/24/2023-12:56:18] [V] [TRT] Tactic: 1002 Time: 0.072832
[03/24/2023-12:56:18] [V] [TRT] Tactic: 0 Time: 0.128
[03/24/2023-12:56:18] [V] [TRT] Fastest Tactic: 1002 Time: 0.072832
[03/24/2023-12:56:18] [V] [TRT] *************** Autotuning Reformat: Float(4147200,1:4,23040,128) -> Float(16588800,32400,180,1) ***************
[03/24/2023-12:56:18] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> onnx::Concat_602) (Reformat)
[03/24/2023-12:56:18] [V] [TRT] Tactic: 1002 Time: 0.095232
[03/24/2023-12:56:18] [V] [TRT] Tactic: 0 Time: 0.205952
[03/24/2023-12:56:18] [V] [TRT] Fastest Tactic: 1002 Time: 0.095232
[03/24/2023-12:56:18] [V] [TRT] *************** Autotuning Reformat: Float(4147200,1:4,23040,128) -> Float(16588800,1,92160,512) ***************
[03/24/2023-12:56:18] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> onnx::Concat_602) (Reformat)
[03/24/2023-12:56:18] [V] [TRT] Tactic: 1002 Time: 0.0768
[03/24/2023-12:56:18] [V] [TRT] Tactic: 0 Time: 0.127744
[03/24/2023-12:56:18] [V] [TRT] Fastest Tactic: 1002 Time: 0.0768
[03/24/2023-12:56:18] [V] [TRT] *************** Autotuning Reformat: Float(4147200,1:4,23040,128) -> Half(16588800,32400,180,1) ***************
[03/24/2023-12:56:18] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> onnx::Concat_602) (Reformat)
[03/24/2023-12:56:18] [V] [TRT] Tactic: 1002 Time: 0.08896
[03/24/2023-12:56:18] [V] [TRT] Tactic: 0 Time: 0.19584
[03/24/2023-12:56:18] [V] [TRT] Fastest Tactic: 1002 Time: 0.08896
[03/24/2023-12:56:18] [V] [TRT] *************** Autotuning Reformat: Float(4147200,1:4,23040,128) -> Half(8294400,32400:2,180,1) ***************
[03/24/2023-12:56:18] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> onnx::Concat_602) (Reformat)
[03/24/2023-12:56:18] [V] [TRT] Tactic: 1002 Time: 0.110208
[03/24/2023-12:56:18] [V] [TRT] Tactic: 0 Time: 0.206976
[03/24/2023-12:56:18] [V] [TRT] Fastest Tactic: 1002 Time: 0.110208
[03/24/2023-12:56:18] [V] [TRT] *************** Autotuning Reformat: Float(4147200,1:4,23040,128) -> Half(2073600,1:8,11520,64) ***************
[03/24/2023-12:56:18] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> onnx::Concat_602) (Reformat)
[03/24/2023-12:56:18] [V] [TRT] Tactic: 1002 Time: 0.073216
[03/24/2023-12:56:18] [V] [TRT] Tactic: 0 Time: 0.149248
[03/24/2023-12:56:18] [V] [TRT] Fastest Tactic: 1002 Time: 0.073216
[03/24/2023-12:56:18] [V] [TRT] *************** Autotuning Reformat: Float(4147200,1:4,23040,128) -> Half(1036800,1:16,5760,32) ***************
[03/24/2023-12:56:18] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> onnx::Concat_602) (Reformat)
[03/24/2023-12:56:18] [V] [TRT] Tactic: 1002 Time: 0.072832
[03/24/2023-12:56:18] [V] [TRT] Tactic: 0 Time: 0.14912
[03/24/2023-12:56:18] [V] [TRT] Fastest Tactic: 1002 Time: 0.072832
[03/24/2023-12:56:18] [V] [TRT] *************** Autotuning Reformat: Half(16588800,32400,180,1) -> Float(16588800,32400,180,1) ***************
[03/24/2023-12:56:18] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> onnx::Concat_602) (Reformat)
[03/24/2023-12:56:18] [V] [TRT] Tactic: 1002 Time: 0.123264
[03/24/2023-12:56:18] [V] [TRT] Tactic: 0 Time: 0.108928
[03/24/2023-12:56:18] [V] [TRT] Fastest Tactic: 0 Time: 0.108928
[03/24/2023-12:56:18] [V] [TRT] *************** Autotuning Reformat: Half(16588800,32400,180,1) -> Float(16588800,1,92160,512) ***************
[03/24/2023-12:56:18] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> onnx::Concat_602) (Reformat)
[03/24/2023-12:56:18] [V] [TRT] Tactic: 1002 Time: 0.08128
[03/24/2023-12:56:18] [V] [TRT] Tactic: 0 Time: 0.19136
[03/24/2023-12:56:18] [V] [TRT] Fastest Tactic: 1002 Time: 0.08128
[03/24/2023-12:56:18] [V] [TRT] *************** Autotuning Reformat: Half(16588800,32400,180,1) -> Float(4147200,1:4,23040,128) ***************
[03/24/2023-12:56:18] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> onnx::Concat_602) (Reformat)
[03/24/2023-12:56:18] [V] [TRT] Tactic: 1002 Time: 0.08128
[03/24/2023-12:56:18] [V] [TRT] Tactic: 0 Time: 0.194048
[03/24/2023-12:56:18] [V] [TRT] Fastest Tactic: 1002 Time: 0.08128
[03/24/2023-12:56:18] [V] [TRT] *************** Autotuning Reformat: Half(16588800,32400,180,1) -> Half(8294400,32400:2,180,1) ***************
[03/24/2023-12:56:18] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> onnx::Concat_602) (Reformat)
[03/24/2023-12:56:18] [V] [TRT] Tactic: 1002 Time: 0.08064
[03/24/2023-12:56:18] [V] [TRT] Tactic: 0 Time: 0.101504
[03/24/2023-12:56:18] [V] [TRT] Fastest Tactic: 1002 Time: 0.08064
[03/24/2023-12:56:18] [V] [TRT] *************** Autotuning Reformat: Half(16588800,32400,180,1) -> Half(2073600,1:8,11520,64) ***************
[03/24/2023-12:56:18] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> onnx::Concat_602) (Reformat)
[03/24/2023-12:56:18] [V] [TRT] Tactic: 1002 Time: 0.086272
[03/24/2023-12:56:18] [V] [TRT] Tactic: 0 Time: 0.061056
[03/24/2023-12:56:18] [V] [TRT] Fastest Tactic: 0 Time: 0.061056
[03/24/2023-12:56:18] [V] [TRT] *************** Autotuning Reformat: Half(16588800,32400,180,1) -> Half(1036800,1:16,5760,32) ***************
[03/24/2023-12:56:18] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> onnx::Concat_602) (Reformat)
[03/24/2023-12:56:18] [V] [TRT] Tactic: 1002 Time: 0.0864
[03/24/2023-12:56:18] [V] [TRT] Tactic: 0 Time: 0.188032
[03/24/2023-12:56:18] [V] [TRT] Fastest Tactic: 1002 Time: 0.0864
[03/24/2023-12:56:18] [V] [TRT] *************** Autotuning Reformat: Half(8294400,32400:2,180,1) -> Float(16588800,32400,180,1) ***************
[03/24/2023-12:56:18] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> onnx::Concat_602) (Reformat)
[03/24/2023-12:56:18] [V] [TRT] Tactic: 1002 Time: 0.097664
[03/24/2023-12:56:18] [V] [TRT] Tactic: 0 Time: 0.124032
[03/24/2023-12:56:18] [V] [TRT] Fastest Tactic: 1002 Time: 0.097664
[03/24/2023-12:56:18] [V] [TRT] *************** Autotuning Reformat: Half(8294400,32400:2,180,1) -> Float(16588800,1,92160,512) ***************
[03/24/2023-12:56:18] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> onnx::Concat_602) (Reformat)
[03/24/2023-12:56:18] [V] [TRT] Tactic: 1002 Time: 0.082176
[03/24/2023-12:56:18] [V] [TRT] Tactic: 0 Time: 0.132352
[03/24/2023-12:56:18] [V] [TRT] Fastest Tactic: 1002 Time: 0.082176
[03/24/2023-12:56:18] [V] [TRT] *************** Autotuning Reformat: Half(8294400,32400:2,180,1) -> Float(4147200,1:4,23040,128) ***************
[03/24/2023-12:56:18] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> onnx::Concat_602) (Reformat)
[03/24/2023-12:56:18] [V] [TRT] Tactic: 1002 Time: 0.082176
[03/24/2023-12:56:18] [V] [TRT] Tactic: 0 Time: 0.150784
[03/24/2023-12:56:18] [V] [TRT] Fastest Tactic: 1002 Time: 0.082176
[03/24/2023-12:56:18] [V] [TRT] *************** Autotuning Reformat: Half(8294400,32400:2,180,1) -> Half(16588800,32400,180,1) ***************
[03/24/2023-12:56:18] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> onnx::Concat_602) (Reformat)
[03/24/2023-12:56:18] [V] [TRT] Tactic: 1002 Time: 0.273792
[03/24/2023-12:56:18] [V] [TRT] Tactic: 0 Time: 0.116864
[03/24/2023-12:56:18] [V] [TRT] Fastest Tactic: 0 Time: 0.116864
[03/24/2023-12:56:18] [V] [TRT] *************** Autotuning Reformat: Half(8294400,32400:2,180,1) -> Half(2073600,1:8,11520,64) ***************
[03/24/2023-12:56:18] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> onnx::Concat_602) (Reformat)
[03/24/2023-12:56:18] [V] [TRT] Tactic: 1002 Time: 0.082176
[03/24/2023-12:56:18] [V] [TRT] Tactic: 0 Time: 0.052224
[03/24/2023-12:56:18] [V] [TRT] Fastest Tactic: 0 Time: 0.052224
[03/24/2023-12:56:18] [V] [TRT] *************** Autotuning Reformat: Half(8294400,32400:2,180,1) -> Half(1036800,1:16,5760,32) ***************
[03/24/2023-12:56:18] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> onnx::Concat_602) (Reformat)
[03/24/2023-12:56:18] [V] [TRT] Tactic: 1002 Time: 0.082304
[03/24/2023-12:56:18] [V] [TRT] Tactic: 0 Time: 0.13952
[03/24/2023-12:56:18] [V] [TRT] Fastest Tactic: 1002 Time: 0.082304
[03/24/2023-12:56:18] [V] [TRT] *************** Autotuning Reformat: Half(2073600,1:8,11520,64) -> Float(16588800,32400,180,1) ***************
[03/24/2023-12:56:18] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> onnx::Concat_602) (Reformat)
[03/24/2023-12:56:18] [V] [TRT] Tactic: 1002 Time: 0.09024
[03/24/2023-12:56:18] [V] [TRT] Tactic: 0 Time: 0.177792
[03/24/2023-12:56:18] [V] [TRT] Fastest Tactic: 1002 Time: 0.09024
[03/24/2023-12:56:18] [V] [TRT] *************** Autotuning Reformat: Half(2073600,1:8,11520,64) -> Float(16588800,1,92160,512) ***************
[03/24/2023-12:56:18] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> onnx::Concat_602) (Reformat)
[03/24/2023-12:56:18] [V] [TRT] Tactic: 1002 Time: 0.07296
[03/24/2023-12:56:18] [V] [TRT] Tactic: 0 Time: 0.130304
[03/24/2023-12:56:18] [V] [TRT] Fastest Tactic: 1002 Time: 0.07296
[03/24/2023-12:56:18] [V] [TRT] *************** Autotuning Reformat: Half(2073600,1:8,11520,64) -> Float(4147200,1:4,23040,128) ***************
[03/24/2023-12:56:18] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> onnx::Concat_602) (Reformat)
[03/24/2023-12:56:18] [V] [TRT] Tactic: 1002 Time: 0.073088
[03/24/2023-12:56:18] [V] [TRT] Tactic: 0 Time: 0.150144
[03/24/2023-12:56:18] [V] [TRT] Fastest Tactic: 1002 Time: 0.073088
[03/24/2023-12:56:18] [V] [TRT] *************** Autotuning Reformat: Half(2073600,1:8,11520,64) -> Half(16588800,32400,180,1) ***************
[03/24/2023-12:56:18] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> onnx::Concat_602) (Reformat)
[03/24/2023-12:56:18] [V] [TRT] Tactic: 1002 Time: 0.206976
[03/24/2023-12:56:18] [V] [TRT] Tactic: 0 Time: 0.172544
[03/24/2023-12:56:18] [V] [TRT] Fastest Tactic: 0 Time: 0.172544
[03/24/2023-12:56:18] [V] [TRT] *************** Autotuning Reformat: Half(2073600,1:8,11520,64) -> Half(8294400,32400:2,180,1) ***************
[03/24/2023-12:56:18] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> onnx::Concat_602) (Reformat)
[03/24/2023-12:56:18] [V] [TRT] Tactic: 1002 Time: 0.106752
[03/24/2023-12:56:18] [V] [TRT] Tactic: 0 Time: 0.04224
[03/24/2023-12:56:18] [V] [TRT] Fastest Tactic: 0 Time: 0.04224
[03/24/2023-12:56:18] [V] [TRT] *************** Autotuning Reformat: Half(2073600,1:8,11520,64) -> Half(1036800,1:16,5760,32) ***************
[03/24/2023-12:56:18] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> onnx::Concat_602) (Reformat)
[03/24/2023-12:56:18] [V] [TRT] Tactic: 1002 Time: 0.07296
[03/24/2023-12:56:18] [V] [TRT] Tactic: 0 Time: 0.13888
[03/24/2023-12:56:18] [V] [TRT] Fastest Tactic: 1002 Time: 0.07296
[03/24/2023-12:56:18] [V] [TRT] *************** Autotuning Reformat: Half(1036800,1:16,5760,32) -> Float(16588800,32400,180,1) ***************
[03/24/2023-12:56:18] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> onnx::Concat_602) (Reformat)
[03/24/2023-12:56:18] [V] [TRT] Tactic: 1002 Time: 0.089984
[03/24/2023-12:56:18] [V] [TRT] Tactic: 0 Time: 0.17792
[03/24/2023-12:56:18] [V] [TRT] Fastest Tactic: 1002 Time: 0.089984
[03/24/2023-12:56:18] [V] [TRT] *************** Autotuning Reformat: Half(1036800,1:16,5760,32) -> Float(16588800,1,92160,512) ***************
[03/24/2023-12:56:18] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> onnx::Concat_602) (Reformat)
[03/24/2023-12:56:18] [V] [TRT] Tactic: 1002 Time: 0.07296
[03/24/2023-12:56:18] [V] [TRT] Tactic: 0 Time: 0.130304
[03/24/2023-12:56:18] [V] [TRT] Fastest Tactic: 1002 Time: 0.07296
[03/24/2023-12:56:18] [V] [TRT] *************** Autotuning Reformat: Half(1036800,1:16,5760,32) -> Float(4147200,1:4,23040,128) ***************
[03/24/2023-12:56:18] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> onnx::Concat_602) (Reformat)
[03/24/2023-12:56:18] [V] [TRT] Tactic: 1002 Time: 0.072576
[03/24/2023-12:56:18] [V] [TRT] Tactic: 0 Time: 0.150016
[03/24/2023-12:56:18] [V] [TRT] Fastest Tactic: 1002 Time: 0.072576
[03/24/2023-12:56:18] [V] [TRT] *************** Autotuning Reformat: Half(1036800,1:16,5760,32) -> Half(16588800,32400,180,1) ***************
[03/24/2023-12:56:18] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> onnx::Concat_602) (Reformat)
[03/24/2023-12:56:18] [V] [TRT] Tactic: 1002 Time: 0.20736
[03/24/2023-12:56:18] [V] [TRT] Tactic: 0 Time: 0.171904
[03/24/2023-12:56:18] [V] [TRT] Fastest Tactic: 0 Time: 0.171904
[03/24/2023-12:56:18] [V] [TRT] *************** Autotuning Reformat: Half(1036800,1:16,5760,32) -> Half(8294400,32400:2,180,1) ***************
[03/24/2023-12:56:18] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> onnx::Concat_602) (Reformat)
[03/24/2023-12:56:18] [V] [TRT] Tactic: 1002 Time: 0.106496
[03/24/2023-12:56:18] [V] [TRT] Tactic: 0 Time: 0.177152
[03/24/2023-12:56:18] [V] [TRT] Fastest Tactic: 1002 Time: 0.106496
[03/24/2023-12:56:18] [V] [TRT] *************** Autotuning Reformat: Half(1036800,1:16,5760,32) -> Half(2073600,1:8,11520,64) ***************
[03/24/2023-12:56:18] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> onnx::Concat_602) (Reformat)
[03/24/2023-12:56:18] [V] [TRT] Tactic: 1002 Time: 0.07296
[03/24/2023-12:56:18] [V] [TRT] Tactic: 0 Time: 0.139648
[03/24/2023-12:56:18] [V] [TRT] Fastest Tactic: 1002 Time: 0.07296
[03/24/2023-12:56:18] [V] [TRT] =============== Computing reformatting costs
[03/24/2023-12:56:18] [V] [TRT] *************** Autotuning Reformat: Float(4147200,32400,180,1) -> Float(4147200,1,23040,128) ***************
[03/24/2023-12:56:18] [V] [TRT] *************** Autotuning Reformat: Float(4147200,32400,180,1) -> Float(1036800,1:4,5760,32) ***************
[03/24/2023-12:56:18] [V] [TRT] *************** Autotuning Reformat: Float(4147200,32400,180,1) -> Half(4147200,32400,180,1) ***************
[03/24/2023-12:56:18] [V] [TRT] *************** Autotuning Reformat: Float(4147200,32400,180,1) -> Half(2073600,32400:2,180,1) ***************
[03/24/2023-12:56:18] [V] [TRT] *************** Autotuning Reformat: Float(4147200,32400,180,1) -> Half(518400,1:8,2880,16) ***************
[03/24/2023-12:56:18] [V] [TRT] *************** Autotuning Reformat: Float(4147200,32400,180,1) -> Half(259200,1:16,1440,8) ***************
[03/24/2023-12:56:18] [V] [TRT] *************** Autotuning Reformat: Float(4147200,1,23040,128) -> Float(4147200,32400,180,1) ***************
[03/24/2023-12:56:18] [V] [TRT] *************** Autotuning Reformat: Float(4147200,1,23040,128) -> Float(1036800,1:4,5760,32) ***************
[03/24/2023-12:56:18] [V] [TRT] *************** Autotuning Reformat: Float(4147200,1,23040,128) -> Half(4147200,32400,180,1) ***************
[03/24/2023-12:56:18] [V] [TRT] *************** Autotuning Reformat: Float(4147200,1,23040,128) -> Half(2073600,32400:2,180,1) ***************
[03/24/2023-12:56:18] [V] [TRT] *************** Autotuning Reformat: Float(4147200,1,23040,128) -> Half(518400,1:8,2880,16) ***************
[03/24/2023-12:56:18] [V] [TRT] *************** Autotuning Reformat: Float(4147200,1,23040,128) -> Half(259200,1:16,1440,8) ***************
[03/24/2023-12:56:18] [V] [TRT] *************** Autotuning Reformat: Float(1036800,1:4,5760,32) -> Float(4147200,32400,180,1) ***************
[03/24/2023-12:56:18] [V] [TRT] *************** Autotuning Reformat: Float(1036800,1:4,5760,32) -> Float(4147200,1,23040,128) ***************
[03/24/2023-12:56:18] [V] [TRT] *************** Autotuning Reformat: Float(1036800,1:4,5760,32) -> Half(4147200,32400,180,1) ***************
[03/24/2023-12:56:18] [V] [TRT] *************** Autotuning Reformat: Float(1036800,1:4,5760,32) -> Half(2073600,32400:2,180,1) ***************
[03/24/2023-12:56:18] [V] [TRT] *************** Autotuning Reformat: Float(1036800,1:4,5760,32) -> Half(518400,1:8,2880,16) ***************
[03/24/2023-12:56:18] [V] [TRT] *************** Autotuning Reformat: Float(1036800,1:4,5760,32) -> Half(259200,1:16,1440,8) ***************
[03/24/2023-12:56:18] [V] [TRT] *************** Autotuning Reformat: Half(4147200,32400,180,1) -> Float(4147200,32400,180,1) ***************
[03/24/2023-12:56:18] [V] [TRT] *************** Autotuning Reformat: Half(4147200,32400,180,1) -> Float(4147200,1,23040,128) ***************
[03/24/2023-12:56:18] [V] [TRT] *************** Autotuning Reformat: Half(4147200,32400,180,1) -> Float(1036800,1:4,5760,32) ***************
[03/24/2023-12:56:18] [V] [TRT] *************** Autotuning Reformat: Half(4147200,32400,180,1) -> Half(2073600,32400:2,180,1) ***************
[03/24/2023-12:56:18] [V] [TRT] *************** Autotuning Reformat: Half(4147200,32400,180,1) -> Half(518400,1:8,2880,16) ***************
[03/24/2023-12:56:18] [V] [TRT] *************** Autotuning Reformat: Half(4147200,32400,180,1) -> Half(259200,1:16,1440,8) ***************
[03/24/2023-12:56:18] [V] [TRT] *************** Autotuning Reformat: Half(2073600,32400:2,180,1) -> Float(4147200,32400,180,1) ***************
[03/24/2023-12:56:18] [V] [TRT] *************** Autotuning Reformat: Half(2073600,32400:2,180,1) -> Float(4147200,1,23040,128) ***************
[03/24/2023-12:56:18] [V] [TRT] *************** Autotuning Reformat: Half(2073600,32400:2,180,1) -> Float(1036800,1:4,5760,32) ***************
[03/24/2023-12:56:18] [V] [TRT] *************** Autotuning Reformat: Half(2073600,32400:2,180,1) -> Half(4147200,32400,180,1) ***************
[03/24/2023-12:56:18] [V] [TRT] *************** Autotuning Reformat: Half(2073600,32400:2,180,1) -> Half(518400,1:8,2880,16) ***************
[03/24/2023-12:56:18] [V] [TRT] *************** Autotuning Reformat: Half(2073600,32400:2,180,1) -> Half(259200,1:16,1440,8) ***************
[03/24/2023-12:56:18] [V] [TRT] *************** Autotuning Reformat: Half(518400,1:8,2880,16) -> Float(4147200,32400,180,1) ***************
[03/24/2023-12:56:18] [V] [TRT] *************** Autotuning Reformat: Half(518400,1:8,2880,16) -> Float(4147200,1,23040,128) ***************
[03/24/2023-12:56:18] [V] [TRT] *************** Autotuning Reformat: Half(518400,1:8,2880,16) -> Float(1036800,1:4,5760,32) ***************
[03/24/2023-12:56:18] [V] [TRT] *************** Autotuning Reformat: Half(518400,1:8,2880,16) -> Half(4147200,32400,180,1) ***************
[03/24/2023-12:56:18] [V] [TRT] *************** Autotuning Reformat: Half(518400,1:8,2880,16) -> Half(2073600,32400:2,180,1) ***************
[03/24/2023-12:56:18] [V] [TRT] *************** Autotuning Reformat: Half(518400,1:8,2880,16) -> Half(259200,1:16,1440,8) ***************
[03/24/2023-12:56:18] [V] [TRT] *************** Autotuning Reformat: Half(259200,1:16,1440,8) -> Float(4147200,32400,180,1) ***************
[03/24/2023-12:56:18] [V] [TRT] *************** Autotuning Reformat: Half(259200,1:16,1440,8) -> Float(4147200,1,23040,128) ***************
[03/24/2023-12:56:18] [V] [TRT] *************** Autotuning Reformat: Half(259200,1:16,1440,8) -> Float(1036800,1:4,5760,32) ***************
[03/24/2023-12:56:18] [V] [TRT] *************** Autotuning Reformat: Half(259200,1:16,1440,8) -> Half(4147200,32400,180,1) ***************
[03/24/2023-12:56:18] [V] [TRT] *************** Autotuning Reformat: Half(259200,1:16,1440,8) -> Half(2073600,32400:2,180,1) ***************
[03/24/2023-12:56:18] [V] [TRT] *************** Autotuning Reformat: Half(259200,1:16,1440,8) -> Half(518400,1:8,2880,16) ***************
[03/24/2023-12:56:18] [V] [TRT] =============== Computing reformatting costs
[03/24/2023-12:56:18] [V] [TRT] *************** Autotuning Reformat: Float(2073600,8100,90,1) -> Float(2073600,1,23040,256) ***************
[03/24/2023-12:56:18] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(input.96 -> <out>) (Reformat)
[03/24/2023-12:56:18] [V] [TRT] Tactic: 1002 Time: 0.034816
[03/24/2023-12:56:18] [V] [TRT] Tactic: 0 Time: 0.055936
[03/24/2023-12:56:18] [V] [TRT] Fastest Tactic: 1002 Time: 0.034816
[03/24/2023-12:56:18] [V] [TRT] *************** Autotuning Reformat: Float(2073600,8100,90,1) -> Float(518400,1:4,5760,64) ***************
[03/24/2023-12:56:18] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(input.96 -> <out>) (Reformat)
[03/24/2023-12:56:18] [V] [TRT] Tactic: 1002 Time: 0.034816
[03/24/2023-12:56:18] [V] [TRT] Tactic: 0 Time: 0.056192
[03/24/2023-12:56:18] [V] [TRT] Fastest Tactic: 1002 Time: 0.034816
[03/24/2023-12:56:18] [V] [TRT] *************** Autotuning Reformat: Float(2073600,8100,90,1) -> Half(2073600,8100,90,1) ***************
[03/24/2023-12:56:18] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(input.96 -> <out>) (Reformat)
[03/24/2023-12:56:18] [V] [TRT] Tactic: 1002 Time: 0.03584
[03/24/2023-12:56:18] [V] [TRT] Tactic: 0 Time: 0.0448
[03/24/2023-12:56:18] [V] [TRT] Fastest Tactic: 1002 Time: 0.03584
[03/24/2023-12:56:18] [V] [TRT] *************** Autotuning Reformat: Float(2073600,8100,90,1) -> Half(1036800,8100:2,90,1) ***************
[03/24/2023-12:56:18] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(input.96 -> <out>) (Reformat)
[03/24/2023-12:56:18] [V] [TRT] Tactic: 1002 Time: 0.041472
[03/24/2023-12:56:18] [V] [TRT] Tactic: 0 Time: 0.033792
[03/24/2023-12:56:18] [V] [TRT] Fastest Tactic: 0 Time: 0.033792
[03/24/2023-12:56:18] [V] [TRT] *************** Autotuning Reformat: Float(2073600,8100,90,1) -> Half(259200,1:8,2880,32) ***************
[03/24/2023-12:56:18] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(input.96 -> <out>) (Reformat)
[03/24/2023-12:56:18] [V] [TRT] Tactic: 1002 Time: 0.031488
[03/24/2023-12:56:18] [V] [TRT] Tactic: 0 Time: 0.022912
[03/24/2023-12:56:18] [V] [TRT] Fastest Tactic: 0 Time: 0.022912
[03/24/2023-12:56:18] [V] [TRT] *************** Autotuning Reformat: Float(2073600,8100,90,1) -> Half(129600,1:16,1440,16) ***************
[03/24/2023-12:56:18] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(input.96 -> <out>) (Reformat)
[03/24/2023-12:56:18] [V] [TRT] Tactic: 1002 Time: 0.031616
[03/24/2023-12:56:18] [V] [TRT] Tactic: 0 Time: 0.0544
[03/24/2023-12:56:18] [V] [TRT] Fastest Tactic: 1002 Time: 0.031616
[03/24/2023-12:56:18] [V] [TRT] *************** Autotuning Reformat: Float(2073600,1,23040,256) -> Float(2073600,8100,90,1) ***************
[03/24/2023-12:56:18] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(input.96 -> <out>) (Reformat)
[03/24/2023-12:56:18] [V] [TRT] Tactic: 1002 Time: 0.041088
[03/24/2023-12:56:18] [V] [TRT] Tactic: 0 Time: 0.054656
[03/24/2023-12:56:18] [V] [TRT] Fastest Tactic: 1002 Time: 0.041088
[03/24/2023-12:56:18] [V] [TRT] *************** Autotuning Reformat: Float(2073600,1,23040,256) -> Float(518400,1:4,5760,64) ***************
[03/24/2023-12:56:18] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(input.96 -> <out>) (Reformat)
[03/24/2023-12:56:18] [V] [TRT] Tactic: 1002 Time: 0.029952
[03/24/2023-12:56:18] [V] [TRT] Tactic: 0 Time: 0.039936
[03/24/2023-12:56:18] [V] [TRT] Fastest Tactic: 1002 Time: 0.029952
[03/24/2023-12:56:18] [V] [TRT] *************** Autotuning Reformat: Float(2073600,1,23040,256) -> Half(2073600,8100,90,1) ***************
[03/24/2023-12:56:18] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(input.96 -> <out>) (Reformat)
[03/24/2023-12:56:18] [V] [TRT] Tactic: 1002 Time: 0.040832
[03/24/2023-12:56:18] [V] [TRT] Tactic: 0 Time: 0.053248
[03/24/2023-12:56:18] [V] [TRT] Fastest Tactic: 1002 Time: 0.040832
[03/24/2023-12:56:18] [V] [TRT] *************** Autotuning Reformat: Float(2073600,1,23040,256) -> Half(1036800,8100:2,90,1) ***************
[03/24/2023-12:56:18] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(input.96 -> <out>) (Reformat)
[03/24/2023-12:56:18] [V] [TRT] Tactic: 1002 Time: 0.040192
[03/24/2023-12:56:18] [V] [TRT] Tactic: 0 Time: 0.057344
[03/24/2023-12:56:18] [V] [TRT] Fastest Tactic: 1002 Time: 0.040192
[03/24/2023-12:56:18] [V] [TRT] *************** Autotuning Reformat: Float(2073600,1,23040,256) -> Half(259200,1:8,2880,32) ***************
[03/24/2023-12:56:18] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(input.96 -> <out>) (Reformat)
[03/24/2023-12:56:18] [V] [TRT] Tactic: 1002 Time: 0.028672
[03/24/2023-12:56:18] [V] [TRT] Tactic: 0 Time: 0.040576
[03/24/2023-12:56:18] [V] [TRT] Fastest Tactic: 1002 Time: 0.028672
[03/24/2023-12:56:18] [V] [TRT] *************** Autotuning Reformat: Float(2073600,1,23040,256) -> Half(129600,1:16,1440,16) ***************
[03/24/2023-12:56:18] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(input.96 -> <out>) (Reformat)
[03/24/2023-12:56:18] [V] [TRT] Tactic: 1002 Time: 0.028672
[03/24/2023-12:56:18] [V] [TRT] Tactic: 0 Time: 0.040448
[03/24/2023-12:56:18] [V] [TRT] Fastest Tactic: 1002 Time: 0.028672
[03/24/2023-12:56:18] [V] [TRT] *************** Autotuning Reformat: Float(518400,1:4,5760,64) -> Float(2073600,8100,90,1) ***************
[03/24/2023-12:56:18] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(input.96 -> <out>) (Reformat)
[03/24/2023-12:56:18] [V] [TRT] Tactic: 1002 Time: 0.041344
[03/24/2023-12:56:18] [V] [TRT] Tactic: 0 Time: 0.054528
[03/24/2023-12:56:18] [V] [TRT] Fastest Tactic: 1002 Time: 0.041344
[03/24/2023-12:56:18] [V] [TRT] *************** Autotuning Reformat: Float(518400,1:4,5760,64) -> Float(2073600,1,23040,256) ***************
[03/24/2023-12:56:18] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(input.96 -> <out>) (Reformat)
[03/24/2023-12:56:18] [V] [TRT] Tactic: 1002 Time: 0.030208
[03/24/2023-12:56:18] [V] [TRT] Tactic: 0 Time: 0.039936
[03/24/2023-12:56:18] [V] [TRT] Fastest Tactic: 1002 Time: 0.030208
[03/24/2023-12:56:18] [V] [TRT] *************** Autotuning Reformat: Float(518400,1:4,5760,64) -> Half(2073600,8100,90,1) ***************
[03/24/2023-12:56:18] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(input.96 -> <out>) (Reformat)
[03/24/2023-12:56:18] [V] [TRT] Tactic: 1002 Time: 0.040704
[03/24/2023-12:56:18] [V] [TRT] Tactic: 0 Time: 0.053248
[03/24/2023-12:56:18] [V] [TRT] Fastest Tactic: 1002 Time: 0.040704
[03/24/2023-12:56:18] [V] [TRT] *************** Autotuning Reformat: Float(518400,1:4,5760,64) -> Half(1036800,8100:2,90,1) ***************
[03/24/2023-12:56:18] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(input.96 -> <out>) (Reformat)
[03/24/2023-12:56:18] [V] [TRT] Tactic: 1002 Time: 0.040064
[03/24/2023-12:56:18] [V] [TRT] Tactic: 0 Time: 0.0576
[03/24/2023-12:56:18] [V] [TRT] Fastest Tactic: 1002 Time: 0.040064
[03/24/2023-12:56:18] [V] [TRT] *************** Autotuning Reformat: Float(518400,1:4,5760,64) -> Half(259200,1:8,2880,32) ***************
[03/24/2023-12:56:18] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(input.96 -> <out>) (Reformat)
[03/24/2023-12:56:18] [V] [TRT] Tactic: 1002 Time: 0.028672
[03/24/2023-12:56:18] [V] [TRT] Tactic: 0 Time: 0.04608
[03/24/2023-12:56:18] [V] [TRT] Fastest Tactic: 1002 Time: 0.028672
[03/24/2023-12:56:18] [V] [TRT] *************** Autotuning Reformat: Float(518400,1:4,5760,64) -> Half(129600,1:16,1440,16) ***************
[03/24/2023-12:56:18] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(input.96 -> <out>) (Reformat)
[03/24/2023-12:56:18] [V] [TRT] Tactic: 1002 Time: 0.028928
[03/24/2023-12:56:18] [V] [TRT] Tactic: 0 Time: 0.045824
[03/24/2023-12:56:18] [V] [TRT] Fastest Tactic: 1002 Time: 0.028928
[03/24/2023-12:56:18] [V] [TRT] *************** Autotuning Reformat: Half(2073600,8100,90,1) -> Float(2073600,8100,90,1) ***************
[03/24/2023-12:56:18] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(input.96 -> <out>) (Reformat)
[03/24/2023-12:56:18] [V] [TRT] Tactic: 1002 Time: 0.036352
[03/24/2023-12:56:18] [V] [TRT] Tactic: 0 Time: 0.043136
[03/24/2023-12:56:18] [V] [TRT] Fastest Tactic: 1002 Time: 0.036352
[03/24/2023-12:56:18] [V] [TRT] *************** Autotuning Reformat: Half(2073600,8100,90,1) -> Float(2073600,1,23040,256) ***************
[03/24/2023-12:56:18] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(input.96 -> <out>) (Reformat)
[03/24/2023-12:56:18] [V] [TRT] Tactic: 1002 Time: 0.031616
[03/24/2023-12:56:18] [V] [TRT] Tactic: 0 Time: 0.059392
[03/24/2023-12:56:18] [V] [TRT] Fastest Tactic: 1002 Time: 0.031616
[03/24/2023-12:56:18] [V] [TRT] *************** Autotuning Reformat: Half(2073600,8100,90,1) -> Float(518400,1:4,5760,64) ***************
[03/24/2023-12:56:18] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(input.96 -> <out>) (Reformat)
[03/24/2023-12:56:18] [V] [TRT] Tactic: 1002 Time: 0.031616
[03/24/2023-12:56:18] [V] [TRT] Tactic: 0 Time: 0.060416
[03/24/2023-12:56:18] [V] [TRT] Fastest Tactic: 1002 Time: 0.031616
[03/24/2023-12:56:18] [V] [TRT] *************** Autotuning Reformat: Half(2073600,8100,90,1) -> Half(1036800,8100:2,90,1) ***************
[03/24/2023-12:56:18] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(input.96 -> <out>) (Reformat)
[03/24/2023-12:56:18] [V] [TRT] Tactic: 1002 Time: 0.03264
[03/24/2023-12:56:18] [V] [TRT] Tactic: 0 Time: 0.033664
[03/24/2023-12:56:18] [V] [TRT] Fastest Tactic: 1002 Time: 0.03264
[03/24/2023-12:56:18] [V] [TRT] *************** Autotuning Reformat: Half(2073600,8100,90,1) -> Half(259200,1:8,2880,32) ***************
[03/24/2023-12:56:18] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(input.96 -> <out>) (Reformat)
[03/24/2023-12:56:18] [V] [TRT] Tactic: 1002 Time: 0.031616
[03/24/2023-12:56:18] [V] [TRT] Tactic: 0 Time: 0.022528
[03/24/2023-12:56:18] [V] [TRT] Fastest Tactic: 0 Time: 0.022528
[03/24/2023-12:56:18] [V] [TRT] *************** Autotuning Reformat: Half(2073600,8100,90,1) -> Half(129600,1:16,1440,16) ***************
[03/24/2023-12:56:18] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(input.96 -> <out>) (Reformat)
[03/24/2023-12:56:18] [V] [TRT] Tactic: 1002 Time: 0.03136
[03/24/2023-12:56:18] [V] [TRT] Tactic: 0 Time: 0.058752
[03/24/2023-12:56:18] [V] [TRT] Fastest Tactic: 1002 Time: 0.03136
[03/24/2023-12:56:18] [V] [TRT] *************** Autotuning Reformat: Half(1036800,8100:2,90,1) -> Float(2073600,8100,90,1) ***************
[03/24/2023-12:56:18] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(input.96 -> <out>) (Reformat)
[03/24/2023-12:56:18] [V] [TRT] Tactic: 1002 Time: 0.043904
[03/24/2023-12:56:18] [V] [TRT] Tactic: 0 Time: 0.033664
[03/24/2023-12:56:18] [V] [TRT] Fastest Tactic: 0 Time: 0.033664
[03/24/2023-12:56:18] [V] [TRT] *************** Autotuning Reformat: Half(1036800,8100:2,90,1) -> Float(2073600,1,23040,256) ***************
[03/24/2023-12:56:18] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(input.96 -> <out>) (Reformat)
[03/24/2023-12:56:18] [V] [TRT] Tactic: 1002 Time: 0.031616
[03/24/2023-12:56:18] [V] [TRT] Tactic: 0 Time: 0.041856
[03/24/2023-12:56:18] [V] [TRT] Fastest Tactic: 1002 Time: 0.031616
[03/24/2023-12:56:18] [V] [TRT] *************** Autotuning Reformat: Half(1036800,8100:2,90,1) -> Float(518400,1:4,5760,64) ***************
[03/24/2023-12:56:18] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(input.96 -> <out>) (Reformat)
[03/24/2023-12:56:18] [V] [TRT] Tactic: 1002 Time: 0.031616
[03/24/2023-12:56:18] [V] [TRT] Tactic: 0 Time: 0.046464
[03/24/2023-12:56:18] [V] [TRT] Fastest Tactic: 1002 Time: 0.031616
[03/24/2023-12:56:18] [V] [TRT] *************** Autotuning Reformat: Half(1036800,8100:2,90,1) -> Half(2073600,8100,90,1) ***************
[03/24/2023-12:56:18] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(input.96 -> <out>) (Reformat)
[03/24/2023-12:56:18] [V] [TRT] Tactic: 1002 Time: 0.10048
[03/24/2023-12:56:18] [V] [TRT] Tactic: 0 Time: 0.033536
[03/24/2023-12:56:18] [V] [TRT] Fastest Tactic: 0 Time: 0.033536
[03/24/2023-12:56:18] [V] [TRT] *************** Autotuning Reformat: Half(1036800,8100:2,90,1) -> Half(259200,1:8,2880,32) ***************
[03/24/2023-12:56:18] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(input.96 -> <out>) (Reformat)
[03/24/2023-12:56:18] [V] [TRT] Tactic: 1002 Time: 0.031616
[03/24/2023-12:56:18] [V] [TRT] Tactic: 0 Time: 0.018432
[03/24/2023-12:56:18] [V] [TRT] Fastest Tactic: 0 Time: 0.018432
[03/24/2023-12:56:18] [V] [TRT] *************** Autotuning Reformat: Half(1036800,8100:2,90,1) -> Half(129600,1:16,1440,16) ***************
[03/24/2023-12:56:18] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(input.96 -> <out>) (Reformat)
[03/24/2023-12:56:18] [V] [TRT] Tactic: 1002 Time: 0.031616
[03/24/2023-12:56:18] [V] [TRT] Tactic: 0 Time: 0.043776
[03/24/2023-12:56:18] [V] [TRT] Fastest Tactic: 1002 Time: 0.031616
[03/24/2023-12:56:18] [V] [TRT] *************** Autotuning Reformat: Half(259200,1:8,2880,32) -> Float(2073600,8100,90,1) ***************
[03/24/2023-12:56:18] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(input.96 -> <out>) (Reformat)
[03/24/2023-12:56:19] [V] [TRT] Tactic: 1002 Time: 0.041216
[03/24/2023-12:56:19] [V] [TRT] Tactic: 0 Time: 0.021888
[03/24/2023-12:56:19] [V] [TRT] Fastest Tactic: 0 Time: 0.021888
[03/24/2023-12:56:19] [V] [TRT] *************** Autotuning Reformat: Half(259200,1:8,2880,32) -> Float(2073600,1,23040,256) ***************
[03/24/2023-12:56:19] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(input.96 -> <out>) (Reformat)
[03/24/2023-12:56:19] [V] [TRT] Tactic: 1002 Time: 0.0288
[03/24/2023-12:56:19] [V] [TRT] Tactic: 0 Time: 0.04096
[03/24/2023-12:56:19] [V] [TRT] Fastest Tactic: 1002 Time: 0.0288
[03/24/2023-12:56:19] [V] [TRT] *************** Autotuning Reformat: Half(259200,1:8,2880,32) -> Float(518400,1:4,5760,64) ***************
[03/24/2023-12:56:19] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(input.96 -> <out>) (Reformat)
[03/24/2023-12:56:19] [V] [TRT] Tactic: 1002 Time: 0.0288
[03/24/2023-12:56:19] [V] [TRT] Tactic: 0 Time: 0.04608
[03/24/2023-12:56:19] [V] [TRT] Fastest Tactic: 1002 Time: 0.0288
[03/24/2023-12:56:19] [V] [TRT] *************** Autotuning Reformat: Half(259200,1:8,2880,32) -> Half(2073600,8100,90,1) ***************
[03/24/2023-12:56:19] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(input.96 -> <out>) (Reformat)
[03/24/2023-12:56:19] [V] [TRT] Tactic: 1002 Time: 0.088192
[03/24/2023-12:56:19] [V] [TRT] Tactic: 0 Time: 0.019712
[03/24/2023-12:56:19] [V] [TRT] Fastest Tactic: 0 Time: 0.019712
[03/24/2023-12:56:19] [V] [TRT] *************** Autotuning Reformat: Half(259200,1:8,2880,32) -> Half(1036800,8100:2,90,1) ***************
[03/24/2023-12:56:19] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(input.96 -> <out>) (Reformat)
[03/24/2023-12:56:19] [V] [TRT] Tactic: 1002 Time: 0.039424
[03/24/2023-12:56:19] [V] [TRT] Tactic: 0 Time: 0.018432
[03/24/2023-12:56:19] [V] [TRT] Fastest Tactic: 0 Time: 0.018432
[03/24/2023-12:56:19] [V] [TRT] *************** Autotuning Reformat: Half(259200,1:8,2880,32) -> Half(129600,1:16,1440,16) ***************
[03/24/2023-12:56:19] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(input.96 -> <out>) (Reformat)
[03/24/2023-12:56:19] [V] [TRT] Tactic: 1002 Time: 0.028928
[03/24/2023-12:56:19] [V] [TRT] Tactic: 0 Time: 0.043136
[03/24/2023-12:56:19] [V] [TRT] Fastest Tactic: 1002 Time: 0.028928
[03/24/2023-12:56:19] [V] [TRT] *************** Autotuning Reformat: Half(129600,1:16,1440,16) -> Float(2073600,8100,90,1) ***************
[03/24/2023-12:56:19] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(input.96 -> <out>) (Reformat)
[03/24/2023-12:56:19] [V] [TRT] Tactic: 1002 Time: 0.0416
[03/24/2023-12:56:19] [V] [TRT] Tactic: 0 Time: 0.05184
[03/24/2023-12:56:19] [V] [TRT] Fastest Tactic: 1002 Time: 0.0416
[03/24/2023-12:56:19] [V] [TRT] *************** Autotuning Reformat: Half(129600,1:16,1440,16) -> Float(2073600,1,23040,256) ***************
[03/24/2023-12:56:19] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(input.96 -> <out>) (Reformat)
[03/24/2023-12:56:19] [V] [TRT] Tactic: 1002 Time: 0.0288
[03/24/2023-12:56:19] [V] [TRT] Tactic: 0 Time: 0.04096
[03/24/2023-12:56:19] [V] [TRT] Fastest Tactic: 1002 Time: 0.0288
[03/24/2023-12:56:19] [V] [TRT] *************** Autotuning Reformat: Half(129600,1:16,1440,16) -> Float(518400,1:4,5760,64) ***************
[03/24/2023-12:56:19] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(input.96 -> <out>) (Reformat)
[03/24/2023-12:56:19] [V] [TRT] Tactic: 1002 Time: 0.0288
[03/24/2023-12:56:19] [V] [TRT] Tactic: 0 Time: 0.04608
[03/24/2023-12:56:19] [V] [TRT] Fastest Tactic: 1002 Time: 0.0288
[03/24/2023-12:56:19] [V] [TRT] *************** Autotuning Reformat: Half(129600,1:16,1440,16) -> Half(2073600,8100,90,1) ***************
[03/24/2023-12:56:19] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(input.96 -> <out>) (Reformat)
[03/24/2023-12:56:19] [V] [TRT] Tactic: 1002 Time: 0.08832
[03/24/2023-12:56:19] [V] [TRT] Tactic: 0 Time: 0.050944
[03/24/2023-12:56:19] [V] [TRT] Fastest Tactic: 0 Time: 0.050944
[03/24/2023-12:56:19] [V] [TRT] *************** Autotuning Reformat: Half(129600,1:16,1440,16) -> Half(1036800,8100:2,90,1) ***************
[03/24/2023-12:56:19] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(input.96 -> <out>) (Reformat)
[03/24/2023-12:56:19] [V] [TRT] Tactic: 1002 Time: 0.039552
[03/24/2023-12:56:19] [V] [TRT] Tactic: 0 Time: 0.053632
[03/24/2023-12:56:19] [V] [TRT] Fastest Tactic: 1002 Time: 0.039552
[03/24/2023-12:56:19] [V] [TRT] *************** Autotuning Reformat: Half(129600,1:16,1440,16) -> Half(259200,1:8,2880,32) ***************
[03/24/2023-12:56:19] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(input.96 -> <out>) (Reformat)
[03/24/2023-12:56:19] [V] [TRT] Tactic: 1002 Time: 0.029056
[03/24/2023-12:56:19] [V] [TRT] Tactic: 0 Time: 0.043008
[03/24/2023-12:56:19] [V] [TRT] Fastest Tactic: 1002 Time: 0.029056
[03/24/2023-12:56:19] [V] [TRT] =============== Computing reformatting costs
[03/24/2023-12:56:19] [V] [TRT] *************** Autotuning Reformat: Float(2073600,8100,90,1) -> Float(2073600,1,23040,256) ***************
[03/24/2023-12:56:19] [V] [TRT] *************** Autotuning Reformat: Float(2073600,8100,90,1) -> Float(518400,1:4,5760,64) ***************
[03/24/2023-12:56:19] [V] [TRT] *************** Autotuning Reformat: Float(2073600,8100,90,1) -> Half(2073600,8100,90,1) ***************
[03/24/2023-12:56:19] [V] [TRT] *************** Autotuning Reformat: Float(2073600,8100,90,1) -> Half(1036800,8100:2,90,1) ***************
[03/24/2023-12:56:19] [V] [TRT] *************** Autotuning Reformat: Float(2073600,8100,90,1) -> Half(259200,1:8,2880,32) ***************
[03/24/2023-12:56:19] [V] [TRT] *************** Autotuning Reformat: Float(2073600,8100,90,1) -> Half(129600,1:16,1440,16) ***************
[03/24/2023-12:56:19] [V] [TRT] *************** Autotuning Reformat: Float(2073600,1,23040,256) -> Float(2073600,8100,90,1) ***************
[03/24/2023-12:56:19] [V] [TRT] *************** Autotuning Reformat: Float(2073600,1,23040,256) -> Float(518400,1:4,5760,64) ***************
[03/24/2023-12:56:19] [V] [TRT] *************** Autotuning Reformat: Float(2073600,1,23040,256) -> Half(2073600,8100,90,1) ***************
[03/24/2023-12:56:19] [V] [TRT] *************** Autotuning Reformat: Float(2073600,1,23040,256) -> Half(1036800,8100:2,90,1) ***************
[03/24/2023-12:56:19] [V] [TRT] *************** Autotuning Reformat: Float(2073600,1,23040,256) -> Half(259200,1:8,2880,32) ***************
[03/24/2023-12:56:19] [V] [TRT] *************** Autotuning Reformat: Float(2073600,1,23040,256) -> Half(129600,1:16,1440,16) ***************
[03/24/2023-12:56:19] [V] [TRT] *************** Autotuning Reformat: Float(518400,1:4,5760,64) -> Float(2073600,8100,90,1) ***************
[03/24/2023-12:56:19] [V] [TRT] *************** Autotuning Reformat: Float(518400,1:4,5760,64) -> Float(2073600,1,23040,256) ***************
[03/24/2023-12:56:19] [V] [TRT] *************** Autotuning Reformat: Float(518400,1:4,5760,64) -> Half(2073600,8100,90,1) ***************
[03/24/2023-12:56:19] [V] [TRT] *************** Autotuning Reformat: Float(518400,1:4,5760,64) -> Half(1036800,8100:2,90,1) ***************
[03/24/2023-12:56:19] [V] [TRT] *************** Autotuning Reformat: Float(518400,1:4,5760,64) -> Half(259200,1:8,2880,32) ***************
[03/24/2023-12:56:19] [V] [TRT] *************** Autotuning Reformat: Float(518400,1:4,5760,64) -> Half(129600,1:16,1440,16) ***************
[03/24/2023-12:56:19] [V] [TRT] *************** Autotuning Reformat: Half(2073600,8100,90,1) -> Float(2073600,8100,90,1) ***************
[03/24/2023-12:56:19] [V] [TRT] *************** Autotuning Reformat: Half(2073600,8100,90,1) -> Float(2073600,1,23040,256) ***************
[03/24/2023-12:56:19] [V] [TRT] *************** Autotuning Reformat: Half(2073600,8100,90,1) -> Float(518400,1:4,5760,64) ***************
[03/24/2023-12:56:19] [V] [TRT] *************** Autotuning Reformat: Half(2073600,8100,90,1) -> Half(1036800,8100:2,90,1) ***************
[03/24/2023-12:56:19] [V] [TRT] *************** Autotuning Reformat: Half(2073600,8100,90,1) -> Half(259200,1:8,2880,32) ***************
[03/24/2023-12:56:19] [V] [TRT] *************** Autotuning Reformat: Half(2073600,8100,90,1) -> Half(129600,1:16,1440,16) ***************
[03/24/2023-12:56:19] [V] [TRT] *************** Autotuning Reformat: Half(1036800,8100:2,90,1) -> Float(2073600,8100,90,1) ***************
[03/24/2023-12:56:19] [V] [TRT] *************** Autotuning Reformat: Half(1036800,8100:2,90,1) -> Float(2073600,1,23040,256) ***************
[03/24/2023-12:56:19] [V] [TRT] *************** Autotuning Reformat: Half(1036800,8100:2,90,1) -> Float(518400,1:4,5760,64) ***************
[03/24/2023-12:56:19] [V] [TRT] *************** Autotuning Reformat: Half(1036800,8100:2,90,1) -> Half(2073600,8100,90,1) ***************
[03/24/2023-12:56:19] [V] [TRT] *************** Autotuning Reformat: Half(1036800,8100:2,90,1) -> Half(259200,1:8,2880,32) ***************
[03/24/2023-12:56:19] [V] [TRT] *************** Autotuning Reformat: Half(1036800,8100:2,90,1) -> Half(129600,1:16,1440,16) ***************
[03/24/2023-12:56:19] [V] [TRT] *************** Autotuning Reformat: Half(259200,1:8,2880,32) -> Float(2073600,8100,90,1) ***************
[03/24/2023-12:56:19] [V] [TRT] *************** Autotuning Reformat: Half(259200,1:8,2880,32) -> Float(2073600,1,23040,256) ***************
[03/24/2023-12:56:19] [V] [TRT] *************** Autotuning Reformat: Half(259200,1:8,2880,32) -> Float(518400,1:4,5760,64) ***************
[03/24/2023-12:56:19] [V] [TRT] *************** Autotuning Reformat: Half(259200,1:8,2880,32) -> Half(2073600,8100,90,1) ***************
[03/24/2023-12:56:19] [V] [TRT] *************** Autotuning Reformat: Half(259200,1:8,2880,32) -> Half(1036800,8100:2,90,1) ***************
[03/24/2023-12:56:19] [V] [TRT] *************** Autotuning Reformat: Half(259200,1:8,2880,32) -> Half(129600,1:16,1440,16) ***************
[03/24/2023-12:56:19] [V] [TRT] *************** Autotuning Reformat: Half(129600,1:16,1440,16) -> Float(2073600,8100,90,1) ***************
[03/24/2023-12:56:19] [V] [TRT] *************** Autotuning Reformat: Half(129600,1:16,1440,16) -> Float(2073600,1,23040,256) ***************
[03/24/2023-12:56:19] [V] [TRT] *************** Autotuning Reformat: Half(129600,1:16,1440,16) -> Float(518400,1:4,5760,64) ***************
[03/24/2023-12:56:19] [V] [TRT] *************** Autotuning Reformat: Half(129600,1:16,1440,16) -> Half(2073600,8100,90,1) ***************
[03/24/2023-12:56:19] [V] [TRT] *************** Autotuning Reformat: Half(129600,1:16,1440,16) -> Half(1036800,8100:2,90,1) ***************
[03/24/2023-12:56:19] [V] [TRT] *************** Autotuning Reformat: Half(129600,1:16,1440,16) -> Half(259200,1:8,2880,32) ***************
[03/24/2023-12:56:19] [V] [TRT] =============== Computing reformatting costs
[03/24/2023-12:56:19] [V] [TRT] *************** Autotuning Reformat: Float(2073600,8100,90,1) -> Float(2073600,1,23040,256) ***************
[03/24/2023-12:56:19] [V] [TRT] *************** Autotuning Reformat: Float(2073600,8100,90,1) -> Float(518400,1:4,5760,64) ***************
[03/24/2023-12:56:19] [V] [TRT] *************** Autotuning Reformat: Float(2073600,8100,90,1) -> Half(2073600,8100,90,1) ***************
[03/24/2023-12:56:19] [V] [TRT] *************** Autotuning Reformat: Float(2073600,8100,90,1) -> Half(1036800,8100:2,90,1) ***************
[03/24/2023-12:56:19] [V] [TRT] *************** Autotuning Reformat: Float(2073600,8100,90,1) -> Half(259200,1:8,2880,32) ***************
[03/24/2023-12:56:19] [V] [TRT] *************** Autotuning Reformat: Float(2073600,8100,90,1) -> Half(129600,1:16,1440,16) ***************
[03/24/2023-12:56:19] [V] [TRT] *************** Autotuning Reformat: Float(2073600,1,23040,256) -> Float(2073600,8100,90,1) ***************
[03/24/2023-12:56:19] [V] [TRT] *************** Autotuning Reformat: Float(2073600,1,23040,256) -> Float(518400,1:4,5760,64) ***************
[03/24/2023-12:56:19] [V] [TRT] *************** Autotuning Reformat: Float(2073600,1,23040,256) -> Half(2073600,8100,90,1) ***************
[03/24/2023-12:56:19] [V] [TRT] *************** Autotuning Reformat: Float(2073600,1,23040,256) -> Half(1036800,8100:2,90,1) ***************
[03/24/2023-12:56:19] [V] [TRT] *************** Autotuning Reformat: Float(2073600,1,23040,256) -> Half(259200,1:8,2880,32) ***************
[03/24/2023-12:56:19] [V] [TRT] *************** Autotuning Reformat: Float(2073600,1,23040,256) -> Half(129600,1:16,1440,16) ***************
[03/24/2023-12:56:19] [V] [TRT] *************** Autotuning Reformat: Float(518400,1:4,5760,64) -> Float(2073600,8100,90,1) ***************
[03/24/2023-12:56:19] [V] [TRT] *************** Autotuning Reformat: Float(518400,1:4,5760,64) -> Float(2073600,1,23040,256) ***************
[03/24/2023-12:56:19] [V] [TRT] *************** Autotuning Reformat: Float(518400,1:4,5760,64) -> Half(2073600,8100,90,1) ***************
[03/24/2023-12:56:19] [V] [TRT] *************** Autotuning Reformat: Float(518400,1:4,5760,64) -> Half(1036800,8100:2,90,1) ***************
[03/24/2023-12:56:19] [V] [TRT] *************** Autotuning Reformat: Float(518400,1:4,5760,64) -> Half(259200,1:8,2880,32) ***************
[03/24/2023-12:56:19] [V] [TRT] *************** Autotuning Reformat: Float(518400,1:4,5760,64) -> Half(129600,1:16,1440,16) ***************
[03/24/2023-12:56:19] [V] [TRT] *************** Autotuning Reformat: Half(2073600,8100,90,1) -> Float(2073600,8100,90,1) ***************
[03/24/2023-12:56:19] [V] [TRT] *************** Autotuning Reformat: Half(2073600,8100,90,1) -> Float(2073600,1,23040,256) ***************
[03/24/2023-12:56:19] [V] [TRT] *************** Autotuning Reformat: Half(2073600,8100,90,1) -> Float(518400,1:4,5760,64) ***************
[03/24/2023-12:56:19] [V] [TRT] *************** Autotuning Reformat: Half(2073600,8100,90,1) -> Half(1036800,8100:2,90,1) ***************
[03/24/2023-12:56:19] [V] [TRT] *************** Autotuning Reformat: Half(2073600,8100,90,1) -> Half(259200,1:8,2880,32) ***************
[03/24/2023-12:56:19] [V] [TRT] *************** Autotuning Reformat: Half(2073600,8100,90,1) -> Half(129600,1:16,1440,16) ***************
[03/24/2023-12:56:19] [V] [TRT] *************** Autotuning Reformat: Half(1036800,8100:2,90,1) -> Float(2073600,8100,90,1) ***************
[03/24/2023-12:56:19] [V] [TRT] *************** Autotuning Reformat: Half(1036800,8100:2,90,1) -> Float(2073600,1,23040,256) ***************
[03/24/2023-12:56:19] [V] [TRT] *************** Autotuning Reformat: Half(1036800,8100:2,90,1) -> Float(518400,1:4,5760,64) ***************
[03/24/2023-12:56:19] [V] [TRT] *************** Autotuning Reformat: Half(1036800,8100:2,90,1) -> Half(2073600,8100,90,1) ***************
[03/24/2023-12:56:19] [V] [TRT] *************** Autotuning Reformat: Half(1036800,8100:2,90,1) -> Half(259200,1:8,2880,32) ***************
[03/24/2023-12:56:19] [V] [TRT] *************** Autotuning Reformat: Half(1036800,8100:2,90,1) -> Half(129600,1:16,1440,16) ***************
[03/24/2023-12:56:19] [V] [TRT] *************** Autotuning Reformat: Half(259200,1:8,2880,32) -> Float(2073600,8100,90,1) ***************
[03/24/2023-12:56:19] [V] [TRT] *************** Autotuning Reformat: Half(259200,1:8,2880,32) -> Float(2073600,1,23040,256) ***************
[03/24/2023-12:56:19] [V] [TRT] *************** Autotuning Reformat: Half(259200,1:8,2880,32) -> Float(518400,1:4,5760,64) ***************
[03/24/2023-12:56:19] [V] [TRT] *************** Autotuning Reformat: Half(259200,1:8,2880,32) -> Half(2073600,8100,90,1) ***************
[03/24/2023-12:56:19] [V] [TRT] *************** Autotuning Reformat: Half(259200,1:8,2880,32) -> Half(1036800,8100:2,90,1) ***************
[03/24/2023-12:56:19] [V] [TRT] *************** Autotuning Reformat: Half(259200,1:8,2880,32) -> Half(129600,1:16,1440,16) ***************
[03/24/2023-12:56:19] [V] [TRT] *************** Autotuning Reformat: Half(129600,1:16,1440,16) -> Float(2073600,8100,90,1) ***************
[03/24/2023-12:56:19] [V] [TRT] *************** Autotuning Reformat: Half(129600,1:16,1440,16) -> Float(2073600,1,23040,256) ***************
[03/24/2023-12:56:19] [V] [TRT] *************** Autotuning Reformat: Half(129600,1:16,1440,16) -> Float(518400,1:4,5760,64) ***************
[03/24/2023-12:56:19] [V] [TRT] *************** Autotuning Reformat: Half(129600,1:16,1440,16) -> Half(2073600,8100,90,1) ***************
[03/24/2023-12:56:19] [V] [TRT] *************** Autotuning Reformat: Half(129600,1:16,1440,16) -> Half(1036800,8100:2,90,1) ***************
[03/24/2023-12:56:19] [V] [TRT] *************** Autotuning Reformat: Half(129600,1:16,1440,16) -> Half(259200,1:8,2880,32) ***************
[03/24/2023-12:56:19] [V] [TRT] =============== Computing reformatting costs
[03/24/2023-12:56:19] [V] [TRT] *************** Autotuning Reformat: Float(2073600,8100,90,1) -> Float(2073600,1,23040,256) ***************
[03/24/2023-12:56:19] [V] [TRT] *************** Autotuning Reformat: Float(2073600,8100,90,1) -> Float(518400,1:4,5760,64) ***************
[03/24/2023-12:56:19] [V] [TRT] *************** Autotuning Reformat: Float(2073600,8100,90,1) -> Half(2073600,8100,90,1) ***************
[03/24/2023-12:56:19] [V] [TRT] *************** Autotuning Reformat: Float(2073600,8100,90,1) -> Half(1036800,8100:2,90,1) ***************
[03/24/2023-12:56:19] [V] [TRT] *************** Autotuning Reformat: Float(2073600,8100,90,1) -> Half(259200,1:8,2880,32) ***************
[03/24/2023-12:56:19] [V] [TRT] *************** Autotuning Reformat: Float(2073600,8100,90,1) -> Half(129600,1:16,1440,16) ***************
[03/24/2023-12:56:19] [V] [TRT] *************** Autotuning Reformat: Float(2073600,1,23040,256) -> Float(2073600,8100,90,1) ***************
[03/24/2023-12:56:19] [V] [TRT] *************** Autotuning Reformat: Float(2073600,1,23040,256) -> Float(518400,1:4,5760,64) ***************
[03/24/2023-12:56:19] [V] [TRT] *************** Autotuning Reformat: Float(2073600,1,23040,256) -> Half(2073600,8100,90,1) ***************
[03/24/2023-12:56:19] [V] [TRT] *************** Autotuning Reformat: Float(2073600,1,23040,256) -> Half(1036800,8100:2,90,1) ***************
[03/24/2023-12:56:19] [V] [TRT] *************** Autotuning Reformat: Float(2073600,1,23040,256) -> Half(259200,1:8,2880,32) ***************
[03/24/2023-12:56:19] [V] [TRT] *************** Autotuning Reformat: Float(2073600,1,23040,256) -> Half(129600,1:16,1440,16) ***************
[03/24/2023-12:56:19] [V] [TRT] *************** Autotuning Reformat: Float(518400,1:4,5760,64) -> Float(2073600,8100,90,1) ***************
[03/24/2023-12:56:19] [V] [TRT] *************** Autotuning Reformat: Float(518400,1:4,5760,64) -> Float(2073600,1,23040,256) ***************
[03/24/2023-12:56:19] [V] [TRT] *************** Autotuning Reformat: Float(518400,1:4,5760,64) -> Half(2073600,8100,90,1) ***************
[03/24/2023-12:56:19] [V] [TRT] *************** Autotuning Reformat: Float(518400,1:4,5760,64) -> Half(1036800,8100:2,90,1) ***************
[03/24/2023-12:56:19] [V] [TRT] *************** Autotuning Reformat: Float(518400,1:4,5760,64) -> Half(259200,1:8,2880,32) ***************
[03/24/2023-12:56:19] [V] [TRT] *************** Autotuning Reformat: Float(518400,1:4,5760,64) -> Half(129600,1:16,1440,16) ***************
[03/24/2023-12:56:19] [V] [TRT] *************** Autotuning Reformat: Half(2073600,8100,90,1) -> Float(2073600,8100,90,1) ***************
[03/24/2023-12:56:19] [V] [TRT] *************** Autotuning Reformat: Half(2073600,8100,90,1) -> Float(2073600,1,23040,256) ***************
[03/24/2023-12:56:19] [V] [TRT] *************** Autotuning Reformat: Half(2073600,8100,90,1) -> Float(518400,1:4,5760,64) ***************
[03/24/2023-12:56:19] [V] [TRT] *************** Autotuning Reformat: Half(2073600,8100,90,1) -> Half(1036800,8100:2,90,1) ***************
[03/24/2023-12:56:19] [V] [TRT] *************** Autotuning Reformat: Half(2073600,8100,90,1) -> Half(259200,1:8,2880,32) ***************
[03/24/2023-12:56:19] [V] [TRT] *************** Autotuning Reformat: Half(2073600,8100,90,1) -> Half(129600,1:16,1440,16) ***************
[03/24/2023-12:56:19] [V] [TRT] *************** Autotuning Reformat: Half(1036800,8100:2,90,1) -> Float(2073600,8100,90,1) ***************
[03/24/2023-12:56:19] [V] [TRT] *************** Autotuning Reformat: Half(1036800,8100:2,90,1) -> Float(2073600,1,23040,256) ***************
[03/24/2023-12:56:19] [V] [TRT] *************** Autotuning Reformat: Half(1036800,8100:2,90,1) -> Float(518400,1:4,5760,64) ***************
[03/24/2023-12:56:19] [V] [TRT] *************** Autotuning Reformat: Half(1036800,8100:2,90,1) -> Half(2073600,8100,90,1) ***************
[03/24/2023-12:56:19] [V] [TRT] *************** Autotuning Reformat: Half(1036800,8100:2,90,1) -> Half(259200,1:8,2880,32) ***************
[03/24/2023-12:56:19] [V] [TRT] *************** Autotuning Reformat: Half(1036800,8100:2,90,1) -> Half(129600,1:16,1440,16) ***************
[03/24/2023-12:56:19] [V] [TRT] *************** Autotuning Reformat: Half(259200,1:8,2880,32) -> Float(2073600,8100,90,1) ***************
[03/24/2023-12:56:19] [V] [TRT] *************** Autotuning Reformat: Half(259200,1:8,2880,32) -> Float(2073600,1,23040,256) ***************
[03/24/2023-12:56:19] [V] [TRT] *************** Autotuning Reformat: Half(259200,1:8,2880,32) -> Float(518400,1:4,5760,64) ***************
[03/24/2023-12:56:19] [V] [TRT] *************** Autotuning Reformat: Half(259200,1:8,2880,32) -> Half(2073600,8100,90,1) ***************
[03/24/2023-12:56:19] [V] [TRT] *************** Autotuning Reformat: Half(259200,1:8,2880,32) -> Half(1036800,8100:2,90,1) ***************
[03/24/2023-12:56:19] [V] [TRT] *************** Autotuning Reformat: Half(259200,1:8,2880,32) -> Half(129600,1:16,1440,16) ***************
[03/24/2023-12:56:19] [V] [TRT] *************** Autotuning Reformat: Half(129600,1:16,1440,16) -> Float(2073600,8100,90,1) ***************
[03/24/2023-12:56:19] [V] [TRT] *************** Autotuning Reformat: Half(129600,1:16,1440,16) -> Float(2073600,1,23040,256) ***************
[03/24/2023-12:56:19] [V] [TRT] *************** Autotuning Reformat: Half(129600,1:16,1440,16) -> Float(518400,1:4,5760,64) ***************
[03/24/2023-12:56:19] [V] [TRT] *************** Autotuning Reformat: Half(129600,1:16,1440,16) -> Half(2073600,8100,90,1) ***************
[03/24/2023-12:56:19] [V] [TRT] *************** Autotuning Reformat: Half(129600,1:16,1440,16) -> Half(1036800,8100:2,90,1) ***************
[03/24/2023-12:56:19] [V] [TRT] *************** Autotuning Reformat: Half(129600,1:16,1440,16) -> Half(259200,1:8,2880,32) ***************
[03/24/2023-12:56:19] [V] [TRT] =============== Computing reformatting costs
[03/24/2023-12:56:19] [V] [TRT] *************** Autotuning Reformat: Float(2073600,8100,90,1) -> Float(2073600,1,23040,256) ***************
[03/24/2023-12:56:19] [V] [TRT] *************** Autotuning Reformat: Float(2073600,8100,90,1) -> Float(518400,1:4,5760,64) ***************
[03/24/2023-12:56:19] [V] [TRT] *************** Autotuning Reformat: Float(2073600,8100,90,1) -> Half(2073600,8100,90,1) ***************
[03/24/2023-12:56:19] [V] [TRT] *************** Autotuning Reformat: Float(2073600,8100,90,1) -> Half(1036800,8100:2,90,1) ***************
[03/24/2023-12:56:19] [V] [TRT] *************** Autotuning Reformat: Float(2073600,8100,90,1) -> Half(259200,1:8,2880,32) ***************
[03/24/2023-12:56:19] [V] [TRT] *************** Autotuning Reformat: Float(2073600,8100,90,1) -> Half(129600,1:16,1440,16) ***************
[03/24/2023-12:56:19] [V] [TRT] *************** Autotuning Reformat: Float(2073600,1,23040,256) -> Float(2073600,8100,90,1) ***************
[03/24/2023-12:56:19] [V] [TRT] *************** Autotuning Reformat: Float(2073600,1,23040,256) -> Float(518400,1:4,5760,64) ***************
[03/24/2023-12:56:19] [V] [TRT] *************** Autotuning Reformat: Float(2073600,1,23040,256) -> Half(2073600,8100,90,1) ***************
[03/24/2023-12:56:19] [V] [TRT] *************** Autotuning Reformat: Float(2073600,1,23040,256) -> Half(1036800,8100:2,90,1) ***************
[03/24/2023-12:56:19] [V] [TRT] *************** Autotuning Reformat: Float(2073600,1,23040,256) -> Half(259200,1:8,2880,32) ***************
[03/24/2023-12:56:19] [V] [TRT] *************** Autotuning Reformat: Float(2073600,1,23040,256) -> Half(129600,1:16,1440,16) ***************
[03/24/2023-12:56:19] [V] [TRT] *************** Autotuning Reformat: Float(518400,1:4,5760,64) -> Float(2073600,8100,90,1) ***************
[03/24/2023-12:56:19] [V] [TRT] *************** Autotuning Reformat: Float(518400,1:4,5760,64) -> Float(2073600,1,23040,256) ***************
[03/24/2023-12:56:19] [V] [TRT] *************** Autotuning Reformat: Float(518400,1:4,5760,64) -> Half(2073600,8100,90,1) ***************
[03/24/2023-12:56:19] [V] [TRT] *************** Autotuning Reformat: Float(518400,1:4,5760,64) -> Half(1036800,8100:2,90,1) ***************
[03/24/2023-12:56:19] [V] [TRT] *************** Autotuning Reformat: Float(518400,1:4,5760,64) -> Half(259200,1:8,2880,32) ***************
[03/24/2023-12:56:19] [V] [TRT] *************** Autotuning Reformat: Float(518400,1:4,5760,64) -> Half(129600,1:16,1440,16) ***************
[03/24/2023-12:56:19] [V] [TRT] *************** Autotuning Reformat: Half(2073600,8100,90,1) -> Float(2073600,8100,90,1) ***************
[03/24/2023-12:56:19] [V] [TRT] *************** Autotuning Reformat: Half(2073600,8100,90,1) -> Float(2073600,1,23040,256) ***************
[03/24/2023-12:56:19] [V] [TRT] *************** Autotuning Reformat: Half(2073600,8100,90,1) -> Float(518400,1:4,5760,64) ***************
[03/24/2023-12:56:19] [V] [TRT] *************** Autotuning Reformat: Half(2073600,8100,90,1) -> Half(1036800,8100:2,90,1) ***************
[03/24/2023-12:56:19] [V] [TRT] *************** Autotuning Reformat: Half(2073600,8100,90,1) -> Half(259200,1:8,2880,32) ***************
[03/24/2023-12:56:19] [V] [TRT] *************** Autotuning Reformat: Half(2073600,8100,90,1) -> Half(129600,1:16,1440,16) ***************
[03/24/2023-12:56:19] [V] [TRT] *************** Autotuning Reformat: Half(1036800,8100:2,90,1) -> Float(2073600,8100,90,1) ***************
[03/24/2023-12:56:19] [V] [TRT] *************** Autotuning Reformat: Half(1036800,8100:2,90,1) -> Float(2073600,1,23040,256) ***************
[03/24/2023-12:56:19] [V] [TRT] *************** Autotuning Reformat: Half(1036800,8100:2,90,1) -> Float(518400,1:4,5760,64) ***************
[03/24/2023-12:56:19] [V] [TRT] *************** Autotuning Reformat: Half(1036800,8100:2,90,1) -> Half(2073600,8100,90,1) ***************
[03/24/2023-12:56:19] [V] [TRT] *************** Autotuning Reformat: Half(1036800,8100:2,90,1) -> Half(259200,1:8,2880,32) ***************
[03/24/2023-12:56:19] [V] [TRT] *************** Autotuning Reformat: Half(1036800,8100:2,90,1) -> Half(129600,1:16,1440,16) ***************
[03/24/2023-12:56:19] [V] [TRT] *************** Autotuning Reformat: Half(259200,1:8,2880,32) -> Float(2073600,8100,90,1) ***************
[03/24/2023-12:56:19] [V] [TRT] *************** Autotuning Reformat: Half(259200,1:8,2880,32) -> Float(2073600,1,23040,256) ***************
[03/24/2023-12:56:19] [V] [TRT] *************** Autotuning Reformat: Half(259200,1:8,2880,32) -> Float(518400,1:4,5760,64) ***************
[03/24/2023-12:56:19] [V] [TRT] *************** Autotuning Reformat: Half(259200,1:8,2880,32) -> Half(2073600,8100,90,1) ***************
[03/24/2023-12:56:19] [V] [TRT] *************** Autotuning Reformat: Half(259200,1:8,2880,32) -> Half(1036800,8100:2,90,1) ***************
[03/24/2023-12:56:19] [V] [TRT] *************** Autotuning Reformat: Half(259200,1:8,2880,32) -> Half(129600,1:16,1440,16) ***************
[03/24/2023-12:56:19] [V] [TRT] *************** Autotuning Reformat: Half(129600,1:16,1440,16) -> Float(2073600,8100,90,1) ***************
[03/24/2023-12:56:19] [V] [TRT] *************** Autotuning Reformat: Half(129600,1:16,1440,16) -> Float(2073600,1,23040,256) ***************
[03/24/2023-12:56:19] [V] [TRT] *************** Autotuning Reformat: Half(129600,1:16,1440,16) -> Float(518400,1:4,5760,64) ***************
[03/24/2023-12:56:19] [V] [TRT] *************** Autotuning Reformat: Half(129600,1:16,1440,16) -> Half(2073600,8100,90,1) ***************
[03/24/2023-12:56:19] [V] [TRT] *************** Autotuning Reformat: Half(129600,1:16,1440,16) -> Half(1036800,8100:2,90,1) ***************
[03/24/2023-12:56:19] [V] [TRT] *************** Autotuning Reformat: Half(129600,1:16,1440,16) -> Half(259200,1:8,2880,32) ***************
[03/24/2023-12:56:19] [V] [TRT] =============== Computing reformatting costs
[03/24/2023-12:56:19] [V] [TRT] *************** Autotuning Reformat: Float(2073600,8100,90,1) -> Float(2073600,1,23040,256) ***************
[03/24/2023-12:56:19] [V] [TRT] *************** Autotuning Reformat: Float(2073600,8100,90,1) -> Float(518400,1:4,5760,64) ***************
[03/24/2023-12:56:19] [V] [TRT] *************** Autotuning Reformat: Float(2073600,8100,90,1) -> Half(2073600,8100,90,1) ***************
[03/24/2023-12:56:19] [V] [TRT] *************** Autotuning Reformat: Float(2073600,8100,90,1) -> Half(1036800,8100:2,90,1) ***************
[03/24/2023-12:56:19] [V] [TRT] *************** Autotuning Reformat: Float(2073600,8100,90,1) -> Half(259200,1:8,2880,32) ***************
[03/24/2023-12:56:19] [V] [TRT] *************** Autotuning Reformat: Float(2073600,8100,90,1) -> Half(129600,1:16,1440,16) ***************
[03/24/2023-12:56:19] [V] [TRT] *************** Autotuning Reformat: Float(2073600,1,23040,256) -> Float(2073600,8100,90,1) ***************
[03/24/2023-12:56:19] [V] [TRT] *************** Autotuning Reformat: Float(2073600,1,23040,256) -> Float(518400,1:4,5760,64) ***************
[03/24/2023-12:56:19] [V] [TRT] *************** Autotuning Reformat: Float(2073600,1,23040,256) -> Half(2073600,8100,90,1) ***************
[03/24/2023-12:56:19] [V] [TRT] *************** Autotuning Reformat: Float(2073600,1,23040,256) -> Half(1036800,8100:2,90,1) ***************
[03/24/2023-12:56:19] [V] [TRT] *************** Autotuning Reformat: Float(2073600,1,23040,256) -> Half(259200,1:8,2880,32) ***************
[03/24/2023-12:56:19] [V] [TRT] *************** Autotuning Reformat: Float(2073600,1,23040,256) -> Half(129600,1:16,1440,16) ***************
[03/24/2023-12:56:19] [V] [TRT] *************** Autotuning Reformat: Float(518400,1:4,5760,64) -> Float(2073600,8100,90,1) ***************
[03/24/2023-12:56:19] [V] [TRT] *************** Autotuning Reformat: Float(518400,1:4,5760,64) -> Float(2073600,1,23040,256) ***************
[03/24/2023-12:56:19] [V] [TRT] *************** Autotuning Reformat: Float(518400,1:4,5760,64) -> Half(2073600,8100,90,1) ***************
[03/24/2023-12:56:19] [V] [TRT] *************** Autotuning Reformat: Float(518400,1:4,5760,64) -> Half(1036800,8100:2,90,1) ***************
[03/24/2023-12:56:19] [V] [TRT] *************** Autotuning Reformat: Float(518400,1:4,5760,64) -> Half(259200,1:8,2880,32) ***************
[03/24/2023-12:56:19] [V] [TRT] *************** Autotuning Reformat: Float(518400,1:4,5760,64) -> Half(129600,1:16,1440,16) ***************
[03/24/2023-12:56:19] [V] [TRT] *************** Autotuning Reformat: Half(2073600,8100,90,1) -> Float(2073600,8100,90,1) ***************
[03/24/2023-12:56:19] [V] [TRT] *************** Autotuning Reformat: Half(2073600,8100,90,1) -> Float(2073600,1,23040,256) ***************
[03/24/2023-12:56:19] [V] [TRT] *************** Autotuning Reformat: Half(2073600,8100,90,1) -> Float(518400,1:4,5760,64) ***************
[03/24/2023-12:56:19] [V] [TRT] *************** Autotuning Reformat: Half(2073600,8100,90,1) -> Half(1036800,8100:2,90,1) ***************
[03/24/2023-12:56:19] [V] [TRT] *************** Autotuning Reformat: Half(2073600,8100,90,1) -> Half(259200,1:8,2880,32) ***************
[03/24/2023-12:56:19] [V] [TRT] *************** Autotuning Reformat: Half(2073600,8100,90,1) -> Half(129600,1:16,1440,16) ***************
[03/24/2023-12:56:19] [V] [TRT] *************** Autotuning Reformat: Half(1036800,8100:2,90,1) -> Float(2073600,8100,90,1) ***************
[03/24/2023-12:56:19] [V] [TRT] *************** Autotuning Reformat: Half(1036800,8100:2,90,1) -> Float(2073600,1,23040,256) ***************
[03/24/2023-12:56:19] [V] [TRT] *************** Autotuning Reformat: Half(1036800,8100:2,90,1) -> Float(518400,1:4,5760,64) ***************
[03/24/2023-12:56:19] [V] [TRT] *************** Autotuning Reformat: Half(1036800,8100:2,90,1) -> Half(2073600,8100,90,1) ***************
[03/24/2023-12:56:19] [V] [TRT] *************** Autotuning Reformat: Half(1036800,8100:2,90,1) -> Half(259200,1:8,2880,32) ***************
[03/24/2023-12:56:19] [V] [TRT] *************** Autotuning Reformat: Half(1036800,8100:2,90,1) -> Half(129600,1:16,1440,16) ***************
[03/24/2023-12:56:19] [V] [TRT] *************** Autotuning Reformat: Half(259200,1:8,2880,32) -> Float(2073600,8100,90,1) ***************
[03/24/2023-12:56:19] [V] [TRT] *************** Autotuning Reformat: Half(259200,1:8,2880,32) -> Float(2073600,1,23040,256) ***************
[03/24/2023-12:56:19] [V] [TRT] *************** Autotuning Reformat: Half(259200,1:8,2880,32) -> Float(518400,1:4,5760,64) ***************
[03/24/2023-12:56:19] [V] [TRT] *************** Autotuning Reformat: Half(259200,1:8,2880,32) -> Half(2073600,8100,90,1) ***************
[03/24/2023-12:56:19] [V] [TRT] *************** Autotuning Reformat: Half(259200,1:8,2880,32) -> Half(1036800,8100:2,90,1) ***************
[03/24/2023-12:56:19] [V] [TRT] *************** Autotuning Reformat: Half(259200,1:8,2880,32) -> Half(129600,1:16,1440,16) ***************
[03/24/2023-12:56:19] [V] [TRT] *************** Autotuning Reformat: Half(129600,1:16,1440,16) -> Float(2073600,8100,90,1) ***************
[03/24/2023-12:56:19] [V] [TRT] *************** Autotuning Reformat: Half(129600,1:16,1440,16) -> Float(2073600,1,23040,256) ***************
[03/24/2023-12:56:19] [V] [TRT] *************** Autotuning Reformat: Half(129600,1:16,1440,16) -> Float(518400,1:4,5760,64) ***************
[03/24/2023-12:56:19] [V] [TRT] *************** Autotuning Reformat: Half(129600,1:16,1440,16) -> Half(2073600,8100,90,1) ***************
[03/24/2023-12:56:19] [V] [TRT] *************** Autotuning Reformat: Half(129600,1:16,1440,16) -> Half(1036800,8100:2,90,1) ***************
[03/24/2023-12:56:19] [V] [TRT] *************** Autotuning Reformat: Half(129600,1:16,1440,16) -> Half(259200,1:8,2880,32) ***************
[03/24/2023-12:56:19] [V] [TRT] =============== Computing reformatting costs
[03/24/2023-12:56:19] [V] [TRT] *************** Autotuning Reformat: Float(8294400,32400,180,1) -> Float(16588800,32400,180,1) ***************
[03/24/2023-12:56:19] [V] [TRT] --------------- Timing Runner: onnx::Concat_647 copy (Reformat)
[03/24/2023-12:56:19] [V] [TRT] Tactic: 1002 Time: 0.122624
[03/24/2023-12:56:19] [V] [TRT] Tactic: 0 Time: 0.06848
[03/24/2023-12:56:19] [V] [TRT] Fastest Tactic: 0 Time: 0.06848
[03/24/2023-12:56:19] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0
[03/24/2023-12:56:19] [V] [TRT] *************** Autotuning Reformat: Float(8294400,32400,180,1) -> Float(16588800,1,92160,512) ***************
[03/24/2023-12:56:19] [V] [TRT] --------------- Timing Runner: onnx::Concat_647 copy (Reformat)
[03/24/2023-12:56:19] [V] [TRT] Tactic: 1002 Time: 0.089216
[03/24/2023-12:56:19] [V] [TRT] Tactic: 0 Time: 0.23744
[03/24/2023-12:56:19] [V] [TRT] Fastest Tactic: 1002 Time: 0.089216
[03/24/2023-12:56:19] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 1002
[03/24/2023-12:56:19] [V] [TRT] *************** Autotuning Reformat: Float(8294400,32400,180,1) -> Float(4147200,1:4,23040,128) ***************
[03/24/2023-12:56:19] [V] [TRT] --------------- Timing Runner: onnx::Concat_647 copy (Reformat)
[03/24/2023-12:56:19] [V] [TRT] Tactic: 1002 Time: 0.089344
[03/24/2023-12:56:19] [V] [TRT] Tactic: 0 Time: 0.237568
[03/24/2023-12:56:19] [V] [TRT] Fastest Tactic: 1002 Time: 0.089344
[03/24/2023-12:56:19] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 1002
[03/24/2023-12:56:19] [V] [TRT] *************** Autotuning Reformat: Float(8294400,32400,180,1) -> Half(16588800,32400,180,1) ***************
[03/24/2023-12:56:19] [V] [TRT] --------------- Timing Runner: onnx::Concat_647 copy (Reformat)
[03/24/2023-12:56:19] [V] [TRT] Tactic: 1002 Time: 0.123264
[03/24/2023-12:56:19] [V] [TRT] Tactic: 0 Time: 0.10688
[03/24/2023-12:56:19] [V] [TRT] Fastest Tactic: 0 Time: 0.10688
[03/24/2023-12:56:19] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0
[03/24/2023-12:56:19] [V] [TRT] *************** Autotuning Reformat: Float(8294400,32400,180,1) -> Half(8294400,32400:2,180,1) ***************
[03/24/2023-12:56:19] [V] [TRT] --------------- Timing Runner: onnx::Concat_647 copy (Reformat)
[03/24/2023-12:56:19] [V] [TRT] Tactic: 1002 Time: 0.115072
[03/24/2023-12:56:19] [V] [TRT] Tactic: 0 Time: 0.101632
[03/24/2023-12:56:19] [V] [TRT] Fastest Tactic: 0 Time: 0.101632
[03/24/2023-12:56:19] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0
[03/24/2023-12:56:19] [V] [TRT] *************** Autotuning Reformat: Float(8294400,32400,180,1) -> Half(2073600,1:8,11520,64) ***************
[03/24/2023-12:56:19] [V] [TRT] --------------- Timing Runner: onnx::Concat_647 copy (Reformat)
[03/24/2023-12:56:19] [V] [TRT] Tactic: 1002 Time: 0.081664
[03/24/2023-12:56:19] [V] [TRT] Tactic: 0 Time: 0.06272
[03/24/2023-12:56:19] [V] [TRT] Fastest Tactic: 0 Time: 0.06272
[03/24/2023-12:56:19] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0
[03/24/2023-12:56:19] [V] [TRT] *************** Autotuning Reformat: Float(8294400,32400,180,1) -> Half(1036800,1:16,5760,32) ***************
[03/24/2023-12:56:19] [V] [TRT] --------------- Timing Runner: onnx::Concat_647 copy (Reformat)
[03/24/2023-12:56:19] [V] [TRT] Tactic: 1002 Time: 0.081152
[03/24/2023-12:56:19] [V] [TRT] Tactic: 0 Time: 0.236416
[03/24/2023-12:56:19] [V] [TRT] Fastest Tactic: 1002 Time: 0.081152
[03/24/2023-12:56:19] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 1002
[03/24/2023-12:56:19] [V] [TRT] *************** Autotuning Reformat: Float(8294400,1,46080,256) -> Float(16588800,32400,180,1) ***************
[03/24/2023-12:56:19] [V] [TRT] --------------- Timing Runner: onnx::Concat_647 copy (Reformat)
[03/24/2023-12:56:19] [V] [TRT] Tactic: 1002 Time: 0.095104
[03/24/2023-12:56:19] [V] [TRT] Tactic: 0 Time: 0.203008
[03/24/2023-12:56:19] [V] [TRT] Fastest Tactic: 1002 Time: 0.095104
[03/24/2023-12:56:19] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 1002
[03/24/2023-12:56:19] [V] [TRT] *************** Autotuning Reformat: Float(8294400,1,46080,256) -> Float(16588800,1,92160,512) ***************
[03/24/2023-12:56:19] [V] [TRT] --------------- Timing Runner: onnx::Concat_647 copy (Reformat)
[03/24/2023-12:56:19] [V] [TRT] Tactic: 1002 Time: 0.104448
[03/24/2023-12:56:19] [V] [TRT] Tactic: 0 Time: 0.112768
[03/24/2023-12:56:19] [V] [TRT] Fastest Tactic: 1002 Time: 0.104448
[03/24/2023-12:56:19] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 1002
[03/24/2023-12:56:19] [V] [TRT] *************** Autotuning Reformat: Float(8294400,1,46080,256) -> Float(4147200,1:4,23040,128) ***************
[03/24/2023-12:56:19] [V] [TRT] --------------- Timing Runner: onnx::Concat_647 copy (Reformat)
[03/24/2023-12:56:19] [V] [TRT] Tactic: 1002 Time: 0.076544
[03/24/2023-12:56:19] [V] [TRT] Tactic: 0 Time: 0.127104
[03/24/2023-12:56:19] [V] [TRT] Fastest Tactic: 1002 Time: 0.076544
[03/24/2023-12:56:19] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 1002
[03/24/2023-12:56:19] [V] [TRT] *************** Autotuning Reformat: Float(8294400,1,46080,256) -> Half(16588800,32400,180,1) ***************
[03/24/2023-12:56:19] [V] [TRT] --------------- Timing Runner: onnx::Concat_647 copy (Reformat)
[03/24/2023-12:56:19] [V] [TRT] Tactic: 1002 Time: 0.08896
[03/24/2023-12:56:19] [V] [TRT] Tactic: 0 Time: 0.190464
[03/24/2023-12:56:19] [V] [TRT] Fastest Tactic: 1002 Time: 0.08896
[03/24/2023-12:56:19] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 1002
[03/24/2023-12:56:19] [V] [TRT] *************** Autotuning Reformat: Float(8294400,1,46080,256) -> Half(8294400,32400:2,180,1) ***************
[03/24/2023-12:56:19] [V] [TRT] --------------- Timing Runner: onnx::Concat_647 copy (Reformat)
[03/24/2023-12:56:19] [V] [TRT] Tactic: 1002 Time: 0.11008
[03/24/2023-12:56:19] [V] [TRT] Tactic: 0 Time: 0.203776
[03/24/2023-12:56:19] [V] [TRT] Fastest Tactic: 1002 Time: 0.11008
[03/24/2023-12:56:19] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 1002
[03/24/2023-12:56:19] [V] [TRT] *************** Autotuning Reformat: Float(8294400,1,46080,256) -> Half(2073600,1:8,11520,64) ***************
[03/24/2023-12:56:19] [V] [TRT] --------------- Timing Runner: onnx::Concat_647 copy (Reformat)
[03/24/2023-12:56:19] [V] [TRT] Tactic: 1002 Time: 0.07296
[03/24/2023-12:56:19] [V] [TRT] Tactic: 0 Time: 0.128256
[03/24/2023-12:56:19] [V] [TRT] Fastest Tactic: 1002 Time: 0.07296
[03/24/2023-12:56:19] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 1002
[03/24/2023-12:56:19] [V] [TRT] *************** Autotuning Reformat: Float(8294400,1,46080,256) -> Half(1036800,1:16,5760,32) ***************
[03/24/2023-12:56:19] [V] [TRT] --------------- Timing Runner: onnx::Concat_647 copy (Reformat)
[03/24/2023-12:56:19] [V] [TRT] Tactic: 1002 Time: 0.07296
[03/24/2023-12:56:19] [V] [TRT] Tactic: 0 Time: 0.128128
[03/24/2023-12:56:19] [V] [TRT] Fastest Tactic: 1002 Time: 0.07296
[03/24/2023-12:56:19] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 1002
[03/24/2023-12:56:19] [V] [TRT] *************** Autotuning Reformat: Float(2073600,1:4,11520,64) -> Float(16588800,32400,180,1) ***************
[03/24/2023-12:56:19] [V] [TRT] --------------- Timing Runner: onnx::Concat_647 copy (Reformat)
[03/24/2023-12:56:19] [V] [TRT] Tactic: 1002 Time: 0.095232
[03/24/2023-12:56:19] [V] [TRT] Tactic: 0 Time: 0.205952
[03/24/2023-12:56:19] [V] [TRT] Fastest Tactic: 1002 Time: 0.095232
[03/24/2023-12:56:19] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 1002
[03/24/2023-12:56:19] [V] [TRT] *************** Autotuning Reformat: Float(2073600,1:4,11520,64) -> Float(16588800,1,92160,512) ***************
[03/24/2023-12:56:19] [V] [TRT] --------------- Timing Runner: onnx::Concat_647 copy (Reformat)
[03/24/2023-12:56:19] [V] [TRT] Tactic: 1002 Time: 0.076672
[03/24/2023-12:56:19] [V] [TRT] Tactic: 0 Time: 0.128
[03/24/2023-12:56:19] [V] [TRT] Fastest Tactic: 1002 Time: 0.076672
[03/24/2023-12:56:19] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 1002
[03/24/2023-12:56:19] [V] [TRT] *************** Autotuning Reformat: Float(2073600,1:4,11520,64) -> Float(4147200,1:4,23040,128) ***************
[03/24/2023-12:56:19] [V] [TRT] --------------- Timing Runner: onnx::Concat_647 copy (Reformat)
[03/24/2023-12:56:19] [V] [TRT] Tactic: 1002 Time: 0.0768
[03/24/2023-12:56:19] [V] [TRT] Tactic: 0 Time: 0.148096
[03/24/2023-12:56:19] [V] [TRT] Fastest Tactic: 1002 Time: 0.0768
[03/24/2023-12:56:19] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 1002
[03/24/2023-12:56:19] [V] [TRT] *************** Autotuning Reformat: Float(2073600,1:4,11520,64) -> Half(16588800,32400,180,1) ***************
[03/24/2023-12:56:19] [V] [TRT] --------------- Timing Runner: onnx::Concat_647 copy (Reformat)
[03/24/2023-12:56:19] [V] [TRT] Tactic: 1002 Time: 0.089472
[03/24/2023-12:56:19] [V] [TRT] Tactic: 0 Time: 0.195584
[03/24/2023-12:56:19] [V] [TRT] Fastest Tactic: 1002 Time: 0.089472
[03/24/2023-12:56:19] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 1002
[03/24/2023-12:56:19] [V] [TRT] *************** Autotuning Reformat: Float(2073600,1:4,11520,64) -> Half(8294400,32400:2,180,1) ***************
[03/24/2023-12:56:19] [V] [TRT] --------------- Timing Runner: onnx::Concat_647 copy (Reformat)
[03/24/2023-12:56:19] [V] [TRT] Tactic: 1002 Time: 0.110208
[03/24/2023-12:56:19] [V] [TRT] Tactic: 0 Time: 0.207616
[03/24/2023-12:56:19] [V] [TRT] Fastest Tactic: 1002 Time: 0.110208
[03/24/2023-12:56:19] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 1002
[03/24/2023-12:56:19] [V] [TRT] *************** Autotuning Reformat: Float(2073600,1:4,11520,64) -> Half(2073600,1:8,11520,64) ***************
[03/24/2023-12:56:19] [V] [TRT] --------------- Timing Runner: onnx::Concat_647 copy (Reformat)
[03/24/2023-12:56:19] [V] [TRT] Tactic: 1002 Time: 0.073088
[03/24/2023-12:56:19] [V] [TRT] Tactic: 0 Time: 0.14912
[03/24/2023-12:56:19] [V] [TRT] Fastest Tactic: 1002 Time: 0.073088
[03/24/2023-12:56:19] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 1002
[03/24/2023-12:56:19] [V] [TRT] *************** Autotuning Reformat: Float(2073600,1:4,11520,64) -> Half(1036800,1:16,5760,32) ***************
[03/24/2023-12:56:19] [V] [TRT] --------------- Timing Runner: onnx::Concat_647 copy (Reformat)
[03/24/2023-12:56:19] [V] [TRT] Tactic: 1002 Time: 0.073088
[03/24/2023-12:56:19] [V] [TRT] Tactic: 0 Time: 0.14912
[03/24/2023-12:56:19] [V] [TRT] Fastest Tactic: 1002 Time: 0.073088
[03/24/2023-12:56:19] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 1002
[03/24/2023-12:56:19] [V] [TRT] *************** Autotuning Reformat: Half(8294400,32400,180,1) -> Float(16588800,32400,180,1) ***************
[03/24/2023-12:56:19] [V] [TRT] --------------- Timing Runner: onnx::Concat_647 copy (Reformat)
[03/24/2023-12:56:19] [V] [TRT] Tactic: 1002 Time: 0.123136
[03/24/2023-12:56:19] [V] [TRT] Tactic: 0 Time: 0.108928
[03/24/2023-12:56:19] [V] [TRT] Fastest Tactic: 0 Time: 0.108928
[03/24/2023-12:56:19] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0
[03/24/2023-12:56:19] [V] [TRT] *************** Autotuning Reformat: Half(8294400,32400,180,1) -> Float(16588800,1,92160,512) ***************
[03/24/2023-12:56:19] [V] [TRT] --------------- Timing Runner: onnx::Concat_647 copy (Reformat)
[03/24/2023-12:56:19] [V] [TRT] Tactic: 1002 Time: 0.081152
[03/24/2023-12:56:19] [V] [TRT] Tactic: 0 Time: 0.191488
[03/24/2023-12:56:19] [V] [TRT] Fastest Tactic: 1002 Time: 0.081152
[03/24/2023-12:56:19] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 1002
[03/24/2023-12:56:19] [V] [TRT] *************** Autotuning Reformat: Half(8294400,32400,180,1) -> Float(4147200,1:4,23040,128) ***************
[03/24/2023-12:56:19] [V] [TRT] --------------- Timing Runner: onnx::Concat_647 copy (Reformat)
[03/24/2023-12:56:19] [V] [TRT] Tactic: 1002 Time: 0.081152
[03/24/2023-12:56:19] [V] [TRT] Tactic: 0 Time: 0.194176
[03/24/2023-12:56:19] [V] [TRT] Fastest Tactic: 1002 Time: 0.081152
[03/24/2023-12:56:19] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 1002
[03/24/2023-12:56:19] [V] [TRT] *************** Autotuning Reformat: Half(8294400,32400,180,1) -> Half(16588800,32400,180,1) ***************
[03/24/2023-12:56:19] [V] [TRT] --------------- Timing Runner: onnx::Concat_647 copy (Reformat)
[03/24/2023-12:56:19] [V] [TRT] Tactic: 1002 Time: 0.09152
[03/24/2023-12:56:19] [V] [TRT] Tactic: 0 Time: 0.03584
[03/24/2023-12:56:19] [V] [TRT] Fastest Tactic: 0 Time: 0.03584
[03/24/2023-12:56:19] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0
[03/24/2023-12:56:19] [V] [TRT] *************** Autotuning Reformat: Half(8294400,32400,180,1) -> Half(8294400,32400:2,180,1) ***************
[03/24/2023-12:56:19] [V] [TRT] --------------- Timing Runner: onnx::Concat_647 copy (Reformat)
[03/24/2023-12:56:19] [V] [TRT] Tactic: 1002 Time: 0.080256
[03/24/2023-12:56:19] [V] [TRT] Tactic: 0 Time: 0.101632
[03/24/2023-12:56:19] [V] [TRT] Fastest Tactic: 1002 Time: 0.080256
[03/24/2023-12:56:19] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 1002
[03/24/2023-12:56:19] [V] [TRT] *************** Autotuning Reformat: Half(8294400,32400,180,1) -> Half(2073600,1:8,11520,64) ***************
[03/24/2023-12:56:19] [V] [TRT] --------------- Timing Runner: onnx::Concat_647 copy (Reformat)
[03/24/2023-12:56:19] [V] [TRT] Tactic: 1002 Time: 0.086528
[03/24/2023-12:56:19] [V] [TRT] Tactic: 0 Time: 0.060928
[03/24/2023-12:56:19] [V] [TRT] Fastest Tactic: 0 Time: 0.060928
[03/24/2023-12:56:19] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0
[03/24/2023-12:56:19] [V] [TRT] *************** Autotuning Reformat: Half(8294400,32400,180,1) -> Half(1036800,1:16,5760,32) ***************
[03/24/2023-12:56:19] [V] [TRT] --------------- Timing Runner: onnx::Concat_647 copy (Reformat)
[03/24/2023-12:56:19] [V] [TRT] Tactic: 1002 Time: 0.086272
[03/24/2023-12:56:19] [V] [TRT] Tactic: 0 Time: 0.18816
[03/24/2023-12:56:19] [V] [TRT] Fastest Tactic: 1002 Time: 0.086272
[03/24/2023-12:56:19] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 1002
[03/24/2023-12:56:19] [V] [TRT] *************** Autotuning Reformat: Half(4147200,32400:2,180,1) -> Float(16588800,32400,180,1) ***************
[03/24/2023-12:56:19] [V] [TRT] --------------- Timing Runner: onnx::Concat_647 copy (Reformat)
[03/24/2023-12:56:19] [V] [TRT] Tactic: 1002 Time: 0.098048
[03/24/2023-12:56:19] [V] [TRT] Tactic: 0 Time: 0.12416
[03/24/2023-12:56:19] [V] [TRT] Fastest Tactic: 1002 Time: 0.098048
[03/24/2023-12:56:19] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 1002
[03/24/2023-12:56:19] [V] [TRT] *************** Autotuning Reformat: Half(4147200,32400:2,180,1) -> Float(16588800,1,92160,512) ***************
[03/24/2023-12:56:19] [V] [TRT] --------------- Timing Runner: onnx::Concat_647 copy (Reformat)
[03/24/2023-12:56:19] [V] [TRT] Tactic: 1002 Time: 0.082048
[03/24/2023-12:56:19] [V] [TRT] Tactic: 0 Time: 0.13248
[03/24/2023-12:56:19] [V] [TRT] Fastest Tactic: 1002 Time: 0.082048
[03/24/2023-12:56:19] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 1002
[03/24/2023-12:56:19] [V] [TRT] *************** Autotuning Reformat: Half(4147200,32400:2,180,1) -> Float(4147200,1:4,23040,128) ***************
[03/24/2023-12:56:19] [V] [TRT] --------------- Timing Runner: onnx::Concat_647 copy (Reformat)
[03/24/2023-12:56:19] [V] [TRT] Tactic: 1002 Time: 0.082048
[03/24/2023-12:56:19] [V] [TRT] Tactic: 0 Time: 0.150912
[03/24/2023-12:56:19] [V] [TRT] Fastest Tactic: 1002 Time: 0.082048
[03/24/2023-12:56:19] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 1002
[03/24/2023-12:56:19] [V] [TRT] *************** Autotuning Reformat: Half(4147200,32400:2,180,1) -> Half(16588800,32400,180,1) ***************
[03/24/2023-12:56:19] [V] [TRT] --------------- Timing Runner: onnx::Concat_647 copy (Reformat)
[03/24/2023-12:56:19] [V] [TRT] Tactic: 1002 Time: 0.274688
[03/24/2023-12:56:19] [V] [TRT] Tactic: 0 Time: 0.116352
[03/24/2023-12:56:19] [V] [TRT] Fastest Tactic: 0 Time: 0.116352
[03/24/2023-12:56:19] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0
[03/24/2023-12:56:19] [V] [TRT] *************** Autotuning Reformat: Half(4147200,32400:2,180,1) -> Half(8294400,32400:2,180,1) ***************
[03/24/2023-12:56:19] [V] [TRT] --------------- Timing Runner: onnx::Concat_647 copy (Reformat)
[03/24/2023-12:56:19] [V] [TRT] Tactic: 1002 Time: 0.116224
[03/24/2023-12:56:19] [V] [TRT] Tactic: 0 Time: 0.036096
[03/24/2023-12:56:19] [V] [TRT] Fastest Tactic: 0 Time: 0.036096
[03/24/2023-12:56:19] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0
[03/24/2023-12:56:19] [V] [TRT] *************** Autotuning Reformat: Half(4147200,32400:2,180,1) -> Half(2073600,1:8,11520,64) ***************
[03/24/2023-12:56:19] [V] [TRT] --------------- Timing Runner: onnx::Concat_647 copy (Reformat)
[03/24/2023-12:56:19] [V] [TRT] Tactic: 1002 Time: 0.082176
[03/24/2023-12:56:19] [V] [TRT] Tactic: 0 Time: 0.052352
[03/24/2023-12:56:19] [V] [TRT] Fastest Tactic: 0 Time: 0.052352
[03/24/2023-12:56:19] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0
[03/24/2023-12:56:19] [V] [TRT] *************** Autotuning Reformat: Half(4147200,32400:2,180,1) -> Half(1036800,1:16,5760,32) ***************
[03/24/2023-12:56:19] [V] [TRT] --------------- Timing Runner: onnx::Concat_647 copy (Reformat)
[03/24/2023-12:56:19] [V] [TRT] Tactic: 1002 Time: 0.082176
[03/24/2023-12:56:19] [V] [TRT] Tactic: 0 Time: 0.139392
[03/24/2023-12:56:19] [V] [TRT] Fastest Tactic: 1002 Time: 0.082176
[03/24/2023-12:56:19] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 1002
[03/24/2023-12:56:19] [V] [TRT] *************** Autotuning Reformat: Half(1036800,1:8,5760,32) -> Float(16588800,32400,180,1) ***************
[03/24/2023-12:56:19] [V] [TRT] --------------- Timing Runner: onnx::Concat_647 copy (Reformat)
[03/24/2023-12:56:19] [V] [TRT] Tactic: 1002 Time: 0.09024
[03/24/2023-12:56:19] [V] [TRT] Tactic: 0 Time: 0.177664
[03/24/2023-12:56:19] [V] [TRT] Fastest Tactic: 1002 Time: 0.09024
[03/24/2023-12:56:19] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 1002
[03/24/2023-12:56:19] [V] [TRT] *************** Autotuning Reformat: Half(1036800,1:8,5760,32) -> Float(16588800,1,92160,512) ***************
[03/24/2023-12:56:19] [V] [TRT] --------------- Timing Runner: onnx::Concat_647 copy (Reformat)
[03/24/2023-12:56:19] [V] [TRT] Tactic: 1002 Time: 0.072704
[03/24/2023-12:56:19] [V] [TRT] Tactic: 0 Time: 0.130304
[03/24/2023-12:56:19] [V] [TRT] Fastest Tactic: 1002 Time: 0.072704
[03/24/2023-12:56:19] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 1002
[03/24/2023-12:56:19] [V] [TRT] *************** Autotuning Reformat: Half(1036800,1:8,5760,32) -> Float(4147200,1:4,23040,128) ***************
[03/24/2023-12:56:19] [V] [TRT] --------------- Timing Runner: onnx::Concat_647 copy (Reformat)
[03/24/2023-12:56:19] [V] [TRT] Tactic: 1002 Time: 0.07296
[03/24/2023-12:56:19] [V] [TRT] Tactic: 0 Time: 0.14976
[03/24/2023-12:56:19] [V] [TRT] Fastest Tactic: 1002 Time: 0.07296
[03/24/2023-12:56:19] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 1002
[03/24/2023-12:56:19] [V] [TRT] *************** Autotuning Reformat: Half(1036800,1:8,5760,32) -> Half(16588800,32400,180,1) ***************
[03/24/2023-12:56:19] [V] [TRT] --------------- Timing Runner: onnx::Concat_647 copy (Reformat)
[03/24/2023-12:56:19] [V] [TRT] Tactic: 1002 Time: 0.208128
[03/24/2023-12:56:19] [V] [TRT] Tactic: 0 Time: 0.172288
[03/24/2023-12:56:19] [V] [TRT] Fastest Tactic: 0 Time: 0.172288
[03/24/2023-12:56:19] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0
[03/24/2023-12:56:19] [V] [TRT] *************** Autotuning Reformat: Half(1036800,1:8,5760,32) -> Half(8294400,32400:2,180,1) ***************
[03/24/2023-12:56:19] [V] [TRT] --------------- Timing Runner: onnx::Concat_647 copy (Reformat)
[03/24/2023-12:56:19] [V] [TRT] Tactic: 1002 Time: 0.106368
[03/24/2023-12:56:19] [V] [TRT] Tactic: 0 Time: 0.04224
[03/24/2023-12:56:19] [V] [TRT] Fastest Tactic: 0 Time: 0.04224
[03/24/2023-12:56:19] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0
[03/24/2023-12:56:19] [V] [TRT] *************** Autotuning Reformat: Half(1036800,1:8,5760,32) -> Half(2073600,1:8,11520,64) ***************
[03/24/2023-12:56:19] [V] [TRT] --------------- Timing Runner: onnx::Concat_647 copy (Reformat)
[03/24/2023-12:56:19] [V] [TRT] Tactic: 1002 Time: 0.07296
[03/24/2023-12:56:19] [V] [TRT] Tactic: 0 Time: 0.138752
[03/24/2023-12:56:19] [V] [TRT] Fastest Tactic: 1002 Time: 0.07296
[03/24/2023-12:56:19] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 1002
[03/24/2023-12:56:19] [V] [TRT] *************** Autotuning Reformat: Half(1036800,1:8,5760,32) -> Half(1036800,1:16,5760,32) ***************
[03/24/2023-12:56:19] [V] [TRT] --------------- Timing Runner: onnx::Concat_647 copy (Reformat)
[03/24/2023-12:56:19] [V] [TRT] Tactic: 1002 Time: 0.07296
[03/24/2023-12:56:19] [V] [TRT] Tactic: 0 Time: 0.139008
[03/24/2023-12:56:19] [V] [TRT] Fastest Tactic: 1002 Time: 0.07296
[03/24/2023-12:56:19] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 1002
[03/24/2023-12:56:19] [V] [TRT] *************** Autotuning Reformat: Half(518400,1:16,2880,16) -> Float(16588800,32400,180,1) ***************
[03/24/2023-12:56:19] [V] [TRT] --------------- Timing Runner: onnx::Concat_647 copy (Reformat)
[03/24/2023-12:56:19] [V] [TRT] Tactic: 1002 Time: 0.09024
[03/24/2023-12:56:19] [V] [TRT] Tactic: 0 Time: 0.17792
[03/24/2023-12:56:19] [V] [TRT] Fastest Tactic: 1002 Time: 0.09024
[03/24/2023-12:56:19] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 1002
[03/24/2023-12:56:19] [V] [TRT] *************** Autotuning Reformat: Half(518400,1:16,2880,16) -> Float(16588800,1,92160,512) ***************
[03/24/2023-12:56:19] [V] [TRT] --------------- Timing Runner: onnx::Concat_647 copy (Reformat)
[03/24/2023-12:56:19] [V] [TRT] Tactic: 1002 Time: 0.072704
[03/24/2023-12:56:19] [V] [TRT] Tactic: 0 Time: 0.130304
[03/24/2023-12:56:19] [V] [TRT] Fastest Tactic: 1002 Time: 0.072704
[03/24/2023-12:56:19] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 1002
[03/24/2023-12:56:19] [V] [TRT] *************** Autotuning Reformat: Half(518400,1:16,2880,16) -> Float(4147200,1:4,23040,128) ***************
[03/24/2023-12:56:19] [V] [TRT] --------------- Timing Runner: onnx::Concat_647 copy (Reformat)
[03/24/2023-12:56:19] [V] [TRT] Tactic: 1002 Time: 0.072832
[03/24/2023-12:56:19] [V] [TRT] Tactic: 0 Time: 0.14976
[03/24/2023-12:56:19] [V] [TRT] Fastest Tactic: 1002 Time: 0.072832
[03/24/2023-12:56:19] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 1002
[03/24/2023-12:56:19] [V] [TRT] *************** Autotuning Reformat: Half(518400,1:16,2880,16) -> Half(16588800,32400,180,1) ***************
[03/24/2023-12:56:19] [V] [TRT] --------------- Timing Runner: onnx::Concat_647 copy (Reformat)
[03/24/2023-12:56:19] [V] [TRT] Tactic: 1002 Time: 0.207872
[03/24/2023-12:56:19] [V] [TRT] Tactic: 0 Time: 0.17216
[03/24/2023-12:56:19] [V] [TRT] Fastest Tactic: 0 Time: 0.17216
[03/24/2023-12:56:19] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0
[03/24/2023-12:56:19] [V] [TRT] *************** Autotuning Reformat: Half(518400,1:16,2880,16) -> Half(8294400,32400:2,180,1) ***************
[03/24/2023-12:56:19] [V] [TRT] --------------- Timing Runner: onnx::Concat_647 copy (Reformat)
[03/24/2023-12:56:19] [V] [TRT] Tactic: 1002 Time: 0.106112
[03/24/2023-12:56:19] [V] [TRT] Tactic: 0 Time: 0.177024
[03/24/2023-12:56:19] [V] [TRT] Fastest Tactic: 1002 Time: 0.106112
[03/24/2023-12:56:19] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 1002
[03/24/2023-12:56:19] [V] [TRT] *************** Autotuning Reformat: Half(518400,1:16,2880,16) -> Half(2073600,1:8,11520,64) ***************
[03/24/2023-12:56:19] [V] [TRT] --------------- Timing Runner: onnx::Concat_647 copy (Reformat)
[03/24/2023-12:56:19] [V] [TRT] Tactic: 1002 Time: 0.07296
[03/24/2023-12:56:19] [V] [TRT] Tactic: 0 Time: 0.139904
[03/24/2023-12:56:19] [V] [TRT] Fastest Tactic: 1002 Time: 0.07296
[03/24/2023-12:56:19] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 1002
[03/24/2023-12:56:19] [V] [TRT] *************** Autotuning Reformat: Half(518400,1:16,2880,16) -> Half(1036800,1:16,5760,32) ***************
[03/24/2023-12:56:19] [V] [TRT] --------------- Timing Runner: onnx::Concat_647 copy (Reformat)
[03/24/2023-12:56:19] [V] [TRT] Tactic: 1002 Time: 0.07296
[03/24/2023-12:56:19] [V] [TRT] Tactic: 0 Time: 0.138752
[03/24/2023-12:56:19] [V] [TRT] Fastest Tactic: 1002 Time: 0.07296
[03/24/2023-12:56:19] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 1002
[03/24/2023-12:56:19] [V] [TRT] =============== Computing reformatting costs
[03/24/2023-12:56:19] [V] [TRT] *************** Autotuning Reformat: Float(16588800,32400,180,1) -> Float(16588800,1,92160,512) ***************
[03/24/2023-12:56:19] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(input.164 -> <out>) (Reformat)
[03/24/2023-12:56:19] [V] [TRT] Tactic: 1002 Time: 0.162816
[03/24/2023-12:56:19] [V] [TRT] Tactic: 0 Time: 0.547328
[03/24/2023-12:56:19] [V] [TRT] Fastest Tactic: 1002 Time: 0.162816
[03/24/2023-12:56:19] [V] [TRT] *************** Autotuning Reformat: Float(16588800,32400,180,1) -> Float(4147200,1:4,23040,128) ***************
[03/24/2023-12:56:19] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(input.164 -> <out>) (Reformat)
[03/24/2023-12:56:19] [V] [TRT] Tactic: 1002 Time: 0.162688
[03/24/2023-12:56:19] [V] [TRT] Tactic: 0 Time: 0.544384
[03/24/2023-12:56:19] [V] [TRT] Fastest Tactic: 1002 Time: 0.162688
[03/24/2023-12:56:19] [V] [TRT] *************** Autotuning Reformat: Float(16588800,32400,180,1) -> Half(16588800,32400,180,1) ***************
[03/24/2023-12:56:19] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(input.164 -> <out>) (Reformat)
[03/24/2023-12:56:19] [V] [TRT] Tactic: 1002 Time: 0.195456
[03/24/2023-12:56:19] [V] [TRT] Tactic: 0 Time: 0.267776
[03/24/2023-12:56:19] [V] [TRT] Fastest Tactic: 1002 Time: 0.195456
[03/24/2023-12:56:19] [V] [TRT] *************** Autotuning Reformat: Float(16588800,32400,180,1) -> Half(8294400,32400:2,180,1) ***************
[03/24/2023-12:56:19] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(input.164 -> <out>) (Reformat)
[03/24/2023-12:56:19] [V] [TRT] Tactic: 1002 Time: 0.209664
[03/24/2023-12:56:19] [V] [TRT] Tactic: 0 Time: 0.191744
[03/24/2023-12:56:19] [V] [TRT] Fastest Tactic: 0 Time: 0.191744
[03/24/2023-12:56:19] [V] [TRT] *************** Autotuning Reformat: Float(16588800,32400,180,1) -> Half(2073600,1:8,11520,64) ***************
[03/24/2023-12:56:19] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(input.164 -> <out>) (Reformat)
[03/24/2023-12:56:19] [V] [TRT] Tactic: 1002 Time: 0.14784
[03/24/2023-12:56:19] [V] [TRT] Tactic: 0 Time: 0.110592
[03/24/2023-12:56:19] [V] [TRT] Fastest Tactic: 0 Time: 0.110592
[03/24/2023-12:56:19] [V] [TRT] *************** Autotuning Reformat: Float(16588800,32400,180,1) -> Half(1036800,1:16,5760,32) ***************
[03/24/2023-12:56:19] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(input.164 -> <out>) (Reformat)
[03/24/2023-12:56:19] [V] [TRT] Tactic: 1002 Time: 0.147968
[03/24/2023-12:56:19] [V] [TRT] Tactic: 0 Time: 0.544128
[03/24/2023-12:56:19] [V] [TRT] Fastest Tactic: 1002 Time: 0.147968
[03/24/2023-12:56:19] [V] [TRT] *************** Autotuning Reformat: Float(16588800,1,92160,512) -> Float(16588800,32400,180,1) ***************
[03/24/2023-12:56:19] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(input.164 -> <out>) (Reformat)
[03/24/2023-12:56:19] [V] [TRT] Tactic: 1002 Time: 0.168448
[03/24/2023-12:56:19] [V] [TRT] Tactic: 0 Time: 0.392064
[03/24/2023-12:56:19] [V] [TRT] Fastest Tactic: 1002 Time: 0.168448
[03/24/2023-12:56:19] [V] [TRT] *************** Autotuning Reformat: Float(16588800,1,92160,512) -> Float(4147200,1:4,23040,128) ***************
[03/24/2023-12:56:19] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(input.164 -> <out>) (Reformat)
[03/24/2023-12:56:19] [V] [TRT] Tactic: 1002 Time: 0.133376
[03/24/2023-12:56:19] [V] [TRT] Tactic: 0 Time: 0.240768
[03/24/2023-12:56:19] [V] [TRT] Fastest Tactic: 1002 Time: 0.133376
[03/24/2023-12:56:19] [V] [TRT] *************** Autotuning Reformat: Float(16588800,1,92160,512) -> Half(16588800,32400,180,1) ***************
[03/24/2023-12:56:19] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(input.164 -> <out>) (Reformat)
[03/24/2023-12:56:19] [V] [TRT] Tactic: 1002 Time: 0.1376
[03/24/2023-12:56:19] [V] [TRT] Tactic: 0 Time: 0.333824
[03/24/2023-12:56:19] [V] [TRT] Fastest Tactic: 1002 Time: 0.1376
[03/24/2023-12:56:19] [V] [TRT] *************** Autotuning Reformat: Float(16588800,1,92160,512) -> Half(8294400,32400:2,180,1) ***************
[03/24/2023-12:56:19] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(input.164 -> <out>) (Reformat)
[03/24/2023-12:56:19] [V] [TRT] Tactic: 1002 Time: 0.176128
[03/24/2023-12:56:19] [V] [TRT] Tactic: 0 Time: 0.355968
[03/24/2023-12:56:19] [V] [TRT] Fastest Tactic: 1002 Time: 0.176128
[03/24/2023-12:56:19] [V] [TRT] *************** Autotuning Reformat: Float(16588800,1,92160,512) -> Half(2073600,1:8,11520,64) ***************
[03/24/2023-12:56:19] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(input.164 -> <out>) (Reformat)
[03/24/2023-12:56:20] [V] [TRT] Tactic: 1002 Time: 0.116864
[03/24/2023-12:56:20] [V] [TRT] Tactic: 0 Time: 0.217216
[03/24/2023-12:56:20] [V] [TRT] Fastest Tactic: 1002 Time: 0.116864
[03/24/2023-12:56:20] [V] [TRT] *************** Autotuning Reformat: Float(16588800,1,92160,512) -> Half(1036800,1:16,5760,32) ***************
[03/24/2023-12:56:20] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(input.164 -> <out>) (Reformat)
[03/24/2023-12:56:20] [V] [TRT] Tactic: 1002 Time: 0.116992
[03/24/2023-12:56:20] [V] [TRT] Tactic: 0 Time: 0.217216
[03/24/2023-12:56:20] [V] [TRT] Fastest Tactic: 1002 Time: 0.116992
[03/24/2023-12:56:20] [V] [TRT] *************** Autotuning Reformat: Float(4147200,1:4,23040,128) -> Float(16588800,32400,180,1) ***************
[03/24/2023-12:56:20] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(input.164 -> <out>) (Reformat)
[03/24/2023-12:56:20] [V] [TRT] Tactic: 1002 Time: 0.14976
[03/24/2023-12:56:20] [V] [TRT] Tactic: 0 Time: 0.360064
[03/24/2023-12:56:20] [V] [TRT] Fastest Tactic: 1002 Time: 0.14976
[03/24/2023-12:56:20] [V] [TRT] *************** Autotuning Reformat: Float(4147200,1:4,23040,128) -> Float(16588800,1,92160,512) ***************
[03/24/2023-12:56:20] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(input.164 -> <out>) (Reformat)
[03/24/2023-12:56:20] [V] [TRT] Tactic: 1002 Time: 0.120576
[03/24/2023-12:56:20] [V] [TRT] Tactic: 0 Time: 0.216576
[03/24/2023-12:56:20] [V] [TRT] Fastest Tactic: 1002 Time: 0.120576
[03/24/2023-12:56:20] [V] [TRT] *************** Autotuning Reformat: Float(4147200,1:4,23040,128) -> Half(16588800,32400,180,1) ***************
[03/24/2023-12:56:20] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(input.164 -> <out>) (Reformat)
[03/24/2023-12:56:20] [V] [TRT] Tactic: 1002 Time: 0.137856
[03/24/2023-12:56:20] [V] [TRT] Tactic: 0 Time: 0.342784
[03/24/2023-12:56:20] [V] [TRT] Fastest Tactic: 1002 Time: 0.137856
[03/24/2023-12:56:20] [V] [TRT] *************** Autotuning Reformat: Float(4147200,1:4,23040,128) -> Half(8294400,32400:2,180,1) ***************
[03/24/2023-12:56:20] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(input.164 -> <out>) (Reformat)
[03/24/2023-12:56:20] [V] [TRT] Tactic: 1002 Time: 0.176384
[03/24/2023-12:56:20] [V] [TRT] Tactic: 0 Time: 0.361088
[03/24/2023-12:56:20] [V] [TRT] Fastest Tactic: 1002 Time: 0.176384
[03/24/2023-12:56:20] [V] [TRT] *************** Autotuning Reformat: Float(4147200,1:4,23040,128) -> Half(2073600,1:8,11520,64) ***************
[03/24/2023-12:56:20] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(input.164 -> <out>) (Reformat)
[03/24/2023-12:56:20] [V] [TRT] Tactic: 1002 Time: 0.116992
[03/24/2023-12:56:20] [V] [TRT] Tactic: 0 Time: 0.254848
[03/24/2023-12:56:20] [V] [TRT] Fastest Tactic: 1002 Time: 0.116992
[03/24/2023-12:56:20] [V] [TRT] *************** Autotuning Reformat: Float(4147200,1:4,23040,128) -> Half(1036800,1:16,5760,32) ***************
[03/24/2023-12:56:20] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(input.164 -> <out>) (Reformat)
[03/24/2023-12:56:20] [V] [TRT] Tactic: 1002 Time: 0.11712
[03/24/2023-12:56:20] [V] [TRT] Tactic: 0 Time: 0.254848
[03/24/2023-12:56:20] [V] [TRT] Fastest Tactic: 1002 Time: 0.11712
[03/24/2023-12:56:20] [V] [TRT] *************** Autotuning Reformat: Half(16588800,32400,180,1) -> Float(16588800,32400,180,1) ***************
[03/24/2023-12:56:20] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(input.164 -> <out>) (Reformat)
[03/24/2023-12:56:20] [V] [TRT] Tactic: 1002 Time: 0.17408
[03/24/2023-12:56:20] [V] [TRT] Tactic: 0 Time: 0.22016
[03/24/2023-12:56:20] [V] [TRT] Fastest Tactic: 1002 Time: 0.17408
[03/24/2023-12:56:20] [V] [TRT] *************** Autotuning Reformat: Half(16588800,32400,180,1) -> Float(16588800,1,92160,512) ***************
[03/24/2023-12:56:20] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(input.164 -> <out>) (Reformat)
[03/24/2023-12:56:20] [V] [TRT] Tactic: 1002 Time: 0.131328
[03/24/2023-12:56:20] [V] [TRT] Tactic: 0 Time: 0.321024
[03/24/2023-12:56:20] [V] [TRT] Fastest Tactic: 1002 Time: 0.131328
[03/24/2023-12:56:20] [V] [TRT] *************** Autotuning Reformat: Half(16588800,32400,180,1) -> Float(4147200,1:4,23040,128) ***************
[03/24/2023-12:56:20] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(input.164 -> <out>) (Reformat)
[03/24/2023-12:56:20] [V] [TRT] Tactic: 1002 Time: 0.131328
[03/24/2023-12:56:20] [V] [TRT] Tactic: 0 Time: 0.30144
[03/24/2023-12:56:20] [V] [TRT] Fastest Tactic: 1002 Time: 0.131328
[03/24/2023-12:56:20] [V] [TRT] *************** Autotuning Reformat: Half(16588800,32400,180,1) -> Half(8294400,32400:2,180,1) ***************
[03/24/2023-12:56:20] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(input.164 -> <out>) (Reformat)
[03/24/2023-12:56:20] [V] [TRT] Tactic: 1002 Time: 0.12096
[03/24/2023-12:56:20] [V] [TRT] Tactic: 0 Time: 0.148736
[03/24/2023-12:56:20] [V] [TRT] Fastest Tactic: 1002 Time: 0.12096
[03/24/2023-12:56:20] [V] [TRT] *************** Autotuning Reformat: Half(16588800,32400,180,1) -> Half(2073600,1:8,11520,64) ***************
[03/24/2023-12:56:20] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(input.164 -> <out>) (Reformat)
[03/24/2023-12:56:20] [V] [TRT] Tactic: 1002 Time: 0.126976
[03/24/2023-12:56:20] [V] [TRT] Tactic: 0 Time: 0.087296
[03/24/2023-12:56:20] [V] [TRT] Fastest Tactic: 0 Time: 0.087296
[03/24/2023-12:56:20] [V] [TRT] *************** Autotuning Reformat: Half(16588800,32400,180,1) -> Half(1036800,1:16,5760,32) ***************
[03/24/2023-12:56:20] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(input.164 -> <out>) (Reformat)
[03/24/2023-12:56:20] [V] [TRT] Tactic: 1002 Time: 0.127488
[03/24/2023-12:56:20] [V] [TRT] Tactic: 0 Time: 0.282752
[03/24/2023-12:56:20] [V] [TRT] Fastest Tactic: 1002 Time: 0.127488
[03/24/2023-12:56:20] [V] [TRT] *************** Autotuning Reformat: Half(8294400,32400:2,180,1) -> Float(16588800,32400,180,1) ***************
[03/24/2023-12:56:20] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(input.164 -> <out>) (Reformat)
[03/24/2023-12:56:20] [V] [TRT] Tactic: 1002 Time: 0.136192
[03/24/2023-12:56:20] [V] [TRT] Tactic: 0 Time: 0.14848
[03/24/2023-12:56:20] [V] [TRT] Fastest Tactic: 1002 Time: 0.136192
[03/24/2023-12:56:20] [V] [TRT] *************** Autotuning Reformat: Half(8294400,32400:2,180,1) -> Float(16588800,1,92160,512) ***************
[03/24/2023-12:56:20] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(input.164 -> <out>) (Reformat)
[03/24/2023-12:56:20] [V] [TRT] Tactic: 1002 Time: 0.117504
[03/24/2023-12:56:20] [V] [TRT] Tactic: 0 Time: 0.198784
[03/24/2023-12:56:20] [V] [TRT] Fastest Tactic: 1002 Time: 0.117504
[03/24/2023-12:56:20] [V] [TRT] *************** Autotuning Reformat: Half(8294400,32400:2,180,1) -> Float(4147200,1:4,23040,128) ***************
[03/24/2023-12:56:20] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(input.164 -> <out>) (Reformat)
[03/24/2023-12:56:20] [V] [TRT] Tactic: 1002 Time: 0.11776
[03/24/2023-12:56:20] [V] [TRT] Tactic: 0 Time: 0.226688
[03/24/2023-12:56:20] [V] [TRT] Fastest Tactic: 1002 Time: 0.11776
[03/24/2023-12:56:20] [V] [TRT] *************** Autotuning Reformat: Half(8294400,32400:2,180,1) -> Half(16588800,32400,180,1) ***************
[03/24/2023-12:56:20] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(input.164 -> <out>) (Reformat)
[03/24/2023-12:56:20] [V] [TRT] Tactic: 1002 Time: 0.420352
[03/24/2023-12:56:20] [V] [TRT] Tactic: 0 Time: 0.148224
[03/24/2023-12:56:20] [V] [TRT] Fastest Tactic: 0 Time: 0.148224
[03/24/2023-12:56:20] [V] [TRT] *************** Autotuning Reformat: Half(8294400,32400:2,180,1) -> Half(2073600,1:8,11520,64) ***************
[03/24/2023-12:56:20] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(input.164 -> <out>) (Reformat)
[03/24/2023-12:56:20] [V] [TRT] Tactic: 1002 Time: 0.118144
[03/24/2023-12:56:20] [V] [TRT] Tactic: 0 Time: 0.077824
[03/24/2023-12:56:20] [V] [TRT] Fastest Tactic: 0 Time: 0.077824
[03/24/2023-12:56:20] [V] [TRT] *************** Autotuning Reformat: Half(8294400,32400:2,180,1) -> Half(1036800,1:16,5760,32) ***************
[03/24/2023-12:56:20] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(input.164 -> <out>) (Reformat)
[03/24/2023-12:56:20] [V] [TRT] Tactic: 1002 Time: 0.117632
[03/24/2023-12:56:20] [V] [TRT] Tactic: 0 Time: 0.209152
[03/24/2023-12:56:20] [V] [TRT] Fastest Tactic: 1002 Time: 0.117632
[03/24/2023-12:56:20] [V] [TRT] *************** Autotuning Reformat: Half(2073600,1:8,11520,64) -> Float(16588800,32400,180,1) ***************
[03/24/2023-12:56:20] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(input.164 -> <out>) (Reformat)
[03/24/2023-12:56:20] [V] [TRT] Tactic: 1002 Time: 0.128256
[03/24/2023-12:56:20] [V] [TRT] Tactic: 0 Time: 0.086912
[03/24/2023-12:56:20] [V] [TRT] Fastest Tactic: 0 Time: 0.086912
[03/24/2023-12:56:20] [V] [TRT] *************** Autotuning Reformat: Half(2073600,1:8,11520,64) -> Float(16588800,1,92160,512) ***************
[03/24/2023-12:56:20] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(input.164 -> <out>) (Reformat)
[03/24/2023-12:56:20] [V] [TRT] Tactic: 1002 Time: 0.102784
[03/24/2023-12:56:20] [V] [TRT] Tactic: 0 Time: 0.194816
[03/24/2023-12:56:20] [V] [TRT] Fastest Tactic: 1002 Time: 0.102784
[03/24/2023-12:56:20] [V] [TRT] *************** Autotuning Reformat: Half(2073600,1:8,11520,64) -> Float(4147200,1:4,23040,128) ***************
[03/24/2023-12:56:20] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(input.164 -> <out>) (Reformat)
[03/24/2023-12:56:20] [V] [TRT] Tactic: 1002 Time: 0.102784
[03/24/2023-12:56:20] [V] [TRT] Tactic: 0 Time: 0.225536
[03/24/2023-12:56:20] [V] [TRT] Fastest Tactic: 1002 Time: 0.102784
[03/24/2023-12:56:20] [V] [TRT] *************** Autotuning Reformat: Half(2073600,1:8,11520,64) -> Half(16588800,32400,180,1) ***************
[03/24/2023-12:56:20] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(input.164 -> <out>) (Reformat)
[03/24/2023-12:56:20] [V] [TRT] Tactic: 1002 Time: 0.320896
[03/24/2023-12:56:20] [V] [TRT] Tactic: 0 Time: 0.062848
[03/24/2023-12:56:20] [V] [TRT] Fastest Tactic: 0 Time: 0.062848
[03/24/2023-12:56:20] [V] [TRT] *************** Autotuning Reformat: Half(2073600,1:8,11520,64) -> Half(8294400,32400:2,180,1) ***************
[03/24/2023-12:56:20] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(input.164 -> <out>) (Reformat)
[03/24/2023-12:56:20] [V] [TRT] Tactic: 1002 Time: 0.1568
[03/24/2023-12:56:20] [V] [TRT] Tactic: 0 Time: 0.061568
[03/24/2023-12:56:20] [V] [TRT] Fastest Tactic: 0 Time: 0.061568
[03/24/2023-12:56:20] [V] [TRT] *************** Autotuning Reformat: Half(2073600,1:8,11520,64) -> Half(1036800,1:16,5760,32) ***************
[03/24/2023-12:56:20] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(input.164 -> <out>) (Reformat)
[03/24/2023-12:56:20] [V] [TRT] Tactic: 1002 Time: 0.103168
[03/24/2023-12:56:20] [V] [TRT] Tactic: 0 Time: 0.208128
[03/24/2023-12:56:20] [V] [TRT] Fastest Tactic: 1002 Time: 0.103168
[03/24/2023-12:56:20] [V] [TRT] *************** Autotuning Reformat: Half(1036800,1:16,5760,32) -> Float(16588800,32400,180,1) ***************
[03/24/2023-12:56:20] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(input.164 -> <out>) (Reformat)
[03/24/2023-12:56:20] [V] [TRT] Tactic: 1002 Time: 0.128
[03/24/2023-12:56:20] [V] [TRT] Tactic: 0 Time: 0.302464
[03/24/2023-12:56:20] [V] [TRT] Fastest Tactic: 1002 Time: 0.128
[03/24/2023-12:56:20] [V] [TRT] *************** Autotuning Reformat: Half(1036800,1:16,5760,32) -> Float(16588800,1,92160,512) ***************
[03/24/2023-12:56:20] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(input.164 -> <out>) (Reformat)
[03/24/2023-12:56:20] [V] [TRT] Tactic: 1002 Time: 0.102784
[03/24/2023-12:56:20] [V] [TRT] Tactic: 0 Time: 0.19456
[03/24/2023-12:56:20] [V] [TRT] Fastest Tactic: 1002 Time: 0.102784
[03/24/2023-12:56:20] [V] [TRT] *************** Autotuning Reformat: Half(1036800,1:16,5760,32) -> Float(4147200,1:4,23040,128) ***************
[03/24/2023-12:56:20] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(input.164 -> <out>) (Reformat)
[03/24/2023-12:56:20] [V] [TRT] Tactic: 1002 Time: 0.102656
[03/24/2023-12:56:20] [V] [TRT] Tactic: 0 Time: 0.225536
[03/24/2023-12:56:20] [V] [TRT] Fastest Tactic: 1002 Time: 0.102656
[03/24/2023-12:56:20] [V] [TRT] *************** Autotuning Reformat: Half(1036800,1:16,5760,32) -> Half(16588800,32400,180,1) ***************
[03/24/2023-12:56:20] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(input.164 -> <out>) (Reformat)
[03/24/2023-12:56:20] [V] [TRT] Tactic: 1002 Time: 0.321024
[03/24/2023-12:56:20] [V] [TRT] Tactic: 0 Time: 0.286208
[03/24/2023-12:56:20] [V] [TRT] Fastest Tactic: 0 Time: 0.286208
[03/24/2023-12:56:20] [V] [TRT] *************** Autotuning Reformat: Half(1036800,1:16,5760,32) -> Half(8294400,32400:2,180,1) ***************
[03/24/2023-12:56:20] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(input.164 -> <out>) (Reformat)
[03/24/2023-12:56:20] [V] [TRT] Tactic: 1002 Time: 0.156672
[03/24/2023-12:56:20] [V] [TRT] Tactic: 0 Time: 0.3072
[03/24/2023-12:56:20] [V] [TRT] Fastest Tactic: 1002 Time: 0.156672
[03/24/2023-12:56:20] [V] [TRT] *************** Autotuning Reformat: Half(1036800,1:16,5760,32) -> Half(2073600,1:8,11520,64) ***************
[03/24/2023-12:56:20] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(input.164 -> <out>) (Reformat)
[03/24/2023-12:56:20] [V] [TRT] Tactic: 1002 Time: 0.103296
[03/24/2023-12:56:20] [V] [TRT] Tactic: 0 Time: 0.208128
[03/24/2023-12:56:20] [V] [TRT] Fastest Tactic: 1002 Time: 0.103296
[03/24/2023-12:56:20] [V] [TRT] =============== Computing reformatting costs
[03/24/2023-12:56:20] [V] [TRT] *************** Autotuning Reformat: Float(2073600,32400,180,1) -> Float(2073600,1,11520,64) ***************
[03/24/2023-12:56:20] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> onnx::Conv_651) (Reformat)
[03/24/2023-12:56:20] [V] [TRT] Tactic: 1002 Time: 0.027392
[03/24/2023-12:56:20] [V] [TRT] Tactic: 0 Time: 0.029184
[03/24/2023-12:56:20] [V] [TRT] Fastest Tactic: 1002 Time: 0.027392
[03/24/2023-12:56:20] [V] [TRT] *************** Autotuning Reformat: Float(2073600,32400,180,1) -> Float(518400,1:4,2880,16) ***************
[03/24/2023-12:56:20] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> onnx::Conv_651) (Reformat)
[03/24/2023-12:56:20] [V] [TRT] Tactic: 1002 Time: 0.027008
[03/24/2023-12:56:20] [V] [TRT] Tactic: 0 Time: 0.031744
[03/24/2023-12:56:20] [V] [TRT] Fastest Tactic: 1002 Time: 0.027008
[03/24/2023-12:56:20] [V] [TRT] *************** Autotuning Reformat: Float(2073600,32400,180,1) -> Half(2073600,32400,180,1) ***************
[03/24/2023-12:56:20] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> onnx::Conv_651) (Reformat)
[03/24/2023-12:56:20] [V] [TRT] Tactic: 1002 Time: 0.02816
[03/24/2023-12:56:20] [V] [TRT] Tactic: 0 Time: 0.03456
[03/24/2023-12:56:20] [V] [TRT] Fastest Tactic: 1002 Time: 0.02816
[03/24/2023-12:56:20] [V] [TRT] *************** Autotuning Reformat: Float(2073600,32400,180,1) -> Half(1036800,32400:2,180,1) ***************
[03/24/2023-12:56:20] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> onnx::Conv_651) (Reformat)
[03/24/2023-12:56:20] [V] [TRT] Tactic: 1002 Time: 0.033152
[03/24/2023-12:56:20] [V] [TRT] Tactic: 0 Time: 0.025856
[03/24/2023-12:56:20] [V] [TRT] Fastest Tactic: 0 Time: 0.025856
[03/24/2023-12:56:20] [V] [TRT] *************** Autotuning Reformat: Float(2073600,32400,180,1) -> Half(259200,1:8,1440,8) ***************
[03/24/2023-12:56:20] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> onnx::Conv_651) (Reformat)
[03/24/2023-12:56:20] [V] [TRT] Tactic: 1002 Time: 0.024576
[03/24/2023-12:56:20] [V] [TRT] Tactic: 0 Time: 0.017792
[03/24/2023-12:56:20] [V] [TRT] Fastest Tactic: 0 Time: 0.017792
[03/24/2023-12:56:20] [V] [TRT] *************** Autotuning Reformat: Float(2073600,32400,180,1) -> Half(129600,1:16,720,4) ***************
[03/24/2023-12:56:20] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> onnx::Conv_651) (Reformat)
[03/24/2023-12:56:20] [V] [TRT] Tactic: 1002 Time: 0.024576
[03/24/2023-12:56:20] [V] [TRT] Tactic: 0 Time: 0.031744
[03/24/2023-12:56:20] [V] [TRT] Fastest Tactic: 1002 Time: 0.024576
[03/24/2023-12:56:20] [V] [TRT] *************** Autotuning Reformat: Float(2073600,1,11520,64) -> Float(2073600,32400,180,1) ***************
[03/24/2023-12:56:20] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> onnx::Conv_651) (Reformat)
[03/24/2023-12:56:20] [V] [TRT] Tactic: 1002 Time: 0.02944
[03/24/2023-12:56:20] [V] [TRT] Tactic: 0 Time: 0.04032
[03/24/2023-12:56:20] [V] [TRT] Fastest Tactic: 1002 Time: 0.02944
[03/24/2023-12:56:20] [V] [TRT] *************** Autotuning Reformat: Float(2073600,1,11520,64) -> Float(518400,1:4,2880,16) ***************
[03/24/2023-12:56:20] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> onnx::Conv_651) (Reformat)
[03/24/2023-12:56:20] [V] [TRT] Tactic: 1002 Time: 0.023552
[03/24/2023-12:56:20] [V] [TRT] Tactic: 0 Time: 0.031744
[03/24/2023-12:56:20] [V] [TRT] Fastest Tactic: 1002 Time: 0.023552
[03/24/2023-12:56:20] [V] [TRT] *************** Autotuning Reformat: Float(2073600,1,11520,64) -> Half(2073600,32400,180,1) ***************
[03/24/2023-12:56:20] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> onnx::Conv_651) (Reformat)
[03/24/2023-12:56:20] [V] [TRT] Tactic: 1002 Time: 0.026368
[03/24/2023-12:56:20] [V] [TRT] Tactic: 0 Time: 0.039936
[03/24/2023-12:56:20] [V] [TRT] Fastest Tactic: 1002 Time: 0.026368
[03/24/2023-12:56:20] [V] [TRT] *************** Autotuning Reformat: Float(2073600,1,11520,64) -> Half(1036800,32400:2,180,1) ***************
[03/24/2023-12:56:20] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> onnx::Conv_651) (Reformat)
[03/24/2023-12:56:20] [V] [TRT] Tactic: 1002 Time: 0.032
[03/24/2023-12:56:20] [V] [TRT] Tactic: 0 Time: 0.041344
[03/24/2023-12:56:20] [V] [TRT] Fastest Tactic: 1002 Time: 0.032
[03/24/2023-12:56:20] [V] [TRT] *************** Autotuning Reformat: Float(2073600,1,11520,64) -> Half(259200,1:8,1440,8) ***************
[03/24/2023-12:56:20] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> onnx::Conv_651) (Reformat)
[03/24/2023-12:56:20] [V] [TRT] Tactic: 1002 Time: 0.022528
[03/24/2023-12:56:20] [V] [TRT] Tactic: 0 Time: 0.031744
[03/24/2023-12:56:20] [V] [TRT] Fastest Tactic: 1002 Time: 0.022528
[03/24/2023-12:56:20] [V] [TRT] *************** Autotuning Reformat: Float(2073600,1,11520,64) -> Half(129600,1:16,720,4) ***************
[03/24/2023-12:56:20] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> onnx::Conv_651) (Reformat)
[03/24/2023-12:56:20] [V] [TRT] Tactic: 1002 Time: 0.022528
[03/24/2023-12:56:20] [V] [TRT] Tactic: 0 Time: 0.031744
[03/24/2023-12:56:20] [V] [TRT] Fastest Tactic: 1002 Time: 0.022528
[03/24/2023-12:56:20] [V] [TRT] *************** Autotuning Reformat: Float(518400,1:4,2880,16) -> Float(2073600,32400,180,1) ***************
[03/24/2023-12:56:20] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> onnx::Conv_651) (Reformat)
[03/24/2023-12:56:20] [V] [TRT] Tactic: 1002 Time: 0.029824
[03/24/2023-12:56:20] [V] [TRT] Tactic: 0 Time: 0.040576
[03/24/2023-12:56:20] [V] [TRT] Fastest Tactic: 1002 Time: 0.029824
[03/24/2023-12:56:20] [V] [TRT] *************** Autotuning Reformat: Float(518400,1:4,2880,16) -> Float(2073600,1,11520,64) ***************
[03/24/2023-12:56:20] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> onnx::Conv_651) (Reformat)
[03/24/2023-12:56:20] [V] [TRT] Tactic: 1002 Time: 0.023552
[03/24/2023-12:56:20] [V] [TRT] Tactic: 0 Time: 0.031744
[03/24/2023-12:56:20] [V] [TRT] Fastest Tactic: 1002 Time: 0.023552
[03/24/2023-12:56:20] [V] [TRT] *************** Autotuning Reformat: Float(518400,1:4,2880,16) -> Half(2073600,32400,180,1) ***************
[03/24/2023-12:56:20] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> onnx::Conv_651) (Reformat)
[03/24/2023-12:56:20] [V] [TRT] Tactic: 1002 Time: 0.026368
[03/24/2023-12:56:20] [V] [TRT] Tactic: 0 Time: 0.039936
[03/24/2023-12:56:20] [V] [TRT] Fastest Tactic: 1002 Time: 0.026368
[03/24/2023-12:56:20] [V] [TRT] *************** Autotuning Reformat: Float(518400,1:4,2880,16) -> Half(1036800,32400:2,180,1) ***************
[03/24/2023-12:56:20] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> onnx::Conv_651) (Reformat)
[03/24/2023-12:56:20] [V] [TRT] Tactic: 1002 Time: 0.031872
[03/24/2023-12:56:20] [V] [TRT] Tactic: 0 Time: 0.041216
[03/24/2023-12:56:20] [V] [TRT] Fastest Tactic: 1002 Time: 0.031872
[03/24/2023-12:56:20] [V] [TRT] *************** Autotuning Reformat: Float(518400,1:4,2880,16) -> Half(259200,1:8,1440,8) ***************
[03/24/2023-12:56:20] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> onnx::Conv_651) (Reformat)
[03/24/2023-12:56:20] [V] [TRT] Tactic: 1002 Time: 0.022528
[03/24/2023-12:56:20] [V] [TRT] Tactic: 0 Time: 0.03584
[03/24/2023-12:56:20] [V] [TRT] Fastest Tactic: 1002 Time: 0.022528
[03/24/2023-12:56:20] [V] [TRT] *************** Autotuning Reformat: Float(518400,1:4,2880,16) -> Half(129600,1:16,720,4) ***************
[03/24/2023-12:56:20] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> onnx::Conv_651) (Reformat)
[03/24/2023-12:56:20] [V] [TRT] Tactic: 1002 Time: 0.022528
[03/24/2023-12:56:20] [V] [TRT] Tactic: 0 Time: 0.03584
[03/24/2023-12:56:20] [V] [TRT] Fastest Tactic: 1002 Time: 0.022528
[03/24/2023-12:56:20] [V] [TRT] *************** Autotuning Reformat: Half(2073600,32400,180,1) -> Float(2073600,32400,180,1) ***************
[03/24/2023-12:56:20] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> onnx::Conv_651) (Reformat)
[03/24/2023-12:56:20] [V] [TRT] Tactic: 1002 Time: 0.028288
[03/24/2023-12:56:20] [V] [TRT] Tactic: 0 Time: 0.033408
[03/24/2023-12:56:20] [V] [TRT] Fastest Tactic: 1002 Time: 0.028288
[03/24/2023-12:56:20] [V] [TRT] *************** Autotuning Reformat: Half(2073600,32400,180,1) -> Float(2073600,1,11520,64) ***************
[03/24/2023-12:56:20] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> onnx::Conv_651) (Reformat)
[03/24/2023-12:56:20] [V] [TRT] Tactic: 1002 Time: 0.024576
[03/24/2023-12:56:20] [V] [TRT] Tactic: 0 Time: 0.029824
[03/24/2023-12:56:20] [V] [TRT] Fastest Tactic: 1002 Time: 0.024576
[03/24/2023-12:56:20] [V] [TRT] *************** Autotuning Reformat: Half(2073600,32400,180,1) -> Float(518400,1:4,2880,16) ***************
[03/24/2023-12:56:20] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> onnx::Conv_651) (Reformat)
[03/24/2023-12:56:20] [V] [TRT] Tactic: 1002 Time: 0.024576
[03/24/2023-12:56:20] [V] [TRT] Tactic: 0 Time: 0.032512
[03/24/2023-12:56:20] [V] [TRT] Fastest Tactic: 1002 Time: 0.024576
[03/24/2023-12:56:20] [V] [TRT] *************** Autotuning Reformat: Half(2073600,32400,180,1) -> Half(1036800,32400:2,180,1) ***************
[03/24/2023-12:56:20] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> onnx::Conv_651) (Reformat)
[03/24/2023-12:56:20] [V] [TRT] Tactic: 1002 Time: 0.02432
[03/24/2023-12:56:20] [V] [TRT] Tactic: 0 Time: 0.026496
[03/24/2023-12:56:20] [V] [TRT] Fastest Tactic: 1002 Time: 0.02432
[03/24/2023-12:56:20] [V] [TRT] *************** Autotuning Reformat: Half(2073600,32400,180,1) -> Half(259200,1:8,1440,8) ***************
[03/24/2023-12:56:20] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> onnx::Conv_651) (Reformat)
[03/24/2023-12:56:20] [V] [TRT] Tactic: 1002 Time: 0.024576
[03/24/2023-12:56:20] [V] [TRT] Tactic: 0 Time: 0.017536
[03/24/2023-12:56:20] [V] [TRT] Fastest Tactic: 0 Time: 0.017536
[03/24/2023-12:56:20] [V] [TRT] *************** Autotuning Reformat: Half(2073600,32400,180,1) -> Half(129600,1:16,720,4) ***************
[03/24/2023-12:56:20] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> onnx::Conv_651) (Reformat)
[03/24/2023-12:56:20] [V] [TRT] Tactic: 1002 Time: 0.024704
[03/24/2023-12:56:20] [V] [TRT] Tactic: 0 Time: 0.031616
[03/24/2023-12:56:20] [V] [TRT] Fastest Tactic: 1002 Time: 0.024704
[03/24/2023-12:56:20] [V] [TRT] *************** Autotuning Reformat: Half(1036800,32400:2,180,1) -> Float(2073600,32400,180,1) ***************
[03/24/2023-12:56:20] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> onnx::Conv_651) (Reformat)
[03/24/2023-12:56:20] [V] [TRT] Tactic: 1002 Time: 0.029056
[03/24/2023-12:56:20] [V] [TRT] Tactic: 0 Time: 0.025856
[03/24/2023-12:56:20] [V] [TRT] Fastest Tactic: 0 Time: 0.025856
[03/24/2023-12:56:20] [V] [TRT] *************** Autotuning Reformat: Half(1036800,32400:2,180,1) -> Float(2073600,1,11520,64) ***************
[03/24/2023-12:56:20] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> onnx::Conv_651) (Reformat)
[03/24/2023-12:56:20] [V] [TRT] Tactic: 1002 Time: 0.024576
[03/24/2023-12:56:20] [V] [TRT] Tactic: 0 Time: 0.032384
[03/24/2023-12:56:20] [V] [TRT] Fastest Tactic: 1002 Time: 0.024576
[03/24/2023-12:56:20] [V] [TRT] *************** Autotuning Reformat: Half(1036800,32400:2,180,1) -> Float(518400,1:4,2880,16) ***************
[03/24/2023-12:56:20] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> onnx::Conv_651) (Reformat)
[03/24/2023-12:56:20] [V] [TRT] Tactic: 1002 Time: 0.024576
[03/24/2023-12:56:20] [V] [TRT] Tactic: 0 Time: 0.03584
[03/24/2023-12:56:20] [V] [TRT] Fastest Tactic: 1002 Time: 0.024576
[03/24/2023-12:56:20] [V] [TRT] *************** Autotuning Reformat: Half(1036800,32400:2,180,1) -> Half(2073600,32400,180,1) ***************
[03/24/2023-12:56:20] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> onnx::Conv_651) (Reformat)
[03/24/2023-12:56:20] [V] [TRT] Tactic: 1002 Time: 0.061312
[03/24/2023-12:56:20] [V] [TRT] Tactic: 0 Time: 0.02624
[03/24/2023-12:56:20] [V] [TRT] Fastest Tactic: 0 Time: 0.02624
[03/24/2023-12:56:20] [V] [TRT] *************** Autotuning Reformat: Half(1036800,32400:2,180,1) -> Half(259200,1:8,1440,8) ***************
[03/24/2023-12:56:20] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> onnx::Conv_651) (Reformat)
[03/24/2023-12:56:20] [V] [TRT] Tactic: 1002 Time: 0.024704
[03/24/2023-12:56:20] [V] [TRT] Tactic: 0 Time: 0.014336
[03/24/2023-12:56:20] [V] [TRT] Fastest Tactic: 0 Time: 0.014336
[03/24/2023-12:56:20] [V] [TRT] *************** Autotuning Reformat: Half(1036800,32400:2,180,1) -> Half(129600,1:16,720,4) ***************
[03/24/2023-12:56:20] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> onnx::Conv_651) (Reformat)
[03/24/2023-12:56:20] [V] [TRT] Tactic: 1002 Time: 0.024576
[03/24/2023-12:56:20] [V] [TRT] Tactic: 0 Time: 0.033792
[03/24/2023-12:56:20] [V] [TRT] Fastest Tactic: 1002 Time: 0.024576
[03/24/2023-12:56:20] [V] [TRT] *************** Autotuning Reformat: Half(259200,1:8,1440,8) -> Float(2073600,32400,180,1) ***************
[03/24/2023-12:56:20] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> onnx::Conv_651) (Reformat)
[03/24/2023-12:56:20] [V] [TRT] Tactic: 1002 Time: 0.027264
[03/24/2023-12:56:20] [V] [TRT] Tactic: 0 Time: 0.015616
[03/24/2023-12:56:20] [V] [TRT] Fastest Tactic: 0 Time: 0.015616
[03/24/2023-12:56:20] [V] [TRT] *************** Autotuning Reformat: Half(259200,1:8,1440,8) -> Float(2073600,1,11520,64) ***************
[03/24/2023-12:56:20] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> onnx::Conv_651) (Reformat)
[03/24/2023-12:56:20] [V] [TRT] Tactic: 1002 Time: 0.022528
[03/24/2023-12:56:20] [V] [TRT] Tactic: 0 Time: 0.032128
[03/24/2023-12:56:20] [V] [TRT] Fastest Tactic: 1002 Time: 0.022528
[03/24/2023-12:56:20] [V] [TRT] *************** Autotuning Reformat: Half(259200,1:8,1440,8) -> Float(518400,1:4,2880,16) ***************
[03/24/2023-12:56:20] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> onnx::Conv_651) (Reformat)
[03/24/2023-12:56:20] [V] [TRT] Tactic: 1002 Time: 0.022656
[03/24/2023-12:56:20] [V] [TRT] Tactic: 0 Time: 0.03584
[03/24/2023-12:56:20] [V] [TRT] Fastest Tactic: 1002 Time: 0.022656
[03/24/2023-12:56:20] [V] [TRT] *************** Autotuning Reformat: Half(259200,1:8,1440,8) -> Half(2073600,32400,180,1) ***************
[03/24/2023-12:56:20] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> onnx::Conv_651) (Reformat)
[03/24/2023-12:56:21] [V] [TRT] Tactic: 1002 Time: 0.054144
[03/24/2023-12:56:21] [V] [TRT] Tactic: 0 Time: 0.014336
[03/24/2023-12:56:21] [V] [TRT] Fastest Tactic: 0 Time: 0.014336
[03/24/2023-12:56:21] [V] [TRT] *************** Autotuning Reformat: Half(259200,1:8,1440,8) -> Half(1036800,32400:2,180,1) ***************
[03/24/2023-12:56:21] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> onnx::Conv_651) (Reformat)
[03/24/2023-12:56:21] [V] [TRT] Tactic: 1002 Time: 0.031616
[03/24/2023-12:56:21] [V] [TRT] Tactic: 0 Time: 0.013312
[03/24/2023-12:56:21] [V] [TRT] Fastest Tactic: 0 Time: 0.013312
[03/24/2023-12:56:21] [V] [TRT] *************** Autotuning Reformat: Half(259200,1:8,1440,8) -> Half(129600,1:16,720,4) ***************
[03/24/2023-12:56:21] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> onnx::Conv_651) (Reformat)
[03/24/2023-12:56:21] [V] [TRT] Tactic: 1002 Time: 0.022528
[03/24/2023-12:56:21] [V] [TRT] Tactic: 0 Time: 0.033792
[03/24/2023-12:56:21] [V] [TRT] Fastest Tactic: 1002 Time: 0.022528
[03/24/2023-12:56:21] [V] [TRT] *************** Autotuning Reformat: Half(129600,1:16,720,4) -> Float(2073600,32400,180,1) ***************
[03/24/2023-12:56:21] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> onnx::Conv_651) (Reformat)
[03/24/2023-12:56:21] [V] [TRT] Tactic: 1002 Time: 0.027136
[03/24/2023-12:56:21] [V] [TRT] Tactic: 0 Time: 0.040448
[03/24/2023-12:56:21] [V] [TRT] Fastest Tactic: 1002 Time: 0.027136
[03/24/2023-12:56:21] [V] [TRT] *************** Autotuning Reformat: Half(129600,1:16,720,4) -> Float(2073600,1,11520,64) ***************
[03/24/2023-12:56:21] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> onnx::Conv_651) (Reformat)
[03/24/2023-12:56:21] [V] [TRT] Tactic: 1002 Time: 0.022528
[03/24/2023-12:56:21] [V] [TRT] Tactic: 0 Time: 0.032512
[03/24/2023-12:56:21] [V] [TRT] Fastest Tactic: 1002 Time: 0.022528
[03/24/2023-12:56:21] [V] [TRT] *************** Autotuning Reformat: Half(129600,1:16,720,4) -> Float(518400,1:4,2880,16) ***************
[03/24/2023-12:56:21] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> onnx::Conv_651) (Reformat)
[03/24/2023-12:56:21] [V] [TRT] Tactic: 1002 Time: 0.022528
[03/24/2023-12:56:21] [V] [TRT] Tactic: 0 Time: 0.03584
[03/24/2023-12:56:21] [V] [TRT] Fastest Tactic: 1002 Time: 0.022528
[03/24/2023-12:56:21] [V] [TRT] *************** Autotuning Reformat: Half(129600,1:16,720,4) -> Half(2073600,32400,180,1) ***************
[03/24/2023-12:56:21] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> onnx::Conv_651) (Reformat)
[03/24/2023-12:56:21] [V] [TRT] Tactic: 1002 Time: 0.054016
[03/24/2023-12:56:21] [V] [TRT] Tactic: 0 Time: 0.040192
[03/24/2023-12:56:21] [V] [TRT] Fastest Tactic: 0 Time: 0.040192
[03/24/2023-12:56:21] [V] [TRT] *************** Autotuning Reformat: Half(129600,1:16,720,4) -> Half(1036800,32400:2,180,1) ***************
[03/24/2023-12:56:21] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> onnx::Conv_651) (Reformat)
[03/24/2023-12:56:21] [V] [TRT] Tactic: 1002 Time: 0.031744
[03/24/2023-12:56:21] [V] [TRT] Tactic: 0 Time: 0.041344
[03/24/2023-12:56:21] [V] [TRT] Fastest Tactic: 1002 Time: 0.031744
[03/24/2023-12:56:21] [V] [TRT] *************** Autotuning Reformat: Half(129600,1:16,720,4) -> Half(259200,1:8,1440,8) ***************
[03/24/2023-12:56:21] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> onnx::Conv_651) (Reformat)
[03/24/2023-12:56:21] [V] [TRT] Tactic: 1002 Time: 0.022528
[03/24/2023-12:56:21] [V] [TRT] Tactic: 0 Time: 0.033792
[03/24/2023-12:56:21] [V] [TRT] Fastest Tactic: 1002 Time: 0.022528
[03/24/2023-12:56:21] [V] [TRT] =============== Computing reformatting costs
[03/24/2023-12:56:21] [V] [TRT] *************** Autotuning Reformat: Float(2073600,32400,180,1) -> Float(2073600,1,11520,64) ***************
[03/24/2023-12:56:21] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(onnx::Conv_651 -> <out>) (Reformat)
[03/24/2023-12:56:21] [V] [TRT] Tactic: 1002 Time: 0.027648
[03/24/2023-12:56:21] [V] [TRT] Tactic: 0 Time: 0.029184
[03/24/2023-12:56:21] [V] [TRT] Fastest Tactic: 1002 Time: 0.027648
[03/24/2023-12:56:21] [V] [TRT] *************** Autotuning Reformat: Float(2073600,32400,180,1) -> Float(518400,1:4,2880,16) ***************
[03/24/2023-12:56:21] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(onnx::Conv_651 -> <out>) (Reformat)
[03/24/2023-12:56:21] [V] [TRT] Tactic: 1002 Time: 0.027648
[03/24/2023-12:56:21] [V] [TRT] Tactic: 0 Time: 0.031744
[03/24/2023-12:56:21] [V] [TRT] Fastest Tactic: 1002 Time: 0.027648
[03/24/2023-12:56:21] [V] [TRT] *************** Autotuning Reformat: Float(2073600,32400,180,1) -> Half(2073600,32400,180,1) ***************
[03/24/2023-12:56:21] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(onnx::Conv_651 -> <out>) (Reformat)
[03/24/2023-12:56:21] [V] [TRT] Tactic: 1002 Time: 0.028288
[03/24/2023-12:56:21] [V] [TRT] Tactic: 0 Time: 0.034176
[03/24/2023-12:56:21] [V] [TRT] Fastest Tactic: 1002 Time: 0.028288
[03/24/2023-12:56:21] [V] [TRT] *************** Autotuning Reformat: Float(2073600,32400,180,1) -> Half(1036800,32400:2,180,1) ***************
[03/24/2023-12:56:21] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(onnx::Conv_651 -> <out>) (Reformat)
[03/24/2023-12:56:21] [V] [TRT] Tactic: 1002 Time: 0.032896
[03/24/2023-12:56:21] [V] [TRT] Tactic: 0 Time: 0.026112
[03/24/2023-12:56:21] [V] [TRT] Fastest Tactic: 0 Time: 0.026112
[03/24/2023-12:56:21] [V] [TRT] *************** Autotuning Reformat: Float(2073600,32400,180,1) -> Half(259200,1:8,1440,8) ***************
[03/24/2023-12:56:21] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(onnx::Conv_651 -> <out>) (Reformat)
[03/24/2023-12:56:21] [V] [TRT] Tactic: 1002 Time: 0.024576
[03/24/2023-12:56:21] [V] [TRT] Tactic: 0 Time: 0.01792
[03/24/2023-12:56:21] [V] [TRT] Fastest Tactic: 0 Time: 0.01792
[03/24/2023-12:56:21] [V] [TRT] *************** Autotuning Reformat: Float(2073600,32400,180,1) -> Half(129600,1:16,720,4) ***************
[03/24/2023-12:56:21] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(onnx::Conv_651 -> <out>) (Reformat)
[03/24/2023-12:56:21] [V] [TRT] Tactic: 1002 Time: 0.024576
[03/24/2023-12:56:21] [V] [TRT] Tactic: 0 Time: 0.031744
[03/24/2023-12:56:21] [V] [TRT] Fastest Tactic: 1002 Time: 0.024576
[03/24/2023-12:56:21] [V] [TRT] *************** Autotuning Reformat: Float(2073600,1,11520,64) -> Float(2073600,32400,180,1) ***************
[03/24/2023-12:56:21] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(onnx::Conv_651 -> <out>) (Reformat)
[03/24/2023-12:56:21] [V] [TRT] Tactic: 1002 Time: 0.029824
[03/24/2023-12:56:21] [V] [TRT] Tactic: 0 Time: 0.04032
[03/24/2023-12:56:21] [V] [TRT] Fastest Tactic: 1002 Time: 0.029824
[03/24/2023-12:56:21] [V] [TRT] *************** Autotuning Reformat: Float(2073600,1,11520,64) -> Float(518400,1:4,2880,16) ***************
[03/24/2023-12:56:21] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(onnx::Conv_651 -> <out>) (Reformat)
[03/24/2023-12:56:21] [V] [TRT] Tactic: 1002 Time: 0.023552
[03/24/2023-12:56:21] [V] [TRT] Tactic: 0 Time: 0.031744
[03/24/2023-12:56:21] [V] [TRT] Fastest Tactic: 1002 Time: 0.023552
[03/24/2023-12:56:21] [V] [TRT] *************** Autotuning Reformat: Float(2073600,1,11520,64) -> Half(2073600,32400,180,1) ***************
[03/24/2023-12:56:21] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(onnx::Conv_651 -> <out>) (Reformat)
[03/24/2023-12:56:21] [V] [TRT] Tactic: 1002 Time: 0.026112
[03/24/2023-12:56:21] [V] [TRT] Tactic: 0 Time: 0.039936
[03/24/2023-12:56:21] [V] [TRT] Fastest Tactic: 1002 Time: 0.026112
[03/24/2023-12:56:21] [V] [TRT] *************** Autotuning Reformat: Float(2073600,1,11520,64) -> Half(1036800,32400:2,180,1) ***************
[03/24/2023-12:56:21] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(onnx::Conv_651 -> <out>) (Reformat)
[03/24/2023-12:56:21] [V] [TRT] Tactic: 1002 Time: 0.032512
[03/24/2023-12:56:21] [V] [TRT] Tactic: 0 Time: 0.041216
[03/24/2023-12:56:21] [V] [TRT] Fastest Tactic: 1002 Time: 0.032512
[03/24/2023-12:56:21] [V] [TRT] *************** Autotuning Reformat: Float(2073600,1,11520,64) -> Half(259200,1:8,1440,8) ***************
[03/24/2023-12:56:21] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(onnx::Conv_651 -> <out>) (Reformat)
[03/24/2023-12:56:21] [V] [TRT] Tactic: 1002 Time: 0.022528
[03/24/2023-12:56:21] [V] [TRT] Tactic: 0 Time: 0.031744
[03/24/2023-12:56:21] [V] [TRT] Fastest Tactic: 1002 Time: 0.022528
[03/24/2023-12:56:21] [V] [TRT] *************** Autotuning Reformat: Float(2073600,1,11520,64) -> Half(129600,1:16,720,4) ***************
[03/24/2023-12:56:21] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(onnx::Conv_651 -> <out>) (Reformat)
[03/24/2023-12:56:21] [V] [TRT] Tactic: 1002 Time: 0.022528
[03/24/2023-12:56:21] [V] [TRT] Tactic: 0 Time: 0.031744
[03/24/2023-12:56:21] [V] [TRT] Fastest Tactic: 1002 Time: 0.022528
[03/24/2023-12:56:21] [V] [TRT] *************** Autotuning Reformat: Float(518400,1:4,2880,16) -> Float(2073600,32400,180,1) ***************
[03/24/2023-12:56:21] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(onnx::Conv_651 -> <out>) (Reformat)
[03/24/2023-12:56:21] [V] [TRT] Tactic: 1002 Time: 0.029952
[03/24/2023-12:56:21] [V] [TRT] Tactic: 0 Time: 0.04032
[03/24/2023-12:56:21] [V] [TRT] Fastest Tactic: 1002 Time: 0.029952
[03/24/2023-12:56:21] [V] [TRT] *************** Autotuning Reformat: Float(518400,1:4,2880,16) -> Float(2073600,1,11520,64) ***************
[03/24/2023-12:56:21] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(onnx::Conv_651 -> <out>) (Reformat)
[03/24/2023-12:56:21] [V] [TRT] Tactic: 1002 Time: 0.023552
[03/24/2023-12:56:21] [V] [TRT] Tactic: 0 Time: 0.031744
[03/24/2023-12:56:21] [V] [TRT] Fastest Tactic: 1002 Time: 0.023552
[03/24/2023-12:56:21] [V] [TRT] *************** Autotuning Reformat: Float(518400,1:4,2880,16) -> Half(2073600,32400,180,1) ***************
[03/24/2023-12:56:21] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(onnx::Conv_651 -> <out>) (Reformat)
[03/24/2023-12:56:21] [V] [TRT] Tactic: 1002 Time: 0.026368
[03/24/2023-12:56:21] [V] [TRT] Tactic: 0 Time: 0.040064
[03/24/2023-12:56:21] [V] [TRT] Fastest Tactic: 1002 Time: 0.026368
[03/24/2023-12:56:21] [V] [TRT] *************** Autotuning Reformat: Float(518400,1:4,2880,16) -> Half(1036800,32400:2,180,1) ***************
[03/24/2023-12:56:21] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(onnx::Conv_651 -> <out>) (Reformat)
[03/24/2023-12:56:21] [V] [TRT] Tactic: 1002 Time: 0.032
[03/24/2023-12:56:21] [V] [TRT] Tactic: 0 Time: 0.041088
[03/24/2023-12:56:21] [V] [TRT] Fastest Tactic: 1002 Time: 0.032
[03/24/2023-12:56:21] [V] [TRT] *************** Autotuning Reformat: Float(518400,1:4,2880,16) -> Half(259200,1:8,1440,8) ***************
[03/24/2023-12:56:21] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(onnx::Conv_651 -> <out>) (Reformat)
[03/24/2023-12:56:21] [V] [TRT] Tactic: 1002 Time: 0.022528
[03/24/2023-12:56:21] [V] [TRT] Tactic: 0 Time: 0.03584
[03/24/2023-12:56:21] [V] [TRT] Fastest Tactic: 1002 Time: 0.022528
[03/24/2023-12:56:21] [V] [TRT] *************** Autotuning Reformat: Float(518400,1:4,2880,16) -> Half(129600,1:16,720,4) ***************
[03/24/2023-12:56:21] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(onnx::Conv_651 -> <out>) (Reformat)
[03/24/2023-12:56:21] [V] [TRT] Tactic: 1002 Time: 0.022528
[03/24/2023-12:56:21] [V] [TRT] Tactic: 0 Time: 0.03584
[03/24/2023-12:56:21] [V] [TRT] Fastest Tactic: 1002 Time: 0.022528
[03/24/2023-12:56:21] [V] [TRT] *************** Autotuning Reformat: Half(2073600,32400,180,1) -> Float(2073600,32400,180,1) ***************
[03/24/2023-12:56:21] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(onnx::Conv_651 -> <out>) (Reformat)
[03/24/2023-12:56:21] [V] [TRT] Tactic: 1002 Time: 0.028288
[03/24/2023-12:56:21] [V] [TRT] Tactic: 0 Time: 0.033792
[03/24/2023-12:56:21] [V] [TRT] Fastest Tactic: 1002 Time: 0.028288
[03/24/2023-12:56:21] [V] [TRT] *************** Autotuning Reformat: Half(2073600,32400,180,1) -> Float(2073600,1,11520,64) ***************
[03/24/2023-12:56:21] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(onnx::Conv_651 -> <out>) (Reformat)
[03/24/2023-12:56:21] [V] [TRT] Tactic: 1002 Time: 0.024576
[03/24/2023-12:56:21] [V] [TRT] Tactic: 0 Time: 0.029696
[03/24/2023-12:56:21] [V] [TRT] Fastest Tactic: 1002 Time: 0.024576
[03/24/2023-12:56:21] [V] [TRT] *************** Autotuning Reformat: Half(2073600,32400,180,1) -> Float(518400,1:4,2880,16) ***************
[03/24/2023-12:56:21] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(onnx::Conv_651 -> <out>) (Reformat)
[03/24/2023-12:56:21] [V] [TRT] Tactic: 1002 Time: 0.024576
[03/24/2023-12:56:21] [V] [TRT] Tactic: 0 Time: 0.032512
[03/24/2023-12:56:21] [V] [TRT] Fastest Tactic: 1002 Time: 0.024576
[03/24/2023-12:56:21] [V] [TRT] *************** Autotuning Reformat: Half(2073600,32400,180,1) -> Half(1036800,32400:2,180,1) ***************
[03/24/2023-12:56:21] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(onnx::Conv_651 -> <out>) (Reformat)
[03/24/2023-12:56:21] [V] [TRT] Tactic: 1002 Time: 0.024448
[03/24/2023-12:56:21] [V] [TRT] Tactic: 0 Time: 0.025984
[03/24/2023-12:56:21] [V] [TRT] Fastest Tactic: 1002 Time: 0.024448
[03/24/2023-12:56:21] [V] [TRT] *************** Autotuning Reformat: Half(2073600,32400,180,1) -> Half(259200,1:8,1440,8) ***************
[03/24/2023-12:56:21] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(onnx::Conv_651 -> <out>) (Reformat)
[03/24/2023-12:56:21] [V] [TRT] Tactic: 1002 Time: 0.024576
[03/24/2023-12:56:21] [V] [TRT] Tactic: 0 Time: 0.017664
[03/24/2023-12:56:21] [V] [TRT] Fastest Tactic: 0 Time: 0.017664
[03/24/2023-12:56:21] [V] [TRT] *************** Autotuning Reformat: Half(2073600,32400,180,1) -> Half(129600,1:16,720,4) ***************
[03/24/2023-12:56:21] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(onnx::Conv_651 -> <out>) (Reformat)
[03/24/2023-12:56:21] [V] [TRT] Tactic: 1002 Time: 0.024576
[03/24/2023-12:56:21] [V] [TRT] Tactic: 0 Time: 0.031616
[03/24/2023-12:56:21] [V] [TRT] Fastest Tactic: 1002 Time: 0.024576
[03/24/2023-12:56:21] [V] [TRT] *************** Autotuning Reformat: Half(1036800,32400:2,180,1) -> Float(2073600,32400,180,1) ***************
[03/24/2023-12:56:21] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(onnx::Conv_651 -> <out>) (Reformat)
[03/24/2023-12:56:21] [V] [TRT] Tactic: 1002 Time: 0.028928
[03/24/2023-12:56:21] [V] [TRT] Tactic: 0 Time: 0.025856
[03/24/2023-12:56:21] [V] [TRT] Fastest Tactic: 0 Time: 0.025856
[03/24/2023-12:56:21] [V] [TRT] *************** Autotuning Reformat: Half(1036800,32400:2,180,1) -> Float(2073600,1,11520,64) ***************
[03/24/2023-12:56:21] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(onnx::Conv_651 -> <out>) (Reformat)
[03/24/2023-12:56:21] [V] [TRT] Tactic: 1002 Time: 0.024704
[03/24/2023-12:56:21] [V] [TRT] Tactic: 0 Time: 0.032512
[03/24/2023-12:56:21] [V] [TRT] Fastest Tactic: 1002 Time: 0.024704
[03/24/2023-12:56:21] [V] [TRT] *************** Autotuning Reformat: Half(1036800,32400:2,180,1) -> Float(518400,1:4,2880,16) ***************
[03/24/2023-12:56:21] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(onnx::Conv_651 -> <out>) (Reformat)
[03/24/2023-12:56:21] [V] [TRT] Tactic: 1002 Time: 0.024576
[03/24/2023-12:56:21] [V] [TRT] Tactic: 0 Time: 0.03584
[03/24/2023-12:56:21] [V] [TRT] Fastest Tactic: 1002 Time: 0.024576
[03/24/2023-12:56:21] [V] [TRT] *************** Autotuning Reformat: Half(1036800,32400:2,180,1) -> Half(2073600,32400,180,1) ***************
[03/24/2023-12:56:21] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(onnx::Conv_651 -> <out>) (Reformat)
[03/24/2023-12:56:21] [V] [TRT] Tactic: 1002 Time: 0.061056
[03/24/2023-12:56:21] [V] [TRT] Tactic: 0 Time: 0.025984
[03/24/2023-12:56:21] [V] [TRT] Fastest Tactic: 0 Time: 0.025984
[03/24/2023-12:56:21] [V] [TRT] *************** Autotuning Reformat: Half(1036800,32400:2,180,1) -> Half(259200,1:8,1440,8) ***************
[03/24/2023-12:56:21] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(onnx::Conv_651 -> <out>) (Reformat)
[03/24/2023-12:56:21] [V] [TRT] Tactic: 1002 Time: 0.024576
[03/24/2023-12:56:21] [V] [TRT] Tactic: 0 Time: 0.014336
[03/24/2023-12:56:21] [V] [TRT] Fastest Tactic: 0 Time: 0.014336
[03/24/2023-12:56:21] [V] [TRT] *************** Autotuning Reformat: Half(1036800,32400:2,180,1) -> Half(129600,1:16,720,4) ***************
[03/24/2023-12:56:21] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(onnx::Conv_651 -> <out>) (Reformat)
[03/24/2023-12:56:21] [V] [TRT] Tactic: 1002 Time: 0.024576
[03/24/2023-12:56:21] [V] [TRT] Tactic: 0 Time: 0.033792
[03/24/2023-12:56:21] [V] [TRT] Fastest Tactic: 1002 Time: 0.024576
[03/24/2023-12:56:21] [V] [TRT] *************** Autotuning Reformat: Half(259200,1:8,1440,8) -> Float(2073600,32400,180,1) ***************
[03/24/2023-12:56:21] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(onnx::Conv_651 -> <out>) (Reformat)
[03/24/2023-12:56:21] [V] [TRT] Tactic: 1002 Time: 0.027008
[03/24/2023-12:56:21] [V] [TRT] Tactic: 0 Time: 0.01536
[03/24/2023-12:56:21] [V] [TRT] Fastest Tactic: 0 Time: 0.01536
[03/24/2023-12:56:21] [V] [TRT] *************** Autotuning Reformat: Half(259200,1:8,1440,8) -> Float(2073600,1,11520,64) ***************
[03/24/2023-12:56:21] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(onnx::Conv_651 -> <out>) (Reformat)
[03/24/2023-12:56:21] [V] [TRT] Tactic: 1002 Time: 0.022528
[03/24/2023-12:56:21] [V] [TRT] Tactic: 0 Time: 0.032384
[03/24/2023-12:56:21] [V] [TRT] Fastest Tactic: 1002 Time: 0.022528
[03/24/2023-12:56:21] [V] [TRT] *************** Autotuning Reformat: Half(259200,1:8,1440,8) -> Float(518400,1:4,2880,16) ***************
[03/24/2023-12:56:21] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(onnx::Conv_651 -> <out>) (Reformat)
[03/24/2023-12:56:21] [V] [TRT] Tactic: 1002 Time: 0.022656
[03/24/2023-12:56:21] [V] [TRT] Tactic: 0 Time: 0.03584
[03/24/2023-12:56:21] [V] [TRT] Fastest Tactic: 1002 Time: 0.022656
[03/24/2023-12:56:21] [V] [TRT] *************** Autotuning Reformat: Half(259200,1:8,1440,8) -> Half(2073600,32400,180,1) ***************
[03/24/2023-12:56:21] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(onnx::Conv_651 -> <out>) (Reformat)
[03/24/2023-12:56:21] [V] [TRT] Tactic: 1002 Time: 0.05376
[03/24/2023-12:56:21] [V] [TRT] Tactic: 0 Time: 0.014336
[03/24/2023-12:56:21] [V] [TRT] Fastest Tactic: 0 Time: 0.014336
[03/24/2023-12:56:21] [V] [TRT] *************** Autotuning Reformat: Half(259200,1:8,1440,8) -> Half(1036800,32400:2,180,1) ***************
[03/24/2023-12:56:21] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(onnx::Conv_651 -> <out>) (Reformat)
[03/24/2023-12:56:21] [V] [TRT] Tactic: 1002 Time: 0.031488
[03/24/2023-12:56:21] [V] [TRT] Tactic: 0 Time: 0.013568
[03/24/2023-12:56:21] [V] [TRT] Fastest Tactic: 0 Time: 0.013568
[03/24/2023-12:56:21] [V] [TRT] *************** Autotuning Reformat: Half(259200,1:8,1440,8) -> Half(129600,1:16,720,4) ***************
[03/24/2023-12:56:21] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(onnx::Conv_651 -> <out>) (Reformat)
[03/24/2023-12:56:21] [V] [TRT] Tactic: 1002 Time: 0.022528
[03/24/2023-12:56:21] [V] [TRT] Tactic: 0 Time: 0.033792
[03/24/2023-12:56:21] [V] [TRT] Fastest Tactic: 1002 Time: 0.022528
[03/24/2023-12:56:21] [V] [TRT] *************** Autotuning Reformat: Half(129600,1:16,720,4) -> Float(2073600,32400,180,1) ***************
[03/24/2023-12:56:21] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(onnx::Conv_651 -> <out>) (Reformat)
[03/24/2023-12:56:21] [V] [TRT] Tactic: 1002 Time: 0.02688
[03/24/2023-12:56:21] [V] [TRT] Tactic: 0 Time: 0.040576
[03/24/2023-12:56:21] [V] [TRT] Fastest Tactic: 1002 Time: 0.02688
[03/24/2023-12:56:21] [V] [TRT] *************** Autotuning Reformat: Half(129600,1:16,720,4) -> Float(2073600,1,11520,64) ***************
[03/24/2023-12:56:21] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(onnx::Conv_651 -> <out>) (Reformat)
[03/24/2023-12:56:21] [V] [TRT] Tactic: 1002 Time: 0.022528
[03/24/2023-12:56:21] [V] [TRT] Tactic: 0 Time: 0.03264
[03/24/2023-12:56:21] [V] [TRT] Fastest Tactic: 1002 Time: 0.022528
[03/24/2023-12:56:21] [V] [TRT] *************** Autotuning Reformat: Half(129600,1:16,720,4) -> Float(518400,1:4,2880,16) ***************
[03/24/2023-12:56:21] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(onnx::Conv_651 -> <out>) (Reformat)
[03/24/2023-12:56:21] [V] [TRT] Tactic: 1002 Time: 0.022528
[03/24/2023-12:56:21] [V] [TRT] Tactic: 0 Time: 0.03584
[03/24/2023-12:56:21] [V] [TRT] Fastest Tactic: 1002 Time: 0.022528
[03/24/2023-12:56:21] [V] [TRT] *************** Autotuning Reformat: Half(129600,1:16,720,4) -> Half(2073600,32400,180,1) ***************
[03/24/2023-12:56:21] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(onnx::Conv_651 -> <out>) (Reformat)
[03/24/2023-12:56:21] [V] [TRT] Tactic: 1002 Time: 0.053888
[03/24/2023-12:56:21] [V] [TRT] Tactic: 0 Time: 0.039936
[03/24/2023-12:56:21] [V] [TRT] Fastest Tactic: 0 Time: 0.039936
[03/24/2023-12:56:21] [V] [TRT] *************** Autotuning Reformat: Half(129600,1:16,720,4) -> Half(1036800,32400:2,180,1) ***************
[03/24/2023-12:56:21] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(onnx::Conv_651 -> <out>) (Reformat)
[03/24/2023-12:56:21] [V] [TRT] Tactic: 1002 Time: 0.031488
[03/24/2023-12:56:21] [V] [TRT] Tactic: 0 Time: 0.041728
[03/24/2023-12:56:21] [V] [TRT] Fastest Tactic: 1002 Time: 0.031488
[03/24/2023-12:56:21] [V] [TRT] *************** Autotuning Reformat: Half(129600,1:16,720,4) -> Half(259200,1:8,1440,8) ***************
[03/24/2023-12:56:21] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(onnx::Conv_651 -> <out>) (Reformat)
[03/24/2023-12:56:21] [V] [TRT] Tactic: 1002 Time: 0.022656
[03/24/2023-12:56:21] [V] [TRT] Tactic: 0 Time: 0.033792
[03/24/2023-12:56:21] [V] [TRT] Fastest Tactic: 1002 Time: 0.022656
[03/24/2023-12:56:21] [V] [TRT] =============== Computing reformatting costs
[03/24/2023-12:56:21] [V] [TRT] *************** Autotuning Reformat: Float(16588800,32400,180,1) -> Float(16588800,1,92160,512) ***************
[03/24/2023-12:56:21] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> Conv_62 + Relu_63 || Conv_65 + Relu_66 || Conv_68 + Relu_69 || Conv_71 + Relu_72 || Conv_74 + Relu_75 || Conv_77 + Relu_78 || Conv_80 + Relu_81 || Conv_83 + Relu_84) (Reformat)
[03/24/2023-12:56:21] [V] [TRT] Tactic: 1002 Time: 0.128384
[03/24/2023-12:56:21] [V] [TRT] Tactic: 0 Time: 0.427264
[03/24/2023-12:56:21] [V] [TRT] Fastest Tactic: 1002 Time: 0.128384
[03/24/2023-12:56:21] [V] [TRT] *************** Autotuning Reformat: Float(16588800,32400,180,1) -> Float(4147200,1:4,23040,128) ***************
[03/24/2023-12:56:21] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> Conv_62 + Relu_63 || Conv_65 + Relu_66 || Conv_68 + Relu_69 || Conv_71 + Relu_72 || Conv_74 + Relu_75 || Conv_77 + Relu_78 || Conv_80 + Relu_81 || Conv_83 + Relu_84) (Reformat)
[03/24/2023-12:56:21] [V] [TRT] Tactic: 1002 Time: 0.128256
[03/24/2023-12:56:21] [V] [TRT] Tactic: 0 Time: 0.42368
[03/24/2023-12:56:21] [V] [TRT] Fastest Tactic: 1002 Time: 0.128256
[03/24/2023-12:56:21] [V] [TRT] *************** Autotuning Reformat: Float(16588800,32400,180,1) -> Half(16588800,32400,180,1) ***************
[03/24/2023-12:56:21] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> Conv_62 + Relu_63 || Conv_65 + Relu_66 || Conv_68 + Relu_69 || Conv_71 + Relu_72 || Conv_74 + Relu_75 || Conv_77 + Relu_78 || Conv_80 + Relu_81 || Conv_83 + Relu_84) (Reformat)
[03/24/2023-12:56:21] [V] [TRT] Tactic: 1002 Time: 0.153344
[03/24/2023-12:56:21] [V] [TRT] Tactic: 0 Time: 0.208128
[03/24/2023-12:56:21] [V] [TRT] Fastest Tactic: 1002 Time: 0.153344
[03/24/2023-12:56:21] [V] [TRT] *************** Autotuning Reformat: Float(16588800,32400,180,1) -> Half(8294400,32400:2,180,1) ***************
[03/24/2023-12:56:21] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> Conv_62 + Relu_63 || Conv_65 + Relu_66 || Conv_68 + Relu_69 || Conv_71 + Relu_72 || Conv_74 + Relu_75 || Conv_77 + Relu_78 || Conv_80 + Relu_81 || Conv_83 + Relu_84) (Reformat)
[03/24/2023-12:56:21] [V] [TRT] Tactic: 1002 Time: 0.164608
[03/24/2023-12:56:21] [V] [TRT] Tactic: 0 Time: 0.148736
[03/24/2023-12:56:21] [V] [TRT] Fastest Tactic: 0 Time: 0.148736
[03/24/2023-12:56:21] [V] [TRT] *************** Autotuning Reformat: Float(16588800,32400,180,1) -> Half(2073600,1:8,11520,64) ***************
[03/24/2023-12:56:21] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> Conv_62 + Relu_63 || Conv_65 + Relu_66 || Conv_68 + Relu_69 || Conv_71 + Relu_72 || Conv_74 + Relu_75 || Conv_77 + Relu_78 || Conv_80 + Relu_81 || Conv_83 + Relu_84) (Reformat)
[03/24/2023-12:56:21] [V] [TRT] Tactic: 1002 Time: 0.116096
[03/24/2023-12:56:21] [V] [TRT] Tactic: 0 Time: 0.09152
[03/24/2023-12:56:21] [V] [TRT] Fastest Tactic: 0 Time: 0.09152
[03/24/2023-12:56:21] [V] [TRT] *************** Autotuning Reformat: Float(16588800,32400,180,1) -> Half(1036800,1:16,5760,32) ***************
[03/24/2023-12:56:21] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> Conv_62 + Relu_63 || Conv_65 + Relu_66 || Conv_68 + Relu_69 || Conv_71 + Relu_72 || Conv_74 + Relu_75 || Conv_77 + Relu_78 || Conv_80 + Relu_81 || Conv_83 + Relu_84) (Reformat)
[03/24/2023-12:56:21] [V] [TRT] Tactic: 1002 Time: 0.116224
[03/24/2023-12:56:21] [V] [TRT] Tactic: 0 Time: 0.423808
[03/24/2023-12:56:21] [V] [TRT] Fastest Tactic: 1002 Time: 0.116224
[03/24/2023-12:56:21] [V] [TRT] *************** Autotuning Reformat: Float(16588800,1,92160,512) -> Float(16588800,32400,180,1) ***************
[03/24/2023-12:56:21] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> Conv_62 + Relu_63 || Conv_65 + Relu_66 || Conv_68 + Relu_69 || Conv_71 + Relu_72 || Conv_74 + Relu_75 || Conv_77 + Relu_78 || Conv_80 + Relu_81 || Conv_83 + Relu_84) (Reformat)
[03/24/2023-12:56:21] [V] [TRT] Tactic: 1002 Time: 0.132352
[03/24/2023-12:56:21] [V] [TRT] Tactic: 0 Time: 0.328192
[03/24/2023-12:56:21] [V] [TRT] Fastest Tactic: 1002 Time: 0.132352
[03/24/2023-12:56:21] [V] [TRT] *************** Autotuning Reformat: Float(16588800,1,92160,512) -> Float(4147200,1:4,23040,128) ***************
[03/24/2023-12:56:21] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> Conv_62 + Relu_63 || Conv_65 + Relu_66 || Conv_68 + Relu_69 || Conv_71 + Relu_72 || Conv_74 + Relu_75 || Conv_77 + Relu_78 || Conv_80 + Relu_81 || Conv_83 + Relu_84) (Reformat)
[03/24/2023-12:56:21] [V] [TRT] Tactic: 1002 Time: 0.11328
[03/24/2023-12:56:21] [V] [TRT] Tactic: 0 Time: 0.189696
[03/24/2023-12:56:21] [V] [TRT] Fastest Tactic: 1002 Time: 0.11328
[03/24/2023-12:56:21] [V] [TRT] *************** Autotuning Reformat: Float(16588800,1,92160,512) -> Half(16588800,32400,180,1) ***************
[03/24/2023-12:56:21] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> Conv_62 + Relu_63 || Conv_65 + Relu_66 || Conv_68 + Relu_69 || Conv_71 + Relu_72 || Conv_74 + Relu_75 || Conv_77 + Relu_78 || Conv_80 + Relu_81 || Conv_83 + Relu_84) (Reformat)
[03/24/2023-12:56:21] [V] [TRT] Tactic: 1002 Time: 0.122752
[03/24/2023-12:56:21] [V] [TRT] Tactic: 0 Time: 0.30912
[03/24/2023-12:56:21] [V] [TRT] Fastest Tactic: 1002 Time: 0.122752
[03/24/2023-12:56:21] [V] [TRT] *************** Autotuning Reformat: Float(16588800,1,92160,512) -> Half(8294400,32400:2,180,1) ***************
[03/24/2023-12:56:21] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> Conv_62 + Relu_63 || Conv_65 + Relu_66 || Conv_68 + Relu_69 || Conv_71 + Relu_72 || Conv_74 + Relu_75 || Conv_77 + Relu_78 || Conv_80 + Relu_81 || Conv_83 + Relu_84) (Reformat)
[03/24/2023-12:56:21] [V] [TRT] Tactic: 1002 Time: 0.176
[03/24/2023-12:56:21] [V] [TRT] Tactic: 0 Time: 0.35584
[03/24/2023-12:56:21] [V] [TRT] Fastest Tactic: 1002 Time: 0.176
[03/24/2023-12:56:21] [V] [TRT] *************** Autotuning Reformat: Float(16588800,1,92160,512) -> Half(2073600,1:8,11520,64) ***************
[03/24/2023-12:56:21] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> Conv_62 + Relu_63 || Conv_65 + Relu_66 || Conv_68 + Relu_69 || Conv_71 + Relu_72 || Conv_74 + Relu_75 || Conv_77 + Relu_78 || Conv_80 + Relu_81 || Conv_83 + Relu_84) (Reformat)
[03/24/2023-12:56:22] [V] [TRT] Tactic: 1002 Time: 0.116864
[03/24/2023-12:56:22] [V] [TRT] Tactic: 0 Time: 0.217216
[03/24/2023-12:56:22] [V] [TRT] Fastest Tactic: 1002 Time: 0.116864
[03/24/2023-12:56:22] [V] [TRT] *************** Autotuning Reformat: Float(16588800,1,92160,512) -> Half(1036800,1:16,5760,32) ***************
[03/24/2023-12:56:22] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> Conv_62 + Relu_63 || Conv_65 + Relu_66 || Conv_68 + Relu_69 || Conv_71 + Relu_72 || Conv_74 + Relu_75 || Conv_77 + Relu_78 || Conv_80 + Relu_81 || Conv_83 + Relu_84) (Reformat)
[03/24/2023-12:56:22] [V] [TRT] Tactic: 1002 Time: 0.116992
[03/24/2023-12:56:22] [V] [TRT] Tactic: 0 Time: 0.217344
[03/24/2023-12:56:22] [V] [TRT] Fastest Tactic: 1002 Time: 0.116992
[03/24/2023-12:56:22] [V] [TRT] *************** Autotuning Reformat: Float(4147200,1:4,23040,128) -> Float(16588800,32400,180,1) ***************
[03/24/2023-12:56:22] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> Conv_62 + Relu_63 || Conv_65 + Relu_66 || Conv_68 + Relu_69 || Conv_71 + Relu_72 || Conv_74 + Relu_75 || Conv_77 + Relu_78 || Conv_80 + Relu_81 || Conv_83 + Relu_84) (Reformat)
[03/24/2023-12:56:22] [V] [TRT] Tactic: 1002 Time: 0.14912
[03/24/2023-12:56:22] [V] [TRT] Tactic: 0 Time: 0.360192
[03/24/2023-12:56:22] [V] [TRT] Fastest Tactic: 1002 Time: 0.14912
[03/24/2023-12:56:22] [V] [TRT] *************** Autotuning Reformat: Float(4147200,1:4,23040,128) -> Float(16588800,1,92160,512) ***************
[03/24/2023-12:56:22] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> Conv_62 + Relu_63 || Conv_65 + Relu_66 || Conv_68 + Relu_69 || Conv_71 + Relu_72 || Conv_74 + Relu_75 || Conv_77 + Relu_78 || Conv_80 + Relu_81 || Conv_83 + Relu_84) (Reformat)
[03/24/2023-12:56:22] [V] [TRT] Tactic: 1002 Time: 0.120448
[03/24/2023-12:56:22] [V] [TRT] Tactic: 0 Time: 0.216448
[03/24/2023-12:56:22] [V] [TRT] Fastest Tactic: 1002 Time: 0.120448
[03/24/2023-12:56:22] [V] [TRT] *************** Autotuning Reformat: Float(4147200,1:4,23040,128) -> Half(16588800,32400,180,1) ***************
[03/24/2023-12:56:22] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> Conv_62 + Relu_63 || Conv_65 + Relu_66 || Conv_68 + Relu_69 || Conv_71 + Relu_72 || Conv_74 + Relu_75 || Conv_77 + Relu_78 || Conv_80 + Relu_81 || Conv_83 + Relu_84) (Reformat)
[03/24/2023-12:56:22] [V] [TRT] Tactic: 1002 Time: 0.137728
[03/24/2023-12:56:22] [V] [TRT] Tactic: 0 Time: 0.343168
[03/24/2023-12:56:22] [V] [TRT] Fastest Tactic: 1002 Time: 0.137728
[03/24/2023-12:56:22] [V] [TRT] *************** Autotuning Reformat: Float(4147200,1:4,23040,128) -> Half(8294400,32400:2,180,1) ***************
[03/24/2023-12:56:22] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> Conv_62 + Relu_63 || Conv_65 + Relu_66 || Conv_68 + Relu_69 || Conv_71 + Relu_72 || Conv_74 + Relu_75 || Conv_77 + Relu_78 || Conv_80 + Relu_81 || Conv_83 + Relu_84) (Reformat)
[03/24/2023-12:56:22] [V] [TRT] Tactic: 1002 Time: 0.176384
[03/24/2023-12:56:22] [V] [TRT] Tactic: 0 Time: 0.361344
[03/24/2023-12:56:22] [V] [TRT] Fastest Tactic: 1002 Time: 0.176384
[03/24/2023-12:56:22] [V] [TRT] *************** Autotuning Reformat: Float(4147200,1:4,23040,128) -> Half(2073600,1:8,11520,64) ***************
[03/24/2023-12:56:22] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> Conv_62 + Relu_63 || Conv_65 + Relu_66 || Conv_68 + Relu_69 || Conv_71 + Relu_72 || Conv_74 + Relu_75 || Conv_77 + Relu_78 || Conv_80 + Relu_81 || Conv_83 + Relu_84) (Reformat)
[03/24/2023-12:56:22] [V] [TRT] Tactic: 1002 Time: 0.116992
[03/24/2023-12:56:22] [V] [TRT] Tactic: 0 Time: 0.254976
[03/24/2023-12:56:22] [V] [TRT] Fastest Tactic: 1002 Time: 0.116992
[03/24/2023-12:56:22] [V] [TRT] *************** Autotuning Reformat: Float(4147200,1:4,23040,128) -> Half(1036800,1:16,5760,32) ***************
[03/24/2023-12:56:22] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> Conv_62 + Relu_63 || Conv_65 + Relu_66 || Conv_68 + Relu_69 || Conv_71 + Relu_72 || Conv_74 + Relu_75 || Conv_77 + Relu_78 || Conv_80 + Relu_81 || Conv_83 + Relu_84) (Reformat)
[03/24/2023-12:56:22] [V] [TRT] Tactic: 1002 Time: 0.116864
[03/24/2023-12:56:22] [V] [TRT] Tactic: 0 Time: 0.254976
[03/24/2023-12:56:22] [V] [TRT] Fastest Tactic: 1002 Time: 0.116864
[03/24/2023-12:56:22] [V] [TRT] *************** Autotuning Reformat: Half(16588800,32400,180,1) -> Float(16588800,32400,180,1) ***************
[03/24/2023-12:56:22] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> Conv_62 + Relu_63 || Conv_65 + Relu_66 || Conv_68 + Relu_69 || Conv_71 + Relu_72 || Conv_74 + Relu_75 || Conv_77 + Relu_78 || Conv_80 + Relu_81 || Conv_83 + Relu_84) (Reformat)
[03/24/2023-12:56:22] [V] [TRT] Tactic: 1002 Time: 0.173824
[03/24/2023-12:56:22] [V] [TRT] Tactic: 0 Time: 0.22016
[03/24/2023-12:56:22] [V] [TRT] Fastest Tactic: 1002 Time: 0.173824
[03/24/2023-12:56:22] [V] [TRT] *************** Autotuning Reformat: Half(16588800,32400,180,1) -> Float(16588800,1,92160,512) ***************
[03/24/2023-12:56:22] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> Conv_62 + Relu_63 || Conv_65 + Relu_66 || Conv_68 + Relu_69 || Conv_71 + Relu_72 || Conv_74 + Relu_75 || Conv_77 + Relu_78 || Conv_80 + Relu_81 || Conv_83 + Relu_84) (Reformat)
[03/24/2023-12:56:22] [V] [TRT] Tactic: 1002 Time: 0.131328
[03/24/2023-12:56:22] [V] [TRT] Tactic: 0 Time: 0.321152
[03/24/2023-12:56:22] [V] [TRT] Fastest Tactic: 1002 Time: 0.131328
[03/24/2023-12:56:22] [V] [TRT] *************** Autotuning Reformat: Half(16588800,32400,180,1) -> Float(4147200,1:4,23040,128) ***************
[03/24/2023-12:56:22] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> Conv_62 + Relu_63 || Conv_65 + Relu_66 || Conv_68 + Relu_69 || Conv_71 + Relu_72 || Conv_74 + Relu_75 || Conv_77 + Relu_78 || Conv_80 + Relu_81 || Conv_83 + Relu_84) (Reformat)
[03/24/2023-12:56:22] [V] [TRT] Tactic: 1002 Time: 0.131072
[03/24/2023-12:56:22] [V] [TRT] Tactic: 0 Time: 0.32576
[03/24/2023-12:56:22] [V] [TRT] Fastest Tactic: 1002 Time: 0.131072
[03/24/2023-12:56:22] [V] [TRT] *************** Autotuning Reformat: Half(16588800,32400,180,1) -> Half(8294400,32400:2,180,1) ***************
[03/24/2023-12:56:22] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> Conv_62 + Relu_63 || Conv_65 + Relu_66 || Conv_68 + Relu_69 || Conv_71 + Relu_72 || Conv_74 + Relu_75 || Conv_77 + Relu_78 || Conv_80 + Relu_81 || Conv_83 + Relu_84) (Reformat)
[03/24/2023-12:56:22] [V] [TRT] Tactic: 1002 Time: 0.121088
[03/24/2023-12:56:22] [V] [TRT] Tactic: 0 Time: 0.148736
[03/24/2023-12:56:22] [V] [TRT] Fastest Tactic: 1002 Time: 0.121088
[03/24/2023-12:56:22] [V] [TRT] *************** Autotuning Reformat: Half(16588800,32400,180,1) -> Half(2073600,1:8,11520,64) ***************
[03/24/2023-12:56:22] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> Conv_62 + Relu_63 || Conv_65 + Relu_66 || Conv_68 + Relu_69 || Conv_71 + Relu_72 || Conv_74 + Relu_75 || Conv_77 + Relu_78 || Conv_80 + Relu_81 || Conv_83 + Relu_84) (Reformat)
[03/24/2023-12:56:22] [V] [TRT] Tactic: 1002 Time: 0.126848
[03/24/2023-12:56:22] [V] [TRT] Tactic: 0 Time: 0.08704
[03/24/2023-12:56:22] [V] [TRT] Fastest Tactic: 0 Time: 0.08704
[03/24/2023-12:56:22] [V] [TRT] *************** Autotuning Reformat: Half(16588800,32400,180,1) -> Half(1036800,1:16,5760,32) ***************
[03/24/2023-12:56:22] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> Conv_62 + Relu_63 || Conv_65 + Relu_66 || Conv_68 + Relu_69 || Conv_71 + Relu_72 || Conv_74 + Relu_75 || Conv_77 + Relu_78 || Conv_80 + Relu_81 || Conv_83 + Relu_84) (Reformat)
[03/24/2023-12:56:22] [V] [TRT] Tactic: 1002 Time: 0.127104
[03/24/2023-12:56:22] [V] [TRT] Tactic: 0 Time: 0.282624
[03/24/2023-12:56:22] [V] [TRT] Fastest Tactic: 1002 Time: 0.127104
[03/24/2023-12:56:22] [V] [TRT] *************** Autotuning Reformat: Half(8294400,32400:2,180,1) -> Float(16588800,32400,180,1) ***************
[03/24/2023-12:56:22] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> Conv_62 + Relu_63 || Conv_65 + Relu_66 || Conv_68 + Relu_69 || Conv_71 + Relu_72 || Conv_74 + Relu_75 || Conv_77 + Relu_78 || Conv_80 + Relu_81 || Conv_83 + Relu_84) (Reformat)
[03/24/2023-12:56:22] [V] [TRT] Tactic: 1002 Time: 0.136064
[03/24/2023-12:56:22] [V] [TRT] Tactic: 0 Time: 0.14848
[03/24/2023-12:56:22] [V] [TRT] Fastest Tactic: 1002 Time: 0.136064
[03/24/2023-12:56:22] [V] [TRT] *************** Autotuning Reformat: Half(8294400,32400:2,180,1) -> Float(16588800,1,92160,512) ***************
[03/24/2023-12:56:22] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> Conv_62 + Relu_63 || Conv_65 + Relu_66 || Conv_68 + Relu_69 || Conv_71 + Relu_72 || Conv_74 + Relu_75 || Conv_77 + Relu_78 || Conv_80 + Relu_81 || Conv_83 + Relu_84) (Reformat)
[03/24/2023-12:56:22] [V] [TRT] Tactic: 1002 Time: 0.117376
[03/24/2023-12:56:22] [V] [TRT] Tactic: 0 Time: 0.198656
[03/24/2023-12:56:22] [V] [TRT] Fastest Tactic: 1002 Time: 0.117376
[03/24/2023-12:56:22] [V] [TRT] *************** Autotuning Reformat: Half(8294400,32400:2,180,1) -> Float(4147200,1:4,23040,128) ***************
[03/24/2023-12:56:22] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> Conv_62 + Relu_63 || Conv_65 + Relu_66 || Conv_68 + Relu_69 || Conv_71 + Relu_72 || Conv_74 + Relu_75 || Conv_77 + Relu_78 || Conv_80 + Relu_81 || Conv_83 + Relu_84) (Reformat)
[03/24/2023-12:56:22] [V] [TRT] Tactic: 1002 Time: 0.117376
[03/24/2023-12:56:22] [V] [TRT] Tactic: 0 Time: 0.226688
[03/24/2023-12:56:22] [V] [TRT] Fastest Tactic: 1002 Time: 0.117376
[03/24/2023-12:56:22] [V] [TRT] *************** Autotuning Reformat: Half(8294400,32400:2,180,1) -> Half(16588800,32400,180,1) ***************
[03/24/2023-12:56:22] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> Conv_62 + Relu_63 || Conv_65 + Relu_66 || Conv_68 + Relu_69 || Conv_71 + Relu_72 || Conv_74 + Relu_75 || Conv_77 + Relu_78 || Conv_80 + Relu_81 || Conv_83 + Relu_84) (Reformat)
[03/24/2023-12:56:22] [V] [TRT] Tactic: 1002 Time: 0.419456
[03/24/2023-12:56:22] [V] [TRT] Tactic: 0 Time: 0.148352
[03/24/2023-12:56:22] [V] [TRT] Fastest Tactic: 0 Time: 0.148352
[03/24/2023-12:56:22] [V] [TRT] *************** Autotuning Reformat: Half(8294400,32400:2,180,1) -> Half(2073600,1:8,11520,64) ***************
[03/24/2023-12:56:22] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> Conv_62 + Relu_63 || Conv_65 + Relu_66 || Conv_68 + Relu_69 || Conv_71 + Relu_72 || Conv_74 + Relu_75 || Conv_77 + Relu_78 || Conv_80 + Relu_81 || Conv_83 + Relu_84) (Reformat)
[03/24/2023-12:56:22] [V] [TRT] Tactic: 1002 Time: 0.117632
[03/24/2023-12:56:22] [V] [TRT] Tactic: 0 Time: 0.077952
[03/24/2023-12:56:22] [V] [TRT] Fastest Tactic: 0 Time: 0.077952
[03/24/2023-12:56:22] [V] [TRT] *************** Autotuning Reformat: Half(8294400,32400:2,180,1) -> Half(1036800,1:16,5760,32) ***************
[03/24/2023-12:56:22] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> Conv_62 + Relu_63 || Conv_65 + Relu_66 || Conv_68 + Relu_69 || Conv_71 + Relu_72 || Conv_74 + Relu_75 || Conv_77 + Relu_78 || Conv_80 + Relu_81 || Conv_83 + Relu_84) (Reformat)
[03/24/2023-12:56:22] [V] [TRT] Tactic: 1002 Time: 0.11776
[03/24/2023-12:56:22] [V] [TRT] Tactic: 0 Time: 0.209152
[03/24/2023-12:56:22] [V] [TRT] Fastest Tactic: 1002 Time: 0.11776
[03/24/2023-12:56:22] [V] [TRT] *************** Autotuning Reformat: Half(2073600,1:8,11520,64) -> Float(16588800,32400,180,1) ***************
[03/24/2023-12:56:22] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> Conv_62 + Relu_63 || Conv_65 + Relu_66 || Conv_68 + Relu_69 || Conv_71 + Relu_72 || Conv_74 + Relu_75 || Conv_77 + Relu_78 || Conv_80 + Relu_81 || Conv_83 + Relu_84) (Reformat)
[03/24/2023-12:56:22] [V] [TRT] Tactic: 1002 Time: 0.127232
[03/24/2023-12:56:22] [V] [TRT] Tactic: 0 Time: 0.086528
[03/24/2023-12:56:22] [V] [TRT] Fastest Tactic: 0 Time: 0.086528
[03/24/2023-12:56:22] [V] [TRT] *************** Autotuning Reformat: Half(2073600,1:8,11520,64) -> Float(16588800,1,92160,512) ***************
[03/24/2023-12:56:22] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> Conv_62 + Relu_63 || Conv_65 + Relu_66 || Conv_68 + Relu_69 || Conv_71 + Relu_72 || Conv_74 + Relu_75 || Conv_77 + Relu_78 || Conv_80 + Relu_81 || Conv_83 + Relu_84) (Reformat)
[03/24/2023-12:56:22] [V] [TRT] Tactic: 1002 Time: 0.102784
[03/24/2023-12:56:22] [V] [TRT] Tactic: 0 Time: 0.194688
[03/24/2023-12:56:22] [V] [TRT] Fastest Tactic: 1002 Time: 0.102784
[03/24/2023-12:56:22] [V] [TRT] *************** Autotuning Reformat: Half(2073600,1:8,11520,64) -> Float(4147200,1:4,23040,128) ***************
[03/24/2023-12:56:22] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> Conv_62 + Relu_63 || Conv_65 + Relu_66 || Conv_68 + Relu_69 || Conv_71 + Relu_72 || Conv_74 + Relu_75 || Conv_77 + Relu_78 || Conv_80 + Relu_81 || Conv_83 + Relu_84) (Reformat)
[03/24/2023-12:56:22] [V] [TRT] Tactic: 1002 Time: 0.102784
[03/24/2023-12:56:22] [V] [TRT] Tactic: 0 Time: 0.225408
[03/24/2023-12:56:22] [V] [TRT] Fastest Tactic: 1002 Time: 0.102784
[03/24/2023-12:56:22] [V] [TRT] *************** Autotuning Reformat: Half(2073600,1:8,11520,64) -> Half(16588800,32400,180,1) ***************
[03/24/2023-12:56:22] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> Conv_62 + Relu_63 || Conv_65 + Relu_66 || Conv_68 + Relu_69 || Conv_71 + Relu_72 || Conv_74 + Relu_75 || Conv_77 + Relu_78 || Conv_80 + Relu_81 || Conv_83 + Relu_84) (Reformat)
[03/24/2023-12:56:22] [V] [TRT] Tactic: 1002 Time: 0.320768
[03/24/2023-12:56:22] [V] [TRT] Tactic: 0 Time: 0.062976
[03/24/2023-12:56:22] [V] [TRT] Fastest Tactic: 0 Time: 0.062976
[03/24/2023-12:56:22] [V] [TRT] *************** Autotuning Reformat: Half(2073600,1:8,11520,64) -> Half(8294400,32400:2,180,1) ***************
[03/24/2023-12:56:22] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> Conv_62 + Relu_63 || Conv_65 + Relu_66 || Conv_68 + Relu_69 || Conv_71 + Relu_72 || Conv_74 + Relu_75 || Conv_77 + Relu_78 || Conv_80 + Relu_81 || Conv_83 + Relu_84) (Reformat)
[03/24/2023-12:56:22] [V] [TRT] Tactic: 1002 Time: 0.1568
[03/24/2023-12:56:22] [V] [TRT] Tactic: 0 Time: 0.061568
[03/24/2023-12:56:22] [V] [TRT] Fastest Tactic: 0 Time: 0.061568
[03/24/2023-12:56:22] [V] [TRT] *************** Autotuning Reformat: Half(2073600,1:8,11520,64) -> Half(1036800,1:16,5760,32) ***************
[03/24/2023-12:56:22] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> Conv_62 + Relu_63 || Conv_65 + Relu_66 || Conv_68 + Relu_69 || Conv_71 + Relu_72 || Conv_74 + Relu_75 || Conv_77 + Relu_78 || Conv_80 + Relu_81 || Conv_83 + Relu_84) (Reformat)
[03/24/2023-12:56:22] [V] [TRT] Tactic: 1002 Time: 0.103296
[03/24/2023-12:56:22] [V] [TRT] Tactic: 0 Time: 0.208128
[03/24/2023-12:56:22] [V] [TRT] Fastest Tactic: 1002 Time: 0.103296
[03/24/2023-12:56:22] [V] [TRT] *************** Autotuning Reformat: Half(1036800,1:16,5760,32) -> Float(16588800,32400,180,1) ***************
[03/24/2023-12:56:22] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> Conv_62 + Relu_63 || Conv_65 + Relu_66 || Conv_68 + Relu_69 || Conv_71 + Relu_72 || Conv_74 + Relu_75 || Conv_77 + Relu_78 || Conv_80 + Relu_81 || Conv_83 + Relu_84) (Reformat)
[03/24/2023-12:56:22] [V] [TRT] Tactic: 1002 Time: 0.127232
[03/24/2023-12:56:22] [V] [TRT] Tactic: 0 Time: 0.30208
[03/24/2023-12:56:22] [V] [TRT] Fastest Tactic: 1002 Time: 0.127232
[03/24/2023-12:56:22] [V] [TRT] *************** Autotuning Reformat: Half(1036800,1:16,5760,32) -> Float(16588800,1,92160,512) ***************
[03/24/2023-12:56:22] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> Conv_62 + Relu_63 || Conv_65 + Relu_66 || Conv_68 + Relu_69 || Conv_71 + Relu_72 || Conv_74 + Relu_75 || Conv_77 + Relu_78 || Conv_80 + Relu_81 || Conv_83 + Relu_84) (Reformat)
[03/24/2023-12:56:22] [V] [TRT] Tactic: 1002 Time: 0.10304
[03/24/2023-12:56:22] [V] [TRT] Tactic: 0 Time: 0.194688
[03/24/2023-12:56:22] [V] [TRT] Fastest Tactic: 1002 Time: 0.10304
[03/24/2023-12:56:22] [V] [TRT] *************** Autotuning Reformat: Half(1036800,1:16,5760,32) -> Float(4147200,1:4,23040,128) ***************
[03/24/2023-12:56:22] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> Conv_62 + Relu_63 || Conv_65 + Relu_66 || Conv_68 + Relu_69 || Conv_71 + Relu_72 || Conv_74 + Relu_75 || Conv_77 + Relu_78 || Conv_80 + Relu_81 || Conv_83 + Relu_84) (Reformat)
[03/24/2023-12:56:22] [V] [TRT] Tactic: 1002 Time: 0.102784
[03/24/2023-12:56:22] [V] [TRT] Tactic: 0 Time: 0.22528
[03/24/2023-12:56:22] [V] [TRT] Fastest Tactic: 1002 Time: 0.102784
[03/24/2023-12:56:22] [V] [TRT] *************** Autotuning Reformat: Half(1036800,1:16,5760,32) -> Half(16588800,32400,180,1) ***************
[03/24/2023-12:56:22] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> Conv_62 + Relu_63 || Conv_65 + Relu_66 || Conv_68 + Relu_69 || Conv_71 + Relu_72 || Conv_74 + Relu_75 || Conv_77 + Relu_78 || Conv_80 + Relu_81 || Conv_83 + Relu_84) (Reformat)
[03/24/2023-12:56:22] [V] [TRT] Tactic: 1002 Time: 0.320768
[03/24/2023-12:56:22] [V] [TRT] Tactic: 0 Time: 0.286208
[03/24/2023-12:56:22] [V] [TRT] Fastest Tactic: 0 Time: 0.286208
[03/24/2023-12:56:22] [V] [TRT] *************** Autotuning Reformat: Half(1036800,1:16,5760,32) -> Half(8294400,32400:2,180,1) ***************
[03/24/2023-12:56:22] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> Conv_62 + Relu_63 || Conv_65 + Relu_66 || Conv_68 + Relu_69 || Conv_71 + Relu_72 || Conv_74 + Relu_75 || Conv_77 + Relu_78 || Conv_80 + Relu_81 || Conv_83 + Relu_84) (Reformat)
[03/24/2023-12:56:22] [V] [TRT] Tactic: 1002 Time: 0.15744
[03/24/2023-12:56:22] [V] [TRT] Tactic: 0 Time: 0.306944
[03/24/2023-12:56:22] [V] [TRT] Fastest Tactic: 1002 Time: 0.15744
[03/24/2023-12:56:22] [V] [TRT] *************** Autotuning Reformat: Half(1036800,1:16,5760,32) -> Half(2073600,1:8,11520,64) ***************
[03/24/2023-12:56:22] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> Conv_62 + Relu_63 || Conv_65 + Relu_66 || Conv_68 + Relu_69 || Conv_71 + Relu_72 || Conv_74 + Relu_75 || Conv_77 + Relu_78 || Conv_80 + Relu_81 || Conv_83 + Relu_84) (Reformat)
[03/24/2023-12:56:22] [V] [TRT] Tactic: 1002 Time: 0.103424
[03/24/2023-12:56:22] [V] [TRT] Tactic: 0 Time: 0.208256
[03/24/2023-12:56:22] [V] [TRT] Fastest Tactic: 1002 Time: 0.103424
[03/24/2023-12:56:22] [V] [TRT] =============== Computing reformatting costs
[03/24/2023-12:56:22] [V] [TRT] *************** Autotuning Reformat: Float(16588800,32400,180,1) -> Float(16588800,1,92160,512) ***************
[03/24/2023-12:56:22] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(input.184 -> <out>) (Reformat)
[03/24/2023-12:56:22] [V] [TRT] Tactic: 1002 Time: 0.02688
[03/24/2023-12:56:22] [V] [TRT] Tactic: 0 Time: 0.029056
[03/24/2023-12:56:22] [V] [TRT] Fastest Tactic: 1002 Time: 0.02688
[03/24/2023-12:56:22] [V] [TRT] *************** Autotuning Reformat: Float(16588800,32400,180,1) -> Float(4147200,1:4,23040,128) ***************
[03/24/2023-12:56:22] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(input.184 -> <out>) (Reformat)
[03/24/2023-12:56:22] [V] [TRT] Tactic: 1002 Time: 0.02688
[03/24/2023-12:56:22] [V] [TRT] Tactic: 0 Time: 0.031744
[03/24/2023-12:56:22] [V] [TRT] Fastest Tactic: 1002 Time: 0.02688
[03/24/2023-12:56:22] [V] [TRT] *************** Autotuning Reformat: Float(16588800,32400,180,1) -> Half(16588800,32400,180,1) ***************
[03/24/2023-12:56:22] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(input.184 -> <out>) (Reformat)
[03/24/2023-12:56:22] [V] [TRT] Tactic: 1002 Time: 0.031744
[03/24/2023-12:56:22] [V] [TRT] Tactic: 0 Time: 0.027648
[03/24/2023-12:56:22] [V] [TRT] Fastest Tactic: 0 Time: 0.027648
[03/24/2023-12:56:22] [V] [TRT] *************** Autotuning Reformat: Float(16588800,32400,180,1) -> Half(8294400,32400:2,180,1) ***************
[03/24/2023-12:56:22] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(input.184 -> <out>) (Reformat)
[03/24/2023-12:56:22] [V] [TRT] Tactic: 1002 Time: 0.03264
[03/24/2023-12:56:22] [V] [TRT] Tactic: 0 Time: 0.03072
[03/24/2023-12:56:22] [V] [TRT] Fastest Tactic: 0 Time: 0.03072
[03/24/2023-12:56:22] [V] [TRT] *************** Autotuning Reformat: Float(16588800,32400,180,1) -> Half(2073600,1:8,11520,64) ***************
[03/24/2023-12:56:22] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(input.184 -> <out>) (Reformat)
[03/24/2023-12:56:22] [V] [TRT] Tactic: 1002 Time: 0.024576
[03/24/2023-12:56:22] [V] [TRT] Tactic: 0 Time: 0.031744
[03/24/2023-12:56:22] [V] [TRT] Fastest Tactic: 1002 Time: 0.024576
[03/24/2023-12:56:22] [V] [TRT] *************** Autotuning Reformat: Float(16588800,32400,180,1) -> Half(1036800,1:16,5760,32) ***************
[03/24/2023-12:56:22] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(input.184 -> <out>) (Reformat)
[03/24/2023-12:56:22] [V] [TRT] Tactic: 1002 Time: 0.024448
[03/24/2023-12:56:22] [V] [TRT] Tactic: 0 Time: 0.031744
[03/24/2023-12:56:22] [V] [TRT] Fastest Tactic: 1002 Time: 0.024448
[03/24/2023-12:56:22] [V] [TRT] *************** Autotuning Reformat: Float(16588800,1,92160,512) -> Float(16588800,32400,180,1) ***************
[03/24/2023-12:56:22] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(input.184 -> <out>) (Reformat)
[03/24/2023-12:56:22] [V] [TRT] Tactic: 1002 Time: 0.029696
[03/24/2023-12:56:22] [V] [TRT] Tactic: 0 Time: 0.042624
[03/24/2023-12:56:22] [V] [TRT] Fastest Tactic: 1002 Time: 0.029696
[03/24/2023-12:56:22] [V] [TRT] *************** Autotuning Reformat: Float(16588800,1,92160,512) -> Float(4147200,1:4,23040,128) ***************
[03/24/2023-12:56:22] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(input.184 -> <out>) (Reformat)
[03/24/2023-12:56:22] [V] [TRT] Tactic: 1002 Time: 0.02368
[03/24/2023-12:56:22] [V] [TRT] Tactic: 0 Time: 0.031744
[03/24/2023-12:56:22] [V] [TRT] Fastest Tactic: 1002 Time: 0.02368
[03/24/2023-12:56:22] [V] [TRT] *************** Autotuning Reformat: Float(16588800,1,92160,512) -> Half(16588800,32400,180,1) ***************
[03/24/2023-12:56:22] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(input.184 -> <out>) (Reformat)
[03/24/2023-12:56:22] [V] [TRT] Tactic: 1002 Time: 0.026624
[03/24/2023-12:56:22] [V] [TRT] Tactic: 0 Time: 0.04096
[03/24/2023-12:56:22] [V] [TRT] Fastest Tactic: 1002 Time: 0.026624
[03/24/2023-12:56:22] [V] [TRT] *************** Autotuning Reformat: Float(16588800,1,92160,512) -> Half(8294400,32400:2,180,1) ***************
[03/24/2023-12:56:22] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(input.184 -> <out>) (Reformat)
[03/24/2023-12:56:22] [V] [TRT] Tactic: 1002 Time: 0.031872
[03/24/2023-12:56:22] [V] [TRT] Tactic: 0 Time: 0.044032
[03/24/2023-12:56:22] [V] [TRT] Fastest Tactic: 1002 Time: 0.031872
[03/24/2023-12:56:22] [V] [TRT] *************** Autotuning Reformat: Float(16588800,1,92160,512) -> Half(2073600,1:8,11520,64) ***************
[03/24/2023-12:56:22] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(input.184 -> <out>) (Reformat)
[03/24/2023-12:56:22] [V] [TRT] Tactic: 1002 Time: 0.022528
[03/24/2023-12:56:22] [V] [TRT] Tactic: 0 Time: 0.031744
[03/24/2023-12:56:22] [V] [TRT] Fastest Tactic: 1002 Time: 0.022528
[03/24/2023-12:56:22] [V] [TRT] *************** Autotuning Reformat: Float(16588800,1,92160,512) -> Half(1036800,1:16,5760,32) ***************
[03/24/2023-12:56:22] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(input.184 -> <out>) (Reformat)
[03/24/2023-12:56:22] [V] [TRT] Tactic: 1002 Time: 0.022528
[03/24/2023-12:56:22] [V] [TRT] Tactic: 0 Time: 0.031744
[03/24/2023-12:56:22] [V] [TRT] Fastest Tactic: 1002 Time: 0.022528
[03/24/2023-12:56:22] [V] [TRT] *************** Autotuning Reformat: Float(4147200,1:4,23040,128) -> Float(16588800,32400,180,1) ***************
[03/24/2023-12:56:22] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(input.184 -> <out>) (Reformat)
[03/24/2023-12:56:22] [V] [TRT] Tactic: 1002 Time: 0.029824
[03/24/2023-12:56:22] [V] [TRT] Tactic: 0 Time: 0.042624
[03/24/2023-12:56:22] [V] [TRT] Fastest Tactic: 1002 Time: 0.029824
[03/24/2023-12:56:22] [V] [TRT] *************** Autotuning Reformat: Float(4147200,1:4,23040,128) -> Float(16588800,1,92160,512) ***************
[03/24/2023-12:56:22] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(input.184 -> <out>) (Reformat)
[03/24/2023-12:56:22] [V] [TRT] Tactic: 1002 Time: 0.023552
[03/24/2023-12:56:22] [V] [TRT] Tactic: 0 Time: 0.031744
[03/24/2023-12:56:22] [V] [TRT] Fastest Tactic: 1002 Time: 0.023552
[03/24/2023-12:56:22] [V] [TRT] *************** Autotuning Reformat: Float(4147200,1:4,23040,128) -> Half(16588800,32400,180,1) ***************
[03/24/2023-12:56:22] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(input.184 -> <out>) (Reformat)
[03/24/2023-12:56:22] [V] [TRT] Tactic: 1002 Time: 0.026624
[03/24/2023-12:56:22] [V] [TRT] Tactic: 0 Time: 0.041216
[03/24/2023-12:56:22] [V] [TRT] Fastest Tactic: 1002 Time: 0.026624
[03/24/2023-12:56:22] [V] [TRT] *************** Autotuning Reformat: Float(4147200,1:4,23040,128) -> Half(8294400,32400:2,180,1) ***************
[03/24/2023-12:56:22] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(input.184 -> <out>) (Reformat)
[03/24/2023-12:56:22] [V] [TRT] Tactic: 1002 Time: 0.031872
[03/24/2023-12:56:22] [V] [TRT] Tactic: 0 Time: 0.044032
[03/24/2023-12:56:22] [V] [TRT] Fastest Tactic: 1002 Time: 0.031872
[03/24/2023-12:56:22] [V] [TRT] *************** Autotuning Reformat: Float(4147200,1:4,23040,128) -> Half(2073600,1:8,11520,64) ***************
[03/24/2023-12:56:22] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(input.184 -> <out>) (Reformat)
[03/24/2023-12:56:22] [V] [TRT] Tactic: 1002 Time: 0.022528
[03/24/2023-12:56:22] [V] [TRT] Tactic: 0 Time: 0.03584
[03/24/2023-12:56:22] [V] [TRT] Fastest Tactic: 1002 Time: 0.022528
[03/24/2023-12:56:22] [V] [TRT] *************** Autotuning Reformat: Float(4147200,1:4,23040,128) -> Half(1036800,1:16,5760,32) ***************
[03/24/2023-12:56:22] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(input.184 -> <out>) (Reformat)
[03/24/2023-12:56:22] [V] [TRT] Tactic: 1002 Time: 0.022528
[03/24/2023-12:56:22] [V] [TRT] Tactic: 0 Time: 0.03584
[03/24/2023-12:56:22] [V] [TRT] Fastest Tactic: 1002 Time: 0.022528
[03/24/2023-12:56:22] [V] [TRT] *************** Autotuning Reformat: Half(16588800,32400,180,1) -> Float(16588800,32400,180,1) ***************
[03/24/2023-12:56:22] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(input.184 -> <out>) (Reformat)
[03/24/2023-12:56:22] [V] [TRT] Tactic: 1002 Time: 0.032
[03/24/2023-12:56:22] [V] [TRT] Tactic: 0 Time: 0.027776
[03/24/2023-12:56:22] [V] [TRT] Fastest Tactic: 0 Time: 0.027776
[03/24/2023-12:56:22] [V] [TRT] *************** Autotuning Reformat: Half(16588800,32400,180,1) -> Float(16588800,1,92160,512) ***************
[03/24/2023-12:56:22] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(input.184 -> <out>) (Reformat)
[03/24/2023-12:56:22] [V] [TRT] Tactic: 1002 Time: 0.024576
[03/24/2023-12:56:22] [V] [TRT] Tactic: 0 Time: 0.029824
[03/24/2023-12:56:22] [V] [TRT] Fastest Tactic: 1002 Time: 0.024576
[03/24/2023-12:56:22] [V] [TRT] *************** Autotuning Reformat: Half(16588800,32400,180,1) -> Float(4147200,1:4,23040,128) ***************
[03/24/2023-12:56:22] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(input.184 -> <out>) (Reformat)
[03/24/2023-12:56:22] [V] [TRT] Tactic: 1002 Time: 0.024576
[03/24/2023-12:56:22] [V] [TRT] Tactic: 0 Time: 0.032512
[03/24/2023-12:56:22] [V] [TRT] Fastest Tactic: 1002 Time: 0.024576
[03/24/2023-12:56:22] [V] [TRT] *************** Autotuning Reformat: Half(16588800,32400,180,1) -> Half(8294400,32400:2,180,1) ***************
[03/24/2023-12:56:22] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(input.184 -> <out>) (Reformat)
[03/24/2023-12:56:22] [V] [TRT] Tactic: 1002 Time: 0.024192
[03/24/2023-12:56:22] [V] [TRT] Tactic: 0 Time: 0.029568
[03/24/2023-12:56:22] [V] [TRT] Fastest Tactic: 1002 Time: 0.024192
[03/24/2023-12:56:22] [V] [TRT] *************** Autotuning Reformat: Half(16588800,32400,180,1) -> Half(2073600,1:8,11520,64) ***************
[03/24/2023-12:56:22] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(input.184 -> <out>) (Reformat)
[03/24/2023-12:56:22] [V] [TRT] Tactic: 1002 Time: 0.024576
[03/24/2023-12:56:22] [V] [TRT] Tactic: 0 Time: 0.031232
[03/24/2023-12:56:22] [V] [TRT] Fastest Tactic: 1002 Time: 0.024576
[03/24/2023-12:56:22] [V] [TRT] *************** Autotuning Reformat: Half(16588800,32400,180,1) -> Half(1036800,1:16,5760,32) ***************
[03/24/2023-12:56:22] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(input.184 -> <out>) (Reformat)
[03/24/2023-12:56:22] [V] [TRT] Tactic: 1002 Time: 0.024576
[03/24/2023-12:56:22] [V] [TRT] Tactic: 0 Time: 0.031488
[03/24/2023-12:56:22] [V] [TRT] Fastest Tactic: 1002 Time: 0.024576
[03/24/2023-12:56:22] [V] [TRT] *************** Autotuning Reformat: Half(8294400,32400:2,180,1) -> Float(16588800,32400,180,1) ***************
[03/24/2023-12:56:22] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(input.184 -> <out>) (Reformat)
[03/24/2023-12:56:22] [V] [TRT] Tactic: 1002 Time: 0.0288
[03/24/2023-12:56:22] [V] [TRT] Tactic: 0 Time: 0.025728
[03/24/2023-12:56:22] [V] [TRT] Fastest Tactic: 0 Time: 0.025728
[03/24/2023-12:56:22] [V] [TRT] *************** Autotuning Reformat: Half(8294400,32400:2,180,1) -> Float(16588800,1,92160,512) ***************
[03/24/2023-12:56:22] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(input.184 -> <out>) (Reformat)
[03/24/2023-12:56:22] [V] [TRT] Tactic: 1002 Time: 0.024576
[03/24/2023-12:56:22] [V] [TRT] Tactic: 0 Time: 0.032512
[03/24/2023-12:56:22] [V] [TRT] Fastest Tactic: 1002 Time: 0.024576
[03/24/2023-12:56:22] [V] [TRT] *************** Autotuning Reformat: Half(8294400,32400:2,180,1) -> Float(4147200,1:4,23040,128) ***************
[03/24/2023-12:56:22] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(input.184 -> <out>) (Reformat)
[03/24/2023-12:56:22] [V] [TRT] Tactic: 1002 Time: 0.024704
[03/24/2023-12:56:22] [V] [TRT] Tactic: 0 Time: 0.03584
[03/24/2023-12:56:22] [V] [TRT] Fastest Tactic: 1002 Time: 0.024704
[03/24/2023-12:56:22] [V] [TRT] *************** Autotuning Reformat: Half(8294400,32400:2,180,1) -> Half(16588800,32400,180,1) ***************
[03/24/2023-12:56:22] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(input.184 -> <out>) (Reformat)
[03/24/2023-12:56:22] [V] [TRT] Tactic: 1002 Time: 0.061952
[03/24/2023-12:56:22] [V] [TRT] Tactic: 0 Time: 0.0256
[03/24/2023-12:56:22] [V] [TRT] Fastest Tactic: 0 Time: 0.0256
[03/24/2023-12:56:22] [V] [TRT] *************** Autotuning Reformat: Half(8294400,32400:2,180,1) -> Half(2073600,1:8,11520,64) ***************
[03/24/2023-12:56:22] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(input.184 -> <out>) (Reformat)
[03/24/2023-12:56:22] [V] [TRT] Tactic: 1002 Time: 0.024704
[03/24/2023-12:56:22] [V] [TRT] Tactic: 0 Time: 0.014336
[03/24/2023-12:56:22] [V] [TRT] Fastest Tactic: 0 Time: 0.014336
[03/24/2023-12:56:22] [V] [TRT] *************** Autotuning Reformat: Half(8294400,32400:2,180,1) -> Half(1036800,1:16,5760,32) ***************
[03/24/2023-12:56:22] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(input.184 -> <out>) (Reformat)
[03/24/2023-12:56:22] [V] [TRT] Tactic: 1002 Time: 0.024576
[03/24/2023-12:56:22] [V] [TRT] Tactic: 0 Time: 0.033792
[03/24/2023-12:56:22] [V] [TRT] Fastest Tactic: 1002 Time: 0.024576
[03/24/2023-12:56:22] [V] [TRT] *************** Autotuning Reformat: Half(2073600,1:8,11520,64) -> Float(16588800,32400,180,1) ***************
[03/24/2023-12:56:22] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(input.184 -> <out>) (Reformat)
[03/24/2023-12:56:22] [V] [TRT] Tactic: 1002 Time: 0.02752
[03/24/2023-12:56:22] [V] [TRT] Tactic: 0 Time: 0.015488
[03/24/2023-12:56:22] [V] [TRT] Fastest Tactic: 0 Time: 0.015488
[03/24/2023-12:56:22] [V] [TRT] *************** Autotuning Reformat: Half(2073600,1:8,11520,64) -> Float(16588800,1,92160,512) ***************
[03/24/2023-12:56:22] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(input.184 -> <out>) (Reformat)
[03/24/2023-12:56:22] [V] [TRT] Tactic: 1002 Time: 0.022656
[03/24/2023-12:56:22] [V] [TRT] Tactic: 0 Time: 0.032384
[03/24/2023-12:56:22] [V] [TRT] Fastest Tactic: 1002 Time: 0.022656
[03/24/2023-12:56:22] [V] [TRT] *************** Autotuning Reformat: Half(2073600,1:8,11520,64) -> Float(4147200,1:4,23040,128) ***************
[03/24/2023-12:56:22] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(input.184 -> <out>) (Reformat)
[03/24/2023-12:56:22] [V] [TRT] Tactic: 1002 Time: 0.022656
[03/24/2023-12:56:22] [V] [TRT] Tactic: 0 Time: 0.03584
[03/24/2023-12:56:22] [V] [TRT] Fastest Tactic: 1002 Time: 0.022656
[03/24/2023-12:56:22] [V] [TRT] *************** Autotuning Reformat: Half(2073600,1:8,11520,64) -> Half(16588800,32400,180,1) ***************
[03/24/2023-12:56:22] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(input.184 -> <out>) (Reformat)
[03/24/2023-12:56:23] [V] [TRT] Tactic: 1002 Time: 0.054656
[03/24/2023-12:56:23] [V] [TRT] Tactic: 0 Time: 0.014336
[03/24/2023-12:56:23] [V] [TRT] Fastest Tactic: 0 Time: 0.014336
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(2073600,1:8,11520,64) -> Half(8294400,32400:2,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(input.184 -> <out>) (Reformat)
[03/24/2023-12:56:23] [V] [TRT] Tactic: 1002 Time: 0.031872
[03/24/2023-12:56:23] [V] [TRT] Tactic: 0 Time: 0.013824
[03/24/2023-12:56:23] [V] [TRT] Fastest Tactic: 0 Time: 0.013824
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(2073600,1:8,11520,64) -> Half(1036800,1:16,5760,32) ***************
[03/24/2023-12:56:23] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(input.184 -> <out>) (Reformat)
[03/24/2023-12:56:23] [V] [TRT] Tactic: 1002 Time: 0.022784
[03/24/2023-12:56:23] [V] [TRT] Tactic: 0 Time: 0.033792
[03/24/2023-12:56:23] [V] [TRT] Fastest Tactic: 1002 Time: 0.022784
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(1036800,1:16,5760,32) -> Float(16588800,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(input.184 -> <out>) (Reformat)
[03/24/2023-12:56:23] [V] [TRT] Tactic: 1002 Time: 0.02752
[03/24/2023-12:56:23] [V] [TRT] Tactic: 0 Time: 0.042368
[03/24/2023-12:56:23] [V] [TRT] Fastest Tactic: 1002 Time: 0.02752
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(1036800,1:16,5760,32) -> Float(16588800,1,92160,512) ***************
[03/24/2023-12:56:23] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(input.184 -> <out>) (Reformat)
[03/24/2023-12:56:23] [V] [TRT] Tactic: 1002 Time: 0.022656
[03/24/2023-12:56:23] [V] [TRT] Tactic: 0 Time: 0.03264
[03/24/2023-12:56:23] [V] [TRT] Fastest Tactic: 1002 Time: 0.022656
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(1036800,1:16,5760,32) -> Float(4147200,1:4,23040,128) ***************
[03/24/2023-12:56:23] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(input.184 -> <out>) (Reformat)
[03/24/2023-12:56:23] [V] [TRT] Tactic: 1002 Time: 0.022528
[03/24/2023-12:56:23] [V] [TRT] Tactic: 0 Time: 0.03584
[03/24/2023-12:56:23] [V] [TRT] Fastest Tactic: 1002 Time: 0.022528
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(1036800,1:16,5760,32) -> Half(16588800,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(input.184 -> <out>) (Reformat)
[03/24/2023-12:56:23] [V] [TRT] Tactic: 1002 Time: 0.0544
[03/24/2023-12:56:23] [V] [TRT] Tactic: 0 Time: 0.041344
[03/24/2023-12:56:23] [V] [TRT] Fastest Tactic: 0 Time: 0.041344
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(1036800,1:16,5760,32) -> Half(8294400,32400:2,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(input.184 -> <out>) (Reformat)
[03/24/2023-12:56:23] [V] [TRT] Tactic: 1002 Time: 0.032
[03/24/2023-12:56:23] [V] [TRT] Tactic: 0 Time: 0.043904
[03/24/2023-12:56:23] [V] [TRT] Fastest Tactic: 1002 Time: 0.032
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(1036800,1:16,5760,32) -> Half(2073600,1:8,11520,64) ***************
[03/24/2023-12:56:23] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(input.184 -> <out>) (Reformat)
[03/24/2023-12:56:23] [V] [TRT] Tactic: 1002 Time: 0.022528
[03/24/2023-12:56:23] [V] [TRT] Tactic: 0 Time: 0.033792
[03/24/2023-12:56:23] [V] [TRT] Fastest Tactic: 1002 Time: 0.022528
[03/24/2023-12:56:23] [V] [TRT] =============== Computing reformatting costs
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(64800,32400,180,1) -> Half(64800,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> reg_0) (Reformat)
[03/24/2023-12:56:23] [V] [TRT] Tactic: 1002 Time: 0.012288
[03/24/2023-12:56:23] [V] [TRT] Tactic: 0 Time: 0.009984
[03/24/2023-12:56:23] [V] [TRT] Fastest Tactic: 0 Time: 0.009984
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(64800,1,360,2) -> Half(64800,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> reg_0) (Reformat)
[03/24/2023-12:56:23] [V] [TRT] Tactic: 1002 Time: 0.017664
[03/24/2023-12:56:23] [V] [TRT] Tactic: 0 Time: 0.01024
[03/24/2023-12:56:23] [V] [TRT] Fastest Tactic: 0 Time: 0.01024
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(32400,1:4,180,1) -> Half(64800,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> reg_0) (Reformat)
[03/24/2023-12:56:23] [V] [TRT] Tactic: 1002 Time: 0.017536
[03/24/2023-12:56:23] [V] [TRT] Tactic: 0 Time: 0.01024
[03/24/2023-12:56:23] [V] [TRT] Fastest Tactic: 0 Time: 0.01024
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(32400,32400:2,180,1) -> Half(64800,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> reg_0) (Reformat)
[03/24/2023-12:56:23] [V] [TRT] Tactic: 1002 Time: 0.033664
[03/24/2023-12:56:23] [V] [TRT] Tactic: 0 Time: 0.009216
[03/24/2023-12:56:23] [V] [TRT] Fastest Tactic: 0 Time: 0.009216
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(32400,1:8,180,1) -> Half(64800,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> reg_0) (Reformat)
[03/24/2023-12:56:23] [V] [TRT] Tactic: 1002 Time: 0.033664
[03/24/2023-12:56:23] [V] [TRT] Tactic: 0 Time: 0.009728
[03/24/2023-12:56:23] [V] [TRT] Fastest Tactic: 0 Time: 0.009728
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(32400,1:16,180,1) -> Half(64800,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> reg_0) (Reformat)
[03/24/2023-12:56:23] [V] [TRT] Tactic: 1002 Time: 0.033792
[03/24/2023-12:56:23] [V] [TRT] Tactic: 0 Time: 0.011008
[03/24/2023-12:56:23] [V] [TRT] Fastest Tactic: 0 Time: 0.011008
[03/24/2023-12:56:23] [V] [TRT] =============== Computing reformatting costs
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(16588800,32400,180,1) -> Float(16588800,1,92160,512) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(16588800,32400,180,1) -> Float(4147200,1:4,23040,128) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(16588800,32400,180,1) -> Half(16588800,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(16588800,32400,180,1) -> Half(8294400,32400:2,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(16588800,32400,180,1) -> Half(2073600,1:8,11520,64) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(16588800,32400,180,1) -> Half(1036800,1:16,5760,32) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(16588800,1,92160,512) -> Float(16588800,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(16588800,1,92160,512) -> Float(4147200,1:4,23040,128) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(16588800,1,92160,512) -> Half(16588800,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(16588800,1,92160,512) -> Half(8294400,32400:2,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(16588800,1,92160,512) -> Half(2073600,1:8,11520,64) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(16588800,1,92160,512) -> Half(1036800,1:16,5760,32) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(4147200,1:4,23040,128) -> Float(16588800,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(4147200,1:4,23040,128) -> Float(16588800,1,92160,512) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(4147200,1:4,23040,128) -> Half(16588800,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(4147200,1:4,23040,128) -> Half(8294400,32400:2,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(4147200,1:4,23040,128) -> Half(2073600,1:8,11520,64) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(4147200,1:4,23040,128) -> Half(1036800,1:16,5760,32) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(16588800,32400,180,1) -> Float(16588800,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(16588800,32400,180,1) -> Float(16588800,1,92160,512) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(16588800,32400,180,1) -> Float(4147200,1:4,23040,128) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(16588800,32400,180,1) -> Half(8294400,32400:2,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(16588800,32400,180,1) -> Half(2073600,1:8,11520,64) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(16588800,32400,180,1) -> Half(1036800,1:16,5760,32) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(8294400,32400:2,180,1) -> Float(16588800,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(8294400,32400:2,180,1) -> Float(16588800,1,92160,512) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(8294400,32400:2,180,1) -> Float(4147200,1:4,23040,128) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(8294400,32400:2,180,1) -> Half(16588800,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(8294400,32400:2,180,1) -> Half(2073600,1:8,11520,64) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(8294400,32400:2,180,1) -> Half(1036800,1:16,5760,32) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(2073600,1:8,11520,64) -> Float(16588800,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(2073600,1:8,11520,64) -> Float(16588800,1,92160,512) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(2073600,1:8,11520,64) -> Float(4147200,1:4,23040,128) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(2073600,1:8,11520,64) -> Half(16588800,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(2073600,1:8,11520,64) -> Half(8294400,32400:2,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(2073600,1:8,11520,64) -> Half(1036800,1:16,5760,32) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(1036800,1:16,5760,32) -> Float(16588800,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(1036800,1:16,5760,32) -> Float(16588800,1,92160,512) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(1036800,1:16,5760,32) -> Float(4147200,1:4,23040,128) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(1036800,1:16,5760,32) -> Half(16588800,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(1036800,1:16,5760,32) -> Half(8294400,32400:2,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(1036800,1:16,5760,32) -> Half(2073600,1:8,11520,64) ***************
[03/24/2023-12:56:23] [V] [TRT] =============== Computing reformatting costs
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(32400,32400,180,1) -> Half(32400,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> height_0) (Reformat)
[03/24/2023-12:56:23] [V] [TRT] Tactic: 1002 Time: 0.01216
[03/24/2023-12:56:23] [V] [TRT] Tactic: 0 Time: 0.0096
[03/24/2023-12:56:23] [V] [TRT] Fastest Tactic: 0 Time: 0.0096
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(32400,1,180,1) -> Half(32400,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> height_0) (Reformat)
[03/24/2023-12:56:23] [V] [TRT] Tactic: 1002 Time: 0.012288
[03/24/2023-12:56:23] [V] [TRT] Tactic: 0 Time: 0.01024
[03/24/2023-12:56:23] [V] [TRT] Fastest Tactic: 0 Time: 0.01024
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(32400,1:4,180,1) -> Half(32400,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> height_0) (Reformat)
[03/24/2023-12:56:23] [V] [TRT] Tactic: 1002 Time: 0.017408
[03/24/2023-12:56:23] [V] [TRT] Tactic: 0 Time: 0.01024
[03/24/2023-12:56:23] [V] [TRT] Fastest Tactic: 0 Time: 0.01024
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(32400,32400:2,180,1) -> Half(32400,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> height_0) (Reformat)
[03/24/2023-12:56:23] [V] [TRT] Tactic: 1002 Time: 0.033408
[03/24/2023-12:56:23] [V] [TRT] Tactic: 0 Time: 0.009216
[03/24/2023-12:56:23] [V] [TRT] Fastest Tactic: 0 Time: 0.009216
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(32400,1:8,180,1) -> Half(32400,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> height_0) (Reformat)
[03/24/2023-12:56:23] [V] [TRT] Tactic: 1002 Time: 0.033792
[03/24/2023-12:56:23] [V] [TRT] Tactic: 0 Time: 0.0096
[03/24/2023-12:56:23] [V] [TRT] Fastest Tactic: 0 Time: 0.0096
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(32400,1:16,180,1) -> Half(32400,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> height_0) (Reformat)
[03/24/2023-12:56:23] [V] [TRT] Tactic: 1002 Time: 0.033792
[03/24/2023-12:56:23] [V] [TRT] Tactic: 0 Time: 0.01024
[03/24/2023-12:56:23] [V] [TRT] Fastest Tactic: 0 Time: 0.01024
[03/24/2023-12:56:23] [V] [TRT] =============== Computing reformatting costs
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(16588800,32400,180,1) -> Float(16588800,1,92160,512) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(16588800,32400,180,1) -> Float(4147200,1:4,23040,128) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(16588800,32400,180,1) -> Half(16588800,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(16588800,32400,180,1) -> Half(8294400,32400:2,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(16588800,32400,180,1) -> Half(2073600,1:8,11520,64) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(16588800,32400,180,1) -> Half(1036800,1:16,5760,32) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(16588800,1,92160,512) -> Float(16588800,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(16588800,1,92160,512) -> Float(4147200,1:4,23040,128) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(16588800,1,92160,512) -> Half(16588800,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(16588800,1,92160,512) -> Half(8294400,32400:2,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(16588800,1,92160,512) -> Half(2073600,1:8,11520,64) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(16588800,1,92160,512) -> Half(1036800,1:16,5760,32) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(4147200,1:4,23040,128) -> Float(16588800,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(4147200,1:4,23040,128) -> Float(16588800,1,92160,512) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(4147200,1:4,23040,128) -> Half(16588800,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(4147200,1:4,23040,128) -> Half(8294400,32400:2,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(4147200,1:4,23040,128) -> Half(2073600,1:8,11520,64) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(4147200,1:4,23040,128) -> Half(1036800,1:16,5760,32) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(16588800,32400,180,1) -> Float(16588800,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(16588800,32400,180,1) -> Float(16588800,1,92160,512) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(16588800,32400,180,1) -> Float(4147200,1:4,23040,128) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(16588800,32400,180,1) -> Half(8294400,32400:2,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(16588800,32400,180,1) -> Half(2073600,1:8,11520,64) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(16588800,32400,180,1) -> Half(1036800,1:16,5760,32) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(8294400,32400:2,180,1) -> Float(16588800,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(8294400,32400:2,180,1) -> Float(16588800,1,92160,512) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(8294400,32400:2,180,1) -> Float(4147200,1:4,23040,128) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(8294400,32400:2,180,1) -> Half(16588800,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(8294400,32400:2,180,1) -> Half(2073600,1:8,11520,64) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(8294400,32400:2,180,1) -> Half(1036800,1:16,5760,32) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(2073600,1:8,11520,64) -> Float(16588800,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(2073600,1:8,11520,64) -> Float(16588800,1,92160,512) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(2073600,1:8,11520,64) -> Float(4147200,1:4,23040,128) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(2073600,1:8,11520,64) -> Half(16588800,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(2073600,1:8,11520,64) -> Half(8294400,32400:2,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(2073600,1:8,11520,64) -> Half(1036800,1:16,5760,32) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(1036800,1:16,5760,32) -> Float(16588800,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(1036800,1:16,5760,32) -> Float(16588800,1,92160,512) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(1036800,1:16,5760,32) -> Float(4147200,1:4,23040,128) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(1036800,1:16,5760,32) -> Half(16588800,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(1036800,1:16,5760,32) -> Half(8294400,32400:2,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(1036800,1:16,5760,32) -> Half(2073600,1:8,11520,64) ***************
[03/24/2023-12:56:23] [V] [TRT] =============== Computing reformatting costs
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(97200,32400,180,1) -> Half(97200,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> dim_0) (Reformat)
[03/24/2023-12:56:23] [V] [TRT] Tactic: 1002 Time: 0.012288
[03/24/2023-12:56:23] [V] [TRT] Tactic: 0 Time: 0.01024
[03/24/2023-12:56:23] [V] [TRT] Fastest Tactic: 0 Time: 0.01024
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(97200,1,540,3) -> Half(97200,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> dim_0) (Reformat)
[03/24/2023-12:56:23] [V] [TRT] Tactic: 1002 Time: 0.01792
[03/24/2023-12:56:23] [V] [TRT] Tactic: 0 Time: 0.011008
[03/24/2023-12:56:23] [V] [TRT] Fastest Tactic: 0 Time: 0.011008
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(32400,1:4,180,1) -> Half(97200,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> dim_0) (Reformat)
[03/24/2023-12:56:23] [V] [TRT] Tactic: 1002 Time: 0.017408
[03/24/2023-12:56:23] [V] [TRT] Tactic: 0 Time: 0.011136
[03/24/2023-12:56:23] [V] [TRT] Fastest Tactic: 0 Time: 0.011136
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(64800,32400:2,180,1) -> Half(97200,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> dim_0) (Reformat)
[03/24/2023-12:56:23] [V] [TRT] Tactic: 1002 Time: 0.033792
[03/24/2023-12:56:23] [V] [TRT] Tactic: 0 Time: 0.0096
[03/24/2023-12:56:23] [V] [TRT] Fastest Tactic: 0 Time: 0.0096
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(32400,1:8,180,1) -> Half(97200,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> dim_0) (Reformat)
[03/24/2023-12:56:23] [V] [TRT] Tactic: 1002 Time: 0.033792
[03/24/2023-12:56:23] [V] [TRT] Tactic: 0 Time: 0.0096
[03/24/2023-12:56:23] [V] [TRT] Fastest Tactic: 0 Time: 0.0096
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(32400,1:16,180,1) -> Half(97200,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> dim_0) (Reformat)
[03/24/2023-12:56:23] [V] [TRT] Tactic: 1002 Time: 0.033792
[03/24/2023-12:56:23] [V] [TRT] Tactic: 0 Time: 0.011264
[03/24/2023-12:56:23] [V] [TRT] Fastest Tactic: 0 Time: 0.011264
[03/24/2023-12:56:23] [V] [TRT] =============== Computing reformatting costs
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(16588800,32400,180,1) -> Float(16588800,1,92160,512) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(16588800,32400,180,1) -> Float(4147200,1:4,23040,128) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(16588800,32400,180,1) -> Half(16588800,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(16588800,32400,180,1) -> Half(8294400,32400:2,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(16588800,32400,180,1) -> Half(2073600,1:8,11520,64) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(16588800,32400,180,1) -> Half(1036800,1:16,5760,32) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(16588800,1,92160,512) -> Float(16588800,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(16588800,1,92160,512) -> Float(4147200,1:4,23040,128) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(16588800,1,92160,512) -> Half(16588800,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(16588800,1,92160,512) -> Half(8294400,32400:2,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(16588800,1,92160,512) -> Half(2073600,1:8,11520,64) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(16588800,1,92160,512) -> Half(1036800,1:16,5760,32) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(4147200,1:4,23040,128) -> Float(16588800,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(4147200,1:4,23040,128) -> Float(16588800,1,92160,512) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(4147200,1:4,23040,128) -> Half(16588800,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(4147200,1:4,23040,128) -> Half(8294400,32400:2,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(4147200,1:4,23040,128) -> Half(2073600,1:8,11520,64) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(4147200,1:4,23040,128) -> Half(1036800,1:16,5760,32) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(16588800,32400,180,1) -> Float(16588800,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(16588800,32400,180,1) -> Float(16588800,1,92160,512) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(16588800,32400,180,1) -> Float(4147200,1:4,23040,128) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(16588800,32400,180,1) -> Half(8294400,32400:2,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(16588800,32400,180,1) -> Half(2073600,1:8,11520,64) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(16588800,32400,180,1) -> Half(1036800,1:16,5760,32) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(8294400,32400:2,180,1) -> Float(16588800,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(8294400,32400:2,180,1) -> Float(16588800,1,92160,512) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(8294400,32400:2,180,1) -> Float(4147200,1:4,23040,128) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(8294400,32400:2,180,1) -> Half(16588800,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(8294400,32400:2,180,1) -> Half(2073600,1:8,11520,64) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(8294400,32400:2,180,1) -> Half(1036800,1:16,5760,32) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(2073600,1:8,11520,64) -> Float(16588800,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(2073600,1:8,11520,64) -> Float(16588800,1,92160,512) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(2073600,1:8,11520,64) -> Float(4147200,1:4,23040,128) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(2073600,1:8,11520,64) -> Half(16588800,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(2073600,1:8,11520,64) -> Half(8294400,32400:2,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(2073600,1:8,11520,64) -> Half(1036800,1:16,5760,32) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(1036800,1:16,5760,32) -> Float(16588800,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(1036800,1:16,5760,32) -> Float(16588800,1,92160,512) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(1036800,1:16,5760,32) -> Float(4147200,1:4,23040,128) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(1036800,1:16,5760,32) -> Half(16588800,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(1036800,1:16,5760,32) -> Half(8294400,32400:2,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(1036800,1:16,5760,32) -> Half(2073600,1:8,11520,64) ***************
[03/24/2023-12:56:23] [V] [TRT] =============== Computing reformatting costs
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(64800,32400,180,1) -> Half(64800,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(64800,1,360,2) -> Half(64800,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(32400,1:4,180,1) -> Half(64800,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(32400,32400:2,180,1) -> Half(64800,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(32400,1:8,180,1) -> Half(64800,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(32400,1:16,180,1) -> Half(64800,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] =============== Computing reformatting costs
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(16588800,32400,180,1) -> Float(16588800,1,92160,512) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(16588800,32400,180,1) -> Float(4147200,1:4,23040,128) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(16588800,32400,180,1) -> Half(16588800,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(16588800,32400,180,1) -> Half(8294400,32400:2,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(16588800,32400,180,1) -> Half(2073600,1:8,11520,64) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(16588800,32400,180,1) -> Half(1036800,1:16,5760,32) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(16588800,1,92160,512) -> Float(16588800,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(16588800,1,92160,512) -> Float(4147200,1:4,23040,128) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(16588800,1,92160,512) -> Half(16588800,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(16588800,1,92160,512) -> Half(8294400,32400:2,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(16588800,1,92160,512) -> Half(2073600,1:8,11520,64) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(16588800,1,92160,512) -> Half(1036800,1:16,5760,32) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(4147200,1:4,23040,128) -> Float(16588800,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(4147200,1:4,23040,128) -> Float(16588800,1,92160,512) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(4147200,1:4,23040,128) -> Half(16588800,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(4147200,1:4,23040,128) -> Half(8294400,32400:2,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(4147200,1:4,23040,128) -> Half(2073600,1:8,11520,64) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(4147200,1:4,23040,128) -> Half(1036800,1:16,5760,32) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(16588800,32400,180,1) -> Float(16588800,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(16588800,32400,180,1) -> Float(16588800,1,92160,512) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(16588800,32400,180,1) -> Float(4147200,1:4,23040,128) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(16588800,32400,180,1) -> Half(8294400,32400:2,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(16588800,32400,180,1) -> Half(2073600,1:8,11520,64) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(16588800,32400,180,1) -> Half(1036800,1:16,5760,32) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(8294400,32400:2,180,1) -> Float(16588800,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(8294400,32400:2,180,1) -> Float(16588800,1,92160,512) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(8294400,32400:2,180,1) -> Float(4147200,1:4,23040,128) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(8294400,32400:2,180,1) -> Half(16588800,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(8294400,32400:2,180,1) -> Half(2073600,1:8,11520,64) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(8294400,32400:2,180,1) -> Half(1036800,1:16,5760,32) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(2073600,1:8,11520,64) -> Float(16588800,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(2073600,1:8,11520,64) -> Float(16588800,1,92160,512) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(2073600,1:8,11520,64) -> Float(4147200,1:4,23040,128) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(2073600,1:8,11520,64) -> Half(16588800,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(2073600,1:8,11520,64) -> Half(8294400,32400:2,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(2073600,1:8,11520,64) -> Half(1036800,1:16,5760,32) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(1036800,1:16,5760,32) -> Float(16588800,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(1036800,1:16,5760,32) -> Float(16588800,1,92160,512) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(1036800,1:16,5760,32) -> Float(4147200,1:4,23040,128) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(1036800,1:16,5760,32) -> Half(16588800,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(1036800,1:16,5760,32) -> Half(8294400,32400:2,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(1036800,1:16,5760,32) -> Half(2073600,1:8,11520,64) ***************
[03/24/2023-12:56:23] [V] [TRT] =============== Computing reformatting costs
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(64800,32400,180,1) -> Half(64800,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(64800,1,360,2) -> Half(64800,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(32400,1:4,180,1) -> Half(64800,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(32400,32400:2,180,1) -> Half(64800,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(32400,1:8,180,1) -> Half(64800,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(32400,1:16,180,1) -> Half(64800,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] =============== Computing reformatting costs
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(16588800,32400,180,1) -> Float(16588800,1,92160,512) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(16588800,32400,180,1) -> Float(4147200,1:4,23040,128) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(16588800,32400,180,1) -> Half(16588800,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(16588800,32400,180,1) -> Half(8294400,32400:2,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(16588800,32400,180,1) -> Half(2073600,1:8,11520,64) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(16588800,32400,180,1) -> Half(1036800,1:16,5760,32) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(16588800,1,92160,512) -> Float(16588800,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(16588800,1,92160,512) -> Float(4147200,1:4,23040,128) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(16588800,1,92160,512) -> Half(16588800,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(16588800,1,92160,512) -> Half(8294400,32400:2,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(16588800,1,92160,512) -> Half(2073600,1:8,11520,64) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(16588800,1,92160,512) -> Half(1036800,1:16,5760,32) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(4147200,1:4,23040,128) -> Float(16588800,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(4147200,1:4,23040,128) -> Float(16588800,1,92160,512) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(4147200,1:4,23040,128) -> Half(16588800,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(4147200,1:4,23040,128) -> Half(8294400,32400:2,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(4147200,1:4,23040,128) -> Half(2073600,1:8,11520,64) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(4147200,1:4,23040,128) -> Half(1036800,1:16,5760,32) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(16588800,32400,180,1) -> Float(16588800,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(16588800,32400,180,1) -> Float(16588800,1,92160,512) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(16588800,32400,180,1) -> Float(4147200,1:4,23040,128) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(16588800,32400,180,1) -> Half(8294400,32400:2,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(16588800,32400,180,1) -> Half(2073600,1:8,11520,64) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(16588800,32400,180,1) -> Half(1036800,1:16,5760,32) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(8294400,32400:2,180,1) -> Float(16588800,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(8294400,32400:2,180,1) -> Float(16588800,1,92160,512) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(8294400,32400:2,180,1) -> Float(4147200,1:4,23040,128) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(8294400,32400:2,180,1) -> Half(16588800,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(8294400,32400:2,180,1) -> Half(2073600,1:8,11520,64) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(8294400,32400:2,180,1) -> Half(1036800,1:16,5760,32) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(2073600,1:8,11520,64) -> Float(16588800,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(2073600,1:8,11520,64) -> Float(16588800,1,92160,512) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(2073600,1:8,11520,64) -> Float(4147200,1:4,23040,128) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(2073600,1:8,11520,64) -> Half(16588800,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(2073600,1:8,11520,64) -> Half(8294400,32400:2,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(2073600,1:8,11520,64) -> Half(1036800,1:16,5760,32) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(1036800,1:16,5760,32) -> Float(16588800,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(1036800,1:16,5760,32) -> Float(16588800,1,92160,512) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(1036800,1:16,5760,32) -> Float(4147200,1:4,23040,128) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(1036800,1:16,5760,32) -> Half(16588800,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(1036800,1:16,5760,32) -> Half(8294400,32400:2,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(1036800,1:16,5760,32) -> Half(2073600,1:8,11520,64) ***************
[03/24/2023-12:56:23] [V] [TRT] =============== Computing reformatting costs
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(32400,32400,180,1) -> Half(32400,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(32400,1,180,1) -> Half(32400,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(32400,1:4,180,1) -> Half(32400,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(32400,32400:2,180,1) -> Half(32400,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(32400,1:8,180,1) -> Half(32400,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(32400,1:16,180,1) -> Half(32400,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] =============== Computing reformatting costs
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(16588800,32400,180,1) -> Float(16588800,1,92160,512) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(16588800,32400,180,1) -> Float(4147200,1:4,23040,128) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(16588800,32400,180,1) -> Half(16588800,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(16588800,32400,180,1) -> Half(8294400,32400:2,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(16588800,32400,180,1) -> Half(2073600,1:8,11520,64) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(16588800,32400,180,1) -> Half(1036800,1:16,5760,32) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(16588800,1,92160,512) -> Float(16588800,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(16588800,1,92160,512) -> Float(4147200,1:4,23040,128) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(16588800,1,92160,512) -> Half(16588800,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(16588800,1,92160,512) -> Half(8294400,32400:2,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(16588800,1,92160,512) -> Half(2073600,1:8,11520,64) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(16588800,1,92160,512) -> Half(1036800,1:16,5760,32) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(4147200,1:4,23040,128) -> Float(16588800,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(4147200,1:4,23040,128) -> Float(16588800,1,92160,512) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(4147200,1:4,23040,128) -> Half(16588800,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(4147200,1:4,23040,128) -> Half(8294400,32400:2,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(4147200,1:4,23040,128) -> Half(2073600,1:8,11520,64) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(4147200,1:4,23040,128) -> Half(1036800,1:16,5760,32) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(16588800,32400,180,1) -> Float(16588800,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(16588800,32400,180,1) -> Float(16588800,1,92160,512) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(16588800,32400,180,1) -> Float(4147200,1:4,23040,128) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(16588800,32400,180,1) -> Half(8294400,32400:2,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(16588800,32400,180,1) -> Half(2073600,1:8,11520,64) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(16588800,32400,180,1) -> Half(1036800,1:16,5760,32) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(8294400,32400:2,180,1) -> Float(16588800,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(8294400,32400:2,180,1) -> Float(16588800,1,92160,512) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(8294400,32400:2,180,1) -> Float(4147200,1:4,23040,128) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(8294400,32400:2,180,1) -> Half(16588800,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(8294400,32400:2,180,1) -> Half(2073600,1:8,11520,64) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(8294400,32400:2,180,1) -> Half(1036800,1:16,5760,32) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(2073600,1:8,11520,64) -> Float(16588800,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(2073600,1:8,11520,64) -> Float(16588800,1,92160,512) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(2073600,1:8,11520,64) -> Float(4147200,1:4,23040,128) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(2073600,1:8,11520,64) -> Half(16588800,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(2073600,1:8,11520,64) -> Half(8294400,32400:2,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(2073600,1:8,11520,64) -> Half(1036800,1:16,5760,32) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(1036800,1:16,5760,32) -> Float(16588800,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(1036800,1:16,5760,32) -> Float(16588800,1,92160,512) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(1036800,1:16,5760,32) -> Float(4147200,1:4,23040,128) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(1036800,1:16,5760,32) -> Half(16588800,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(1036800,1:16,5760,32) -> Half(8294400,32400:2,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(1036800,1:16,5760,32) -> Half(2073600,1:8,11520,64) ***************
[03/24/2023-12:56:23] [V] [TRT] =============== Computing reformatting costs
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(64800,32400,180,1) -> Half(64800,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(64800,1,360,2) -> Half(64800,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(32400,1:4,180,1) -> Half(64800,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(32400,32400:2,180,1) -> Half(64800,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(32400,1:8,180,1) -> Half(64800,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(32400,1:16,180,1) -> Half(64800,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] =============== Computing reformatting costs
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(16588800,32400,180,1) -> Float(16588800,1,92160,512) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(16588800,32400,180,1) -> Float(4147200,1:4,23040,128) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(16588800,32400,180,1) -> Half(16588800,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(16588800,32400,180,1) -> Half(8294400,32400:2,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(16588800,32400,180,1) -> Half(2073600,1:8,11520,64) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(16588800,32400,180,1) -> Half(1036800,1:16,5760,32) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(16588800,1,92160,512) -> Float(16588800,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(16588800,1,92160,512) -> Float(4147200,1:4,23040,128) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(16588800,1,92160,512) -> Half(16588800,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(16588800,1,92160,512) -> Half(8294400,32400:2,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(16588800,1,92160,512) -> Half(2073600,1:8,11520,64) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(16588800,1,92160,512) -> Half(1036800,1:16,5760,32) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(4147200,1:4,23040,128) -> Float(16588800,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(4147200,1:4,23040,128) -> Float(16588800,1,92160,512) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(4147200,1:4,23040,128) -> Half(16588800,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(4147200,1:4,23040,128) -> Half(8294400,32400:2,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(4147200,1:4,23040,128) -> Half(2073600,1:8,11520,64) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(4147200,1:4,23040,128) -> Half(1036800,1:16,5760,32) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(16588800,32400,180,1) -> Float(16588800,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(16588800,32400,180,1) -> Float(16588800,1,92160,512) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(16588800,32400,180,1) -> Float(4147200,1:4,23040,128) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(16588800,32400,180,1) -> Half(8294400,32400:2,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(16588800,32400,180,1) -> Half(2073600,1:8,11520,64) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(16588800,32400,180,1) -> Half(1036800,1:16,5760,32) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(8294400,32400:2,180,1) -> Float(16588800,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(8294400,32400:2,180,1) -> Float(16588800,1,92160,512) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(8294400,32400:2,180,1) -> Float(4147200,1:4,23040,128) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(8294400,32400:2,180,1) -> Half(16588800,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(8294400,32400:2,180,1) -> Half(2073600,1:8,11520,64) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(8294400,32400:2,180,1) -> Half(1036800,1:16,5760,32) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(2073600,1:8,11520,64) -> Float(16588800,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(2073600,1:8,11520,64) -> Float(16588800,1,92160,512) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(2073600,1:8,11520,64) -> Float(4147200,1:4,23040,128) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(2073600,1:8,11520,64) -> Half(16588800,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(2073600,1:8,11520,64) -> Half(8294400,32400:2,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(2073600,1:8,11520,64) -> Half(1036800,1:16,5760,32) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(1036800,1:16,5760,32) -> Float(16588800,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(1036800,1:16,5760,32) -> Float(16588800,1,92160,512) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(1036800,1:16,5760,32) -> Float(4147200,1:4,23040,128) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(1036800,1:16,5760,32) -> Half(16588800,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(1036800,1:16,5760,32) -> Half(8294400,32400:2,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(1036800,1:16,5760,32) -> Half(2073600,1:8,11520,64) ***************
[03/24/2023-12:56:23] [V] [TRT] =============== Computing reformatting costs
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(32400,32400,180,1) -> Half(32400,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(32400,1,180,1) -> Half(32400,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(32400,1:4,180,1) -> Half(32400,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(32400,32400:2,180,1) -> Half(32400,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(32400,1:8,180,1) -> Half(32400,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(32400,1:16,180,1) -> Half(32400,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] =============== Computing reformatting costs
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(2073600,32400,180,1) -> Float(2073600,1,11520,64) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(2073600,32400,180,1) -> Float(518400,1:4,2880,16) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(2073600,32400,180,1) -> Half(2073600,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(2073600,32400,180,1) -> Half(1036800,32400:2,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(2073600,32400,180,1) -> Half(259200,1:8,1440,8) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(2073600,32400,180,1) -> Half(129600,1:16,720,4) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(2073600,1,11520,64) -> Float(2073600,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(2073600,1,11520,64) -> Float(518400,1:4,2880,16) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(2073600,1,11520,64) -> Half(2073600,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(2073600,1,11520,64) -> Half(1036800,32400:2,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(2073600,1,11520,64) -> Half(259200,1:8,1440,8) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(2073600,1,11520,64) -> Half(129600,1:16,720,4) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(518400,1:4,2880,16) -> Float(2073600,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(518400,1:4,2880,16) -> Float(2073600,1,11520,64) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(518400,1:4,2880,16) -> Half(2073600,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(518400,1:4,2880,16) -> Half(1036800,32400:2,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(518400,1:4,2880,16) -> Half(259200,1:8,1440,8) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(518400,1:4,2880,16) -> Half(129600,1:16,720,4) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(2073600,32400,180,1) -> Float(2073600,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(2073600,32400,180,1) -> Float(2073600,1,11520,64) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(2073600,32400,180,1) -> Float(518400,1:4,2880,16) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(2073600,32400,180,1) -> Half(1036800,32400:2,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(2073600,32400,180,1) -> Half(259200,1:8,1440,8) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(2073600,32400,180,1) -> Half(129600,1:16,720,4) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(1036800,32400:2,180,1) -> Float(2073600,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(1036800,32400:2,180,1) -> Float(2073600,1,11520,64) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(1036800,32400:2,180,1) -> Float(518400,1:4,2880,16) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(1036800,32400:2,180,1) -> Half(2073600,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(1036800,32400:2,180,1) -> Half(259200,1:8,1440,8) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(1036800,32400:2,180,1) -> Half(129600,1:16,720,4) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(259200,1:8,1440,8) -> Float(2073600,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(259200,1:8,1440,8) -> Float(2073600,1,11520,64) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(259200,1:8,1440,8) -> Float(518400,1:4,2880,16) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(259200,1:8,1440,8) -> Half(2073600,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(259200,1:8,1440,8) -> Half(1036800,32400:2,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(259200,1:8,1440,8) -> Half(129600,1:16,720,4) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(129600,1:16,720,4) -> Float(2073600,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(129600,1:16,720,4) -> Float(2073600,1,11520,64) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(129600,1:16,720,4) -> Float(518400,1:4,2880,16) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(129600,1:16,720,4) -> Half(2073600,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(129600,1:16,720,4) -> Half(1036800,32400:2,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(129600,1:16,720,4) -> Half(259200,1:8,1440,8) ***************
[03/24/2023-12:56:23] [V] [TRT] =============== Computing reformatting costs
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(16588800,32400,180,1) -> Float(16588800,1,92160,512) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(16588800,32400,180,1) -> Float(4147200,1:4,23040,128) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(16588800,32400,180,1) -> Half(16588800,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(16588800,32400,180,1) -> Half(8294400,32400:2,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(16588800,32400,180,1) -> Half(2073600,1:8,11520,64) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(16588800,32400,180,1) -> Half(1036800,1:16,5760,32) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(16588800,1,92160,512) -> Float(16588800,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(16588800,1,92160,512) -> Float(4147200,1:4,23040,128) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(16588800,1,92160,512) -> Half(16588800,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(16588800,1,92160,512) -> Half(8294400,32400:2,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(16588800,1,92160,512) -> Half(2073600,1:8,11520,64) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(16588800,1,92160,512) -> Half(1036800,1:16,5760,32) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(4147200,1:4,23040,128) -> Float(16588800,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(4147200,1:4,23040,128) -> Float(16588800,1,92160,512) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(4147200,1:4,23040,128) -> Half(16588800,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(4147200,1:4,23040,128) -> Half(8294400,32400:2,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(4147200,1:4,23040,128) -> Half(2073600,1:8,11520,64) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(4147200,1:4,23040,128) -> Half(1036800,1:16,5760,32) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(16588800,32400,180,1) -> Float(16588800,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(16588800,32400,180,1) -> Float(16588800,1,92160,512) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(16588800,32400,180,1) -> Float(4147200,1:4,23040,128) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(16588800,32400,180,1) -> Half(8294400,32400:2,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(16588800,32400,180,1) -> Half(2073600,1:8,11520,64) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(16588800,32400,180,1) -> Half(1036800,1:16,5760,32) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(8294400,32400:2,180,1) -> Float(16588800,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(8294400,32400:2,180,1) -> Float(16588800,1,92160,512) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(8294400,32400:2,180,1) -> Float(4147200,1:4,23040,128) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(8294400,32400:2,180,1) -> Half(16588800,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(8294400,32400:2,180,1) -> Half(2073600,1:8,11520,64) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(8294400,32400:2,180,1) -> Half(1036800,1:16,5760,32) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(2073600,1:8,11520,64) -> Float(16588800,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(2073600,1:8,11520,64) -> Float(16588800,1,92160,512) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(2073600,1:8,11520,64) -> Float(4147200,1:4,23040,128) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(2073600,1:8,11520,64) -> Half(16588800,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(2073600,1:8,11520,64) -> Half(8294400,32400:2,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(2073600,1:8,11520,64) -> Half(1036800,1:16,5760,32) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(1036800,1:16,5760,32) -> Float(16588800,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(1036800,1:16,5760,32) -> Float(16588800,1,92160,512) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(1036800,1:16,5760,32) -> Float(4147200,1:4,23040,128) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(1036800,1:16,5760,32) -> Half(16588800,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(1036800,1:16,5760,32) -> Half(8294400,32400:2,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(1036800,1:16,5760,32) -> Half(2073600,1:8,11520,64) ***************
[03/24/2023-12:56:23] [V] [TRT] =============== Computing reformatting costs
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(16588800,32400,180,1) -> Float(16588800,1,92160,512) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(16588800,32400,180,1) -> Float(4147200,1:4,23040,128) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(16588800,32400,180,1) -> Half(16588800,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(16588800,32400,180,1) -> Half(8294400,32400:2,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(16588800,32400,180,1) -> Half(2073600,1:8,11520,64) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(16588800,32400,180,1) -> Half(1036800,1:16,5760,32) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(16588800,1,92160,512) -> Float(16588800,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(16588800,1,92160,512) -> Float(4147200,1:4,23040,128) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(16588800,1,92160,512) -> Half(16588800,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(16588800,1,92160,512) -> Half(8294400,32400:2,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(16588800,1,92160,512) -> Half(2073600,1:8,11520,64) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(16588800,1,92160,512) -> Half(1036800,1:16,5760,32) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(4147200,1:4,23040,128) -> Float(16588800,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(4147200,1:4,23040,128) -> Float(16588800,1,92160,512) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(4147200,1:4,23040,128) -> Half(16588800,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(4147200,1:4,23040,128) -> Half(8294400,32400:2,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(4147200,1:4,23040,128) -> Half(2073600,1:8,11520,64) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(4147200,1:4,23040,128) -> Half(1036800,1:16,5760,32) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(16588800,32400,180,1) -> Float(16588800,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(16588800,32400,180,1) -> Float(16588800,1,92160,512) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(16588800,32400,180,1) -> Float(4147200,1:4,23040,128) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(16588800,32400,180,1) -> Half(8294400,32400:2,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(16588800,32400,180,1) -> Half(2073600,1:8,11520,64) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(16588800,32400,180,1) -> Half(1036800,1:16,5760,32) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(8294400,32400:2,180,1) -> Float(16588800,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(8294400,32400:2,180,1) -> Float(16588800,1,92160,512) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(8294400,32400:2,180,1) -> Float(4147200,1:4,23040,128) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(8294400,32400:2,180,1) -> Half(16588800,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(8294400,32400:2,180,1) -> Half(2073600,1:8,11520,64) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(8294400,32400:2,180,1) -> Half(1036800,1:16,5760,32) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(2073600,1:8,11520,64) -> Float(16588800,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(2073600,1:8,11520,64) -> Float(16588800,1,92160,512) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(2073600,1:8,11520,64) -> Float(4147200,1:4,23040,128) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(2073600,1:8,11520,64) -> Half(16588800,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(2073600,1:8,11520,64) -> Half(8294400,32400:2,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(2073600,1:8,11520,64) -> Half(1036800,1:16,5760,32) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(1036800,1:16,5760,32) -> Float(16588800,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(1036800,1:16,5760,32) -> Float(16588800,1,92160,512) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(1036800,1:16,5760,32) -> Float(4147200,1:4,23040,128) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(1036800,1:16,5760,32) -> Half(16588800,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(1036800,1:16,5760,32) -> Half(8294400,32400:2,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(1036800,1:16,5760,32) -> Half(2073600,1:8,11520,64) ***************
[03/24/2023-12:56:23] [V] [TRT] =============== Computing reformatting costs
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(97200,32400,180,1) -> Half(97200,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(97200,1,540,3) -> Half(97200,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(32400,1:4,180,1) -> Half(97200,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(64800,32400:2,180,1) -> Half(97200,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(32400,1:8,180,1) -> Half(97200,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(32400,1:16,180,1) -> Half(97200,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] =============== Computing reformatting costs
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(16588800,32400,180,1) -> Float(16588800,1,92160,512) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(16588800,32400,180,1) -> Float(4147200,1:4,23040,128) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(16588800,32400,180,1) -> Half(16588800,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(16588800,32400,180,1) -> Half(8294400,32400:2,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(16588800,32400,180,1) -> Half(2073600,1:8,11520,64) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(16588800,32400,180,1) -> Half(1036800,1:16,5760,32) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(16588800,1,92160,512) -> Float(16588800,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(16588800,1,92160,512) -> Float(4147200,1:4,23040,128) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(16588800,1,92160,512) -> Half(16588800,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(16588800,1,92160,512) -> Half(8294400,32400:2,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(16588800,1,92160,512) -> Half(2073600,1:8,11520,64) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(16588800,1,92160,512) -> Half(1036800,1:16,5760,32) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(4147200,1:4,23040,128) -> Float(16588800,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(4147200,1:4,23040,128) -> Float(16588800,1,92160,512) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(4147200,1:4,23040,128) -> Half(16588800,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(4147200,1:4,23040,128) -> Half(8294400,32400:2,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(4147200,1:4,23040,128) -> Half(2073600,1:8,11520,64) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(4147200,1:4,23040,128) -> Half(1036800,1:16,5760,32) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(16588800,32400,180,1) -> Float(16588800,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(16588800,32400,180,1) -> Float(16588800,1,92160,512) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(16588800,32400,180,1) -> Float(4147200,1:4,23040,128) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(16588800,32400,180,1) -> Half(8294400,32400:2,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(16588800,32400,180,1) -> Half(2073600,1:8,11520,64) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(16588800,32400,180,1) -> Half(1036800,1:16,5760,32) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(8294400,32400:2,180,1) -> Float(16588800,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(8294400,32400:2,180,1) -> Float(16588800,1,92160,512) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(8294400,32400:2,180,1) -> Float(4147200,1:4,23040,128) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(8294400,32400:2,180,1) -> Half(16588800,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(8294400,32400:2,180,1) -> Half(2073600,1:8,11520,64) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(8294400,32400:2,180,1) -> Half(1036800,1:16,5760,32) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(2073600,1:8,11520,64) -> Float(16588800,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(2073600,1:8,11520,64) -> Float(16588800,1,92160,512) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(2073600,1:8,11520,64) -> Float(4147200,1:4,23040,128) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(2073600,1:8,11520,64) -> Half(16588800,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(2073600,1:8,11520,64) -> Half(8294400,32400:2,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(2073600,1:8,11520,64) -> Half(1036800,1:16,5760,32) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(1036800,1:16,5760,32) -> Float(16588800,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(1036800,1:16,5760,32) -> Float(16588800,1,92160,512) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(1036800,1:16,5760,32) -> Float(4147200,1:4,23040,128) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(1036800,1:16,5760,32) -> Half(16588800,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(1036800,1:16,5760,32) -> Half(8294400,32400:2,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(1036800,1:16,5760,32) -> Half(2073600,1:8,11520,64) ***************
[03/24/2023-12:56:23] [V] [TRT] =============== Computing reformatting costs
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(64800,32400,180,1) -> Half(64800,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(64800,1,360,2) -> Half(64800,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(32400,1:4,180,1) -> Half(64800,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(32400,32400:2,180,1) -> Half(64800,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(32400,1:8,180,1) -> Half(64800,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(32400,1:16,180,1) -> Half(64800,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] =============== Computing reformatting costs
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(16588800,32400,180,1) -> Float(16588800,1,92160,512) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(16588800,32400,180,1) -> Float(4147200,1:4,23040,128) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(16588800,32400,180,1) -> Half(16588800,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(16588800,32400,180,1) -> Half(8294400,32400:2,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(16588800,32400,180,1) -> Half(2073600,1:8,11520,64) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(16588800,32400,180,1) -> Half(1036800,1:16,5760,32) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(16588800,1,92160,512) -> Float(16588800,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(16588800,1,92160,512) -> Float(4147200,1:4,23040,128) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(16588800,1,92160,512) -> Half(16588800,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(16588800,1,92160,512) -> Half(8294400,32400:2,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(16588800,1,92160,512) -> Half(2073600,1:8,11520,64) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(16588800,1,92160,512) -> Half(1036800,1:16,5760,32) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(4147200,1:4,23040,128) -> Float(16588800,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(4147200,1:4,23040,128) -> Float(16588800,1,92160,512) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(4147200,1:4,23040,128) -> Half(16588800,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(4147200,1:4,23040,128) -> Half(8294400,32400:2,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(4147200,1:4,23040,128) -> Half(2073600,1:8,11520,64) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(4147200,1:4,23040,128) -> Half(1036800,1:16,5760,32) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(16588800,32400,180,1) -> Float(16588800,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(16588800,32400,180,1) -> Float(16588800,1,92160,512) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(16588800,32400,180,1) -> Float(4147200,1:4,23040,128) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(16588800,32400,180,1) -> Half(8294400,32400:2,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(16588800,32400,180,1) -> Half(2073600,1:8,11520,64) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(16588800,32400,180,1) -> Half(1036800,1:16,5760,32) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(8294400,32400:2,180,1) -> Float(16588800,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(8294400,32400:2,180,1) -> Float(16588800,1,92160,512) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(8294400,32400:2,180,1) -> Float(4147200,1:4,23040,128) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(8294400,32400:2,180,1) -> Half(16588800,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(8294400,32400:2,180,1) -> Half(2073600,1:8,11520,64) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(8294400,32400:2,180,1) -> Half(1036800,1:16,5760,32) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(2073600,1:8,11520,64) -> Float(16588800,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(2073600,1:8,11520,64) -> Float(16588800,1,92160,512) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(2073600,1:8,11520,64) -> Float(4147200,1:4,23040,128) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(2073600,1:8,11520,64) -> Half(16588800,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(2073600,1:8,11520,64) -> Half(8294400,32400:2,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(2073600,1:8,11520,64) -> Half(1036800,1:16,5760,32) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(1036800,1:16,5760,32) -> Float(16588800,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(1036800,1:16,5760,32) -> Float(16588800,1,92160,512) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(1036800,1:16,5760,32) -> Float(4147200,1:4,23040,128) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(1036800,1:16,5760,32) -> Half(16588800,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(1036800,1:16,5760,32) -> Half(8294400,32400:2,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(1036800,1:16,5760,32) -> Half(2073600,1:8,11520,64) ***************
[03/24/2023-12:56:23] [V] [TRT] =============== Computing reformatting costs
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(64800,32400,180,1) -> Half(64800,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(64800,1,360,2) -> Half(64800,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(32400,1:4,180,1) -> Half(64800,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(32400,32400:2,180,1) -> Half(64800,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(32400,1:8,180,1) -> Half(64800,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(32400,1:16,180,1) -> Half(64800,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] =============== Computing reformatting costs
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(16588800,32400,180,1) -> Float(16588800,1,92160,512) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(16588800,32400,180,1) -> Float(4147200,1:4,23040,128) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(16588800,32400,180,1) -> Half(16588800,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(16588800,32400,180,1) -> Half(8294400,32400:2,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(16588800,32400,180,1) -> Half(2073600,1:8,11520,64) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(16588800,32400,180,1) -> Half(1036800,1:16,5760,32) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(16588800,1,92160,512) -> Float(16588800,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(16588800,1,92160,512) -> Float(4147200,1:4,23040,128) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(16588800,1,92160,512) -> Half(16588800,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(16588800,1,92160,512) -> Half(8294400,32400:2,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(16588800,1,92160,512) -> Half(2073600,1:8,11520,64) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(16588800,1,92160,512) -> Half(1036800,1:16,5760,32) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(4147200,1:4,23040,128) -> Float(16588800,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(4147200,1:4,23040,128) -> Float(16588800,1,92160,512) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(4147200,1:4,23040,128) -> Half(16588800,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(4147200,1:4,23040,128) -> Half(8294400,32400:2,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(4147200,1:4,23040,128) -> Half(2073600,1:8,11520,64) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(4147200,1:4,23040,128) -> Half(1036800,1:16,5760,32) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(16588800,32400,180,1) -> Float(16588800,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(16588800,32400,180,1) -> Float(16588800,1,92160,512) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(16588800,32400,180,1) -> Float(4147200,1:4,23040,128) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(16588800,32400,180,1) -> Half(8294400,32400:2,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(16588800,32400,180,1) -> Half(2073600,1:8,11520,64) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(16588800,32400,180,1) -> Half(1036800,1:16,5760,32) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(8294400,32400:2,180,1) -> Float(16588800,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(8294400,32400:2,180,1) -> Float(16588800,1,92160,512) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(8294400,32400:2,180,1) -> Float(4147200,1:4,23040,128) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(8294400,32400:2,180,1) -> Half(16588800,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(8294400,32400:2,180,1) -> Half(2073600,1:8,11520,64) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(8294400,32400:2,180,1) -> Half(1036800,1:16,5760,32) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(2073600,1:8,11520,64) -> Float(16588800,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(2073600,1:8,11520,64) -> Float(16588800,1,92160,512) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(2073600,1:8,11520,64) -> Float(4147200,1:4,23040,128) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(2073600,1:8,11520,64) -> Half(16588800,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(2073600,1:8,11520,64) -> Half(8294400,32400:2,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(2073600,1:8,11520,64) -> Half(1036800,1:16,5760,32) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(1036800,1:16,5760,32) -> Float(16588800,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(1036800,1:16,5760,32) -> Float(16588800,1,92160,512) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(1036800,1:16,5760,32) -> Float(4147200,1:4,23040,128) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(1036800,1:16,5760,32) -> Half(16588800,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(1036800,1:16,5760,32) -> Half(8294400,32400:2,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(1036800,1:16,5760,32) -> Half(2073600,1:8,11520,64) ***************
[03/24/2023-12:56:23] [V] [TRT] =============== Computing reformatting costs
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(64800,32400,180,1) -> Half(64800,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(64800,1,360,2) -> Half(64800,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(32400,1:4,180,1) -> Half(64800,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(32400,32400:2,180,1) -> Half(64800,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(32400,1:8,180,1) -> Half(64800,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(32400,1:16,180,1) -> Half(64800,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] =============== Computing reformatting costs
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(16588800,32400,180,1) -> Float(16588800,1,92160,512) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(16588800,32400,180,1) -> Float(4147200,1:4,23040,128) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(16588800,32400,180,1) -> Half(16588800,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(16588800,32400,180,1) -> Half(8294400,32400:2,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(16588800,32400,180,1) -> Half(2073600,1:8,11520,64) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(16588800,32400,180,1) -> Half(1036800,1:16,5760,32) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(16588800,1,92160,512) -> Float(16588800,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(16588800,1,92160,512) -> Float(4147200,1:4,23040,128) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(16588800,1,92160,512) -> Half(16588800,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(16588800,1,92160,512) -> Half(8294400,32400:2,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(16588800,1,92160,512) -> Half(2073600,1:8,11520,64) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(16588800,1,92160,512) -> Half(1036800,1:16,5760,32) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(4147200,1:4,23040,128) -> Float(16588800,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(4147200,1:4,23040,128) -> Float(16588800,1,92160,512) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(4147200,1:4,23040,128) -> Half(16588800,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(4147200,1:4,23040,128) -> Half(8294400,32400:2,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(4147200,1:4,23040,128) -> Half(2073600,1:8,11520,64) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(4147200,1:4,23040,128) -> Half(1036800,1:16,5760,32) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(16588800,32400,180,1) -> Float(16588800,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(16588800,32400,180,1) -> Float(16588800,1,92160,512) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(16588800,32400,180,1) -> Float(4147200,1:4,23040,128) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(16588800,32400,180,1) -> Half(8294400,32400:2,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(16588800,32400,180,1) -> Half(2073600,1:8,11520,64) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(16588800,32400,180,1) -> Half(1036800,1:16,5760,32) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(8294400,32400:2,180,1) -> Float(16588800,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(8294400,32400:2,180,1) -> Float(16588800,1,92160,512) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(8294400,32400:2,180,1) -> Float(4147200,1:4,23040,128) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(8294400,32400:2,180,1) -> Half(16588800,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(8294400,32400:2,180,1) -> Half(2073600,1:8,11520,64) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(8294400,32400:2,180,1) -> Half(1036800,1:16,5760,32) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(2073600,1:8,11520,64) -> Float(16588800,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(2073600,1:8,11520,64) -> Float(16588800,1,92160,512) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(2073600,1:8,11520,64) -> Float(4147200,1:4,23040,128) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(2073600,1:8,11520,64) -> Half(16588800,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(2073600,1:8,11520,64) -> Half(8294400,32400:2,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(2073600,1:8,11520,64) -> Half(1036800,1:16,5760,32) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(1036800,1:16,5760,32) -> Float(16588800,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(1036800,1:16,5760,32) -> Float(16588800,1,92160,512) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(1036800,1:16,5760,32) -> Float(4147200,1:4,23040,128) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(1036800,1:16,5760,32) -> Half(16588800,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(1036800,1:16,5760,32) -> Half(8294400,32400:2,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(1036800,1:16,5760,32) -> Half(2073600,1:8,11520,64) ***************
[03/24/2023-12:56:23] [V] [TRT] =============== Computing reformatting costs
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(64800,32400,180,1) -> Half(64800,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(64800,1,360,2) -> Half(64800,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(32400,1:4,180,1) -> Half(64800,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(32400,32400:2,180,1) -> Half(64800,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(32400,1:8,180,1) -> Half(64800,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(32400,1:16,180,1) -> Half(64800,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] =============== Computing reformatting costs
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(16588800,32400,180,1) -> Float(16588800,1,92160,512) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(16588800,32400,180,1) -> Float(4147200,1:4,23040,128) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(16588800,32400,180,1) -> Half(16588800,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(16588800,32400,180,1) -> Half(8294400,32400:2,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(16588800,32400,180,1) -> Half(2073600,1:8,11520,64) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(16588800,32400,180,1) -> Half(1036800,1:16,5760,32) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(16588800,1,92160,512) -> Float(16588800,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(16588800,1,92160,512) -> Float(4147200,1:4,23040,128) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(16588800,1,92160,512) -> Half(16588800,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(16588800,1,92160,512) -> Half(8294400,32400:2,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(16588800,1,92160,512) -> Half(2073600,1:8,11520,64) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(16588800,1,92160,512) -> Half(1036800,1:16,5760,32) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(4147200,1:4,23040,128) -> Float(16588800,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(4147200,1:4,23040,128) -> Float(16588800,1,92160,512) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(4147200,1:4,23040,128) -> Half(16588800,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(4147200,1:4,23040,128) -> Half(8294400,32400:2,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(4147200,1:4,23040,128) -> Half(2073600,1:8,11520,64) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(4147200,1:4,23040,128) -> Half(1036800,1:16,5760,32) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(16588800,32400,180,1) -> Float(16588800,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(16588800,32400,180,1) -> Float(16588800,1,92160,512) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(16588800,32400,180,1) -> Float(4147200,1:4,23040,128) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(16588800,32400,180,1) -> Half(8294400,32400:2,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(16588800,32400,180,1) -> Half(2073600,1:8,11520,64) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(16588800,32400,180,1) -> Half(1036800,1:16,5760,32) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(8294400,32400:2,180,1) -> Float(16588800,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(8294400,32400:2,180,1) -> Float(16588800,1,92160,512) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(8294400,32400:2,180,1) -> Float(4147200,1:4,23040,128) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(8294400,32400:2,180,1) -> Half(16588800,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(8294400,32400:2,180,1) -> Half(2073600,1:8,11520,64) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(8294400,32400:2,180,1) -> Half(1036800,1:16,5760,32) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(2073600,1:8,11520,64) -> Float(16588800,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(2073600,1:8,11520,64) -> Float(16588800,1,92160,512) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(2073600,1:8,11520,64) -> Float(4147200,1:4,23040,128) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(2073600,1:8,11520,64) -> Half(16588800,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(2073600,1:8,11520,64) -> Half(8294400,32400:2,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(2073600,1:8,11520,64) -> Half(1036800,1:16,5760,32) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(1036800,1:16,5760,32) -> Float(16588800,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(1036800,1:16,5760,32) -> Float(16588800,1,92160,512) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(1036800,1:16,5760,32) -> Float(4147200,1:4,23040,128) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(1036800,1:16,5760,32) -> Half(16588800,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(1036800,1:16,5760,32) -> Half(8294400,32400:2,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(1036800,1:16,5760,32) -> Half(2073600,1:8,11520,64) ***************
[03/24/2023-12:56:23] [V] [TRT] =============== Computing reformatting costs
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(32400,32400,180,1) -> Half(32400,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(32400,1,180,1) -> Half(32400,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(32400,1:4,180,1) -> Half(32400,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(32400,32400:2,180,1) -> Half(32400,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(32400,1:8,180,1) -> Half(32400,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(32400,1:16,180,1) -> Half(32400,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] =============== Computing reformatting costs
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(16588800,32400,180,1) -> Float(16588800,1,92160,512) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(16588800,32400,180,1) -> Float(4147200,1:4,23040,128) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(16588800,32400,180,1) -> Half(16588800,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(16588800,32400,180,1) -> Half(8294400,32400:2,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(16588800,32400,180,1) -> Half(2073600,1:8,11520,64) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(16588800,32400,180,1) -> Half(1036800,1:16,5760,32) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(16588800,1,92160,512) -> Float(16588800,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(16588800,1,92160,512) -> Float(4147200,1:4,23040,128) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(16588800,1,92160,512) -> Half(16588800,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(16588800,1,92160,512) -> Half(8294400,32400:2,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(16588800,1,92160,512) -> Half(2073600,1:8,11520,64) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(16588800,1,92160,512) -> Half(1036800,1:16,5760,32) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(4147200,1:4,23040,128) -> Float(16588800,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(4147200,1:4,23040,128) -> Float(16588800,1,92160,512) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(4147200,1:4,23040,128) -> Half(16588800,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(4147200,1:4,23040,128) -> Half(8294400,32400:2,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(4147200,1:4,23040,128) -> Half(2073600,1:8,11520,64) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(4147200,1:4,23040,128) -> Half(1036800,1:16,5760,32) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(16588800,32400,180,1) -> Float(16588800,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(16588800,32400,180,1) -> Float(16588800,1,92160,512) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(16588800,32400,180,1) -> Float(4147200,1:4,23040,128) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(16588800,32400,180,1) -> Half(8294400,32400:2,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(16588800,32400,180,1) -> Half(2073600,1:8,11520,64) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(16588800,32400,180,1) -> Half(1036800,1:16,5760,32) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(8294400,32400:2,180,1) -> Float(16588800,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(8294400,32400:2,180,1) -> Float(16588800,1,92160,512) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(8294400,32400:2,180,1) -> Float(4147200,1:4,23040,128) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(8294400,32400:2,180,1) -> Half(16588800,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(8294400,32400:2,180,1) -> Half(2073600,1:8,11520,64) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(8294400,32400:2,180,1) -> Half(1036800,1:16,5760,32) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(2073600,1:8,11520,64) -> Float(16588800,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(2073600,1:8,11520,64) -> Float(16588800,1,92160,512) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(2073600,1:8,11520,64) -> Float(4147200,1:4,23040,128) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(2073600,1:8,11520,64) -> Half(16588800,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(2073600,1:8,11520,64) -> Half(8294400,32400:2,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(2073600,1:8,11520,64) -> Half(1036800,1:16,5760,32) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(1036800,1:16,5760,32) -> Float(16588800,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(1036800,1:16,5760,32) -> Float(16588800,1,92160,512) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(1036800,1:16,5760,32) -> Float(4147200,1:4,23040,128) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(1036800,1:16,5760,32) -> Half(16588800,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(1036800,1:16,5760,32) -> Half(8294400,32400:2,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(1036800,1:16,5760,32) -> Half(2073600,1:8,11520,64) ***************
[03/24/2023-12:56:23] [V] [TRT] =============== Computing reformatting costs
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(97200,32400,180,1) -> Half(97200,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(97200,1,540,3) -> Half(97200,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(32400,1:4,180,1) -> Half(97200,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(64800,32400:2,180,1) -> Half(97200,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(32400,1:8,180,1) -> Half(97200,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(32400,1:16,180,1) -> Half(97200,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] =============== Computing reformatting costs
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(16588800,32400,180,1) -> Float(16588800,1,92160,512) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(16588800,32400,180,1) -> Float(4147200,1:4,23040,128) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(16588800,32400,180,1) -> Half(16588800,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(16588800,32400,180,1) -> Half(8294400,32400:2,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(16588800,32400,180,1) -> Half(2073600,1:8,11520,64) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(16588800,32400,180,1) -> Half(1036800,1:16,5760,32) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(16588800,1,92160,512) -> Float(16588800,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(16588800,1,92160,512) -> Float(4147200,1:4,23040,128) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(16588800,1,92160,512) -> Half(16588800,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(16588800,1,92160,512) -> Half(8294400,32400:2,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(16588800,1,92160,512) -> Half(2073600,1:8,11520,64) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(16588800,1,92160,512) -> Half(1036800,1:16,5760,32) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(4147200,1:4,23040,128) -> Float(16588800,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(4147200,1:4,23040,128) -> Float(16588800,1,92160,512) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(4147200,1:4,23040,128) -> Half(16588800,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(4147200,1:4,23040,128) -> Half(8294400,32400:2,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(4147200,1:4,23040,128) -> Half(2073600,1:8,11520,64) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(4147200,1:4,23040,128) -> Half(1036800,1:16,5760,32) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(16588800,32400,180,1) -> Float(16588800,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(16588800,32400,180,1) -> Float(16588800,1,92160,512) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(16588800,32400,180,1) -> Float(4147200,1:4,23040,128) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(16588800,32400,180,1) -> Half(8294400,32400:2,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(16588800,32400,180,1) -> Half(2073600,1:8,11520,64) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(16588800,32400,180,1) -> Half(1036800,1:16,5760,32) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(8294400,32400:2,180,1) -> Float(16588800,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(8294400,32400:2,180,1) -> Float(16588800,1,92160,512) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(8294400,32400:2,180,1) -> Float(4147200,1:4,23040,128) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(8294400,32400:2,180,1) -> Half(16588800,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(8294400,32400:2,180,1) -> Half(2073600,1:8,11520,64) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(8294400,32400:2,180,1) -> Half(1036800,1:16,5760,32) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(2073600,1:8,11520,64) -> Float(16588800,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(2073600,1:8,11520,64) -> Float(16588800,1,92160,512) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(2073600,1:8,11520,64) -> Float(4147200,1:4,23040,128) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(2073600,1:8,11520,64) -> Half(16588800,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(2073600,1:8,11520,64) -> Half(8294400,32400:2,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(2073600,1:8,11520,64) -> Half(1036800,1:16,5760,32) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(1036800,1:16,5760,32) -> Float(16588800,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(1036800,1:16,5760,32) -> Float(16588800,1,92160,512) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(1036800,1:16,5760,32) -> Float(4147200,1:4,23040,128) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(1036800,1:16,5760,32) -> Half(16588800,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(1036800,1:16,5760,32) -> Half(8294400,32400:2,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(1036800,1:16,5760,32) -> Half(2073600,1:8,11520,64) ***************
[03/24/2023-12:56:23] [V] [TRT] =============== Computing reformatting costs
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(64800,32400,180,1) -> Half(64800,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(64800,1,360,2) -> Half(64800,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(32400,1:4,180,1) -> Half(64800,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(32400,32400:2,180,1) -> Half(64800,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(32400,1:8,180,1) -> Half(64800,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(32400,1:16,180,1) -> Half(64800,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] =============== Computing reformatting costs
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(2073600,32400,180,1) -> Float(2073600,1,11520,64) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(2073600,32400,180,1) -> Float(518400,1:4,2880,16) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(2073600,32400,180,1) -> Half(2073600,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(2073600,32400,180,1) -> Half(1036800,32400:2,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(2073600,32400,180,1) -> Half(259200,1:8,1440,8) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(2073600,32400,180,1) -> Half(129600,1:16,720,4) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(2073600,1,11520,64) -> Float(2073600,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(2073600,1,11520,64) -> Float(518400,1:4,2880,16) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(2073600,1,11520,64) -> Half(2073600,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(2073600,1,11520,64) -> Half(1036800,32400:2,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(2073600,1,11520,64) -> Half(259200,1:8,1440,8) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(2073600,1,11520,64) -> Half(129600,1:16,720,4) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(518400,1:4,2880,16) -> Float(2073600,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(518400,1:4,2880,16) -> Float(2073600,1,11520,64) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(518400,1:4,2880,16) -> Half(2073600,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(518400,1:4,2880,16) -> Half(1036800,32400:2,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(518400,1:4,2880,16) -> Half(259200,1:8,1440,8) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(518400,1:4,2880,16) -> Half(129600,1:16,720,4) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(2073600,32400,180,1) -> Float(2073600,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(2073600,32400,180,1) -> Float(2073600,1,11520,64) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(2073600,32400,180,1) -> Float(518400,1:4,2880,16) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(2073600,32400,180,1) -> Half(1036800,32400:2,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(2073600,32400,180,1) -> Half(259200,1:8,1440,8) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(2073600,32400,180,1) -> Half(129600,1:16,720,4) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(1036800,32400:2,180,1) -> Float(2073600,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(1036800,32400:2,180,1) -> Float(2073600,1,11520,64) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(1036800,32400:2,180,1) -> Float(518400,1:4,2880,16) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(1036800,32400:2,180,1) -> Half(2073600,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(1036800,32400:2,180,1) -> Half(259200,1:8,1440,8) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(1036800,32400:2,180,1) -> Half(129600,1:16,720,4) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(259200,1:8,1440,8) -> Float(2073600,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(259200,1:8,1440,8) -> Float(2073600,1,11520,64) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(259200,1:8,1440,8) -> Float(518400,1:4,2880,16) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(259200,1:8,1440,8) -> Half(2073600,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(259200,1:8,1440,8) -> Half(1036800,32400:2,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(259200,1:8,1440,8) -> Half(129600,1:16,720,4) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(129600,1:16,720,4) -> Float(2073600,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(129600,1:16,720,4) -> Float(2073600,1,11520,64) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(129600,1:16,720,4) -> Float(518400,1:4,2880,16) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(129600,1:16,720,4) -> Half(2073600,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(129600,1:16,720,4) -> Half(1036800,32400:2,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(129600,1:16,720,4) -> Half(259200,1:8,1440,8) ***************
[03/24/2023-12:56:23] [V] [TRT] =============== Computing reformatting costs
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(16588800,32400,180,1) -> Float(16588800,1,92160,512) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(16588800,32400,180,1) -> Float(4147200,1:4,23040,128) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(16588800,32400,180,1) -> Half(16588800,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(16588800,32400,180,1) -> Half(8294400,32400:2,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(16588800,32400,180,1) -> Half(2073600,1:8,11520,64) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(16588800,32400,180,1) -> Half(1036800,1:16,5760,32) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(16588800,1,92160,512) -> Float(16588800,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(16588800,1,92160,512) -> Float(4147200,1:4,23040,128) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(16588800,1,92160,512) -> Half(16588800,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(16588800,1,92160,512) -> Half(8294400,32400:2,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(16588800,1,92160,512) -> Half(2073600,1:8,11520,64) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(16588800,1,92160,512) -> Half(1036800,1:16,5760,32) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(4147200,1:4,23040,128) -> Float(16588800,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(4147200,1:4,23040,128) -> Float(16588800,1,92160,512) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(4147200,1:4,23040,128) -> Half(16588800,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(4147200,1:4,23040,128) -> Half(8294400,32400:2,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(4147200,1:4,23040,128) -> Half(2073600,1:8,11520,64) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(4147200,1:4,23040,128) -> Half(1036800,1:16,5760,32) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(16588800,32400,180,1) -> Float(16588800,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(16588800,32400,180,1) -> Float(16588800,1,92160,512) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(16588800,32400,180,1) -> Float(4147200,1:4,23040,128) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(16588800,32400,180,1) -> Half(8294400,32400:2,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(16588800,32400,180,1) -> Half(2073600,1:8,11520,64) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(16588800,32400,180,1) -> Half(1036800,1:16,5760,32) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(8294400,32400:2,180,1) -> Float(16588800,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(8294400,32400:2,180,1) -> Float(16588800,1,92160,512) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(8294400,32400:2,180,1) -> Float(4147200,1:4,23040,128) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(8294400,32400:2,180,1) -> Half(16588800,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(8294400,32400:2,180,1) -> Half(2073600,1:8,11520,64) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(8294400,32400:2,180,1) -> Half(1036800,1:16,5760,32) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(2073600,1:8,11520,64) -> Float(16588800,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(2073600,1:8,11520,64) -> Float(16588800,1,92160,512) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(2073600,1:8,11520,64) -> Float(4147200,1:4,23040,128) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(2073600,1:8,11520,64) -> Half(16588800,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(2073600,1:8,11520,64) -> Half(8294400,32400:2,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(2073600,1:8,11520,64) -> Half(1036800,1:16,5760,32) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(1036800,1:16,5760,32) -> Float(16588800,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(1036800,1:16,5760,32) -> Float(16588800,1,92160,512) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(1036800,1:16,5760,32) -> Float(4147200,1:4,23040,128) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(1036800,1:16,5760,32) -> Half(16588800,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(1036800,1:16,5760,32) -> Half(8294400,32400:2,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(1036800,1:16,5760,32) -> Half(2073600,1:8,11520,64) ***************
[03/24/2023-12:56:23] [V] [TRT] =============== Computing reformatting costs
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(16588800,32400,180,1) -> Float(16588800,1,92160,512) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(16588800,32400,180,1) -> Float(4147200,1:4,23040,128) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(16588800,32400,180,1) -> Half(16588800,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(16588800,32400,180,1) -> Half(8294400,32400:2,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(16588800,32400,180,1) -> Half(2073600,1:8,11520,64) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(16588800,32400,180,1) -> Half(1036800,1:16,5760,32) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(16588800,1,92160,512) -> Float(16588800,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(16588800,1,92160,512) -> Float(4147200,1:4,23040,128) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(16588800,1,92160,512) -> Half(16588800,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(16588800,1,92160,512) -> Half(8294400,32400:2,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(16588800,1,92160,512) -> Half(2073600,1:8,11520,64) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(16588800,1,92160,512) -> Half(1036800,1:16,5760,32) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(4147200,1:4,23040,128) -> Float(16588800,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(4147200,1:4,23040,128) -> Float(16588800,1,92160,512) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(4147200,1:4,23040,128) -> Half(16588800,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(4147200,1:4,23040,128) -> Half(8294400,32400:2,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(4147200,1:4,23040,128) -> Half(2073600,1:8,11520,64) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(4147200,1:4,23040,128) -> Half(1036800,1:16,5760,32) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(16588800,32400,180,1) -> Float(16588800,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(16588800,32400,180,1) -> Float(16588800,1,92160,512) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(16588800,32400,180,1) -> Float(4147200,1:4,23040,128) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(16588800,32400,180,1) -> Half(8294400,32400:2,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(16588800,32400,180,1) -> Half(2073600,1:8,11520,64) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(16588800,32400,180,1) -> Half(1036800,1:16,5760,32) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(8294400,32400:2,180,1) -> Float(16588800,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(8294400,32400:2,180,1) -> Float(16588800,1,92160,512) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(8294400,32400:2,180,1) -> Float(4147200,1:4,23040,128) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(8294400,32400:2,180,1) -> Half(16588800,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(8294400,32400:2,180,1) -> Half(2073600,1:8,11520,64) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(8294400,32400:2,180,1) -> Half(1036800,1:16,5760,32) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(2073600,1:8,11520,64) -> Float(16588800,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(2073600,1:8,11520,64) -> Float(16588800,1,92160,512) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(2073600,1:8,11520,64) -> Float(4147200,1:4,23040,128) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(2073600,1:8,11520,64) -> Half(16588800,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(2073600,1:8,11520,64) -> Half(8294400,32400:2,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(2073600,1:8,11520,64) -> Half(1036800,1:16,5760,32) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(1036800,1:16,5760,32) -> Float(16588800,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(1036800,1:16,5760,32) -> Float(16588800,1,92160,512) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(1036800,1:16,5760,32) -> Float(4147200,1:4,23040,128) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(1036800,1:16,5760,32) -> Half(16588800,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(1036800,1:16,5760,32) -> Half(8294400,32400:2,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(1036800,1:16,5760,32) -> Half(2073600,1:8,11520,64) ***************
[03/24/2023-12:56:23] [V] [TRT] =============== Computing reformatting costs
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(64800,32400,180,1) -> Half(64800,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(64800,1,360,2) -> Half(64800,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(32400,1:4,180,1) -> Half(64800,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(32400,32400:2,180,1) -> Half(64800,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(32400,1:8,180,1) -> Half(64800,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(32400,1:16,180,1) -> Half(64800,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] =============== Computing reformatting costs
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(16588800,32400,180,1) -> Float(16588800,1,92160,512) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(16588800,32400,180,1) -> Float(4147200,1:4,23040,128) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(16588800,32400,180,1) -> Half(16588800,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(16588800,32400,180,1) -> Half(8294400,32400:2,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(16588800,32400,180,1) -> Half(2073600,1:8,11520,64) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(16588800,32400,180,1) -> Half(1036800,1:16,5760,32) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(16588800,1,92160,512) -> Float(16588800,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(16588800,1,92160,512) -> Float(4147200,1:4,23040,128) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(16588800,1,92160,512) -> Half(16588800,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(16588800,1,92160,512) -> Half(8294400,32400:2,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(16588800,1,92160,512) -> Half(2073600,1:8,11520,64) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(16588800,1,92160,512) -> Half(1036800,1:16,5760,32) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(4147200,1:4,23040,128) -> Float(16588800,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(4147200,1:4,23040,128) -> Float(16588800,1,92160,512) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(4147200,1:4,23040,128) -> Half(16588800,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(4147200,1:4,23040,128) -> Half(8294400,32400:2,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(4147200,1:4,23040,128) -> Half(2073600,1:8,11520,64) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(4147200,1:4,23040,128) -> Half(1036800,1:16,5760,32) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(16588800,32400,180,1) -> Float(16588800,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(16588800,32400,180,1) -> Float(16588800,1,92160,512) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(16588800,32400,180,1) -> Float(4147200,1:4,23040,128) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(16588800,32400,180,1) -> Half(8294400,32400:2,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(16588800,32400,180,1) -> Half(2073600,1:8,11520,64) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(16588800,32400,180,1) -> Half(1036800,1:16,5760,32) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(8294400,32400:2,180,1) -> Float(16588800,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(8294400,32400:2,180,1) -> Float(16588800,1,92160,512) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(8294400,32400:2,180,1) -> Float(4147200,1:4,23040,128) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(8294400,32400:2,180,1) -> Half(16588800,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(8294400,32400:2,180,1) -> Half(2073600,1:8,11520,64) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(8294400,32400:2,180,1) -> Half(1036800,1:16,5760,32) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(2073600,1:8,11520,64) -> Float(16588800,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(2073600,1:8,11520,64) -> Float(16588800,1,92160,512) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(2073600,1:8,11520,64) -> Float(4147200,1:4,23040,128) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(2073600,1:8,11520,64) -> Half(16588800,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(2073600,1:8,11520,64) -> Half(8294400,32400:2,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(2073600,1:8,11520,64) -> Half(1036800,1:16,5760,32) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(1036800,1:16,5760,32) -> Float(16588800,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(1036800,1:16,5760,32) -> Float(16588800,1,92160,512) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(1036800,1:16,5760,32) -> Float(4147200,1:4,23040,128) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(1036800,1:16,5760,32) -> Half(16588800,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(1036800,1:16,5760,32) -> Half(8294400,32400:2,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(1036800,1:16,5760,32) -> Half(2073600,1:8,11520,64) ***************
[03/24/2023-12:56:23] [V] [TRT] =============== Computing reformatting costs
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(64800,32400,180,1) -> Half(64800,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(64800,1,360,2) -> Half(64800,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(32400,1:4,180,1) -> Half(64800,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(32400,32400:2,180,1) -> Half(64800,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(32400,1:8,180,1) -> Half(64800,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(32400,1:16,180,1) -> Half(64800,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] =============== Computing reformatting costs
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(16588800,32400,180,1) -> Float(16588800,1,92160,512) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(16588800,32400,180,1) -> Float(4147200,1:4,23040,128) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(16588800,32400,180,1) -> Half(16588800,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(16588800,32400,180,1) -> Half(8294400,32400:2,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(16588800,32400,180,1) -> Half(2073600,1:8,11520,64) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(16588800,32400,180,1) -> Half(1036800,1:16,5760,32) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(16588800,1,92160,512) -> Float(16588800,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(16588800,1,92160,512) -> Float(4147200,1:4,23040,128) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(16588800,1,92160,512) -> Half(16588800,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(16588800,1,92160,512) -> Half(8294400,32400:2,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(16588800,1,92160,512) -> Half(2073600,1:8,11520,64) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(16588800,1,92160,512) -> Half(1036800,1:16,5760,32) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(4147200,1:4,23040,128) -> Float(16588800,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(4147200,1:4,23040,128) -> Float(16588800,1,92160,512) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(4147200,1:4,23040,128) -> Half(16588800,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(4147200,1:4,23040,128) -> Half(8294400,32400:2,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(4147200,1:4,23040,128) -> Half(2073600,1:8,11520,64) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(4147200,1:4,23040,128) -> Half(1036800,1:16,5760,32) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(16588800,32400,180,1) -> Float(16588800,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(16588800,32400,180,1) -> Float(16588800,1,92160,512) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(16588800,32400,180,1) -> Float(4147200,1:4,23040,128) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(16588800,32400,180,1) -> Half(8294400,32400:2,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(16588800,32400,180,1) -> Half(2073600,1:8,11520,64) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(16588800,32400,180,1) -> Half(1036800,1:16,5760,32) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(8294400,32400:2,180,1) -> Float(16588800,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(8294400,32400:2,180,1) -> Float(16588800,1,92160,512) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(8294400,32400:2,180,1) -> Float(4147200,1:4,23040,128) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(8294400,32400:2,180,1) -> Half(16588800,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(8294400,32400:2,180,1) -> Half(2073600,1:8,11520,64) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(8294400,32400:2,180,1) -> Half(1036800,1:16,5760,32) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(2073600,1:8,11520,64) -> Float(16588800,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(2073600,1:8,11520,64) -> Float(16588800,1,92160,512) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(2073600,1:8,11520,64) -> Float(4147200,1:4,23040,128) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(2073600,1:8,11520,64) -> Half(16588800,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(2073600,1:8,11520,64) -> Half(8294400,32400:2,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(2073600,1:8,11520,64) -> Half(1036800,1:16,5760,32) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(1036800,1:16,5760,32) -> Float(16588800,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(1036800,1:16,5760,32) -> Float(16588800,1,92160,512) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(1036800,1:16,5760,32) -> Float(4147200,1:4,23040,128) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(1036800,1:16,5760,32) -> Half(16588800,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(1036800,1:16,5760,32) -> Half(8294400,32400:2,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(1036800,1:16,5760,32) -> Half(2073600,1:8,11520,64) ***************
[03/24/2023-12:56:23] [V] [TRT] =============== Computing reformatting costs
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(64800,32400,180,1) -> Half(64800,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(64800,1,360,2) -> Half(64800,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(32400,1:4,180,1) -> Half(64800,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(32400,32400:2,180,1) -> Half(64800,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(32400,1:8,180,1) -> Half(64800,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(32400,1:16,180,1) -> Half(64800,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] =============== Computing reformatting costs
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(16588800,32400,180,1) -> Float(16588800,1,92160,512) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(16588800,32400,180,1) -> Float(4147200,1:4,23040,128) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(16588800,32400,180,1) -> Half(16588800,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(16588800,32400,180,1) -> Half(8294400,32400:2,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(16588800,32400,180,1) -> Half(2073600,1:8,11520,64) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(16588800,32400,180,1) -> Half(1036800,1:16,5760,32) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(16588800,1,92160,512) -> Float(16588800,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(16588800,1,92160,512) -> Float(4147200,1:4,23040,128) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(16588800,1,92160,512) -> Half(16588800,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(16588800,1,92160,512) -> Half(8294400,32400:2,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(16588800,1,92160,512) -> Half(2073600,1:8,11520,64) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(16588800,1,92160,512) -> Half(1036800,1:16,5760,32) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(4147200,1:4,23040,128) -> Float(16588800,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(4147200,1:4,23040,128) -> Float(16588800,1,92160,512) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(4147200,1:4,23040,128) -> Half(16588800,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(4147200,1:4,23040,128) -> Half(8294400,32400:2,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(4147200,1:4,23040,128) -> Half(2073600,1:8,11520,64) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(4147200,1:4,23040,128) -> Half(1036800,1:16,5760,32) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(16588800,32400,180,1) -> Float(16588800,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(16588800,32400,180,1) -> Float(16588800,1,92160,512) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(16588800,32400,180,1) -> Float(4147200,1:4,23040,128) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(16588800,32400,180,1) -> Half(8294400,32400:2,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(16588800,32400,180,1) -> Half(2073600,1:8,11520,64) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(16588800,32400,180,1) -> Half(1036800,1:16,5760,32) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(8294400,32400:2,180,1) -> Float(16588800,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(8294400,32400:2,180,1) -> Float(16588800,1,92160,512) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(8294400,32400:2,180,1) -> Float(4147200,1:4,23040,128) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(8294400,32400:2,180,1) -> Half(16588800,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(8294400,32400:2,180,1) -> Half(2073600,1:8,11520,64) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(8294400,32400:2,180,1) -> Half(1036800,1:16,5760,32) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(2073600,1:8,11520,64) -> Float(16588800,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(2073600,1:8,11520,64) -> Float(16588800,1,92160,512) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(2073600,1:8,11520,64) -> Float(4147200,1:4,23040,128) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(2073600,1:8,11520,64) -> Half(16588800,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(2073600,1:8,11520,64) -> Half(8294400,32400:2,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(2073600,1:8,11520,64) -> Half(1036800,1:16,5760,32) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(1036800,1:16,5760,32) -> Float(16588800,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(1036800,1:16,5760,32) -> Float(16588800,1,92160,512) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(1036800,1:16,5760,32) -> Float(4147200,1:4,23040,128) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(1036800,1:16,5760,32) -> Half(16588800,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(1036800,1:16,5760,32) -> Half(8294400,32400:2,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(1036800,1:16,5760,32) -> Half(2073600,1:8,11520,64) ***************
[03/24/2023-12:56:23] [V] [TRT] =============== Computing reformatting costs
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(32400,32400,180,1) -> Half(32400,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(32400,1,180,1) -> Half(32400,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(32400,1:4,180,1) -> Half(32400,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(32400,32400:2,180,1) -> Half(32400,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(32400,1:8,180,1) -> Half(32400,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(32400,1:16,180,1) -> Half(32400,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] =============== Computing reformatting costs
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(16588800,32400,180,1) -> Float(16588800,1,92160,512) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(16588800,32400,180,1) -> Float(4147200,1:4,23040,128) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(16588800,32400,180,1) -> Half(16588800,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(16588800,32400,180,1) -> Half(8294400,32400:2,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(16588800,32400,180,1) -> Half(2073600,1:8,11520,64) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(16588800,32400,180,1) -> Half(1036800,1:16,5760,32) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(16588800,1,92160,512) -> Float(16588800,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(16588800,1,92160,512) -> Float(4147200,1:4,23040,128) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(16588800,1,92160,512) -> Half(16588800,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(16588800,1,92160,512) -> Half(8294400,32400:2,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(16588800,1,92160,512) -> Half(2073600,1:8,11520,64) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(16588800,1,92160,512) -> Half(1036800,1:16,5760,32) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(4147200,1:4,23040,128) -> Float(16588800,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(4147200,1:4,23040,128) -> Float(16588800,1,92160,512) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(4147200,1:4,23040,128) -> Half(16588800,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(4147200,1:4,23040,128) -> Half(8294400,32400:2,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(4147200,1:4,23040,128) -> Half(2073600,1:8,11520,64) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(4147200,1:4,23040,128) -> Half(1036800,1:16,5760,32) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(16588800,32400,180,1) -> Float(16588800,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(16588800,32400,180,1) -> Float(16588800,1,92160,512) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(16588800,32400,180,1) -> Float(4147200,1:4,23040,128) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(16588800,32400,180,1) -> Half(8294400,32400:2,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(16588800,32400,180,1) -> Half(2073600,1:8,11520,64) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(16588800,32400,180,1) -> Half(1036800,1:16,5760,32) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(8294400,32400:2,180,1) -> Float(16588800,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(8294400,32400:2,180,1) -> Float(16588800,1,92160,512) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(8294400,32400:2,180,1) -> Float(4147200,1:4,23040,128) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(8294400,32400:2,180,1) -> Half(16588800,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(8294400,32400:2,180,1) -> Half(2073600,1:8,11520,64) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(8294400,32400:2,180,1) -> Half(1036800,1:16,5760,32) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(2073600,1:8,11520,64) -> Float(16588800,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(2073600,1:8,11520,64) -> Float(16588800,1,92160,512) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(2073600,1:8,11520,64) -> Float(4147200,1:4,23040,128) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(2073600,1:8,11520,64) -> Half(16588800,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(2073600,1:8,11520,64) -> Half(8294400,32400:2,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(2073600,1:8,11520,64) -> Half(1036800,1:16,5760,32) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(1036800,1:16,5760,32) -> Float(16588800,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(1036800,1:16,5760,32) -> Float(16588800,1,92160,512) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(1036800,1:16,5760,32) -> Float(4147200,1:4,23040,128) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(1036800,1:16,5760,32) -> Half(16588800,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(1036800,1:16,5760,32) -> Half(8294400,32400:2,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(1036800,1:16,5760,32) -> Half(2073600,1:8,11520,64) ***************
[03/24/2023-12:56:23] [V] [TRT] =============== Computing reformatting costs
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(97200,32400,180,1) -> Half(97200,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(97200,1,540,3) -> Half(97200,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(32400,1:4,180,1) -> Half(97200,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(64800,32400:2,180,1) -> Half(97200,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(32400,1:8,180,1) -> Half(97200,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(32400,1:16,180,1) -> Half(97200,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] =============== Computing reformatting costs
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(16588800,32400,180,1) -> Float(16588800,1,92160,512) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(16588800,32400,180,1) -> Float(4147200,1:4,23040,128) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(16588800,32400,180,1) -> Half(16588800,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(16588800,32400,180,1) -> Half(8294400,32400:2,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(16588800,32400,180,1) -> Half(2073600,1:8,11520,64) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(16588800,32400,180,1) -> Half(1036800,1:16,5760,32) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(16588800,1,92160,512) -> Float(16588800,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(16588800,1,92160,512) -> Float(4147200,1:4,23040,128) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(16588800,1,92160,512) -> Half(16588800,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(16588800,1,92160,512) -> Half(8294400,32400:2,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(16588800,1,92160,512) -> Half(2073600,1:8,11520,64) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(16588800,1,92160,512) -> Half(1036800,1:16,5760,32) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(4147200,1:4,23040,128) -> Float(16588800,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(4147200,1:4,23040,128) -> Float(16588800,1,92160,512) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(4147200,1:4,23040,128) -> Half(16588800,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(4147200,1:4,23040,128) -> Half(8294400,32400:2,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(4147200,1:4,23040,128) -> Half(2073600,1:8,11520,64) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(4147200,1:4,23040,128) -> Half(1036800,1:16,5760,32) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(16588800,32400,180,1) -> Float(16588800,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(16588800,32400,180,1) -> Float(16588800,1,92160,512) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(16588800,32400,180,1) -> Float(4147200,1:4,23040,128) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(16588800,32400,180,1) -> Half(8294400,32400:2,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(16588800,32400,180,1) -> Half(2073600,1:8,11520,64) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(16588800,32400,180,1) -> Half(1036800,1:16,5760,32) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(8294400,32400:2,180,1) -> Float(16588800,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(8294400,32400:2,180,1) -> Float(16588800,1,92160,512) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(8294400,32400:2,180,1) -> Float(4147200,1:4,23040,128) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(8294400,32400:2,180,1) -> Half(16588800,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(8294400,32400:2,180,1) -> Half(2073600,1:8,11520,64) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(8294400,32400:2,180,1) -> Half(1036800,1:16,5760,32) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(2073600,1:8,11520,64) -> Float(16588800,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(2073600,1:8,11520,64) -> Float(16588800,1,92160,512) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(2073600,1:8,11520,64) -> Float(4147200,1:4,23040,128) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(2073600,1:8,11520,64) -> Half(16588800,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(2073600,1:8,11520,64) -> Half(8294400,32400:2,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(2073600,1:8,11520,64) -> Half(1036800,1:16,5760,32) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(1036800,1:16,5760,32) -> Float(16588800,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(1036800,1:16,5760,32) -> Float(16588800,1,92160,512) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(1036800,1:16,5760,32) -> Float(4147200,1:4,23040,128) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(1036800,1:16,5760,32) -> Half(16588800,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(1036800,1:16,5760,32) -> Half(8294400,32400:2,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(1036800,1:16,5760,32) -> Half(2073600,1:8,11520,64) ***************
[03/24/2023-12:56:23] [V] [TRT] =============== Computing reformatting costs
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(64800,32400,180,1) -> Half(64800,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(64800,1,360,2) -> Half(64800,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(32400,1:4,180,1) -> Half(64800,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(32400,32400:2,180,1) -> Half(64800,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(32400,1:8,180,1) -> Half(64800,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(32400,1:16,180,1) -> Half(64800,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] =============== Computing reformatting costs
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(16588800,32400,180,1) -> Float(16588800,1,92160,512) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(16588800,32400,180,1) -> Float(4147200,1:4,23040,128) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(16588800,32400,180,1) -> Half(16588800,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(16588800,32400,180,1) -> Half(8294400,32400:2,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(16588800,32400,180,1) -> Half(2073600,1:8,11520,64) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(16588800,32400,180,1) -> Half(1036800,1:16,5760,32) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(16588800,1,92160,512) -> Float(16588800,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(16588800,1,92160,512) -> Float(4147200,1:4,23040,128) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(16588800,1,92160,512) -> Half(16588800,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(16588800,1,92160,512) -> Half(8294400,32400:2,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(16588800,1,92160,512) -> Half(2073600,1:8,11520,64) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(16588800,1,92160,512) -> Half(1036800,1:16,5760,32) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(4147200,1:4,23040,128) -> Float(16588800,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(4147200,1:4,23040,128) -> Float(16588800,1,92160,512) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(4147200,1:4,23040,128) -> Half(16588800,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(4147200,1:4,23040,128) -> Half(8294400,32400:2,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(4147200,1:4,23040,128) -> Half(2073600,1:8,11520,64) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(4147200,1:4,23040,128) -> Half(1036800,1:16,5760,32) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(16588800,32400,180,1) -> Float(16588800,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(16588800,32400,180,1) -> Float(16588800,1,92160,512) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(16588800,32400,180,1) -> Float(4147200,1:4,23040,128) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(16588800,32400,180,1) -> Half(8294400,32400:2,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(16588800,32400,180,1) -> Half(2073600,1:8,11520,64) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(16588800,32400,180,1) -> Half(1036800,1:16,5760,32) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(8294400,32400:2,180,1) -> Float(16588800,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(8294400,32400:2,180,1) -> Float(16588800,1,92160,512) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(8294400,32400:2,180,1) -> Float(4147200,1:4,23040,128) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(8294400,32400:2,180,1) -> Half(16588800,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(8294400,32400:2,180,1) -> Half(2073600,1:8,11520,64) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(8294400,32400:2,180,1) -> Half(1036800,1:16,5760,32) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(2073600,1:8,11520,64) -> Float(16588800,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(2073600,1:8,11520,64) -> Float(16588800,1,92160,512) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(2073600,1:8,11520,64) -> Float(4147200,1:4,23040,128) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(2073600,1:8,11520,64) -> Half(16588800,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(2073600,1:8,11520,64) -> Half(8294400,32400:2,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(2073600,1:8,11520,64) -> Half(1036800,1:16,5760,32) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(1036800,1:16,5760,32) -> Float(16588800,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(1036800,1:16,5760,32) -> Float(16588800,1,92160,512) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(1036800,1:16,5760,32) -> Float(4147200,1:4,23040,128) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(1036800,1:16,5760,32) -> Half(16588800,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(1036800,1:16,5760,32) -> Half(8294400,32400:2,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(1036800,1:16,5760,32) -> Half(2073600,1:8,11520,64) ***************
[03/24/2023-12:56:23] [V] [TRT] =============== Computing reformatting costs
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(64800,32400,180,1) -> Half(64800,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(64800,1,360,2) -> Half(64800,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(32400,1:4,180,1) -> Half(64800,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(32400,32400:2,180,1) -> Half(64800,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(32400,1:8,180,1) -> Half(64800,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(32400,1:16,180,1) -> Half(64800,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] =============== Computing reformatting costs
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(16588800,32400,180,1) -> Float(16588800,1,92160,512) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(16588800,32400,180,1) -> Float(4147200,1:4,23040,128) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(16588800,32400,180,1) -> Half(16588800,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(16588800,32400,180,1) -> Half(8294400,32400:2,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(16588800,32400,180,1) -> Half(2073600,1:8,11520,64) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(16588800,32400,180,1) -> Half(1036800,1:16,5760,32) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(16588800,1,92160,512) -> Float(16588800,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(16588800,1,92160,512) -> Float(4147200,1:4,23040,128) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(16588800,1,92160,512) -> Half(16588800,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(16588800,1,92160,512) -> Half(8294400,32400:2,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(16588800,1,92160,512) -> Half(2073600,1:8,11520,64) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(16588800,1,92160,512) -> Half(1036800,1:16,5760,32) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(4147200,1:4,23040,128) -> Float(16588800,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(4147200,1:4,23040,128) -> Float(16588800,1,92160,512) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(4147200,1:4,23040,128) -> Half(16588800,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(4147200,1:4,23040,128) -> Half(8294400,32400:2,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(4147200,1:4,23040,128) -> Half(2073600,1:8,11520,64) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(4147200,1:4,23040,128) -> Half(1036800,1:16,5760,32) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(16588800,32400,180,1) -> Float(16588800,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(16588800,32400,180,1) -> Float(16588800,1,92160,512) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(16588800,32400,180,1) -> Float(4147200,1:4,23040,128) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(16588800,32400,180,1) -> Half(8294400,32400:2,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(16588800,32400,180,1) -> Half(2073600,1:8,11520,64) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(16588800,32400,180,1) -> Half(1036800,1:16,5760,32) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(8294400,32400:2,180,1) -> Float(16588800,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(8294400,32400:2,180,1) -> Float(16588800,1,92160,512) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(8294400,32400:2,180,1) -> Float(4147200,1:4,23040,128) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(8294400,32400:2,180,1) -> Half(16588800,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(8294400,32400:2,180,1) -> Half(2073600,1:8,11520,64) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(8294400,32400:2,180,1) -> Half(1036800,1:16,5760,32) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(2073600,1:8,11520,64) -> Float(16588800,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(2073600,1:8,11520,64) -> Float(16588800,1,92160,512) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(2073600,1:8,11520,64) -> Float(4147200,1:4,23040,128) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(2073600,1:8,11520,64) -> Half(16588800,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(2073600,1:8,11520,64) -> Half(8294400,32400:2,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(2073600,1:8,11520,64) -> Half(1036800,1:16,5760,32) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(1036800,1:16,5760,32) -> Float(16588800,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(1036800,1:16,5760,32) -> Float(16588800,1,92160,512) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(1036800,1:16,5760,32) -> Float(4147200,1:4,23040,128) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(1036800,1:16,5760,32) -> Half(16588800,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(1036800,1:16,5760,32) -> Half(8294400,32400:2,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(1036800,1:16,5760,32) -> Half(2073600,1:8,11520,64) ***************
[03/24/2023-12:56:23] [V] [TRT] =============== Computing reformatting costs
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(32400,32400,180,1) -> Half(32400,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(32400,1,180,1) -> Half(32400,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(32400,1:4,180,1) -> Half(32400,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(32400,32400:2,180,1) -> Half(32400,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(32400,1:8,180,1) -> Half(32400,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(32400,1:16,180,1) -> Half(32400,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] =============== Computing reformatting costs
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(2073600,32400,180,1) -> Float(2073600,1,11520,64) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(2073600,32400,180,1) -> Float(518400,1:4,2880,16) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(2073600,32400,180,1) -> Half(2073600,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(2073600,32400,180,1) -> Half(1036800,32400:2,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(2073600,32400,180,1) -> Half(259200,1:8,1440,8) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(2073600,32400,180,1) -> Half(129600,1:16,720,4) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(2073600,1,11520,64) -> Float(2073600,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(2073600,1,11520,64) -> Float(518400,1:4,2880,16) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(2073600,1,11520,64) -> Half(2073600,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(2073600,1,11520,64) -> Half(1036800,32400:2,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(2073600,1,11520,64) -> Half(259200,1:8,1440,8) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(2073600,1,11520,64) -> Half(129600,1:16,720,4) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(518400,1:4,2880,16) -> Float(2073600,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(518400,1:4,2880,16) -> Float(2073600,1,11520,64) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(518400,1:4,2880,16) -> Half(2073600,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(518400,1:4,2880,16) -> Half(1036800,32400:2,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(518400,1:4,2880,16) -> Half(259200,1:8,1440,8) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(518400,1:4,2880,16) -> Half(129600,1:16,720,4) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(2073600,32400,180,1) -> Float(2073600,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(2073600,32400,180,1) -> Float(2073600,1,11520,64) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(2073600,32400,180,1) -> Float(518400,1:4,2880,16) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(2073600,32400,180,1) -> Half(1036800,32400:2,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(2073600,32400,180,1) -> Half(259200,1:8,1440,8) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(2073600,32400,180,1) -> Half(129600,1:16,720,4) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(1036800,32400:2,180,1) -> Float(2073600,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(1036800,32400:2,180,1) -> Float(2073600,1,11520,64) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(1036800,32400:2,180,1) -> Float(518400,1:4,2880,16) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(1036800,32400:2,180,1) -> Half(2073600,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(1036800,32400:2,180,1) -> Half(259200,1:8,1440,8) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(1036800,32400:2,180,1) -> Half(129600,1:16,720,4) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(259200,1:8,1440,8) -> Float(2073600,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(259200,1:8,1440,8) -> Float(2073600,1,11520,64) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(259200,1:8,1440,8) -> Float(518400,1:4,2880,16) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(259200,1:8,1440,8) -> Half(2073600,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(259200,1:8,1440,8) -> Half(1036800,32400:2,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(259200,1:8,1440,8) -> Half(129600,1:16,720,4) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(129600,1:16,720,4) -> Float(2073600,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(129600,1:16,720,4) -> Float(2073600,1,11520,64) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(129600,1:16,720,4) -> Float(518400,1:4,2880,16) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(129600,1:16,720,4) -> Half(2073600,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(129600,1:16,720,4) -> Half(1036800,32400:2,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(129600,1:16,720,4) -> Half(259200,1:8,1440,8) ***************
[03/24/2023-12:56:23] [V] [TRT] =============== Computing reformatting costs
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(16588800,32400,180,1) -> Float(16588800,1,92160,512) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(16588800,32400,180,1) -> Float(4147200,1:4,23040,128) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(16588800,32400,180,1) -> Half(16588800,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(16588800,32400,180,1) -> Half(8294400,32400:2,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(16588800,32400,180,1) -> Half(2073600,1:8,11520,64) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(16588800,32400,180,1) -> Half(1036800,1:16,5760,32) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(16588800,1,92160,512) -> Float(16588800,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(16588800,1,92160,512) -> Float(4147200,1:4,23040,128) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(16588800,1,92160,512) -> Half(16588800,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(16588800,1,92160,512) -> Half(8294400,32400:2,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(16588800,1,92160,512) -> Half(2073600,1:8,11520,64) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(16588800,1,92160,512) -> Half(1036800,1:16,5760,32) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(4147200,1:4,23040,128) -> Float(16588800,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(4147200,1:4,23040,128) -> Float(16588800,1,92160,512) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(4147200,1:4,23040,128) -> Half(16588800,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(4147200,1:4,23040,128) -> Half(8294400,32400:2,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(4147200,1:4,23040,128) -> Half(2073600,1:8,11520,64) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(4147200,1:4,23040,128) -> Half(1036800,1:16,5760,32) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(16588800,32400,180,1) -> Float(16588800,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(16588800,32400,180,1) -> Float(16588800,1,92160,512) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(16588800,32400,180,1) -> Float(4147200,1:4,23040,128) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(16588800,32400,180,1) -> Half(8294400,32400:2,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(16588800,32400,180,1) -> Half(2073600,1:8,11520,64) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(16588800,32400,180,1) -> Half(1036800,1:16,5760,32) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(8294400,32400:2,180,1) -> Float(16588800,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(8294400,32400:2,180,1) -> Float(16588800,1,92160,512) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(8294400,32400:2,180,1) -> Float(4147200,1:4,23040,128) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(8294400,32400:2,180,1) -> Half(16588800,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(8294400,32400:2,180,1) -> Half(2073600,1:8,11520,64) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(8294400,32400:2,180,1) -> Half(1036800,1:16,5760,32) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(2073600,1:8,11520,64) -> Float(16588800,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(2073600,1:8,11520,64) -> Float(16588800,1,92160,512) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(2073600,1:8,11520,64) -> Float(4147200,1:4,23040,128) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(2073600,1:8,11520,64) -> Half(16588800,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(2073600,1:8,11520,64) -> Half(8294400,32400:2,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(2073600,1:8,11520,64) -> Half(1036800,1:16,5760,32) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(1036800,1:16,5760,32) -> Float(16588800,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(1036800,1:16,5760,32) -> Float(16588800,1,92160,512) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(1036800,1:16,5760,32) -> Float(4147200,1:4,23040,128) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(1036800,1:16,5760,32) -> Half(16588800,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(1036800,1:16,5760,32) -> Half(8294400,32400:2,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(1036800,1:16,5760,32) -> Half(2073600,1:8,11520,64) ***************
[03/24/2023-12:56:23] [V] [TRT] =============== Computing reformatting costs
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(16588800,32400,180,1) -> Float(16588800,1,92160,512) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(16588800,32400,180,1) -> Float(4147200,1:4,23040,128) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(16588800,32400,180,1) -> Half(16588800,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(16588800,32400,180,1) -> Half(8294400,32400:2,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(16588800,32400,180,1) -> Half(2073600,1:8,11520,64) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(16588800,32400,180,1) -> Half(1036800,1:16,5760,32) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(16588800,1,92160,512) -> Float(16588800,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(16588800,1,92160,512) -> Float(4147200,1:4,23040,128) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(16588800,1,92160,512) -> Half(16588800,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(16588800,1,92160,512) -> Half(8294400,32400:2,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(16588800,1,92160,512) -> Half(2073600,1:8,11520,64) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(16588800,1,92160,512) -> Half(1036800,1:16,5760,32) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(4147200,1:4,23040,128) -> Float(16588800,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(4147200,1:4,23040,128) -> Float(16588800,1,92160,512) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(4147200,1:4,23040,128) -> Half(16588800,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(4147200,1:4,23040,128) -> Half(8294400,32400:2,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(4147200,1:4,23040,128) -> Half(2073600,1:8,11520,64) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(4147200,1:4,23040,128) -> Half(1036800,1:16,5760,32) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(16588800,32400,180,1) -> Float(16588800,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(16588800,32400,180,1) -> Float(16588800,1,92160,512) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(16588800,32400,180,1) -> Float(4147200,1:4,23040,128) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(16588800,32400,180,1) -> Half(8294400,32400:2,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(16588800,32400,180,1) -> Half(2073600,1:8,11520,64) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(16588800,32400,180,1) -> Half(1036800,1:16,5760,32) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(8294400,32400:2,180,1) -> Float(16588800,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(8294400,32400:2,180,1) -> Float(16588800,1,92160,512) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(8294400,32400:2,180,1) -> Float(4147200,1:4,23040,128) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(8294400,32400:2,180,1) -> Half(16588800,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(8294400,32400:2,180,1) -> Half(2073600,1:8,11520,64) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(8294400,32400:2,180,1) -> Half(1036800,1:16,5760,32) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(2073600,1:8,11520,64) -> Float(16588800,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(2073600,1:8,11520,64) -> Float(16588800,1,92160,512) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(2073600,1:8,11520,64) -> Float(4147200,1:4,23040,128) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(2073600,1:8,11520,64) -> Half(16588800,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(2073600,1:8,11520,64) -> Half(8294400,32400:2,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(2073600,1:8,11520,64) -> Half(1036800,1:16,5760,32) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(1036800,1:16,5760,32) -> Float(16588800,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(1036800,1:16,5760,32) -> Float(16588800,1,92160,512) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(1036800,1:16,5760,32) -> Float(4147200,1:4,23040,128) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(1036800,1:16,5760,32) -> Half(16588800,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(1036800,1:16,5760,32) -> Half(8294400,32400:2,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(1036800,1:16,5760,32) -> Half(2073600,1:8,11520,64) ***************
[03/24/2023-12:56:23] [V] [TRT] =============== Computing reformatting costs
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(64800,32400,180,1) -> Half(64800,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(64800,1,360,2) -> Half(64800,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(32400,1:4,180,1) -> Half(64800,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(32400,32400:2,180,1) -> Half(64800,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(32400,1:8,180,1) -> Half(64800,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(32400,1:16,180,1) -> Half(64800,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] =============== Computing reformatting costs
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(16588800,32400,180,1) -> Float(16588800,1,92160,512) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(16588800,32400,180,1) -> Float(4147200,1:4,23040,128) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(16588800,32400,180,1) -> Half(16588800,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(16588800,32400,180,1) -> Half(8294400,32400:2,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(16588800,32400,180,1) -> Half(2073600,1:8,11520,64) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(16588800,32400,180,1) -> Half(1036800,1:16,5760,32) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(16588800,1,92160,512) -> Float(16588800,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(16588800,1,92160,512) -> Float(4147200,1:4,23040,128) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(16588800,1,92160,512) -> Half(16588800,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(16588800,1,92160,512) -> Half(8294400,32400:2,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(16588800,1,92160,512) -> Half(2073600,1:8,11520,64) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(16588800,1,92160,512) -> Half(1036800,1:16,5760,32) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(4147200,1:4,23040,128) -> Float(16588800,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(4147200,1:4,23040,128) -> Float(16588800,1,92160,512) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(4147200,1:4,23040,128) -> Half(16588800,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(4147200,1:4,23040,128) -> Half(8294400,32400:2,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(4147200,1:4,23040,128) -> Half(2073600,1:8,11520,64) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(4147200,1:4,23040,128) -> Half(1036800,1:16,5760,32) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(16588800,32400,180,1) -> Float(16588800,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(16588800,32400,180,1) -> Float(16588800,1,92160,512) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(16588800,32400,180,1) -> Float(4147200,1:4,23040,128) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(16588800,32400,180,1) -> Half(8294400,32400:2,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(16588800,32400,180,1) -> Half(2073600,1:8,11520,64) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(16588800,32400,180,1) -> Half(1036800,1:16,5760,32) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(8294400,32400:2,180,1) -> Float(16588800,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(8294400,32400:2,180,1) -> Float(16588800,1,92160,512) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(8294400,32400:2,180,1) -> Float(4147200,1:4,23040,128) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(8294400,32400:2,180,1) -> Half(16588800,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(8294400,32400:2,180,1) -> Half(2073600,1:8,11520,64) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(8294400,32400:2,180,1) -> Half(1036800,1:16,5760,32) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(2073600,1:8,11520,64) -> Float(16588800,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(2073600,1:8,11520,64) -> Float(16588800,1,92160,512) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(2073600,1:8,11520,64) -> Float(4147200,1:4,23040,128) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(2073600,1:8,11520,64) -> Half(16588800,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(2073600,1:8,11520,64) -> Half(8294400,32400:2,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(2073600,1:8,11520,64) -> Half(1036800,1:16,5760,32) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(1036800,1:16,5760,32) -> Float(16588800,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(1036800,1:16,5760,32) -> Float(16588800,1,92160,512) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(1036800,1:16,5760,32) -> Float(4147200,1:4,23040,128) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(1036800,1:16,5760,32) -> Half(16588800,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(1036800,1:16,5760,32) -> Half(8294400,32400:2,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(1036800,1:16,5760,32) -> Half(2073600,1:8,11520,64) ***************
[03/24/2023-12:56:23] [V] [TRT] =============== Computing reformatting costs
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(32400,32400,180,1) -> Half(32400,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(32400,1,180,1) -> Half(32400,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(32400,1:4,180,1) -> Half(32400,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(32400,32400:2,180,1) -> Half(32400,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(32400,1:8,180,1) -> Half(32400,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(32400,1:16,180,1) -> Half(32400,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] =============== Computing reformatting costs
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(16588800,32400,180,1) -> Float(16588800,1,92160,512) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(16588800,32400,180,1) -> Float(4147200,1:4,23040,128) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(16588800,32400,180,1) -> Half(16588800,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(16588800,32400,180,1) -> Half(8294400,32400:2,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(16588800,32400,180,1) -> Half(2073600,1:8,11520,64) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(16588800,32400,180,1) -> Half(1036800,1:16,5760,32) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(16588800,1,92160,512) -> Float(16588800,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(16588800,1,92160,512) -> Float(4147200,1:4,23040,128) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(16588800,1,92160,512) -> Half(16588800,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(16588800,1,92160,512) -> Half(8294400,32400:2,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(16588800,1,92160,512) -> Half(2073600,1:8,11520,64) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(16588800,1,92160,512) -> Half(1036800,1:16,5760,32) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(4147200,1:4,23040,128) -> Float(16588800,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(4147200,1:4,23040,128) -> Float(16588800,1,92160,512) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(4147200,1:4,23040,128) -> Half(16588800,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(4147200,1:4,23040,128) -> Half(8294400,32400:2,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(4147200,1:4,23040,128) -> Half(2073600,1:8,11520,64) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(4147200,1:4,23040,128) -> Half(1036800,1:16,5760,32) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(16588800,32400,180,1) -> Float(16588800,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(16588800,32400,180,1) -> Float(16588800,1,92160,512) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(16588800,32400,180,1) -> Float(4147200,1:4,23040,128) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(16588800,32400,180,1) -> Half(8294400,32400:2,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(16588800,32400,180,1) -> Half(2073600,1:8,11520,64) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(16588800,32400,180,1) -> Half(1036800,1:16,5760,32) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(8294400,32400:2,180,1) -> Float(16588800,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(8294400,32400:2,180,1) -> Float(16588800,1,92160,512) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(8294400,32400:2,180,1) -> Float(4147200,1:4,23040,128) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(8294400,32400:2,180,1) -> Half(16588800,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(8294400,32400:2,180,1) -> Half(2073600,1:8,11520,64) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(8294400,32400:2,180,1) -> Half(1036800,1:16,5760,32) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(2073600,1:8,11520,64) -> Float(16588800,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(2073600,1:8,11520,64) -> Float(16588800,1,92160,512) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(2073600,1:8,11520,64) -> Float(4147200,1:4,23040,128) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(2073600,1:8,11520,64) -> Half(16588800,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(2073600,1:8,11520,64) -> Half(8294400,32400:2,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(2073600,1:8,11520,64) -> Half(1036800,1:16,5760,32) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(1036800,1:16,5760,32) -> Float(16588800,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(1036800,1:16,5760,32) -> Float(16588800,1,92160,512) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(1036800,1:16,5760,32) -> Float(4147200,1:4,23040,128) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(1036800,1:16,5760,32) -> Half(16588800,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(1036800,1:16,5760,32) -> Half(8294400,32400:2,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(1036800,1:16,5760,32) -> Half(2073600,1:8,11520,64) ***************
[03/24/2023-12:56:23] [V] [TRT] =============== Computing reformatting costs
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(97200,32400,180,1) -> Half(97200,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(97200,1,540,3) -> Half(97200,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(32400,1:4,180,1) -> Half(97200,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(64800,32400:2,180,1) -> Half(97200,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(32400,1:8,180,1) -> Half(97200,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(32400,1:16,180,1) -> Half(97200,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] =============== Computing reformatting costs
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(16588800,32400,180,1) -> Float(16588800,1,92160,512) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(16588800,32400,180,1) -> Float(4147200,1:4,23040,128) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(16588800,32400,180,1) -> Half(16588800,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(16588800,32400,180,1) -> Half(8294400,32400:2,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(16588800,32400,180,1) -> Half(2073600,1:8,11520,64) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(16588800,32400,180,1) -> Half(1036800,1:16,5760,32) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(16588800,1,92160,512) -> Float(16588800,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(16588800,1,92160,512) -> Float(4147200,1:4,23040,128) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(16588800,1,92160,512) -> Half(16588800,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(16588800,1,92160,512) -> Half(8294400,32400:2,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(16588800,1,92160,512) -> Half(2073600,1:8,11520,64) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(16588800,1,92160,512) -> Half(1036800,1:16,5760,32) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(4147200,1:4,23040,128) -> Float(16588800,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(4147200,1:4,23040,128) -> Float(16588800,1,92160,512) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(4147200,1:4,23040,128) -> Half(16588800,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(4147200,1:4,23040,128) -> Half(8294400,32400:2,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(4147200,1:4,23040,128) -> Half(2073600,1:8,11520,64) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(4147200,1:4,23040,128) -> Half(1036800,1:16,5760,32) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(16588800,32400,180,1) -> Float(16588800,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(16588800,32400,180,1) -> Float(16588800,1,92160,512) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(16588800,32400,180,1) -> Float(4147200,1:4,23040,128) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(16588800,32400,180,1) -> Half(8294400,32400:2,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(16588800,32400,180,1) -> Half(2073600,1:8,11520,64) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(16588800,32400,180,1) -> Half(1036800,1:16,5760,32) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(8294400,32400:2,180,1) -> Float(16588800,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(8294400,32400:2,180,1) -> Float(16588800,1,92160,512) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(8294400,32400:2,180,1) -> Float(4147200,1:4,23040,128) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(8294400,32400:2,180,1) -> Half(16588800,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(8294400,32400:2,180,1) -> Half(2073600,1:8,11520,64) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(8294400,32400:2,180,1) -> Half(1036800,1:16,5760,32) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(2073600,1:8,11520,64) -> Float(16588800,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(2073600,1:8,11520,64) -> Float(16588800,1,92160,512) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(2073600,1:8,11520,64) -> Float(4147200,1:4,23040,128) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(2073600,1:8,11520,64) -> Half(16588800,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(2073600,1:8,11520,64) -> Half(8294400,32400:2,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(2073600,1:8,11520,64) -> Half(1036800,1:16,5760,32) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(1036800,1:16,5760,32) -> Float(16588800,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(1036800,1:16,5760,32) -> Float(16588800,1,92160,512) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(1036800,1:16,5760,32) -> Float(4147200,1:4,23040,128) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(1036800,1:16,5760,32) -> Half(16588800,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(1036800,1:16,5760,32) -> Half(8294400,32400:2,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(1036800,1:16,5760,32) -> Half(2073600,1:8,11520,64) ***************
[03/24/2023-12:56:23] [V] [TRT] =============== Computing reformatting costs
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(64800,32400,180,1) -> Half(64800,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(64800,1,360,2) -> Half(64800,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(32400,1:4,180,1) -> Half(64800,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(32400,32400:2,180,1) -> Half(64800,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(32400,1:8,180,1) -> Half(64800,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(32400,1:16,180,1) -> Half(64800,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] =============== Computing reformatting costs
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(16588800,32400,180,1) -> Float(16588800,1,92160,512) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(16588800,32400,180,1) -> Float(4147200,1:4,23040,128) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(16588800,32400,180,1) -> Half(16588800,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(16588800,32400,180,1) -> Half(8294400,32400:2,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(16588800,32400,180,1) -> Half(2073600,1:8,11520,64) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(16588800,32400,180,1) -> Half(1036800,1:16,5760,32) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(16588800,1,92160,512) -> Float(16588800,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(16588800,1,92160,512) -> Float(4147200,1:4,23040,128) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(16588800,1,92160,512) -> Half(16588800,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(16588800,1,92160,512) -> Half(8294400,32400:2,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(16588800,1,92160,512) -> Half(2073600,1:8,11520,64) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(16588800,1,92160,512) -> Half(1036800,1:16,5760,32) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(4147200,1:4,23040,128) -> Float(16588800,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(4147200,1:4,23040,128) -> Float(16588800,1,92160,512) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(4147200,1:4,23040,128) -> Half(16588800,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(4147200,1:4,23040,128) -> Half(8294400,32400:2,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(4147200,1:4,23040,128) -> Half(2073600,1:8,11520,64) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(4147200,1:4,23040,128) -> Half(1036800,1:16,5760,32) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(16588800,32400,180,1) -> Float(16588800,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(16588800,32400,180,1) -> Float(16588800,1,92160,512) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(16588800,32400,180,1) -> Float(4147200,1:4,23040,128) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(16588800,32400,180,1) -> Half(8294400,32400:2,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(16588800,32400,180,1) -> Half(2073600,1:8,11520,64) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(16588800,32400,180,1) -> Half(1036800,1:16,5760,32) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(8294400,32400:2,180,1) -> Float(16588800,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(8294400,32400:2,180,1) -> Float(16588800,1,92160,512) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(8294400,32400:2,180,1) -> Float(4147200,1:4,23040,128) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(8294400,32400:2,180,1) -> Half(16588800,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(8294400,32400:2,180,1) -> Half(2073600,1:8,11520,64) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(8294400,32400:2,180,1) -> Half(1036800,1:16,5760,32) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(2073600,1:8,11520,64) -> Float(16588800,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(2073600,1:8,11520,64) -> Float(16588800,1,92160,512) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(2073600,1:8,11520,64) -> Float(4147200,1:4,23040,128) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(2073600,1:8,11520,64) -> Half(16588800,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(2073600,1:8,11520,64) -> Half(8294400,32400:2,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(2073600,1:8,11520,64) -> Half(1036800,1:16,5760,32) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(1036800,1:16,5760,32) -> Float(16588800,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(1036800,1:16,5760,32) -> Float(16588800,1,92160,512) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(1036800,1:16,5760,32) -> Float(4147200,1:4,23040,128) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(1036800,1:16,5760,32) -> Half(16588800,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(1036800,1:16,5760,32) -> Half(8294400,32400:2,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(1036800,1:16,5760,32) -> Half(2073600,1:8,11520,64) ***************
[03/24/2023-12:56:23] [V] [TRT] =============== Computing reformatting costs
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(64800,32400,180,1) -> Half(64800,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(64800,1,360,2) -> Half(64800,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(32400,1:4,180,1) -> Half(64800,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(32400,32400:2,180,1) -> Half(64800,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(32400,1:8,180,1) -> Half(64800,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(32400,1:16,180,1) -> Half(64800,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] =============== Computing reformatting costs
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(16588800,32400,180,1) -> Float(16588800,1,92160,512) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(16588800,32400,180,1) -> Float(4147200,1:4,23040,128) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(16588800,32400,180,1) -> Half(16588800,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(16588800,32400,180,1) -> Half(8294400,32400:2,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(16588800,32400,180,1) -> Half(2073600,1:8,11520,64) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(16588800,32400,180,1) -> Half(1036800,1:16,5760,32) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(16588800,1,92160,512) -> Float(16588800,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(16588800,1,92160,512) -> Float(4147200,1:4,23040,128) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(16588800,1,92160,512) -> Half(16588800,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(16588800,1,92160,512) -> Half(8294400,32400:2,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(16588800,1,92160,512) -> Half(2073600,1:8,11520,64) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(16588800,1,92160,512) -> Half(1036800,1:16,5760,32) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(4147200,1:4,23040,128) -> Float(16588800,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(4147200,1:4,23040,128) -> Float(16588800,1,92160,512) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(4147200,1:4,23040,128) -> Half(16588800,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(4147200,1:4,23040,128) -> Half(8294400,32400:2,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(4147200,1:4,23040,128) -> Half(2073600,1:8,11520,64) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(4147200,1:4,23040,128) -> Half(1036800,1:16,5760,32) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(16588800,32400,180,1) -> Float(16588800,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(16588800,32400,180,1) -> Float(16588800,1,92160,512) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(16588800,32400,180,1) -> Float(4147200,1:4,23040,128) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(16588800,32400,180,1) -> Half(8294400,32400:2,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(16588800,32400,180,1) -> Half(2073600,1:8,11520,64) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(16588800,32400,180,1) -> Half(1036800,1:16,5760,32) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(8294400,32400:2,180,1) -> Float(16588800,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(8294400,32400:2,180,1) -> Float(16588800,1,92160,512) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(8294400,32400:2,180,1) -> Float(4147200,1:4,23040,128) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(8294400,32400:2,180,1) -> Half(16588800,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(8294400,32400:2,180,1) -> Half(2073600,1:8,11520,64) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(8294400,32400:2,180,1) -> Half(1036800,1:16,5760,32) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(2073600,1:8,11520,64) -> Float(16588800,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(2073600,1:8,11520,64) -> Float(16588800,1,92160,512) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(2073600,1:8,11520,64) -> Float(4147200,1:4,23040,128) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(2073600,1:8,11520,64) -> Half(16588800,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(2073600,1:8,11520,64) -> Half(8294400,32400:2,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(2073600,1:8,11520,64) -> Half(1036800,1:16,5760,32) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(1036800,1:16,5760,32) -> Float(16588800,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(1036800,1:16,5760,32) -> Float(16588800,1,92160,512) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(1036800,1:16,5760,32) -> Float(4147200,1:4,23040,128) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(1036800,1:16,5760,32) -> Half(16588800,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(1036800,1:16,5760,32) -> Half(8294400,32400:2,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(1036800,1:16,5760,32) -> Half(2073600,1:8,11520,64) ***************
[03/24/2023-12:56:23] [V] [TRT] =============== Computing reformatting costs
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(64800,32400,180,1) -> Half(64800,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(64800,1,360,2) -> Half(64800,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(32400,1:4,180,1) -> Half(64800,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(32400,32400:2,180,1) -> Half(64800,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(32400,1:8,180,1) -> Half(64800,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(32400,1:16,180,1) -> Half(64800,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] =============== Computing reformatting costs
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(16588800,32400,180,1) -> Float(16588800,1,92160,512) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(16588800,32400,180,1) -> Float(4147200,1:4,23040,128) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(16588800,32400,180,1) -> Half(16588800,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(16588800,32400,180,1) -> Half(8294400,32400:2,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(16588800,32400,180,1) -> Half(2073600,1:8,11520,64) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(16588800,32400,180,1) -> Half(1036800,1:16,5760,32) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(16588800,1,92160,512) -> Float(16588800,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(16588800,1,92160,512) -> Float(4147200,1:4,23040,128) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(16588800,1,92160,512) -> Half(16588800,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(16588800,1,92160,512) -> Half(8294400,32400:2,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(16588800,1,92160,512) -> Half(2073600,1:8,11520,64) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(16588800,1,92160,512) -> Half(1036800,1:16,5760,32) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(4147200,1:4,23040,128) -> Float(16588800,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(4147200,1:4,23040,128) -> Float(16588800,1,92160,512) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(4147200,1:4,23040,128) -> Half(16588800,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(4147200,1:4,23040,128) -> Half(8294400,32400:2,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(4147200,1:4,23040,128) -> Half(2073600,1:8,11520,64) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(4147200,1:4,23040,128) -> Half(1036800,1:16,5760,32) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(16588800,32400,180,1) -> Float(16588800,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(16588800,32400,180,1) -> Float(16588800,1,92160,512) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(16588800,32400,180,1) -> Float(4147200,1:4,23040,128) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(16588800,32400,180,1) -> Half(8294400,32400:2,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(16588800,32400,180,1) -> Half(2073600,1:8,11520,64) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(16588800,32400,180,1) -> Half(1036800,1:16,5760,32) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(8294400,32400:2,180,1) -> Float(16588800,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(8294400,32400:2,180,1) -> Float(16588800,1,92160,512) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(8294400,32400:2,180,1) -> Float(4147200,1:4,23040,128) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(8294400,32400:2,180,1) -> Half(16588800,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(8294400,32400:2,180,1) -> Half(2073600,1:8,11520,64) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(8294400,32400:2,180,1) -> Half(1036800,1:16,5760,32) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(2073600,1:8,11520,64) -> Float(16588800,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(2073600,1:8,11520,64) -> Float(16588800,1,92160,512) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(2073600,1:8,11520,64) -> Float(4147200,1:4,23040,128) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(2073600,1:8,11520,64) -> Half(16588800,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(2073600,1:8,11520,64) -> Half(8294400,32400:2,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(2073600,1:8,11520,64) -> Half(1036800,1:16,5760,32) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(1036800,1:16,5760,32) -> Float(16588800,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(1036800,1:16,5760,32) -> Float(16588800,1,92160,512) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(1036800,1:16,5760,32) -> Float(4147200,1:4,23040,128) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(1036800,1:16,5760,32) -> Half(16588800,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(1036800,1:16,5760,32) -> Half(8294400,32400:2,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(1036800,1:16,5760,32) -> Half(2073600,1:8,11520,64) ***************
[03/24/2023-12:56:23] [V] [TRT] =============== Computing reformatting costs
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(64800,32400,180,1) -> Half(64800,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(64800,1,360,2) -> Half(64800,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(32400,1:4,180,1) -> Half(64800,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(32400,32400:2,180,1) -> Half(64800,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(32400,1:8,180,1) -> Half(64800,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(32400,1:16,180,1) -> Half(64800,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] =============== Computing reformatting costs
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(16588800,32400,180,1) -> Float(16588800,1,92160,512) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(16588800,32400,180,1) -> Float(4147200,1:4,23040,128) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(16588800,32400,180,1) -> Half(16588800,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(16588800,32400,180,1) -> Half(8294400,32400:2,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(16588800,32400,180,1) -> Half(2073600,1:8,11520,64) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(16588800,32400,180,1) -> Half(1036800,1:16,5760,32) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(16588800,1,92160,512) -> Float(16588800,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(16588800,1,92160,512) -> Float(4147200,1:4,23040,128) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(16588800,1,92160,512) -> Half(16588800,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(16588800,1,92160,512) -> Half(8294400,32400:2,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(16588800,1,92160,512) -> Half(2073600,1:8,11520,64) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(16588800,1,92160,512) -> Half(1036800,1:16,5760,32) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(4147200,1:4,23040,128) -> Float(16588800,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(4147200,1:4,23040,128) -> Float(16588800,1,92160,512) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(4147200,1:4,23040,128) -> Half(16588800,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(4147200,1:4,23040,128) -> Half(8294400,32400:2,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(4147200,1:4,23040,128) -> Half(2073600,1:8,11520,64) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(4147200,1:4,23040,128) -> Half(1036800,1:16,5760,32) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(16588800,32400,180,1) -> Float(16588800,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(16588800,32400,180,1) -> Float(16588800,1,92160,512) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(16588800,32400,180,1) -> Float(4147200,1:4,23040,128) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(16588800,32400,180,1) -> Half(8294400,32400:2,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(16588800,32400,180,1) -> Half(2073600,1:8,11520,64) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(16588800,32400,180,1) -> Half(1036800,1:16,5760,32) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(8294400,32400:2,180,1) -> Float(16588800,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(8294400,32400:2,180,1) -> Float(16588800,1,92160,512) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(8294400,32400:2,180,1) -> Float(4147200,1:4,23040,128) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(8294400,32400:2,180,1) -> Half(16588800,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(8294400,32400:2,180,1) -> Half(2073600,1:8,11520,64) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(8294400,32400:2,180,1) -> Half(1036800,1:16,5760,32) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(2073600,1:8,11520,64) -> Float(16588800,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(2073600,1:8,11520,64) -> Float(16588800,1,92160,512) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(2073600,1:8,11520,64) -> Float(4147200,1:4,23040,128) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(2073600,1:8,11520,64) -> Half(16588800,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(2073600,1:8,11520,64) -> Half(8294400,32400:2,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(2073600,1:8,11520,64) -> Half(1036800,1:16,5760,32) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(1036800,1:16,5760,32) -> Float(16588800,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(1036800,1:16,5760,32) -> Float(16588800,1,92160,512) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(1036800,1:16,5760,32) -> Float(4147200,1:4,23040,128) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(1036800,1:16,5760,32) -> Half(16588800,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(1036800,1:16,5760,32) -> Half(8294400,32400:2,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(1036800,1:16,5760,32) -> Half(2073600,1:8,11520,64) ***************
[03/24/2023-12:56:23] [V] [TRT] =============== Computing reformatting costs
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(32400,32400,180,1) -> Half(32400,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(32400,1,180,1) -> Half(32400,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(32400,1:4,180,1) -> Half(32400,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(32400,32400:2,180,1) -> Half(32400,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(32400,1:8,180,1) -> Half(32400,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(32400,1:16,180,1) -> Half(32400,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] =============== Computing reformatting costs
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(2073600,32400,180,1) -> Float(2073600,1,11520,64) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(2073600,32400,180,1) -> Float(518400,1:4,2880,16) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(2073600,32400,180,1) -> Half(2073600,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(2073600,32400,180,1) -> Half(1036800,32400:2,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(2073600,32400,180,1) -> Half(259200,1:8,1440,8) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(2073600,32400,180,1) -> Half(129600,1:16,720,4) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(2073600,1,11520,64) -> Float(2073600,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(2073600,1,11520,64) -> Float(518400,1:4,2880,16) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(2073600,1,11520,64) -> Half(2073600,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(2073600,1,11520,64) -> Half(1036800,32400:2,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(2073600,1,11520,64) -> Half(259200,1:8,1440,8) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(2073600,1,11520,64) -> Half(129600,1:16,720,4) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(518400,1:4,2880,16) -> Float(2073600,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(518400,1:4,2880,16) -> Float(2073600,1,11520,64) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(518400,1:4,2880,16) -> Half(2073600,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(518400,1:4,2880,16) -> Half(1036800,32400:2,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(518400,1:4,2880,16) -> Half(259200,1:8,1440,8) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(518400,1:4,2880,16) -> Half(129600,1:16,720,4) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(2073600,32400,180,1) -> Float(2073600,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(2073600,32400,180,1) -> Float(2073600,1,11520,64) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(2073600,32400,180,1) -> Float(518400,1:4,2880,16) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(2073600,32400,180,1) -> Half(1036800,32400:2,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(2073600,32400,180,1) -> Half(259200,1:8,1440,8) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(2073600,32400,180,1) -> Half(129600,1:16,720,4) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(1036800,32400:2,180,1) -> Float(2073600,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(1036800,32400:2,180,1) -> Float(2073600,1,11520,64) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(1036800,32400:2,180,1) -> Float(518400,1:4,2880,16) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(1036800,32400:2,180,1) -> Half(2073600,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(1036800,32400:2,180,1) -> Half(259200,1:8,1440,8) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(1036800,32400:2,180,1) -> Half(129600,1:16,720,4) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(259200,1:8,1440,8) -> Float(2073600,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(259200,1:8,1440,8) -> Float(2073600,1,11520,64) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(259200,1:8,1440,8) -> Float(518400,1:4,2880,16) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(259200,1:8,1440,8) -> Half(2073600,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(259200,1:8,1440,8) -> Half(1036800,32400:2,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(259200,1:8,1440,8) -> Half(129600,1:16,720,4) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(129600,1:16,720,4) -> Float(2073600,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(129600,1:16,720,4) -> Float(2073600,1,11520,64) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(129600,1:16,720,4) -> Float(518400,1:4,2880,16) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(129600,1:16,720,4) -> Half(2073600,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(129600,1:16,720,4) -> Half(1036800,32400:2,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(129600,1:16,720,4) -> Half(259200,1:8,1440,8) ***************
[03/24/2023-12:56:23] [V] [TRT] =============== Computing reformatting costs
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(8294400,32400,180,1) -> Float(8294400,1,46080,256) ***************
[03/24/2023-12:56:23] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> Conv_158 + Relu_159 || Conv_161 + Relu_162 || Conv_164 + Relu_165 || Conv_167 + Relu_168) (Reformat)
[03/24/2023-12:56:23] [V] [TRT] Tactic: 1002 Time: 0.070784
[03/24/2023-12:56:23] [V] [TRT] Tactic: 0 Time: 0.185216
[03/24/2023-12:56:23] [V] [TRT] Fastest Tactic: 1002 Time: 0.070784
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(8294400,32400,180,1) -> Float(2073600,1:4,11520,64) ***************
[03/24/2023-12:56:23] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> Conv_158 + Relu_159 || Conv_161 + Relu_162 || Conv_164 + Relu_165 || Conv_167 + Relu_168) (Reformat)
[03/24/2023-12:56:23] [V] [TRT] Tactic: 1002 Time: 0.070656
[03/24/2023-12:56:23] [V] [TRT] Tactic: 0 Time: 0.185344
[03/24/2023-12:56:23] [V] [TRT] Fastest Tactic: 1002 Time: 0.070656
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(8294400,32400,180,1) -> Half(8294400,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> Conv_158 + Relu_159 || Conv_161 + Relu_162 || Conv_164 + Relu_165 || Conv_167 + Relu_168) (Reformat)
[03/24/2023-12:56:23] [V] [TRT] Tactic: 1002 Time: 0.082176
[03/24/2023-12:56:23] [V] [TRT] Tactic: 0 Time: 0.110848
[03/24/2023-12:56:23] [V] [TRT] Fastest Tactic: 1002 Time: 0.082176
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(8294400,32400,180,1) -> Half(4147200,32400:2,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> Conv_158 + Relu_159 || Conv_161 + Relu_162 || Conv_164 + Relu_165 || Conv_167 + Relu_168) (Reformat)
[03/24/2023-12:56:23] [V] [TRT] Tactic: 1002 Time: 0.089728
[03/24/2023-12:56:23] [V] [TRT] Tactic: 0 Time: 0.078976
[03/24/2023-12:56:23] [V] [TRT] Fastest Tactic: 0 Time: 0.078976
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(8294400,32400,180,1) -> Half(1036800,1:8,5760,32) ***************
[03/24/2023-12:56:23] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> Conv_158 + Relu_159 || Conv_161 + Relu_162 || Conv_164 + Relu_165 || Conv_167 + Relu_168) (Reformat)
[03/24/2023-12:56:23] [V] [TRT] Tactic: 1002 Time: 0.064
[03/24/2023-12:56:23] [V] [TRT] Tactic: 0 Time: 0.051968
[03/24/2023-12:56:23] [V] [TRT] Fastest Tactic: 0 Time: 0.051968
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(8294400,32400,180,1) -> Half(518400,1:16,2880,16) ***************
[03/24/2023-12:56:23] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> Conv_158 + Relu_159 || Conv_161 + Relu_162 || Conv_164 + Relu_165 || Conv_167 + Relu_168) (Reformat)
[03/24/2023-12:56:23] [V] [TRT] Tactic: 1002 Time: 0.063872
[03/24/2023-12:56:23] [V] [TRT] Tactic: 0 Time: 0.184448
[03/24/2023-12:56:23] [V] [TRT] Fastest Tactic: 1002 Time: 0.063872
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(8294400,1,46080,256) -> Float(8294400,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> Conv_158 + Relu_159 || Conv_161 + Relu_162 || Conv_164 + Relu_165 || Conv_167 + Relu_168) (Reformat)
[03/24/2023-12:56:23] [V] [TRT] Tactic: 1002 Time: 0.074624
[03/24/2023-12:56:23] [V] [TRT] Tactic: 0 Time: 0.16896
[03/24/2023-12:56:23] [V] [TRT] Fastest Tactic: 1002 Time: 0.074624
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(8294400,1,46080,256) -> Float(2073600,1:4,11520,64) ***************
[03/24/2023-12:56:23] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> Conv_158 + Relu_159 || Conv_161 + Relu_162 || Conv_164 + Relu_165 || Conv_167 + Relu_168) (Reformat)
[03/24/2023-12:56:23] [V] [TRT] Tactic: 1002 Time: 0.065152
[03/24/2023-12:56:23] [V] [TRT] Tactic: 0 Time: 0.100224
[03/24/2023-12:56:23] [V] [TRT] Fastest Tactic: 1002 Time: 0.065152
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(8294400,1,46080,256) -> Half(8294400,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> Conv_158 + Relu_159 || Conv_161 + Relu_162 || Conv_164 + Relu_165 || Conv_167 + Relu_168) (Reformat)
[03/24/2023-12:56:23] [V] [TRT] Tactic: 1002 Time: 0.068992
[03/24/2023-12:56:23] [V] [TRT] Tactic: 0 Time: 0.15872
[03/24/2023-12:56:23] [V] [TRT] Fastest Tactic: 1002 Time: 0.068992
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(8294400,1,46080,256) -> Half(4147200,32400:2,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> Conv_158 + Relu_159 || Conv_161 + Relu_162 || Conv_164 + Relu_165 || Conv_167 + Relu_168) (Reformat)
[03/24/2023-12:56:23] [V] [TRT] Tactic: 1002 Time: 0.086656
[03/24/2023-12:56:23] [V] [TRT] Tactic: 0 Time: 0.169216
[03/24/2023-12:56:23] [V] [TRT] Fastest Tactic: 1002 Time: 0.086656
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(8294400,1,46080,256) -> Half(1036800,1:8,5760,32) ***************
[03/24/2023-12:56:23] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> Conv_158 + Relu_159 || Conv_161 + Relu_162 || Conv_164 + Relu_165 || Conv_167 + Relu_168) (Reformat)
[03/24/2023-12:56:23] [V] [TRT] Tactic: 1002 Time: 0.057472
[03/24/2023-12:56:23] [V] [TRT] Tactic: 0 Time: 0.100608
[03/24/2023-12:56:23] [V] [TRT] Fastest Tactic: 1002 Time: 0.057472
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(8294400,1,46080,256) -> Half(518400,1:16,2880,16) ***************
[03/24/2023-12:56:23] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> Conv_158 + Relu_159 || Conv_161 + Relu_162 || Conv_164 + Relu_165 || Conv_167 + Relu_168) (Reformat)
[03/24/2023-12:56:23] [V] [TRT] Tactic: 1002 Time: 0.057088
[03/24/2023-12:56:23] [V] [TRT] Tactic: 0 Time: 0.100608
[03/24/2023-12:56:23] [V] [TRT] Fastest Tactic: 1002 Time: 0.057088
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(2073600,1:4,11520,64) -> Float(8294400,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> Conv_158 + Relu_159 || Conv_161 + Relu_162 || Conv_164 + Relu_165 || Conv_167 + Relu_168) (Reformat)
[03/24/2023-12:56:23] [V] [TRT] Tactic: 1002 Time: 0.075136
[03/24/2023-12:56:23] [V] [TRT] Tactic: 0 Time: 0.170752
[03/24/2023-12:56:23] [V] [TRT] Fastest Tactic: 1002 Time: 0.075136
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(2073600,1:4,11520,64) -> Float(8294400,1,46080,256) ***************
[03/24/2023-12:56:23] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> Conv_158 + Relu_159 || Conv_161 + Relu_162 || Conv_164 + Relu_165 || Conv_167 + Relu_168) (Reformat)
[03/24/2023-12:56:23] [V] [TRT] Tactic: 1002 Time: 0.065024
[03/24/2023-12:56:23] [V] [TRT] Tactic: 0 Time: 0.100608
[03/24/2023-12:56:23] [V] [TRT] Fastest Tactic: 1002 Time: 0.065024
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(2073600,1:4,11520,64) -> Half(8294400,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> Conv_158 + Relu_159 || Conv_161 + Relu_162 || Conv_164 + Relu_165 || Conv_167 + Relu_168) (Reformat)
[03/24/2023-12:56:23] [V] [TRT] Tactic: 1002 Time: 0.069376
[03/24/2023-12:56:23] [V] [TRT] Tactic: 0 Time: 0.162176
[03/24/2023-12:56:23] [V] [TRT] Fastest Tactic: 1002 Time: 0.069376
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(2073600,1:4,11520,64) -> Half(4147200,32400:2,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> Conv_158 + Relu_159 || Conv_161 + Relu_162 || Conv_164 + Relu_165 || Conv_167 + Relu_168) (Reformat)
[03/24/2023-12:56:23] [V] [TRT] Tactic: 1002 Time: 0.086144
[03/24/2023-12:56:23] [V] [TRT] Tactic: 0 Time: 0.171904
[03/24/2023-12:56:23] [V] [TRT] Fastest Tactic: 1002 Time: 0.086144
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(2073600,1:4,11520,64) -> Half(1036800,1:8,5760,32) ***************
[03/24/2023-12:56:23] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> Conv_158 + Relu_159 || Conv_161 + Relu_162 || Conv_164 + Relu_165 || Conv_167 + Relu_168) (Reformat)
[03/24/2023-12:56:23] [V] [TRT] Tactic: 1002 Time: 0.057472
[03/24/2023-12:56:23] [V] [TRT] Tactic: 0 Time: 0.116992
[03/24/2023-12:56:23] [V] [TRT] Fastest Tactic: 1002 Time: 0.057472
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(2073600,1:4,11520,64) -> Half(518400,1:16,2880,16) ***************
[03/24/2023-12:56:23] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> Conv_158 + Relu_159 || Conv_161 + Relu_162 || Conv_164 + Relu_165 || Conv_167 + Relu_168) (Reformat)
[03/24/2023-12:56:23] [V] [TRT] Tactic: 1002 Time: 0.057344
[03/24/2023-12:56:23] [V] [TRT] Tactic: 0 Time: 0.116992
[03/24/2023-12:56:23] [V] [TRT] Fastest Tactic: 1002 Time: 0.057344
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(8294400,32400,180,1) -> Float(8294400,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> Conv_158 + Relu_159 || Conv_161 + Relu_162 || Conv_164 + Relu_165 || Conv_167 + Relu_168) (Reformat)
[03/24/2023-12:56:23] [V] [TRT] Tactic: 1002 Time: 0.082048
[03/24/2023-12:56:23] [V] [TRT] Tactic: 0 Time: 0.10496
[03/24/2023-12:56:23] [V] [TRT] Fastest Tactic: 1002 Time: 0.082048
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(8294400,32400,180,1) -> Float(8294400,1,46080,256) ***************
[03/24/2023-12:56:23] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> Conv_158 + Relu_159 || Conv_161 + Relu_162 || Conv_164 + Relu_165 || Conv_167 + Relu_168) (Reformat)
[03/24/2023-12:56:23] [V] [TRT] Tactic: 1002 Time: 0.063872
[03/24/2023-12:56:23] [V] [TRT] Tactic: 0 Time: 0.148096
[03/24/2023-12:56:23] [V] [TRT] Fastest Tactic: 1002 Time: 0.063872
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(8294400,32400,180,1) -> Float(2073600,1:4,11520,64) ***************
[03/24/2023-12:56:23] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> Conv_158 + Relu_159 || Conv_161 + Relu_162 || Conv_164 + Relu_165 || Conv_167 + Relu_168) (Reformat)
[03/24/2023-12:56:23] [V] [TRT] Tactic: 1002 Time: 0.063744
[03/24/2023-12:56:23] [V] [TRT] Tactic: 0 Time: 0.150656
[03/24/2023-12:56:23] [V] [TRT] Fastest Tactic: 1002 Time: 0.063744
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(8294400,32400,180,1) -> Half(4147200,32400:2,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> Conv_158 + Relu_159 || Conv_161 + Relu_162 || Conv_164 + Relu_165 || Conv_167 + Relu_168) (Reformat)
[03/24/2023-12:56:23] [V] [TRT] Tactic: 1002 Time: 0.06464
[03/24/2023-12:56:23] [V] [TRT] Tactic: 0 Time: 0.078848
[03/24/2023-12:56:23] [V] [TRT] Fastest Tactic: 1002 Time: 0.06464
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(8294400,32400,180,1) -> Half(1036800,1:8,5760,32) ***************
[03/24/2023-12:56:23] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> Conv_158 + Relu_159 || Conv_161 + Relu_162 || Conv_164 + Relu_165 || Conv_167 + Relu_168) (Reformat)
[03/24/2023-12:56:23] [V] [TRT] Tactic: 1002 Time: 0.068736
[03/24/2023-12:56:23] [V] [TRT] Tactic: 0 Time: 0.048256
[03/24/2023-12:56:23] [V] [TRT] Fastest Tactic: 0 Time: 0.048256
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(8294400,32400,180,1) -> Half(518400,1:16,2880,16) ***************
[03/24/2023-12:56:23] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> Conv_158 + Relu_159 || Conv_161 + Relu_162 || Conv_164 + Relu_165 || Conv_167 + Relu_168) (Reformat)
[03/24/2023-12:56:23] [V] [TRT] Tactic: 1002 Time: 0.068608
[03/24/2023-12:56:23] [V] [TRT] Tactic: 0 Time: 0.145536
[03/24/2023-12:56:23] [V] [TRT] Fastest Tactic: 1002 Time: 0.068608
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(4147200,32400:2,180,1) -> Float(8294400,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> Conv_158 + Relu_159 || Conv_161 + Relu_162 || Conv_164 + Relu_165 || Conv_167 + Relu_168) (Reformat)
[03/24/2023-12:56:23] [V] [TRT] Tactic: 1002 Time: 0.075904
[03/24/2023-12:56:23] [V] [TRT] Tactic: 0 Time: 0.07872
[03/24/2023-12:56:23] [V] [TRT] Fastest Tactic: 1002 Time: 0.075904
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(4147200,32400:2,180,1) -> Float(8294400,1,46080,256) ***************
[03/24/2023-12:56:23] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> Conv_158 + Relu_159 || Conv_161 + Relu_162 || Conv_164 + Relu_165 || Conv_167 + Relu_168) (Reformat)
[03/24/2023-12:56:23] [V] [TRT] Tactic: 1002 Time: 0.06464
[03/24/2023-12:56:23] [V] [TRT] Tactic: 0 Time: 0.104192
[03/24/2023-12:56:23] [V] [TRT] Fastest Tactic: 1002 Time: 0.06464
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(4147200,32400:2,180,1) -> Float(2073600,1:4,11520,64) ***************
[03/24/2023-12:56:23] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> Conv_158 + Relu_159 || Conv_161 + Relu_162 || Conv_164 + Relu_165 || Conv_167 + Relu_168) (Reformat)
[03/24/2023-12:56:23] [V] [TRT] Tactic: 1002 Time: 0.064512
[03/24/2023-12:56:23] [V] [TRT] Tactic: 0 Time: 0.1184
[03/24/2023-12:56:23] [V] [TRT] Fastest Tactic: 1002 Time: 0.064512
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(4147200,32400:2,180,1) -> Half(8294400,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> Conv_158 + Relu_159 || Conv_161 + Relu_162 || Conv_164 + Relu_165 || Conv_167 + Relu_168) (Reformat)
[03/24/2023-12:56:23] [V] [TRT] Tactic: 1002 Time: 0.213376
[03/24/2023-12:56:23] [V] [TRT] Tactic: 0 Time: 0.078208
[03/24/2023-12:56:23] [V] [TRT] Fastest Tactic: 0 Time: 0.078208
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(4147200,32400:2,180,1) -> Half(1036800,1:8,5760,32) ***************
[03/24/2023-12:56:23] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> Conv_158 + Relu_159 || Conv_161 + Relu_162 || Conv_164 + Relu_165 || Conv_167 + Relu_168) (Reformat)
[03/24/2023-12:56:23] [V] [TRT] Tactic: 1002 Time: 0.06464
[03/24/2023-12:56:23] [V] [TRT] Tactic: 0 Time: 0.042368
[03/24/2023-12:56:23] [V] [TRT] Fastest Tactic: 0 Time: 0.042368
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(4147200,32400:2,180,1) -> Half(518400,1:16,2880,16) ***************
[03/24/2023-12:56:23] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> Conv_158 + Relu_159 || Conv_161 + Relu_162 || Conv_164 + Relu_165 || Conv_167 + Relu_168) (Reformat)
[03/24/2023-12:56:23] [V] [TRT] Tactic: 1002 Time: 0.064512
[03/24/2023-12:56:23] [V] [TRT] Tactic: 0 Time: 0.109568
[03/24/2023-12:56:23] [V] [TRT] Fastest Tactic: 1002 Time: 0.064512
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(1036800,1:8,5760,32) -> Float(8294400,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> Conv_158 + Relu_159 || Conv_161 + Relu_162 || Conv_164 + Relu_165 || Conv_167 + Relu_168) (Reformat)
[03/24/2023-12:56:23] [V] [TRT] Tactic: 1002 Time: 0.070272
[03/24/2023-12:56:23] [V] [TRT] Tactic: 0 Time: 0.047488
[03/24/2023-12:56:23] [V] [TRT] Fastest Tactic: 0 Time: 0.047488
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(1036800,1:8,5760,32) -> Float(8294400,1,46080,256) ***************
[03/24/2023-12:56:23] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> Conv_158 + Relu_159 || Conv_161 + Relu_162 || Conv_164 + Relu_165 || Conv_167 + Relu_168) (Reformat)
[03/24/2023-12:56:23] [V] [TRT] Tactic: 1002 Time: 0.057344
[03/24/2023-12:56:23] [V] [TRT] Tactic: 0 Time: 0.102528
[03/24/2023-12:56:23] [V] [TRT] Fastest Tactic: 1002 Time: 0.057344
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(1036800,1:8,5760,32) -> Float(2073600,1:4,11520,64) ***************
[03/24/2023-12:56:23] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> Conv_158 + Relu_159 || Conv_161 + Relu_162 || Conv_164 + Relu_165 || Conv_167 + Relu_168) (Reformat)
[03/24/2023-12:56:23] [V] [TRT] Tactic: 1002 Time: 0.057472
[03/24/2023-12:56:23] [V] [TRT] Tactic: 0 Time: 0.117888
[03/24/2023-12:56:23] [V] [TRT] Fastest Tactic: 1002 Time: 0.057472
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(1036800,1:8,5760,32) -> Half(8294400,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> Conv_158 + Relu_159 || Conv_161 + Relu_162 || Conv_164 + Relu_165 || Conv_167 + Relu_168) (Reformat)
[03/24/2023-12:56:23] [V] [TRT] Tactic: 1002 Time: 0.16064
[03/24/2023-12:56:23] [V] [TRT] Tactic: 0 Time: 0.034944
[03/24/2023-12:56:23] [V] [TRT] Fastest Tactic: 0 Time: 0.034944
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(1036800,1:8,5760,32) -> Half(4147200,32400:2,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> Conv_158 + Relu_159 || Conv_161 + Relu_162 || Conv_164 + Relu_165 || Conv_167 + Relu_168) (Reformat)
[03/24/2023-12:56:23] [V] [TRT] Tactic: 1002 Time: 0.082816
[03/24/2023-12:56:23] [V] [TRT] Tactic: 0 Time: 0.034048
[03/24/2023-12:56:23] [V] [TRT] Fastest Tactic: 0 Time: 0.034048
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(1036800,1:8,5760,32) -> Half(518400,1:16,2880,16) ***************
[03/24/2023-12:56:23] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> Conv_158 + Relu_159 || Conv_161 + Relu_162 || Conv_164 + Relu_165 || Conv_167 + Relu_168) (Reformat)
[03/24/2023-12:56:23] [V] [TRT] Tactic: 1002 Time: 0.057216
[03/24/2023-12:56:23] [V] [TRT] Tactic: 0 Time: 0.109056
[03/24/2023-12:56:23] [V] [TRT] Fastest Tactic: 1002 Time: 0.057216
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(518400,1:16,2880,16) -> Float(8294400,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> Conv_158 + Relu_159 || Conv_161 + Relu_162 || Conv_164 + Relu_165 || Conv_167 + Relu_168) (Reformat)
[03/24/2023-12:56:23] [V] [TRT] Tactic: 1002 Time: 0.070144
[03/24/2023-12:56:23] [V] [TRT] Tactic: 0 Time: 0.141056
[03/24/2023-12:56:23] [V] [TRT] Fastest Tactic: 1002 Time: 0.070144
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(518400,1:16,2880,16) -> Float(8294400,1,46080,256) ***************
[03/24/2023-12:56:23] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> Conv_158 + Relu_159 || Conv_161 + Relu_162 || Conv_164 + Relu_165 || Conv_167 + Relu_168) (Reformat)
[03/24/2023-12:56:23] [V] [TRT] Tactic: 1002 Time: 0.057216
[03/24/2023-12:56:23] [V] [TRT] Tactic: 0 Time: 0.102528
[03/24/2023-12:56:23] [V] [TRT] Fastest Tactic: 1002 Time: 0.057216
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(518400,1:16,2880,16) -> Float(2073600,1:4,11520,64) ***************
[03/24/2023-12:56:23] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> Conv_158 + Relu_159 || Conv_161 + Relu_162 || Conv_164 + Relu_165 || Conv_167 + Relu_168) (Reformat)
[03/24/2023-12:56:23] [V] [TRT] Tactic: 1002 Time: 0.057216
[03/24/2023-12:56:23] [V] [TRT] Tactic: 0 Time: 0.11776
[03/24/2023-12:56:23] [V] [TRT] Fastest Tactic: 1002 Time: 0.057216
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(518400,1:16,2880,16) -> Half(8294400,32400,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> Conv_158 + Relu_159 || Conv_161 + Relu_162 || Conv_164 + Relu_165 || Conv_167 + Relu_168) (Reformat)
[03/24/2023-12:56:23] [V] [TRT] Tactic: 1002 Time: 0.160384
[03/24/2023-12:56:23] [V] [TRT] Tactic: 0 Time: 0.13568
[03/24/2023-12:56:23] [V] [TRT] Fastest Tactic: 0 Time: 0.13568
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(518400,1:16,2880,16) -> Half(4147200,32400:2,180,1) ***************
[03/24/2023-12:56:23] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> Conv_158 + Relu_159 || Conv_161 + Relu_162 || Conv_164 + Relu_165 || Conv_167 + Relu_168) (Reformat)
[03/24/2023-12:56:23] [V] [TRT] Tactic: 1002 Time: 0.083968
[03/24/2023-12:56:23] [V] [TRT] Tactic: 0 Time: 0.177408
[03/24/2023-12:56:23] [V] [TRT] Fastest Tactic: 1002 Time: 0.083968
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Half(518400,1:16,2880,16) -> Half(1036800,1:8,5760,32) ***************
[03/24/2023-12:56:23] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> Conv_158 + Relu_159 || Conv_161 + Relu_162 || Conv_164 + Relu_165 || Conv_167 + Relu_168) (Reformat)
[03/24/2023-12:56:23] [V] [TRT] Tactic: 1002 Time: 0.0736
[03/24/2023-12:56:23] [V] [TRT] Tactic: 0 Time: 0.13888
[03/24/2023-12:56:23] [V] [TRT] Fastest Tactic: 1002 Time: 0.0736
[03/24/2023-12:56:23] [V] [TRT] =============== Computing reformatting costs
[03/24/2023-12:56:23] [V] [TRT] *************** Autotuning Reformat: Float(8294400,32400,180,1) -> Float(8294400,1,46080,256) ***************
[03/24/2023-12:56:23] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(input.568 -> <out>) (Reformat)
[03/24/2023-12:56:24] [V] [TRT] Tactic: 1002 Time: 0.034816
[03/24/2023-12:56:24] [V] [TRT] Tactic: 0 Time: 0.03776
[03/24/2023-12:56:24] [V] [TRT] Fastest Tactic: 1002 Time: 0.034816
[03/24/2023-12:56:24] [V] [TRT] *************** Autotuning Reformat: Float(8294400,32400,180,1) -> Float(2073600,1:4,11520,64) ***************
[03/24/2023-12:56:24] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(input.568 -> <out>) (Reformat)
[03/24/2023-12:56:24] [V] [TRT] Tactic: 1002 Time: 0.034816
[03/24/2023-12:56:24] [V] [TRT] Tactic: 0 Time: 0.04096
[03/24/2023-12:56:24] [V] [TRT] Fastest Tactic: 1002 Time: 0.034816
[03/24/2023-12:56:24] [V] [TRT] *************** Autotuning Reformat: Float(8294400,32400,180,1) -> Half(8294400,32400,180,1) ***************
[03/24/2023-12:56:24] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(input.568 -> <out>) (Reformat)
[03/24/2023-12:56:24] [V] [TRT] Tactic: 1002 Time: 0.04096
[03/24/2023-12:56:24] [V] [TRT] Tactic: 0 Time: 0.03584
[03/24/2023-12:56:24] [V] [TRT] Fastest Tactic: 0 Time: 0.03584
[03/24/2023-12:56:24] [V] [TRT] *************** Autotuning Reformat: Float(8294400,32400,180,1) -> Half(4147200,32400:2,180,1) ***************
[03/24/2023-12:56:24] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(input.568 -> <out>) (Reformat)
[03/24/2023-12:56:24] [V] [TRT] Tactic: 1002 Time: 0.042496
[03/24/2023-12:56:24] [V] [TRT] Tactic: 0 Time: 0.038912
[03/24/2023-12:56:24] [V] [TRT] Fastest Tactic: 0 Time: 0.038912
[03/24/2023-12:56:24] [V] [TRT] *************** Autotuning Reformat: Float(8294400,32400,180,1) -> Half(1036800,1:8,5760,32) ***************
[03/24/2023-12:56:24] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(input.568 -> <out>) (Reformat)
[03/24/2023-12:56:24] [V] [TRT] Tactic: 1002 Time: 0.031616
[03/24/2023-12:56:24] [V] [TRT] Tactic: 0 Time: 0.040832
[03/24/2023-12:56:24] [V] [TRT] Fastest Tactic: 1002 Time: 0.031616
[03/24/2023-12:56:24] [V] [TRT] *************** Autotuning Reformat: Float(8294400,32400,180,1) -> Half(518400,1:16,2880,16) ***************
[03/24/2023-12:56:24] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(input.568 -> <out>) (Reformat)
[03/24/2023-12:56:24] [V] [TRT] Tactic: 1002 Time: 0.031488
[03/24/2023-12:56:24] [V] [TRT] Tactic: 0 Time: 0.040832
[03/24/2023-12:56:24] [V] [TRT] Fastest Tactic: 1002 Time: 0.031488
[03/24/2023-12:56:24] [V] [TRT] *************** Autotuning Reformat: Float(8294400,1,46080,256) -> Float(8294400,32400,180,1) ***************
[03/24/2023-12:56:24] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(input.568 -> <out>) (Reformat)
[03/24/2023-12:56:24] [V] [TRT] Tactic: 1002 Time: 0.038528
[03/24/2023-12:56:24] [V] [TRT] Tactic: 0 Time: 0.054656
[03/24/2023-12:56:24] [V] [TRT] Fastest Tactic: 1002 Time: 0.038528
[03/24/2023-12:56:24] [V] [TRT] *************** Autotuning Reformat: Float(8294400,1,46080,256) -> Float(2073600,1:4,11520,64) ***************
[03/24/2023-12:56:24] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(input.568 -> <out>) (Reformat)
[03/24/2023-12:56:24] [V] [TRT] Tactic: 1002 Time: 0.030592
[03/24/2023-12:56:24] [V] [TRT] Tactic: 0 Time: 0.040064
[03/24/2023-12:56:24] [V] [TRT] Fastest Tactic: 1002 Time: 0.030592
[03/24/2023-12:56:24] [V] [TRT] *************** Autotuning Reformat: Float(8294400,1,46080,256) -> Half(8294400,32400,180,1) ***************
[03/24/2023-12:56:24] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(input.568 -> <out>) (Reformat)
[03/24/2023-12:56:24] [V] [TRT] Tactic: 1002 Time: 0.034176
[03/24/2023-12:56:24] [V] [TRT] Tactic: 0 Time: 0.053248
[03/24/2023-12:56:24] [V] [TRT] Fastest Tactic: 1002 Time: 0.034176
[03/24/2023-12:56:24] [V] [TRT] *************** Autotuning Reformat: Float(8294400,1,46080,256) -> Half(4147200,32400:2,180,1) ***************
[03/24/2023-12:56:24] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(input.568 -> <out>) (Reformat)
[03/24/2023-12:56:24] [V] [TRT] Tactic: 1002 Time: 0.041344
[03/24/2023-12:56:24] [V] [TRT] Tactic: 0 Time: 0.056704
[03/24/2023-12:56:24] [V] [TRT] Fastest Tactic: 1002 Time: 0.041344
[03/24/2023-12:56:24] [V] [TRT] *************** Autotuning Reformat: Float(8294400,1,46080,256) -> Half(1036800,1:8,5760,32) ***************
[03/24/2023-12:56:24] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(input.568 -> <out>) (Reformat)
[03/24/2023-12:56:24] [V] [TRT] Tactic: 1002 Time: 0.028672
[03/24/2023-12:56:24] [V] [TRT] Tactic: 0 Time: 0.04096
[03/24/2023-12:56:24] [V] [TRT] Fastest Tactic: 1002 Time: 0.028672
[03/24/2023-12:56:24] [V] [TRT] *************** Autotuning Reformat: Float(8294400,1,46080,256) -> Half(518400,1:16,2880,16) ***************
[03/24/2023-12:56:24] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(input.568 -> <out>) (Reformat)
[03/24/2023-12:56:24] [V] [TRT] Tactic: 1002 Time: 0.028672
[03/24/2023-12:56:24] [V] [TRT] Tactic: 0 Time: 0.04096
[03/24/2023-12:56:24] [V] [TRT] Fastest Tactic: 1002 Time: 0.028672
[03/24/2023-12:56:24] [V] [TRT] *************** Autotuning Reformat: Float(2073600,1:4,11520,64) -> Float(8294400,32400,180,1) ***************
[03/24/2023-12:56:24] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(input.568 -> <out>) (Reformat)
[03/24/2023-12:56:24] [V] [TRT] Tactic: 1002 Time: 0.038528
[03/24/2023-12:56:24] [V] [TRT] Tactic: 0 Time: 0.055168
[03/24/2023-12:56:24] [V] [TRT] Fastest Tactic: 1002 Time: 0.038528
[03/24/2023-12:56:24] [V] [TRT] *************** Autotuning Reformat: Float(2073600,1:4,11520,64) -> Float(8294400,1,46080,256) ***************
[03/24/2023-12:56:24] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(input.568 -> <out>) (Reformat)
[03/24/2023-12:56:24] [V] [TRT] Tactic: 1002 Time: 0.030336
[03/24/2023-12:56:24] [V] [TRT] Tactic: 0 Time: 0.040064
[03/24/2023-12:56:24] [V] [TRT] Fastest Tactic: 1002 Time: 0.030336
[03/24/2023-12:56:24] [V] [TRT] *************** Autotuning Reformat: Float(2073600,1:4,11520,64) -> Half(8294400,32400,180,1) ***************
[03/24/2023-12:56:24] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(input.568 -> <out>) (Reformat)
[03/24/2023-12:56:24] [V] [TRT] Tactic: 1002 Time: 0.034048
[03/24/2023-12:56:24] [V] [TRT] Tactic: 0 Time: 0.053376
[03/24/2023-12:56:24] [V] [TRT] Fastest Tactic: 1002 Time: 0.034048
[03/24/2023-12:56:24] [V] [TRT] *************** Autotuning Reformat: Float(2073600,1:4,11520,64) -> Half(4147200,32400:2,180,1) ***************
[03/24/2023-12:56:24] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(input.568 -> <out>) (Reformat)
[03/24/2023-12:56:24] [V] [TRT] Tactic: 1002 Time: 0.0416
[03/24/2023-12:56:24] [V] [TRT] Tactic: 0 Time: 0.056448
[03/24/2023-12:56:24] [V] [TRT] Fastest Tactic: 1002 Time: 0.0416
[03/24/2023-12:56:24] [V] [TRT] *************** Autotuning Reformat: Float(2073600,1:4,11520,64) -> Half(1036800,1:8,5760,32) ***************
[03/24/2023-12:56:24] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(input.568 -> <out>) (Reformat)
[03/24/2023-12:56:24] [V] [TRT] Tactic: 1002 Time: 0.028672
[03/24/2023-12:56:24] [V] [TRT] Tactic: 0 Time: 0.04608
[03/24/2023-12:56:24] [V] [TRT] Fastest Tactic: 1002 Time: 0.028672
[03/24/2023-12:56:24] [V] [TRT] *************** Autotuning Reformat: Float(2073600,1:4,11520,64) -> Half(518400,1:16,2880,16) ***************
[03/24/2023-12:56:24] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(input.568 -> <out>) (Reformat)
[03/24/2023-12:56:24] [V] [TRT] Tactic: 1002 Time: 0.0288
[03/24/2023-12:56:24] [V] [TRT] Tactic: 0 Time: 0.045952
[03/24/2023-12:56:24] [V] [TRT] Fastest Tactic: 1002 Time: 0.0288
[03/24/2023-12:56:24] [V] [TRT] *************** Autotuning Reformat: Half(8294400,32400,180,1) -> Float(8294400,32400,180,1) ***************
[03/24/2023-12:56:24] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(input.568 -> <out>) (Reformat)
[03/24/2023-12:56:24] [V] [TRT] Tactic: 1002 Time: 0.041088
[03/24/2023-12:56:24] [V] [TRT] Tactic: 0 Time: 0.035712
[03/24/2023-12:56:24] [V] [TRT] Fastest Tactic: 0 Time: 0.035712
[03/24/2023-12:56:24] [V] [TRT] *************** Autotuning Reformat: Half(8294400,32400,180,1) -> Float(8294400,1,46080,256) ***************
[03/24/2023-12:56:24] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(input.568 -> <out>) (Reformat)
[03/24/2023-12:56:24] [V] [TRT] Tactic: 1002 Time: 0.031744
[03/24/2023-12:56:24] [V] [TRT] Tactic: 0 Time: 0.038656
[03/24/2023-12:56:24] [V] [TRT] Fastest Tactic: 1002 Time: 0.031744
[03/24/2023-12:56:24] [V] [TRT] *************** Autotuning Reformat: Half(8294400,32400,180,1) -> Float(2073600,1:4,11520,64) ***************
[03/24/2023-12:56:24] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(input.568 -> <out>) (Reformat)
[03/24/2023-12:56:24] [V] [TRT] Tactic: 1002 Time: 0.031616
[03/24/2023-12:56:24] [V] [TRT] Tactic: 0 Time: 0.041728
[03/24/2023-12:56:24] [V] [TRT] Fastest Tactic: 1002 Time: 0.031616
[03/24/2023-12:56:24] [V] [TRT] *************** Autotuning Reformat: Half(8294400,32400,180,1) -> Half(4147200,32400:2,180,1) ***************
[03/24/2023-12:56:24] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(input.568 -> <out>) (Reformat)
[03/24/2023-12:56:24] [V] [TRT] Tactic: 1002 Time: 0.030976
[03/24/2023-12:56:24] [V] [TRT] Tactic: 0 Time: 0.037888
[03/24/2023-12:56:24] [V] [TRT] Fastest Tactic: 1002 Time: 0.030976
[03/24/2023-12:56:24] [V] [TRT] *************** Autotuning Reformat: Half(8294400,32400,180,1) -> Half(1036800,1:8,5760,32) ***************
[03/24/2023-12:56:24] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(input.568 -> <out>) (Reformat)
[03/24/2023-12:56:24] [V] [TRT] Tactic: 1002 Time: 0.031616
[03/24/2023-12:56:24] [V] [TRT] Tactic: 0 Time: 0.040064
[03/24/2023-12:56:24] [V] [TRT] Fastest Tactic: 1002 Time: 0.031616
[03/24/2023-12:56:24] [V] [TRT] *************** Autotuning Reformat: Half(8294400,32400,180,1) -> Half(518400,1:16,2880,16) ***************
[03/24/2023-12:56:24] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(input.568 -> <out>) (Reformat)
[03/24/2023-12:56:24] [V] [TRT] Tactic: 1002 Time: 0.031488
[03/24/2023-12:56:24] [V] [TRT] Tactic: 0 Time: 0.040704
[03/24/2023-12:56:24] [V] [TRT] Fastest Tactic: 1002 Time: 0.031488
[03/24/2023-12:56:24] [V] [TRT] *************** Autotuning Reformat: Half(4147200,32400:2,180,1) -> Float(8294400,32400,180,1) ***************
[03/24/2023-12:56:24] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(input.568 -> <out>) (Reformat)
[03/24/2023-12:56:24] [V] [TRT] Tactic: 1002 Time: 0.037632
[03/24/2023-12:56:24] [V] [TRT] Tactic: 0 Time: 0.033664
[03/24/2023-12:56:24] [V] [TRT] Fastest Tactic: 0 Time: 0.033664
[03/24/2023-12:56:24] [V] [TRT] *************** Autotuning Reformat: Half(4147200,32400:2,180,1) -> Float(8294400,1,46080,256) ***************
[03/24/2023-12:56:24] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(input.568 -> <out>) (Reformat)
[03/24/2023-12:56:24] [V] [TRT] Tactic: 1002 Time: 0.031616
[03/24/2023-12:56:24] [V] [TRT] Tactic: 0 Time: 0.04096
[03/24/2023-12:56:24] [V] [TRT] Fastest Tactic: 1002 Time: 0.031616
[03/24/2023-12:56:24] [V] [TRT] *************** Autotuning Reformat: Half(4147200,32400:2,180,1) -> Float(2073600,1:4,11520,64) ***************
[03/24/2023-12:56:24] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(input.568 -> <out>) (Reformat)
[03/24/2023-12:56:24] [V] [TRT] Tactic: 1002 Time: 0.031616
[03/24/2023-12:56:24] [V] [TRT] Tactic: 0 Time: 0.045952
[03/24/2023-12:56:24] [V] [TRT] Fastest Tactic: 1002 Time: 0.031616
[03/24/2023-12:56:24] [V] [TRT] *************** Autotuning Reformat: Half(4147200,32400:2,180,1) -> Half(8294400,32400,180,1) ***************
[03/24/2023-12:56:24] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(input.568 -> <out>) (Reformat)
[03/24/2023-12:56:24] [V] [TRT] Tactic: 1002 Time: 0.080512
[03/24/2023-12:56:24] [V] [TRT] Tactic: 0 Time: 0.033664
[03/24/2023-12:56:24] [V] [TRT] Fastest Tactic: 0 Time: 0.033664
[03/24/2023-12:56:24] [V] [TRT] *************** Autotuning Reformat: Half(4147200,32400:2,180,1) -> Half(1036800,1:8,5760,32) ***************
[03/24/2023-12:56:24] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(input.568 -> <out>) (Reformat)
[03/24/2023-12:56:24] [V] [TRT] Tactic: 1002 Time: 0.031744
[03/24/2023-12:56:24] [V] [TRT] Tactic: 0 Time: 0.018304
[03/24/2023-12:56:24] [V] [TRT] Fastest Tactic: 0 Time: 0.018304
[03/24/2023-12:56:24] [V] [TRT] *************** Autotuning Reformat: Half(4147200,32400:2,180,1) -> Half(518400,1:16,2880,16) ***************
[03/24/2023-12:56:24] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(input.568 -> <out>) (Reformat)
[03/24/2023-12:56:24] [V] [TRT] Tactic: 1002 Time: 0.031872
[03/24/2023-12:56:24] [V] [TRT] Tactic: 0 Time: 0.04352
[03/24/2023-12:56:24] [V] [TRT] Fastest Tactic: 1002 Time: 0.031872
[03/24/2023-12:56:24] [V] [TRT] *************** Autotuning Reformat: Half(1036800,1:8,5760,32) -> Float(8294400,32400,180,1) ***************
[03/24/2023-12:56:24] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(input.568 -> <out>) (Reformat)
[03/24/2023-12:56:24] [V] [TRT] Tactic: 1002 Time: 0.035072
[03/24/2023-12:56:24] [V] [TRT] Tactic: 0 Time: 0.020096
[03/24/2023-12:56:24] [V] [TRT] Fastest Tactic: 0 Time: 0.020096
[03/24/2023-12:56:24] [V] [TRT] *************** Autotuning Reformat: Half(1036800,1:8,5760,32) -> Float(8294400,1,46080,256) ***************
[03/24/2023-12:56:24] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(input.568 -> <out>) (Reformat)
[03/24/2023-12:56:24] [V] [TRT] Tactic: 1002 Time: 0.0288
[03/24/2023-12:56:24] [V] [TRT] Tactic: 0 Time: 0.04096
[03/24/2023-12:56:24] [V] [TRT] Fastest Tactic: 1002 Time: 0.0288
[03/24/2023-12:56:24] [V] [TRT] *************** Autotuning Reformat: Half(1036800,1:8,5760,32) -> Float(2073600,1:4,11520,64) ***************
[03/24/2023-12:56:24] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(input.568 -> <out>) (Reformat)
[03/24/2023-12:56:24] [V] [TRT] Tactic: 1002 Time: 0.0288
[03/24/2023-12:56:24] [V] [TRT] Tactic: 0 Time: 0.04608
[03/24/2023-12:56:24] [V] [TRT] Fastest Tactic: 1002 Time: 0.0288
[03/24/2023-12:56:24] [V] [TRT] *************** Autotuning Reformat: Half(1036800,1:8,5760,32) -> Half(8294400,32400,180,1) ***************
[03/24/2023-12:56:24] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(input.568 -> <out>) (Reformat)
[03/24/2023-12:56:24] [V] [TRT] Tactic: 1002 Time: 0.070656
[03/24/2023-12:56:24] [V] [TRT] Tactic: 0 Time: 0.018432
[03/24/2023-12:56:24] [V] [TRT] Fastest Tactic: 0 Time: 0.018432
[03/24/2023-12:56:24] [V] [TRT] *************** Autotuning Reformat: Half(1036800,1:8,5760,32) -> Half(4147200,32400:2,180,1) ***************
[03/24/2023-12:56:24] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(input.568 -> <out>) (Reformat)
[03/24/2023-12:56:24] [V] [TRT] Tactic: 1002 Time: 0.040704
[03/24/2023-12:56:24] [V] [TRT] Tactic: 0 Time: 0.017408
[03/24/2023-12:56:24] [V] [TRT] Fastest Tactic: 0 Time: 0.017408
[03/24/2023-12:56:24] [V] [TRT] *************** Autotuning Reformat: Half(1036800,1:8,5760,32) -> Half(518400,1:16,2880,16) ***************
[03/24/2023-12:56:24] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(input.568 -> <out>) (Reformat)
[03/24/2023-12:56:24] [V] [TRT] Tactic: 1002 Time: 0.0288
[03/24/2023-12:56:24] [V] [TRT] Tactic: 0 Time: 0.043136
[03/24/2023-12:56:24] [V] [TRT] Fastest Tactic: 1002 Time: 0.0288
[03/24/2023-12:56:24] [V] [TRT] *************** Autotuning Reformat: Half(518400,1:16,2880,16) -> Float(8294400,32400,180,1) ***************
[03/24/2023-12:56:24] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(input.568 -> <out>) (Reformat)
[03/24/2023-12:56:24] [V] [TRT] Tactic: 1002 Time: 0.034816
[03/24/2023-12:56:24] [V] [TRT] Tactic: 0 Time: 0.052096
[03/24/2023-12:56:24] [V] [TRT] Fastest Tactic: 1002 Time: 0.034816
[03/24/2023-12:56:24] [V] [TRT] *************** Autotuning Reformat: Half(518400,1:16,2880,16) -> Float(8294400,1,46080,256) ***************
[03/24/2023-12:56:24] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(input.568 -> <out>) (Reformat)
[03/24/2023-12:56:24] [V] [TRT] Tactic: 1002 Time: 0.0288
[03/24/2023-12:56:24] [V] [TRT] Tactic: 0 Time: 0.04096
[03/24/2023-12:56:24] [V] [TRT] Fastest Tactic: 1002 Time: 0.0288
[03/24/2023-12:56:24] [V] [TRT] *************** Autotuning Reformat: Half(518400,1:16,2880,16) -> Float(2073600,1:4,11520,64) ***************
[03/24/2023-12:56:24] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(input.568 -> <out>) (Reformat)
[03/24/2023-12:56:24] [V] [TRT] Tactic: 1002 Time: 0.028928
[03/24/2023-12:56:24] [V] [TRT] Tactic: 0 Time: 0.04608
[03/24/2023-12:56:24] [V] [TRT] Fastest Tactic: 1002 Time: 0.028928
[03/24/2023-12:56:24] [V] [TRT] *************** Autotuning Reformat: Half(518400,1:16,2880,16) -> Half(8294400,32400,180,1) ***************
[03/24/2023-12:56:24] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(input.568 -> <out>) (Reformat)
[03/24/2023-12:56:24] [V] [TRT] Tactic: 1002 Time: 0.071168
[03/24/2023-12:56:24] [V] [TRT] Tactic: 0 Time: 0.051072
[03/24/2023-12:56:24] [V] [TRT] Fastest Tactic: 0 Time: 0.051072
[03/24/2023-12:56:24] [V] [TRT] *************** Autotuning Reformat: Half(518400,1:16,2880,16) -> Half(4147200,32400:2,180,1) ***************
[03/24/2023-12:56:24] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(input.568 -> <out>) (Reformat)
[03/24/2023-12:56:24] [V] [TRT] Tactic: 1002 Time: 0.040704
[03/24/2023-12:56:24] [V] [TRT] Tactic: 0 Time: 0.052992
[03/24/2023-12:56:24] [V] [TRT] Fastest Tactic: 1002 Time: 0.040704
[03/24/2023-12:56:24] [V] [TRT] *************** Autotuning Reformat: Half(518400,1:16,2880,16) -> Half(1036800,1:8,5760,32) ***************
[03/24/2023-12:56:24] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(input.568 -> <out>) (Reformat)
[03/24/2023-12:56:24] [V] [TRT] Tactic: 1002 Time: 0.028928
[03/24/2023-12:56:24] [V] [TRT] Tactic: 0 Time: 0.043136
[03/24/2023-12:56:24] [V] [TRT] Fastest Tactic: 1002 Time: 0.028928
[03/24/2023-12:56:24] [V] [TRT] =============== Computing reformatting costs
[03/24/2023-12:56:24] [V] [TRT] *************** Autotuning Reformat: Float(97200,32400,180,1) -> Half(97200,32400,180,1) ***************
[03/24/2023-12:56:24] [V] [TRT] *************** Autotuning Reformat: Float(97200,1,540,3) -> Half(97200,32400,180,1) ***************
[03/24/2023-12:56:24] [V] [TRT] *************** Autotuning Reformat: Float(32400,1:4,180,1) -> Half(97200,32400,180,1) ***************
[03/24/2023-12:56:24] [V] [TRT] *************** Autotuning Reformat: Half(64800,32400:2,180,1) -> Half(97200,32400,180,1) ***************
[03/24/2023-12:56:24] [V] [TRT] *************** Autotuning Reformat: Half(32400,1:8,180,1) -> Half(97200,32400,180,1) ***************
[03/24/2023-12:56:24] [V] [TRT] *************** Autotuning Reformat: Half(32400,1:16,180,1) -> Half(97200,32400,180,1) ***************
[03/24/2023-12:56:24] [V] [TRT] =============== Computing reformatting costs
[03/24/2023-12:56:24] [V] [TRT] *************** Autotuning Reformat: Float(8294400,32400,180,1) -> Float(8294400,1,46080,256) ***************
[03/24/2023-12:56:24] [V] [TRT] *************** Autotuning Reformat: Float(8294400,32400,180,1) -> Float(2073600,1:4,11520,64) ***************
[03/24/2023-12:56:24] [V] [TRT] *************** Autotuning Reformat: Float(8294400,32400,180,1) -> Half(8294400,32400,180,1) ***************
[03/24/2023-12:56:24] [V] [TRT] *************** Autotuning Reformat: Float(8294400,32400,180,1) -> Half(4147200,32400:2,180,1) ***************
[03/24/2023-12:56:24] [V] [TRT] *************** Autotuning Reformat: Float(8294400,32400,180,1) -> Half(1036800,1:8,5760,32) ***************
[03/24/2023-12:56:24] [V] [TRT] *************** Autotuning Reformat: Float(8294400,32400,180,1) -> Half(518400,1:16,2880,16) ***************
[03/24/2023-12:56:24] [V] [TRT] *************** Autotuning Reformat: Float(8294400,1,46080,256) -> Float(8294400,32400,180,1) ***************
[03/24/2023-12:56:24] [V] [TRT] *************** Autotuning Reformat: Float(8294400,1,46080,256) -> Float(2073600,1:4,11520,64) ***************
[03/24/2023-12:56:24] [V] [TRT] *************** Autotuning Reformat: Float(8294400,1,46080,256) -> Half(8294400,32400,180,1) ***************
[03/24/2023-12:56:24] [V] [TRT] *************** Autotuning Reformat: Float(8294400,1,46080,256) -> Half(4147200,32400:2,180,1) ***************
[03/24/2023-12:56:24] [V] [TRT] *************** Autotuning Reformat: Float(8294400,1,46080,256) -> Half(1036800,1:8,5760,32) ***************
[03/24/2023-12:56:24] [V] [TRT] *************** Autotuning Reformat: Float(8294400,1,46080,256) -> Half(518400,1:16,2880,16) ***************
[03/24/2023-12:56:24] [V] [TRT] *************** Autotuning Reformat: Float(2073600,1:4,11520,64) -> Float(8294400,32400,180,1) ***************
[03/24/2023-12:56:24] [V] [TRT] *************** Autotuning Reformat: Float(2073600,1:4,11520,64) -> Float(8294400,1,46080,256) ***************
[03/24/2023-12:56:24] [V] [TRT] *************** Autotuning Reformat: Float(2073600,1:4,11520,64) -> Half(8294400,32400,180,1) ***************
[03/24/2023-12:56:24] [V] [TRT] *************** Autotuning Reformat: Float(2073600,1:4,11520,64) -> Half(4147200,32400:2,180,1) ***************
[03/24/2023-12:56:24] [V] [TRT] *************** Autotuning Reformat: Float(2073600,1:4,11520,64) -> Half(1036800,1:8,5760,32) ***************
[03/24/2023-12:56:24] [V] [TRT] *************** Autotuning Reformat: Float(2073600,1:4,11520,64) -> Half(518400,1:16,2880,16) ***************
[03/24/2023-12:56:24] [V] [TRT] *************** Autotuning Reformat: Half(8294400,32400,180,1) -> Float(8294400,32400,180,1) ***************
[03/24/2023-12:56:24] [V] [TRT] *************** Autotuning Reformat: Half(8294400,32400,180,1) -> Float(8294400,1,46080,256) ***************
[03/24/2023-12:56:24] [V] [TRT] *************** Autotuning Reformat: Half(8294400,32400,180,1) -> Float(2073600,1:4,11520,64) ***************
[03/24/2023-12:56:24] [V] [TRT] *************** Autotuning Reformat: Half(8294400,32400,180,1) -> Half(4147200,32400:2,180,1) ***************
[03/24/2023-12:56:24] [V] [TRT] *************** Autotuning Reformat: Half(8294400,32400,180,1) -> Half(1036800,1:8,5760,32) ***************
[03/24/2023-12:56:24] [V] [TRT] *************** Autotuning Reformat: Half(8294400,32400,180,1) -> Half(518400,1:16,2880,16) ***************
[03/24/2023-12:56:24] [V] [TRT] *************** Autotuning Reformat: Half(4147200,32400:2,180,1) -> Float(8294400,32400,180,1) ***************
[03/24/2023-12:56:24] [V] [TRT] *************** Autotuning Reformat: Half(4147200,32400:2,180,1) -> Float(8294400,1,46080,256) ***************
[03/24/2023-12:56:24] [V] [TRT] *************** Autotuning Reformat: Half(4147200,32400:2,180,1) -> Float(2073600,1:4,11520,64) ***************
[03/24/2023-12:56:24] [V] [TRT] *************** Autotuning Reformat: Half(4147200,32400:2,180,1) -> Half(8294400,32400,180,1) ***************
[03/24/2023-12:56:24] [V] [TRT] *************** Autotuning Reformat: Half(4147200,32400:2,180,1) -> Half(1036800,1:8,5760,32) ***************
[03/24/2023-12:56:24] [V] [TRT] *************** Autotuning Reformat: Half(4147200,32400:2,180,1) -> Half(518400,1:16,2880,16) ***************
[03/24/2023-12:56:24] [V] [TRT] *************** Autotuning Reformat: Half(1036800,1:8,5760,32) -> Float(8294400,32400,180,1) ***************
[03/24/2023-12:56:24] [V] [TRT] *************** Autotuning Reformat: Half(1036800,1:8,5760,32) -> Float(8294400,1,46080,256) ***************
[03/24/2023-12:56:24] [V] [TRT] *************** Autotuning Reformat: Half(1036800,1:8,5760,32) -> Float(2073600,1:4,11520,64) ***************
[03/24/2023-12:56:24] [V] [TRT] *************** Autotuning Reformat: Half(1036800,1:8,5760,32) -> Half(8294400,32400,180,1) ***************
[03/24/2023-12:56:24] [V] [TRT] *************** Autotuning Reformat: Half(1036800,1:8,5760,32) -> Half(4147200,32400:2,180,1) ***************
[03/24/2023-12:56:24] [V] [TRT] *************** Autotuning Reformat: Half(1036800,1:8,5760,32) -> Half(518400,1:16,2880,16) ***************
[03/24/2023-12:56:24] [V] [TRT] *************** Autotuning Reformat: Half(518400,1:16,2880,16) -> Float(8294400,32400,180,1) ***************
[03/24/2023-12:56:24] [V] [TRT] *************** Autotuning Reformat: Half(518400,1:16,2880,16) -> Float(8294400,1,46080,256) ***************
[03/24/2023-12:56:24] [V] [TRT] *************** Autotuning Reformat: Half(518400,1:16,2880,16) -> Float(2073600,1:4,11520,64) ***************
[03/24/2023-12:56:24] [V] [TRT] *************** Autotuning Reformat: Half(518400,1:16,2880,16) -> Half(8294400,32400,180,1) ***************
[03/24/2023-12:56:24] [V] [TRT] *************** Autotuning Reformat: Half(518400,1:16,2880,16) -> Half(4147200,32400:2,180,1) ***************
[03/24/2023-12:56:24] [V] [TRT] *************** Autotuning Reformat: Half(518400,1:16,2880,16) -> Half(1036800,1:8,5760,32) ***************
[03/24/2023-12:56:24] [V] [TRT] =============== Computing reformatting costs
[03/24/2023-12:56:24] [V] [TRT] *************** Autotuning Reformat: Float(64800,32400,180,1) -> Half(64800,32400,180,1) ***************
[03/24/2023-12:56:24] [V] [TRT] *************** Autotuning Reformat: Float(64800,1,360,2) -> Half(64800,32400,180,1) ***************
[03/24/2023-12:56:24] [V] [TRT] *************** Autotuning Reformat: Float(32400,1:4,180,1) -> Half(64800,32400,180,1) ***************
[03/24/2023-12:56:24] [V] [TRT] *************** Autotuning Reformat: Half(32400,32400:2,180,1) -> Half(64800,32400,180,1) ***************
[03/24/2023-12:56:24] [V] [TRT] *************** Autotuning Reformat: Half(32400,1:8,180,1) -> Half(64800,32400,180,1) ***************
[03/24/2023-12:56:24] [V] [TRT] *************** Autotuning Reformat: Half(32400,1:16,180,1) -> Half(64800,32400,180,1) ***************
[03/24/2023-12:56:24] [V] [TRT] =============== Computing reformatting costs
[03/24/2023-12:56:24] [V] [TRT] *************** Autotuning Reformat: Float(8294400,32400,180,1) -> Float(8294400,1,46080,256) ***************
[03/24/2023-12:56:24] [V] [TRT] *************** Autotuning Reformat: Float(8294400,32400,180,1) -> Float(2073600,1:4,11520,64) ***************
[03/24/2023-12:56:24] [V] [TRT] *************** Autotuning Reformat: Float(8294400,32400,180,1) -> Half(8294400,32400,180,1) ***************
[03/24/2023-12:56:24] [V] [TRT] *************** Autotuning Reformat: Float(8294400,32400,180,1) -> Half(4147200,32400:2,180,1) ***************
[03/24/2023-12:56:24] [V] [TRT] *************** Autotuning Reformat: Float(8294400,32400,180,1) -> Half(1036800,1:8,5760,32) ***************
[03/24/2023-12:56:24] [V] [TRT] *************** Autotuning Reformat: Float(8294400,32400,180,1) -> Half(518400,1:16,2880,16) ***************
[03/24/2023-12:56:24] [V] [TRT] *************** Autotuning Reformat: Float(8294400,1,46080,256) -> Float(8294400,32400,180,1) ***************
[03/24/2023-12:56:24] [V] [TRT] *************** Autotuning Reformat: Float(8294400,1,46080,256) -> Float(2073600,1:4,11520,64) ***************
[03/24/2023-12:56:24] [V] [TRT] *************** Autotuning Reformat: Float(8294400,1,46080,256) -> Half(8294400,32400,180,1) ***************
[03/24/2023-12:56:24] [V] [TRT] *************** Autotuning Reformat: Float(8294400,1,46080,256) -> Half(4147200,32400:2,180,1) ***************
[03/24/2023-12:56:24] [V] [TRT] *************** Autotuning Reformat: Float(8294400,1,46080,256) -> Half(1036800,1:8,5760,32) ***************
[03/24/2023-12:56:24] [V] [TRT] *************** Autotuning Reformat: Float(8294400,1,46080,256) -> Half(518400,1:16,2880,16) ***************
[03/24/2023-12:56:24] [V] [TRT] *************** Autotuning Reformat: Float(2073600,1:4,11520,64) -> Float(8294400,32400,180,1) ***************
[03/24/2023-12:56:24] [V] [TRT] *************** Autotuning Reformat: Float(2073600,1:4,11520,64) -> Float(8294400,1,46080,256) ***************
[03/24/2023-12:56:24] [V] [TRT] *************** Autotuning Reformat: Float(2073600,1:4,11520,64) -> Half(8294400,32400,180,1) ***************
[03/24/2023-12:56:24] [V] [TRT] *************** Autotuning Reformat: Float(2073600,1:4,11520,64) -> Half(4147200,32400:2,180,1) ***************
[03/24/2023-12:56:24] [V] [TRT] *************** Autotuning Reformat: Float(2073600,1:4,11520,64) -> Half(1036800,1:8,5760,32) ***************
[03/24/2023-12:56:24] [V] [TRT] *************** Autotuning Reformat: Float(2073600,1:4,11520,64) -> Half(518400,1:16,2880,16) ***************
[03/24/2023-12:56:24] [V] [TRT] *************** Autotuning Reformat: Half(8294400,32400,180,1) -> Float(8294400,32400,180,1) ***************
[03/24/2023-12:56:24] [V] [TRT] *************** Autotuning Reformat: Half(8294400,32400,180,1) -> Float(8294400,1,46080,256) ***************
[03/24/2023-12:56:24] [V] [TRT] *************** Autotuning Reformat: Half(8294400,32400,180,1) -> Float(2073600,1:4,11520,64) ***************
[03/24/2023-12:56:24] [V] [TRT] *************** Autotuning Reformat: Half(8294400,32400,180,1) -> Half(4147200,32400:2,180,1) ***************
[03/24/2023-12:56:24] [V] [TRT] *************** Autotuning Reformat: Half(8294400,32400,180,1) -> Half(1036800,1:8,5760,32) ***************
[03/24/2023-12:56:24] [V] [TRT] *************** Autotuning Reformat: Half(8294400,32400,180,1) -> Half(518400,1:16,2880,16) ***************
[03/24/2023-12:56:24] [V] [TRT] *************** Autotuning Reformat: Half(4147200,32400:2,180,1) -> Float(8294400,32400,180,1) ***************
[03/24/2023-12:56:24] [V] [TRT] *************** Autotuning Reformat: Half(4147200,32400:2,180,1) -> Float(8294400,1,46080,256) ***************
[03/24/2023-12:56:24] [V] [TRT] *************** Autotuning Reformat: Half(4147200,32400:2,180,1) -> Float(2073600,1:4,11520,64) ***************
[03/24/2023-12:56:24] [V] [TRT] *************** Autotuning Reformat: Half(4147200,32400:2,180,1) -> Half(8294400,32400,180,1) ***************
[03/24/2023-12:56:24] [V] [TRT] *************** Autotuning Reformat: Half(4147200,32400:2,180,1) -> Half(1036800,1:8,5760,32) ***************
[03/24/2023-12:56:24] [V] [TRT] *************** Autotuning Reformat: Half(4147200,32400:2,180,1) -> Half(518400,1:16,2880,16) ***************
[03/24/2023-12:56:24] [V] [TRT] *************** Autotuning Reformat: Half(1036800,1:8,5760,32) -> Float(8294400,32400,180,1) ***************
[03/24/2023-12:56:24] [V] [TRT] *************** Autotuning Reformat: Half(1036800,1:8,5760,32) -> Float(8294400,1,46080,256) ***************
[03/24/2023-12:56:24] [V] [TRT] *************** Autotuning Reformat: Half(1036800,1:8,5760,32) -> Float(2073600,1:4,11520,64) ***************
[03/24/2023-12:56:24] [V] [TRT] *************** Autotuning Reformat: Half(1036800,1:8,5760,32) -> Half(8294400,32400,180,1) ***************
[03/24/2023-12:56:24] [V] [TRT] *************** Autotuning Reformat: Half(1036800,1:8,5760,32) -> Half(4147200,32400:2,180,1) ***************
[03/24/2023-12:56:24] [V] [TRT] *************** Autotuning Reformat: Half(1036800,1:8,5760,32) -> Half(518400,1:16,2880,16) ***************
[03/24/2023-12:56:24] [V] [TRT] *************** Autotuning Reformat: Half(518400,1:16,2880,16) -> Float(8294400,32400,180,1) ***************
[03/24/2023-12:56:24] [V] [TRT] *************** Autotuning Reformat: Half(518400,1:16,2880,16) -> Float(8294400,1,46080,256) ***************
[03/24/2023-12:56:24] [V] [TRT] *************** Autotuning Reformat: Half(518400,1:16,2880,16) -> Float(2073600,1:4,11520,64) ***************
[03/24/2023-12:56:24] [V] [TRT] *************** Autotuning Reformat: Half(518400,1:16,2880,16) -> Half(8294400,32400,180,1) ***************
[03/24/2023-12:56:24] [V] [TRT] *************** Autotuning Reformat: Half(518400,1:16,2880,16) -> Half(4147200,32400:2,180,1) ***************
[03/24/2023-12:56:24] [V] [TRT] *************** Autotuning Reformat: Half(518400,1:16,2880,16) -> Half(1036800,1:8,5760,32) ***************
[03/24/2023-12:56:24] [V] [TRT] =============== Computing reformatting costs
[03/24/2023-12:56:24] [V] [TRT] *************** Autotuning Reformat: Float(64800,32400,180,1) -> Half(64800,32400,180,1) ***************
[03/24/2023-12:56:24] [V] [TRT] *************** Autotuning Reformat: Float(64800,1,360,2) -> Half(64800,32400,180,1) ***************
[03/24/2023-12:56:24] [V] [TRT] *************** Autotuning Reformat: Float(32400,1:4,180,1) -> Half(64800,32400,180,1) ***************
[03/24/2023-12:56:24] [V] [TRT] *************** Autotuning Reformat: Half(32400,32400:2,180,1) -> Half(64800,32400,180,1) ***************
[03/24/2023-12:56:24] [V] [TRT] *************** Autotuning Reformat: Half(32400,1:8,180,1) -> Half(64800,32400,180,1) ***************
[03/24/2023-12:56:24] [V] [TRT] *************** Autotuning Reformat: Half(32400,1:16,180,1) -> Half(64800,32400,180,1) ***************
[03/24/2023-12:56:24] [V] [TRT] =============== Computing reformatting costs
[03/24/2023-12:56:24] [V] [TRT] *************** Autotuning Reformat: Float(8294400,32400,180,1) -> Float(8294400,1,46080,256) ***************
[03/24/2023-12:56:24] [V] [TRT] *************** Autotuning Reformat: Float(8294400,32400,180,1) -> Float(2073600,1:4,11520,64) ***************
[03/24/2023-12:56:24] [V] [TRT] *************** Autotuning Reformat: Float(8294400,32400,180,1) -> Half(8294400,32400,180,1) ***************
[03/24/2023-12:56:24] [V] [TRT] *************** Autotuning Reformat: Float(8294400,32400,180,1) -> Half(4147200,32400:2,180,1) ***************
[03/24/2023-12:56:24] [V] [TRT] *************** Autotuning Reformat: Float(8294400,32400,180,1) -> Half(1036800,1:8,5760,32) ***************
[03/24/2023-12:56:24] [V] [TRT] *************** Autotuning Reformat: Float(8294400,32400,180,1) -> Half(518400,1:16,2880,16) ***************
[03/24/2023-12:56:24] [V] [TRT] *************** Autotuning Reformat: Float(8294400,1,46080,256) -> Float(8294400,32400,180,1) ***************
[03/24/2023-12:56:24] [V] [TRT] *************** Autotuning Reformat: Float(8294400,1,46080,256) -> Float(2073600,1:4,11520,64) ***************
[03/24/2023-12:56:24] [V] [TRT] *************** Autotuning Reformat: Float(8294400,1,46080,256) -> Half(8294400,32400,180,1) ***************
[03/24/2023-12:56:24] [V] [TRT] *************** Autotuning Reformat: Float(8294400,1,46080,256) -> Half(4147200,32400:2,180,1) ***************
[03/24/2023-12:56:24] [V] [TRT] *************** Autotuning Reformat: Float(8294400,1,46080,256) -> Half(1036800,1:8,5760,32) ***************
[03/24/2023-12:56:24] [V] [TRT] *************** Autotuning Reformat: Float(8294400,1,46080,256) -> Half(518400,1:16,2880,16) ***************
[03/24/2023-12:56:24] [V] [TRT] *************** Autotuning Reformat: Float(2073600,1:4,11520,64) -> Float(8294400,32400,180,1) ***************
[03/24/2023-12:56:24] [V] [TRT] *************** Autotuning Reformat: Float(2073600,1:4,11520,64) -> Float(8294400,1,46080,256) ***************
[03/24/2023-12:56:24] [V] [TRT] *************** Autotuning Reformat: Float(2073600,1:4,11520,64) -> Half(8294400,32400,180,1) ***************
[03/24/2023-12:56:24] [V] [TRT] *************** Autotuning Reformat: Float(2073600,1:4,11520,64) -> Half(4147200,32400:2,180,1) ***************
[03/24/2023-12:56:24] [V] [TRT] *************** Autotuning Reformat: Float(2073600,1:4,11520,64) -> Half(1036800,1:8,5760,32) ***************
[03/24/2023-12:56:24] [V] [TRT] *************** Autotuning Reformat: Float(2073600,1:4,11520,64) -> Half(518400,1:16,2880,16) ***************
[03/24/2023-12:56:24] [V] [TRT] *************** Autotuning Reformat: Half(8294400,32400,180,1) -> Float(8294400,32400,180,1) ***************
[03/24/2023-12:56:24] [V] [TRT] *************** Autotuning Reformat: Half(8294400,32400,180,1) -> Float(8294400,1,46080,256) ***************
[03/24/2023-12:56:24] [V] [TRT] *************** Autotuning Reformat: Half(8294400,32400,180,1) -> Float(2073600,1:4,11520,64) ***************
[03/24/2023-12:56:24] [V] [TRT] *************** Autotuning Reformat: Half(8294400,32400,180,1) -> Half(4147200,32400:2,180,1) ***************
[03/24/2023-12:56:24] [V] [TRT] *************** Autotuning Reformat: Half(8294400,32400,180,1) -> Half(1036800,1:8,5760,32) ***************
[03/24/2023-12:56:24] [V] [TRT] *************** Autotuning Reformat: Half(8294400,32400,180,1) -> Half(518400,1:16,2880,16) ***************
[03/24/2023-12:56:24] [V] [TRT] *************** Autotuning Reformat: Half(4147200,32400:2,180,1) -> Float(8294400,32400,180,1) ***************
[03/24/2023-12:56:24] [V] [TRT] *************** Autotuning Reformat: Half(4147200,32400:2,180,1) -> Float(8294400,1,46080,256) ***************
[03/24/2023-12:56:24] [V] [TRT] *************** Autotuning Reformat: Half(4147200,32400:2,180,1) -> Float(2073600,1:4,11520,64) ***************
[03/24/2023-12:56:24] [V] [TRT] *************** Autotuning Reformat: Half(4147200,32400:2,180,1) -> Half(8294400,32400,180,1) ***************
[03/24/2023-12:56:24] [V] [TRT] *************** Autotuning Reformat: Half(4147200,32400:2,180,1) -> Half(1036800,1:8,5760,32) ***************
[03/24/2023-12:56:24] [V] [TRT] *************** Autotuning Reformat: Half(4147200,32400:2,180,1) -> Half(518400,1:16,2880,16) ***************
[03/24/2023-12:56:24] [V] [TRT] *************** Autotuning Reformat: Half(1036800,1:8,5760,32) -> Float(8294400,32400,180,1) ***************
[03/24/2023-12:56:24] [V] [TRT] *************** Autotuning Reformat: Half(1036800,1:8,5760,32) -> Float(8294400,1,46080,256) ***************
[03/24/2023-12:56:24] [V] [TRT] *************** Autotuning Reformat: Half(1036800,1:8,5760,32) -> Float(2073600,1:4,11520,64) ***************
[03/24/2023-12:56:24] [V] [TRT] *************** Autotuning Reformat: Half(1036800,1:8,5760,32) -> Half(8294400,32400,180,1) ***************
[03/24/2023-12:56:24] [V] [TRT] *************** Autotuning Reformat: Half(1036800,1:8,5760,32) -> Half(4147200,32400:2,180,1) ***************
[03/24/2023-12:56:24] [V] [TRT] *************** Autotuning Reformat: Half(1036800,1:8,5760,32) -> Half(518400,1:16,2880,16) ***************
[03/24/2023-12:56:24] [V] [TRT] *************** Autotuning Reformat: Half(518400,1:16,2880,16) -> Float(8294400,32400,180,1) ***************
[03/24/2023-12:56:24] [V] [TRT] *************** Autotuning Reformat: Half(518400,1:16,2880,16) -> Float(8294400,1,46080,256) ***************
[03/24/2023-12:56:24] [V] [TRT] *************** Autotuning Reformat: Half(518400,1:16,2880,16) -> Float(2073600,1:4,11520,64) ***************
[03/24/2023-12:56:24] [V] [TRT] *************** Autotuning Reformat: Half(518400,1:16,2880,16) -> Half(8294400,32400,180,1) ***************
[03/24/2023-12:56:24] [V] [TRT] *************** Autotuning Reformat: Half(518400,1:16,2880,16) -> Half(4147200,32400:2,180,1) ***************
[03/24/2023-12:56:24] [V] [TRT] *************** Autotuning Reformat: Half(518400,1:16,2880,16) -> Half(1036800,1:8,5760,32) ***************
[03/24/2023-12:56:24] [V] [TRT] =============== Computing reformatting costs
[03/24/2023-12:56:24] [V] [TRT] *************** Autotuning Reformat: Float(64800,32400,180,1) -> Half(64800,32400,180,1) ***************
[03/24/2023-12:56:24] [V] [TRT] *************** Autotuning Reformat: Float(64800,1,360,2) -> Half(64800,32400,180,1) ***************
[03/24/2023-12:56:24] [V] [TRT] *************** Autotuning Reformat: Float(32400,1:4,180,1) -> Half(64800,32400,180,1) ***************
[03/24/2023-12:56:24] [V] [TRT] *************** Autotuning Reformat: Half(32400,32400:2,180,1) -> Half(64800,32400,180,1) ***************
[03/24/2023-12:56:24] [V] [TRT] *************** Autotuning Reformat: Half(32400,1:8,180,1) -> Half(64800,32400,180,1) ***************
[03/24/2023-12:56:24] [V] [TRT] *************** Autotuning Reformat: Half(32400,1:16,180,1) -> Half(64800,32400,180,1) ***************
[03/24/2023-12:56:24] [V] [TRT] =============== Computing costs for 
[03/24/2023-12:56:24] [V] [TRT] *************** Autotuning format combination: Float(8294400,32400,180,1) -> Float(4147200,32400,180,1) ***************
[03/24/2023-12:56:24] [V] [TRT] --------------- Timing Runner: Conv_15 + Relu_16 (CudaDepthwiseConvolution)
[03/24/2023-12:56:24] [V] [TRT] CudaDepthwiseConvolution has no valid tactics for this config, skipping
[03/24/2023-12:56:24] [V] [TRT] --------------- Timing Runner: Conv_15 + Relu_16 (FusedConvActConvolution)
[03/24/2023-12:56:24] [V] [TRT] Tactic: 524287 Time: 2.01933
[03/24/2023-12:56:24] [V] [TRT] Tactic: 720895 Time: 1.75923
[03/24/2023-12:56:24] [V] [TRT] Tactic: 983039 Time: 1.72608
[03/24/2023-12:56:25] [V] [TRT] Tactic: 1048575 Time: 1.22714
[03/24/2023-12:56:25] [V] [TRT] Tactic: 1703935 Time: 1.1689
[03/24/2023-12:56:25] [V] [TRT] Tactic: 1769471 Time: 1.25978
[03/24/2023-12:56:25] [V] [TRT] Tactic: 1966079 Time: 1.25542
[03/24/2023-12:56:25] [V] [TRT] Tactic: 2031615 Time: 1.19424
[03/24/2023-12:56:25] [V] [TRT] Tactic: 2228223 Time: 1.24032
[03/24/2023-12:56:25] [V] [TRT] Tactic: 2424831 Time: 1.2521
[03/24/2023-12:56:25] [V] [TRT] Tactic: 2621439 Time: 1.1735
[03/24/2023-12:56:25] [V] [TRT] Tactic: 2752511 Time: 1.19027
[03/24/2023-12:56:25] [V] [TRT] Tactic: 2818047 Time: 1.17542
[03/24/2023-12:56:25] [V] [TRT] Tactic: 2883583 Time: 1.26592
[03/24/2023-12:56:25] [V] [TRT] Tactic: 3014655 Time: 1.21702
[03/24/2023-12:56:25] [V] [TRT] Tactic: 3145727 Time: 1.14368
[03/24/2023-12:56:25] [V] [TRT] Tactic: 3473407 Time: 1.20269
[03/24/2023-12:56:26] [V] [TRT] Tactic: 3604479 Time: 1.19565
[03/24/2023-12:56:26] [V] [TRT] Tactic: 3735551 Time: 1.20717
[03/24/2023-12:56:26] [V] [TRT] Tactic: 4390911 Time: 1.36947
[03/24/2023-12:56:26] [V] [TRT] Tactic: 5046271 Time: 1.16083
[03/24/2023-12:56:26] [V] [TRT] Tactic: 5963775 Time: 1.30227
[03/24/2023-12:56:26] [V] [TRT] Tactic: 6160383 Time: 1.2041
[03/24/2023-12:56:26] [V] [TRT] Tactic: 6488063 Time: 1.19859
[03/24/2023-12:56:26] [V] [TRT] Tactic: 6881279 Time: 1.27514
[03/24/2023-12:56:26] [V] [TRT] Tactic: 7274495 Time: 1.17875
[03/24/2023-12:56:26] [V] [TRT] Tactic: 7864319 Time: 1.16518
[03/24/2023-12:56:26] [V] [TRT] Tactic: 7995391 Time: 1.1849
[03/24/2023-12:56:26] [V] [TRT] Tactic: 8585215 Time: 1.22662
[03/24/2023-12:56:26] [V] [TRT] Tactic: 8847359 Time: 1.17965
[03/24/2023-12:56:26] [V] [TRT] Tactic: 8978431 Time: 1.31174
[03/24/2023-12:56:27] [V] [TRT] Tactic: 9043967 Time: 1.17414
[03/24/2023-12:56:27] [V] [TRT] Tactic: 9175039 Time: 1.19642
[03/24/2023-12:56:27] [V] [TRT] Tactic: 9502719 Time: 1.36525
[03/24/2023-12:56:27] [V] [TRT] Tactic: 9830399 Time: 1.22726
[03/24/2023-12:56:27] [V] [TRT] Tactic: 9961471 Time: 1.28819
[03/24/2023-12:56:27] [V] [TRT] Tactic: 10027007 Time: 1.17504
[03/24/2023-12:56:27] [V] [TRT] Tactic: 10092543 Time: 1.37088
[03/24/2023-12:56:27] [V] [TRT] Tactic: 10289151 Time: 1.25555
[03/24/2023-12:56:27] [V] [TRT] Tactic: 10485759 Time: 1.13165
[03/24/2023-12:56:27] [V] [TRT] Tactic: 10682367 Time: 1.16902
[03/24/2023-12:56:27] [V] [TRT] Tactic: 10813439 Time: 1.15021
[03/24/2023-12:56:27] [V] [TRT] Fastest Tactic: 10485759 Time: 1.13165
[03/24/2023-12:56:27] [V] [TRT] --------------- Timing Runner: Conv_15 + Relu_16 (CudnnConvolution)
[03/24/2023-12:56:28] [V] [TRT] Tactic: 0 Time: 1.57453
[03/24/2023-12:56:28] [V] [TRT] Tactic: 1 Time: 0.292736
[03/24/2023-12:56:28] [V] [TRT] Tactic: 2 Time: 1.79341
[03/24/2023-12:56:28] [V] [TRT] Tactic: 4 skipped. Scratch requested: 17450532864, available: 4294967296
[03/24/2023-12:56:28] [V] [TRT] Tactic: 5 Time: 4.3671
[03/24/2023-12:56:28] [V] [TRT] Tactic: 6 Time: 0.646016
[03/24/2023-12:56:28] [V] [TRT] Tactic: 56 Time: 1.57542
[03/24/2023-12:56:29] [V] [TRT] Tactic: 57 Time: 0.293376
[03/24/2023-12:56:29] [V] [TRT] Tactic: 58 Time: 1.79456
[03/24/2023-12:56:29] [V] [TRT] Tactic: 60 skipped. Scratch requested: 17450532864, available: 4294967296
[03/24/2023-12:56:29] [V] [TRT] Tactic: 61 Time: 4.35994
[03/24/2023-12:56:29] [V] [TRT] Tactic: 62 Time: 0.645376
[03/24/2023-12:56:29] [V] [TRT] Tactic: 112 Time: 1.57466
[03/24/2023-12:56:29] [V] [TRT] Tactic: 113 Time: 1.16045
[03/24/2023-12:56:29] [V] [TRT] Tactic: 114 Time: 1.79533
[03/24/2023-12:56:29] [V] [TRT] Tactic: 116 skipped. Scratch requested: 17450532864, available: 4294967296
[03/24/2023-12:56:29] [V] [TRT] Tactic: 117 Time: 4.35418
[03/24/2023-12:56:29] [V] [TRT] Tactic: 118 Time: 0.64512
[03/24/2023-12:56:29] [I] [TRT] Some tactics do not have sufficient workspace memory to run. Increasing workspace size may increase performance, please check verbose output.
[03/24/2023-12:56:29] [V] [TRT] Fastest Tactic: 1 Time: 0.292736
[03/24/2023-12:56:29] [V] [TRT] Setting workspace to 17450532864enables more tactics for profiling
[03/24/2023-12:56:29] [V] [TRT] --------------- Timing Runner: Conv_15 + Relu_16 (CaskConvolution)
[03/24/2023-12:56:29] [V] [TRT] Conv_15 + Relu_16 Set Tactic Name: ampere_scudnn_128x64_relu_small_nn_v1 Tactic: 4549827808004681195
[03/24/2023-12:56:29] [V] [TRT] Tactic: 4549827808004681195 Time: 1.13626
[03/24/2023-12:56:29] [V] [TRT] Conv_15 + Relu_16 Set Tactic Name: ampere_scudnn_128x128_relu_small_nn_v1 Tactic: 5779835512569528575
[03/24/2023-12:56:29] [V] [TRT] Tactic: 5779835512569528575 Time: 1.29536
[03/24/2023-12:56:29] [V] [TRT] Conv_15 + Relu_16 Set Tactic Name: ampere_scudnn_128x128_relu_xregs_large_nn_v1 Tactic: 6053873026024413720
[03/24/2023-12:56:29] [V] [TRT] Tactic: 6053873026024413720 Time: 1.34259
[03/24/2023-12:56:29] [V] [TRT] Conv_15 + Relu_16 Set Tactic Name: ampere_scudnn_128x64_relu_xregs_large_nn_v1 Tactic: 6767548733843469815
[03/24/2023-12:56:29] [V] [TRT] Tactic: 6767548733843469815 Time: 1.12026
[03/24/2023-12:56:29] [V] [TRT] Conv_15 + Relu_16 Set Tactic Name: ampere_scudnn_128x32_relu_small_nn_v1 Tactic: -6313876406580483184
[03/24/2023-12:56:29] [V] [TRT] Tactic: -6313876406580483184 Time: 1.38061
[03/24/2023-12:56:29] [V] [TRT] Conv_15 + Relu_16 Set Tactic Name: ampere_scudnn_128x128_relu_medium_nn_v1 Tactic: -1123676555321336786
[03/24/2023-12:56:29] [V] [TRT] Tactic: -1123676555321336786 Time: 1.29626
[03/24/2023-12:56:29] [V] [TRT] Conv_15 + Relu_16 Set Tactic Name: ampere_scudnn_128x64_relu_medium_nn_v1 Tactic: -701551393537224327
[03/24/2023-12:56:29] [V] [TRT] Tactic: -701551393537224327 Time: 1.14842
[03/24/2023-12:56:29] [V] [TRT] Fastest Tactic: 6767548733843469815 Time: 1.12026
[03/24/2023-12:56:29] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CudnnConvolution Tactic: 1
[03/24/2023-12:56:29] [V] [TRT] *************** Autotuning format combination: Float(8294400,1,46080,256) -> Float(4147200,1,23040,128) ***************
[03/24/2023-12:56:29] [V] [TRT] --------------- Timing Runner: Conv_15 + Relu_16 (CudnnConvolution)
[03/24/2023-12:56:29] [V] [TRT] CudnnConvolution has no valid tactics for this config, skipping
[03/24/2023-12:56:29] [V] [TRT] --------------- Timing Runner: Conv_15 + Relu_16 (CaskConvolution)
[03/24/2023-12:56:29] [V] [TRT] Conv_15 + Relu_16 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize64x128x8_stage3_warpsize1x4x1_g1_ffma_t1r3s3 Tactic: 2086609538387166260
[03/24/2023-12:56:29] [V] [TRT] Tactic: 2086609538387166260 Time: 1.07955
[03/24/2023-12:56:29] [V] [TRT] Conv_15 + Relu_16 Set Tactic Name: ampere_scudnn_128x64_sliced1x2_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: 2860655430572478466
[03/24/2023-12:56:29] [V] [TRT] Tactic: 2860655430572478466 Time: 1.10502
[03/24/2023-12:56:29] [V] [TRT] Conv_15 + Relu_16 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize64x128x8_stage3_warpsize1x4x1_g1_ffma Tactic: 3239733199291090177
[03/24/2023-12:56:29] [V] [TRT] Tactic: 3239733199291090177 Time: 1.07648
[03/24/2023-12:56:29] [V] [TRT] Conv_15 + Relu_16 Set Tactic Name: ampere_scudnn_128x32_sliced1x4_ldg4_relu_exp_medium_nhwc_tn_v1 Tactic: 4474630279712975759
[03/24/2023-12:56:29] [V] [TRT] Tactic: 4474630279712975759 Time: 1.1159
[03/24/2023-12:56:29] [V] [TRT] Conv_15 + Relu_16 Set Tactic Name: ampere_scudnn_128x32_sliced1x4_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: 4479823862704990365
[03/24/2023-12:56:29] [V] [TRT] Tactic: 4479823862704990365 Time: 1.1104
[03/24/2023-12:56:29] [V] [TRT] Conv_15 + Relu_16 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize64x256x8_stage3_warpsize1x4x1_g1_ffma Tactic: 4517590677127196184
[03/24/2023-12:56:29] [V] [TRT] Tactic: 4517590677127196184 Time: 2.62861
[03/24/2023-12:56:29] [V] [TRT] Conv_15 + Relu_16 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize128x128x8_stage3_warpsize2x4x1_g1_ffma_t1r3s3 Tactic: 4634080872644479428
[03/24/2023-12:56:29] [V] [TRT] Tactic: 4634080872644479428 Time: 1.30074
[03/24/2023-12:56:29] [V] [TRT] Conv_15 + Relu_16 Set Tactic Name: ampere_scudnn_128x64_sliced1x2_ldg4_relu_exp_medium_nhwc_tn_v1 Tactic: 4696204239951173149
[03/24/2023-12:56:29] [V] [TRT] Tactic: 4696204239951173149 Time: 1.10515
[03/24/2023-12:56:29] [V] [TRT] Conv_15 + Relu_16 Set Tactic Name: ampere_scudnn_128x128_relu_exp_small_nhwc_tn_v1 Tactic: 5778138195697110003
[03/24/2023-12:56:29] [V] [TRT] Tactic: 5778138195697110003 Time: 1.29267
[03/24/2023-12:56:29] [V] [TRT] Conv_15 + Relu_16 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize256x128x8_stage3_warpsize2x4x1_g1_ffma Tactic: 6310198979346901507
[03/24/2023-12:56:29] [V] [TRT] Tactic: 6310198979346901507 Time: 1.79878
[03/24/2023-12:56:29] [V] [TRT] Conv_15 + Relu_16 Set Tactic Name: ampere_scudnn_128x128_ldg4_relu_exp_large_nhwc_tn_v1 Tactic: 7155825427510256858
[03/24/2023-12:56:29] [V] [TRT] Tactic: 7155825427510256858 Time: 1.30048
[03/24/2023-12:56:29] [V] [TRT] Conv_15 + Relu_16 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize128x64x8_stage3_warpsize1x4x1_g1_ffma Tactic: 7222247112373541608
[03/24/2023-12:56:29] [V] [TRT] Tactic: 7222247112373541608 Time: 1.35846
[03/24/2023-12:56:29] [V] [TRT] Conv_15 + Relu_16 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize128x128x8_stage3_warpsize2x4x1_g1_ffma Tactic: 7472640475524677095
[03/24/2023-12:56:29] [V] [TRT] Tactic: 7472640475524677095 Time: 1.32698
[03/24/2023-12:56:29] [V] [TRT] Conv_15 + Relu_16 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize128x256x8_stage3_warpsize2x4x1_g1_ffma Tactic: 8498373915030836990
[03/24/2023-12:56:29] [V] [TRT] Tactic: 8498373915030836990 Time: 2.6199
[03/24/2023-12:56:29] [V] [TRT] Conv_15 + Relu_16 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize256x64x8_stage3_warpsize1x4x1_g1_ffma Tactic: 8869697132622550639
[03/24/2023-12:56:30] [V] [TRT] Tactic: 8869697132622550639 Time: 1.99194
[03/24/2023-12:56:30] [V] [TRT] Conv_15 + Relu_16 Set Tactic Name: ampere_scudnn_128x128_ldg4_relu_exp_medium_nhwc_tn_v1 Tactic: 8918020581761223752
[03/24/2023-12:56:30] [V] [TRT] Tactic: 8918020581761223752 Time: 1.28934
[03/24/2023-12:56:30] [V] [TRT] Conv_15 + Relu_16 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize256x128x8_stage3_warpsize2x4x1_g1_ffma_t1r3s3 Tactic: -8937725997228636978
[03/24/2023-12:56:30] [V] [TRT] Tactic: -8937725997228636978 Time: 1.73056
[03/24/2023-12:56:30] [V] [TRT] Conv_15 + Relu_16 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize128x256x8_stage3_warpsize2x4x1_g1_ffma_t1r3s3 Tactic: -8833858409138163072
[03/24/2023-12:56:30] [V] [TRT] Tactic: -8833858409138163072 Time: 2.56934
[03/24/2023-12:56:30] [V] [TRT] Conv_15 + Relu_16 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize64x64x8_stage3_warpsize1x4x1_g1_ffma_t1r3s3 Tactic: -7989138351613022500
[03/24/2023-12:56:30] [V] [TRT] Tactic: -7989138351613022500 Time: 1.0889
[03/24/2023-12:56:30] [V] [TRT] Conv_15 + Relu_16 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize256x128x8_stage3_warpsize2x4x1_g1_ffma Tactic: -7872883691240863058
[03/24/2023-12:56:30] [V] [TRT] Tactic: -7872883691240863058 Time: 1.79546
[03/24/2023-12:56:30] [V] [TRT] Conv_15 + Relu_16 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize128x128x8_stage3_warpsize2x4x1_g1_ffma Tactic: -6729618519651721910
[03/24/2023-12:56:30] [V] [TRT] Tactic: -6729618519651721910 Time: 1.31098
[03/24/2023-12:56:30] [V] [TRT] Conv_15 + Relu_16 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize256x64x8_stage3_warpsize1x4x1_g1_ffma Tactic: -5893833996418445881
[03/24/2023-12:56:30] [V] [TRT] Tactic: -5893833996418445881 Time: 1.93549
[03/24/2023-12:56:30] [V] [TRT] Conv_15 + Relu_16 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize128x256x8_stage3_warpsize2x4x1_g1_ffma Tactic: -5701562095007058349
[03/24/2023-12:56:30] [V] [TRT] Tactic: -5701562095007058349 Time: 2.58381
[03/24/2023-12:56:30] [V] [TRT] Conv_15 + Relu_16 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize128x64x8_stage3_warpsize1x4x1_g1_ffma Tactic: -5685503422376017600
[03/24/2023-12:56:30] [V] [TRT] Tactic: -5685503422376017600 Time: 1.31507
[03/24/2023-12:56:30] [V] [TRT] Conv_15 + Relu_16 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize64x64x8_stage3_warpsize1x4x1_g1_ffma Tactic: -5521125187060117489
[03/24/2023-12:56:30] [V] [TRT] Tactic: -5521125187060117489 Time: 1.18272
[03/24/2023-12:56:30] [V] [TRT] Conv_15 + Relu_16 Set Tactic Name: ampere_scudnn_128x64_sliced1x2_ldg4_relu_exp_large_nhwc_tn_v1 Tactic: -4756382386362004279
[03/24/2023-12:56:30] [V] [TRT] Tactic: -4756382386362004279 Time: 1.09018
[03/24/2023-12:56:30] [V] [TRT] Conv_15 + Relu_16 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize64x64x8_stage3_warpsize1x4x1_g1_ffma Tactic: -4615000974950361663
[03/24/2023-12:56:30] [V] [TRT] Tactic: -4615000974950361663 Time: 1.1305
[03/24/2023-12:56:30] [V] [TRT] Conv_15 + Relu_16 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize256x64x8_stage3_warpsize1x4x1_g1_ffma_t1r3s3 Tactic: -4314913710375142296
[03/24/2023-12:56:30] [V] [TRT] Tactic: -4314913710375142296 Time: 1.86611
[03/24/2023-12:56:30] [V] [TRT] Conv_15 + Relu_16 Set Tactic Name: ampere_scudnn_128x128_relu_exp_large_nhwc_tn_v1 Tactic: -3855385237722507464
[03/24/2023-12:56:30] [V] [TRT] Tactic: -3855385237722507464 Time: 1.29933
[03/24/2023-12:56:30] [V] [TRT] Conv_15 + Relu_16 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize128x64x8_stage3_warpsize1x4x1_g1_ffma_t1r3s3 Tactic: -3697587361057948972
[03/24/2023-12:56:30] [V] [TRT] Tactic: -3697587361057948972 Time: 1.31942
[03/24/2023-12:56:30] [V] [TRT] Conv_15 + Relu_16 Set Tactic Name: ampere_scudnn_128x128_relu_exp_medium_nhwc_tn_v1 Tactic: -2809379259463049391
[03/24/2023-12:56:30] [V] [TRT] Tactic: -2809379259463049391 Time: 1.29754
[03/24/2023-12:56:30] [V] [TRT] Conv_15 + Relu_16 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize64x256x8_stage3_warpsize1x4x1_g1_ffma_t1r3s3 Tactic: -2747929399988666512
[03/24/2023-12:56:30] [V] [TRT] Tactic: -2747929399988666512 Time: 2.56448
[03/24/2023-12:56:30] [V] [TRT] Conv_15 + Relu_16 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize64x256x8_stage3_warpsize1x4x1_g1_ffma Tactic: -1472061967969061456
[03/24/2023-12:56:30] [V] [TRT] Tactic: -1472061967969061456 Time: 2.21888
[03/24/2023-12:56:30] [V] [TRT] Conv_15 + Relu_16 Set Tactic Name: ampere_scudnn_128x128_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: -504296718212024303
[03/24/2023-12:56:30] [V] [TRT] Tactic: -504296718212024303 Time: 1.28768
[03/24/2023-12:56:30] [V] [TRT] Conv_15 + Relu_16 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize64x128x8_stage3_warpsize1x4x1_g1_ffma Tactic: -444093195553988951
[03/24/2023-12:56:30] [V] [TRT] Tactic: -444093195553988951 Time: 1.13165
[03/24/2023-12:56:30] [V] [TRT] Fastest Tactic: 3239733199291090177 Time: 1.07648
[03/24/2023-12:56:30] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: 3239733199291090177
[03/24/2023-12:56:30] [V] [TRT] *************** Autotuning format combination: Float(2073600,1:4,11520,64) -> Float(1036800,1:4,5760,32) ***************
[03/24/2023-12:56:30] [V] [TRT] --------------- Timing Runner: Conv_15 + Relu_16 (CudnnConvolution)
[03/24/2023-12:56:30] [V] [TRT] CudnnConvolution has no valid tactics for this config, skipping
[03/24/2023-12:56:30] [V] [TRT] --------------- Timing Runner: Conv_15 + Relu_16 (CaskConvolution)
[03/24/2023-12:56:30] [V] [TRT] Conv_15 + Relu_16 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize64x128x32_stage5_warpsize2x2x1_g1_tensor16x8x8 Tactic: 1237784342446422381
[03/24/2023-12:56:30] [V] [TRT] Tactic: 1237784342446422381 Time: 0.24576
[03/24/2023-12:56:30] [V] [TRT] Conv_15 + Relu_16 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x64x32_stage5_warpsize2x2x1_g1_tensor16x8x8 Tactic: 1426562292875733922
[03/24/2023-12:56:30] [V] [TRT] Tactic: 1426562292875733922 Time: 0.260096
[03/24/2023-12:56:30] [V] [TRT] Conv_15 + Relu_16 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize64x128x8_stage3_warpsize1x4x1_g1_ffma_t1r3s3 Tactic: 2086609538387166260
[03/24/2023-12:56:30] [V] [TRT] Tactic: 2086609538387166260 Time: 1.0793
[03/24/2023-12:56:30] [V] [TRT] Conv_15 + Relu_16 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize256x128x32_stage3_warpsize4x2x1_g1_tensor16x8x8_t1r3s3 Tactic: 2388153022056233219
[03/24/2023-12:56:30] [V] [TRT] Tactic: 2388153022056233219 Time: 0.257408
[03/24/2023-12:56:30] [V] [TRT] Conv_15 + Relu_16 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x128x32_stage4_warpsize2x2x1_g1_tensor16x8x8 Tactic: 2716437853123234317
[03/24/2023-12:56:30] [V] [TRT] Tactic: 2716437853123234317 Time: 0.205184
[03/24/2023-12:56:30] [V] [TRT] Conv_15 + Relu_16 Set Tactic Name: ampere_scudnn_128x64_sliced1x2_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: 2860655430572478466
[03/24/2023-12:56:30] [V] [TRT] Tactic: 2860655430572478466 Time: 1.10477
[03/24/2023-12:56:30] [V] [TRT] Conv_15 + Relu_16 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize64x128x8_stage3_warpsize1x4x1_g1_ffma Tactic: 3239733199291090177
[03/24/2023-12:56:30] [V] [TRT] Tactic: 3239733199291090177 Time: 1.07648
[03/24/2023-12:56:30] [V] [TRT] Conv_15 + Relu_16 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize64x64x64_stage4_warpsize2x2x1_g1_tensor16x8x8_t1r3s3 Tactic: 3278852197192504305
[03/24/2023-12:56:30] [V] [TRT] Tactic: 3278852197192504305 Time: 0.286208
[03/24/2023-12:56:30] [V] [TRT] Conv_15 + Relu_16 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize256x128x32_stage3_warpsize4x2x1_g1_tensor16x8x8 Tactic: 3904690393614050557
[03/24/2023-12:56:30] [V] [TRT] Tactic: 3904690393614050557 Time: 0.334592
[03/24/2023-12:56:30] [V] [TRT] Conv_15 + Relu_16 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize64x64x64_stage4_warpsize2x2x1_g1_tensor16x8x8 Tactic: 4061115162338989075
[03/24/2023-12:56:30] [V] [TRT] Tactic: 4061115162338989075 Time: 0.318592
[03/24/2023-12:56:30] [V] [TRT] Conv_15 + Relu_16 Set Tactic Name: ampere_scudnn_128x32_sliced1x4_ldg4_relu_exp_medium_nhwc_tn_v1 Tactic: 4474630279712975759
[03/24/2023-12:56:30] [V] [TRT] Tactic: 4474630279712975759 Time: 1.1159
[03/24/2023-12:56:30] [V] [TRT] Conv_15 + Relu_16 Set Tactic Name: ampere_scudnn_128x32_sliced1x4_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: 4479823862704990365
[03/24/2023-12:56:30] [V] [TRT] Tactic: 4479823862704990365 Time: 1.11053
[03/24/2023-12:56:30] [V] [TRT] Conv_15 + Relu_16 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize64x256x8_stage3_warpsize1x4x1_g1_ffma Tactic: 4517590677127196184
[03/24/2023-12:56:30] [V] [TRT] Tactic: 4517590677127196184 Time: 2.6295
[03/24/2023-12:56:30] [V] [TRT] Conv_15 + Relu_16 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize128x128x8_stage3_warpsize2x4x1_g1_ffma_t1r3s3 Tactic: 4634080872644479428
[03/24/2023-12:56:30] [V] [TRT] Tactic: 4634080872644479428 Time: 1.30125
[03/24/2023-12:56:30] [V] [TRT] Conv_15 + Relu_16 Set Tactic Name: ampere_scudnn_128x64_sliced1x2_ldg4_relu_exp_medium_nhwc_tn_v1 Tactic: 4696204239951173149
[03/24/2023-12:56:30] [V] [TRT] Tactic: 4696204239951173149 Time: 1.10541
[03/24/2023-12:56:30] [V] [TRT] Conv_15 + Relu_16 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x256x32_stage3_warpsize2x4x1_g1_tensor16x8x8 Tactic: 5200329514761435342
[03/24/2023-12:56:30] [V] [TRT] Tactic: 5200329514761435342 Time: 0.365056
[03/24/2023-12:56:30] [V] [TRT] Conv_15 + Relu_16 Set Tactic Name: ampere_scudnn_128x128_relu_exp_small_nhwc_tn_v1 Tactic: 5778138195697110003
[03/24/2023-12:56:30] [V] [TRT] Tactic: 5778138195697110003 Time: 1.29293
[03/24/2023-12:56:30] [V] [TRT] Conv_15 + Relu_16 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize256x128x8_stage3_warpsize2x4x1_g1_ffma Tactic: 6310198979346901507
[03/24/2023-12:56:31] [V] [TRT] Tactic: 6310198979346901507 Time: 1.80032
[03/24/2023-12:56:31] [V] [TRT] Conv_15 + Relu_16 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x256x32_stage3_warpsize2x4x1_g1_tensor16x8x8_t1r3s3 Tactic: 7011693366046809027
[03/24/2023-12:56:31] [V] [TRT] Tactic: 7011693366046809027 Time: 0.355328
[03/24/2023-12:56:31] [V] [TRT] Conv_15 + Relu_16 Set Tactic Name: ampere_scudnn_128x128_ldg4_relu_exp_large_nhwc_tn_v1 Tactic: 7155825427510256858
[03/24/2023-12:56:31] [V] [TRT] Tactic: 7155825427510256858 Time: 1.30086
[03/24/2023-12:56:31] [V] [TRT] Conv_15 + Relu_16 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize128x64x8_stage3_warpsize1x4x1_g1_ffma Tactic: 7222247112373541608
[03/24/2023-12:56:31] [V] [TRT] Tactic: 7222247112373541608 Time: 1.35846
[03/24/2023-12:56:31] [V] [TRT] Conv_15 + Relu_16 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x128x16_stage4_warpsize2x2x1_g1_tensor16x8x8 Tactic: 7342025736444949634
[03/24/2023-12:56:31] [V] [TRT] Tactic: 7342025736444949634 Time: 0.251136
[03/24/2023-12:56:31] [V] [TRT] Conv_15 + Relu_16 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize64x128x32_stage5_warpsize2x2x1_g1_tensor16x8x8 Tactic: 7347365539922924600
[03/24/2023-12:56:31] [V] [TRT] Tactic: 7347365539922924600 Time: 0.21632
[03/24/2023-12:56:31] [V] [TRT] Conv_15 + Relu_16 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x64x32_stage5_warpsize2x2x1_g1_tensor16x8x8 Tactic: 7428197830878119671
[03/24/2023-12:56:31] [V] [TRT] Tactic: 7428197830878119671 Time: 0.231936
[03/24/2023-12:56:31] [V] [TRT] Conv_15 + Relu_16 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize64x32x64_stage5_warpsize2x2x1_g1_tensor16x8x8_t1r3s3 Tactic: 7465323447915168822
[03/24/2023-12:56:31] [V] [TRT] Tactic: 7465323447915168822 Time: 0.405888
[03/24/2023-12:56:31] [V] [TRT] Conv_15 + Relu_16 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize128x128x8_stage3_warpsize2x4x1_g1_ffma Tactic: 7472640475524677095
[03/24/2023-12:56:31] [V] [TRT] Tactic: 7472640475524677095 Time: 1.32723
[03/24/2023-12:56:31] [V] [TRT] Conv_15 + Relu_16 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize64x32x64_stage5_warpsize2x2x1_g1_tensor16x8x8 Tactic: 7938223790021272801
[03/24/2023-12:56:31] [V] [TRT] Tactic: 7938223790021272801 Time: 0.420224
[03/24/2023-12:56:31] [V] [TRT] Conv_15 + Relu_16 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize128x256x8_stage3_warpsize2x4x1_g1_ffma Tactic: 8498373915030836990
[03/24/2023-12:56:31] [V] [TRT] Tactic: 8498373915030836990 Time: 2.6217
[03/24/2023-12:56:31] [V] [TRT] Conv_15 + Relu_16 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x64x32_stage5_warpsize2x2x1_g1_tensor16x8x8_t1r3s3 Tactic: 8836645772682419994
[03/24/2023-12:56:31] [V] [TRT] Tactic: 8836645772682419994 Time: 0.221952
[03/24/2023-12:56:31] [V] [TRT] Conv_15 + Relu_16 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize256x64x8_stage3_warpsize1x4x1_g1_ffma Tactic: 8869697132622550639
[03/24/2023-12:56:31] [V] [TRT] Tactic: 8869697132622550639 Time: 1.99219
[03/24/2023-12:56:31] [V] [TRT] Conv_15 + Relu_16 Set Tactic Name: ampere_scudnn_128x128_ldg4_relu_exp_medium_nhwc_tn_v1 Tactic: 8918020581761223752
[03/24/2023-12:56:31] [V] [TRT] Tactic: 8918020581761223752 Time: 1.2896
[03/24/2023-12:56:31] [V] [TRT] Conv_15 + Relu_16 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize64x64x64_stage4_warpsize2x2x1_g1_tensor16x8x8 Tactic: -9114138070928278731
[03/24/2023-12:56:31] [V] [TRT] Tactic: -9114138070928278731 Time: 0.29568
[03/24/2023-12:56:31] [V] [TRT] Conv_15 + Relu_16 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize256x128x8_stage3_warpsize2x4x1_g1_ffma_t1r3s3 Tactic: -8937725997228636978
[03/24/2023-12:56:31] [V] [TRT] Tactic: -8937725997228636978 Time: 1.73222
[03/24/2023-12:56:31] [V] [TRT] Conv_15 + Relu_16 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize128x256x8_stage3_warpsize2x4x1_g1_ffma_t1r3s3 Tactic: -8833858409138163072
[03/24/2023-12:56:31] [V] [TRT] Tactic: -8833858409138163072 Time: 2.57344
[03/24/2023-12:56:31] [V] [TRT] Conv_15 + Relu_16 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize64x64x8_stage3_warpsize1x4x1_g1_ffma_t1r3s3 Tactic: -7989138351613022500
[03/24/2023-12:56:31] [V] [TRT] Tactic: -7989138351613022500 Time: 1.0912
[03/24/2023-12:56:31] [V] [TRT] Conv_15 + Relu_16 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize256x128x8_stage3_warpsize2x4x1_g1_ffma Tactic: -7872883691240863058
[03/24/2023-12:56:31] [V] [TRT] Tactic: -7872883691240863058 Time: 1.79584
[03/24/2023-12:56:31] [V] [TRT] Conv_15 + Relu_16 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x256x32_stage3_warpsize2x4x1_g1_tensor16x8x8 Tactic: -7382359095196034537
[03/24/2023-12:56:31] [V] [TRT] Tactic: -7382359095196034537 Time: 0.368768
[03/24/2023-12:56:31] [V] [TRT] Conv_15 + Relu_16 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x128x16_stage4_warpsize2x2x1_g1_tensor16x8x8_t1r3s3 Tactic: -7377458734869418330
[03/24/2023-12:56:31] [V] [TRT] Tactic: -7377458734869418330 Time: 0.228864
[03/24/2023-12:56:31] [V] [TRT] Conv_15 + Relu_16 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize128x128x8_stage3_warpsize2x4x1_g1_ffma Tactic: -6729618519651721910
[03/24/2023-12:56:31] [V] [TRT] Tactic: -6729618519651721910 Time: 1.31098
[03/24/2023-12:56:31] [V] [TRT] Conv_15 + Relu_16 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize256x64x32_stage3_warpsize4x2x1_g1_tensor16x8x8_t1r3s3 Tactic: -6223854811627385844
[03/24/2023-12:56:31] [V] [TRT] Tactic: -6223854811627385844 Time: 0.220288
[03/24/2023-12:56:31] [V] [TRT] Conv_15 + Relu_16 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize256x64x8_stage3_warpsize1x4x1_g1_ffma Tactic: -5893833996418445881
[03/24/2023-12:56:31] [V] [TRT] Tactic: -5893833996418445881 Time: 1.93574
[03/24/2023-12:56:31] [V] [TRT] Conv_15 + Relu_16 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize128x256x8_stage3_warpsize2x4x1_g1_ffma Tactic: -5701562095007058349
[03/24/2023-12:56:31] [V] [TRT] Tactic: -5701562095007058349 Time: 2.58458
[03/24/2023-12:56:31] [V] [TRT] Conv_15 + Relu_16 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize128x64x8_stage3_warpsize1x4x1_g1_ffma Tactic: -5685503422376017600
[03/24/2023-12:56:31] [V] [TRT] Tactic: -5685503422376017600 Time: 1.31494
[03/24/2023-12:56:31] [V] [TRT] Conv_15 + Relu_16 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize64x64x8_stage3_warpsize1x4x1_g1_ffma Tactic: -5521125187060117489
[03/24/2023-12:56:31] [V] [TRT] Tactic: -5521125187060117489 Time: 1.18234
[03/24/2023-12:56:31] [V] [TRT] Conv_15 + Relu_16 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x128x16_stage4_warpsize2x2x1_g1_tensor16x8x8 Tactic: -5457304872213719461
[03/24/2023-12:56:31] [V] [TRT] Tactic: -5457304872213719461 Time: 0.234496
[03/24/2023-12:56:31] [V] [TRT] Conv_15 + Relu_16 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x64x64_stage3_warpsize2x2x1_g1_tensor16x8x8 Tactic: -5441054706931585554
[03/24/2023-12:56:31] [V] [TRT] Tactic: -5441054706931585554 Time: 0.24704
[03/24/2023-12:56:31] [V] [TRT] Conv_15 + Relu_16 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize256x64x32_stage3_warpsize4x2x1_g1_tensor16x8x8 Tactic: -5043603702497465467
[03/24/2023-12:56:31] [V] [TRT] Tactic: -5043603702497465467 Time: 0.275328
[03/24/2023-12:56:31] [V] [TRT] Conv_15 + Relu_16 Set Tactic Name: ampere_scudnn_128x64_sliced1x2_ldg4_relu_exp_large_nhwc_tn_v1 Tactic: -4756382386362004279
[03/24/2023-12:56:31] [V] [TRT] Tactic: -4756382386362004279 Time: 1.09043
[03/24/2023-12:56:31] [V] [TRT] Conv_15 + Relu_16 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize64x64x8_stage3_warpsize1x4x1_g1_ffma Tactic: -4615000974950361663
[03/24/2023-12:56:31] [V] [TRT] Tactic: -4615000974950361663 Time: 1.13062
[03/24/2023-12:56:31] [V] [TRT] Conv_15 + Relu_16 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x64x64_stage3_warpsize2x2x1_g1_tensor16x8x8 Tactic: -4564655677311401797
[03/24/2023-12:56:31] [V] [TRT] Tactic: -4564655677311401797 Time: 0.240768
[03/24/2023-12:56:31] [V] [TRT] Conv_15 + Relu_16 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize256x64x8_stage3_warpsize1x4x1_g1_ffma_t1r3s3 Tactic: -4314913710375142296
[03/24/2023-12:56:31] [V] [TRT] Tactic: -4314913710375142296 Time: 1.86739
[03/24/2023-12:56:31] [V] [TRT] Conv_15 + Relu_16 Set Tactic Name: ampere_scudnn_128x128_relu_exp_large_nhwc_tn_v1 Tactic: -3855385237722507464
[03/24/2023-12:56:31] [V] [TRT] Tactic: -3855385237722507464 Time: 1.29933
[03/24/2023-12:56:31] [V] [TRT] Conv_15 + Relu_16 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize128x64x8_stage3_warpsize1x4x1_g1_ffma_t1r3s3 Tactic: -3697587361057948972
[03/24/2023-12:56:31] [V] [TRT] Tactic: -3697587361057948972 Time: 1.31942
[03/24/2023-12:56:31] [V] [TRT] Conv_15 + Relu_16 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize256x64x32_stage3_warpsize4x2x1_g1_tensor16x8x8 Tactic: -3540975627865078064
[03/24/2023-12:56:31] [V] [TRT] Tactic: -3540975627865078064 Time: 0.235776
[03/24/2023-12:56:31] [V] [TRT] Conv_15 + Relu_16 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize64x128x32_stage5_warpsize2x2x1_g1_tensor16x8x8_t1r3s3 Tactic: -3151804561246216835
[03/24/2023-12:56:31] [V] [TRT] Tactic: -3151804561246216835 Time: 0.217344
[03/24/2023-12:56:31] [V] [TRT] Conv_15 + Relu_16 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize64x32x64_stage5_warpsize2x2x1_g1_tensor16x8x8 Tactic: -2885165284206163001
[03/24/2023-12:56:31] [V] [TRT] Tactic: -2885165284206163001 Time: 0.469376
[03/24/2023-12:56:31] [V] [TRT] Conv_15 + Relu_16 Set Tactic Name: ampere_scudnn_128x128_relu_exp_medium_nhwc_tn_v1 Tactic: -2809379259463049391
[03/24/2023-12:56:31] [V] [TRT] Tactic: -2809379259463049391 Time: 1.29754
[03/24/2023-12:56:31] [V] [TRT] Conv_15 + Relu_16 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x128x32_stage4_warpsize2x2x1_g1_tensor16x8x8_t1r3s3 Tactic: -2801041895330778813
[03/24/2023-12:56:31] [V] [TRT] Tactic: -2801041895330778813 Time: 0.226304
[03/24/2023-12:56:31] [V] [TRT] Conv_15 + Relu_16 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize64x256x8_stage3_warpsize1x4x1_g1_ffma_t1r3s3 Tactic: -2747929399988666512
[03/24/2023-12:56:31] [V] [TRT] Tactic: -2747929399988666512 Time: 2.56474
[03/24/2023-12:56:31] [V] [TRT] Conv_15 + Relu_16 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize256x128x32_stage3_warpsize4x2x1_g1_tensor16x8x8 Tactic: -1758690179295738332
[03/24/2023-12:56:31] [V] [TRT] Tactic: -1758690179295738332 Time: 0.271872
[03/24/2023-12:56:31] [V] [TRT] Conv_15 + Relu_16 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x64x64_stage3_warpsize2x2x1_g1_tensor16x8x8_t1r3s3 Tactic: -1484546572846226796
[03/24/2023-12:56:31] [V] [TRT] Tactic: -1484546572846226796 Time: 0.229248
[03/24/2023-12:56:31] [V] [TRT] Conv_15 + Relu_16 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize64x256x8_stage3_warpsize1x4x1_g1_ffma Tactic: -1472061967969061456
[03/24/2023-12:56:32] [V] [TRT] Tactic: -1472061967969061456 Time: 2.21914
[03/24/2023-12:56:32] [V] [TRT] Conv_15 + Relu_16 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x128x32_stage4_warpsize2x2x1_g1_tensor16x8x8 Tactic: -858667497925695276
[03/24/2023-12:56:32] [V] [TRT] Tactic: -858667497925695276 Time: 0.345344
[03/24/2023-12:56:32] [V] [TRT] Conv_15 + Relu_16 Set Tactic Name: ampere_scudnn_128x128_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: -504296718212024303
[03/24/2023-12:56:32] [V] [TRT] Tactic: -504296718212024303 Time: 1.28845
[03/24/2023-12:56:32] [V] [TRT] Conv_15 + Relu_16 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize64x128x8_stage3_warpsize1x4x1_g1_ffma Tactic: -444093195553988951
[03/24/2023-12:56:32] [V] [TRT] Tactic: -444093195553988951 Time: 1.13126
[03/24/2023-12:56:32] [V] [TRT] Fastest Tactic: 2716437853123234317 Time: 0.205184
[03/24/2023-12:56:32] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: 2716437853123234317
[03/24/2023-12:56:32] [V] [TRT] *************** Autotuning format combination: Half(8294400,32400,180,1) -> Half(4147200,32400,180,1) ***************
[03/24/2023-12:56:32] [V] [TRT] --------------- Timing Runner: Conv_15 + Relu_16 (CudnnConvolution)
[03/24/2023-12:56:32] [V] [TRT] Tactic: 0 Time: 1.58208
[03/24/2023-12:56:32] [V] [TRT] Tactic: 1 Time: 1.376
[03/24/2023-12:56:32] [V] [TRT] Tactic: 2 Time: 1.68384
[03/24/2023-12:56:32] [V] [TRT] Tactic: 4 skipped. Scratch requested: 17450532864, available: 4294967296
[03/24/2023-12:56:32] [V] [TRT] Tactic: 5 Time: 4.36173
[03/24/2023-12:56:32] [V] [TRT] Tactic: 6 Time: 0.706816
[03/24/2023-12:56:32] [V] [TRT] Tactic: 56 Time: 1.58221
[03/24/2023-12:56:32] [V] [TRT] Tactic: 58 Time: 1.68602
[03/24/2023-12:56:32] [V] [TRT] Tactic: 60 skipped. Scratch requested: 17450532864, available: 4294967296
[03/24/2023-12:56:32] [V] [TRT] Tactic: 61 Time: 4.35789
[03/24/2023-12:56:32] [V] [TRT] Tactic: 62 Time: 0.706944
[03/24/2023-12:56:32] [V] [TRT] Fastest Tactic: 6 Time: 0.706816
[03/24/2023-12:56:32] [V] [TRT] Setting workspace to 17450532864enables more tactics for profiling
[03/24/2023-12:56:32] [V] [TRT] --------------- Timing Runner: Conv_15 + Relu_16 (CaskConvolution)
[03/24/2023-12:56:32] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[03/24/2023-12:56:32] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CudnnConvolution Tactic: 6
[03/24/2023-12:56:32] [V] [TRT] *************** Autotuning format combination: Half(4147200,32400:2,180,1) -> Half(2073600,32400:2,180,1) ***************
[03/24/2023-12:56:32] [V] [TRT] --------------- Timing Runner: Conv_15 + Relu_16 (FusedConvActConvolution)
[03/24/2023-12:56:32] [V] [TRT] Tactic: 524287 Time: 0.510592
[03/24/2023-12:56:32] [V] [TRT] Tactic: 720895 Time: 0.42624
[03/24/2023-12:56:32] [V] [TRT] Tactic: 983039 Time: 0.460416
[03/24/2023-12:56:32] [V] [TRT] Tactic: 1048575 Time: 0.511104
[03/24/2023-12:56:32] [V] [TRT] Tactic: 1703935 Time: 0.478592
[03/24/2023-12:56:32] [V] [TRT] Tactic: 1769471 Time: 0.555904
[03/24/2023-12:56:32] [V] [TRT] Tactic: 1966079 Time: 0.477056
[03/24/2023-12:56:32] [V] [TRT] Tactic: 2031615 Time: 0.435328
[03/24/2023-12:56:32] [V] [TRT] Tactic: 2228223 Time: 0.527104
[03/24/2023-12:56:32] [V] [TRT] Tactic: 2424831 Time: 0.592384
[03/24/2023-12:56:32] [V] [TRT] Tactic: 2621439 Time: 0.493312
[03/24/2023-12:56:32] [V] [TRT] Tactic: 2752511 Time: 0.48448
[03/24/2023-12:56:32] [V] [TRT] Tactic: 2818047 Time: 0.521856
[03/24/2023-12:56:32] [V] [TRT] Tactic: 2883583 Time: 0.525312
[03/24/2023-12:56:32] [V] [TRT] Tactic: 3014655 Time: 0.479104
[03/24/2023-12:56:33] [V] [TRT] Tactic: 3145727 Time: 0.437376
[03/24/2023-12:56:33] [V] [TRT] Tactic: 3473407 Time: 0.461312
[03/24/2023-12:56:33] [V] [TRT] Tactic: 3604479 Time: 0.499968
[03/24/2023-12:56:33] [V] [TRT] Tactic: 3735551 Time: 0.496384
[03/24/2023-12:56:33] [V] [TRT] Tactic: 4390911 Time: 0.502528
[03/24/2023-12:56:33] [V] [TRT] Tactic: 5046271 Time: 0.483328
[03/24/2023-12:56:33] [V] [TRT] Tactic: 5963775 Time: 0.488064
[03/24/2023-12:56:33] [V] [TRT] Tactic: 6160383 Time: 0.503552
[03/24/2023-12:56:33] [V] [TRT] Tactic: 6488063 Time: 0.499072
[03/24/2023-12:56:33] [V] [TRT] Tactic: 6881279 Time: 0.502144
[03/24/2023-12:56:33] [V] [TRT] Tactic: 7274495 Time: 0.511616
[03/24/2023-12:56:33] [V] [TRT] Tactic: 7864319 Time: 0.493952
[03/24/2023-12:56:33] [V] [TRT] Tactic: 7995391 Time: 0.52608
[03/24/2023-12:56:33] [V] [TRT] Tactic: 8585215 Time: 0.510208
[03/24/2023-12:56:33] [V] [TRT] Tactic: 8847359 Time: 0.495872
[03/24/2023-12:56:33] [V] [TRT] Tactic: 8978431 Time: 0.491264
[03/24/2023-12:56:33] [V] [TRT] Tactic: 9043967 Time: 0.473728
[03/24/2023-12:56:33] [V] [TRT] Tactic: 9175039 Time: 0.49984
[03/24/2023-12:56:33] [V] [TRT] Tactic: 9502719 Time: 0.490368
[03/24/2023-12:56:33] [V] [TRT] Tactic: 9830399 Time: 0.514816
[03/24/2023-12:56:33] [V] [TRT] Tactic: 9961471 Time: 0.62016
[03/24/2023-12:56:33] [V] [TRT] Tactic: 10027007 Time: 0.471936
[03/24/2023-12:56:33] [V] [TRT] Tactic: 10092543 Time: 0.502016
[03/24/2023-12:56:33] [V] [TRT] Tactic: 10289151 Time: 0.476544
[03/24/2023-12:56:33] [V] [TRT] Tactic: 10485759 Time: 0.460032
[03/24/2023-12:56:33] [V] [TRT] Tactic: 10682367 Time: 0.513152
[03/24/2023-12:56:33] [V] [TRT] Tactic: 10813439 Time: 0.5024
[03/24/2023-12:56:33] [V] [TRT] Fastest Tactic: 720895 Time: 0.42624
[03/24/2023-12:56:33] [V] [TRT] --------------- Timing Runner: Conv_15 + Relu_16 (CudnnConvolution)
[03/24/2023-12:56:33] [V] [TRT] CudnnConvolution has no valid tactics for this config, skipping
[03/24/2023-12:56:33] [V] [TRT] --------------- Timing Runner: Conv_15 + Relu_16 (CaskConvolution)
[03/24/2023-12:56:33] [V] [TRT] Conv_15 + Relu_16 Set Tactic Name: ampere_fp16x2_hcudnn_fp16x2_128x32_relu_medium_nn_v1 Tactic: 2195670545862694453
[03/24/2023-12:56:33] [V] [TRT] Tactic: 2195670545862694453 Time: 0.61312
[03/24/2023-12:56:33] [V] [TRT] Conv_15 + Relu_16 Set Tactic Name: ampere_fp16x2_hcudnn_fp16x2_128x64_relu_large_nn_v1 Tactic: 3419182076704469245
[03/24/2023-12:56:33] [V] [TRT] Tactic: 3419182076704469245 Time: 0.592128
[03/24/2023-12:56:33] [V] [TRT] Conv_15 + Relu_16 Set Tactic Name: ampere_fp16x2_hcudnn_fp16x2_128x128_relu_medium_nn_v1 Tactic: 3891805945559659536
[03/24/2023-12:56:34] [V] [TRT] Tactic: 3891805945559659536 Time: 0.669952
[03/24/2023-12:56:34] [V] [TRT] Conv_15 + Relu_16 Set Tactic Name: ampere_fp16x2_hcudnn_fp16x2_128x64_relu_medium_nn_v1 Tactic: 5548126322150286555
[03/24/2023-12:56:34] [V] [TRT] Tactic: 5548126322150286555 Time: 0.585216
[03/24/2023-12:56:34] [V] [TRT] Conv_15 + Relu_16 Set Tactic Name: ampere_fp16x2_hcudnn_fp16x2_128x64_relu_small_nn_v1 Tactic: 6057304366605292508
[03/24/2023-12:56:34] [V] [TRT] Tactic: 6057304366605292508 Time: 0.574592
[03/24/2023-12:56:34] [V] [TRT] Conv_15 + Relu_16 Set Tactic Name: ampere_fp16x2_hcudnn_fp16x2_128x128_relu_large_nn_v1 Tactic: -7928611605886347652
[03/24/2023-12:56:34] [V] [TRT] Tactic: -7928611605886347652 Time: 0.692992
[03/24/2023-12:56:34] [V] [TRT] Conv_15 + Relu_16 Set Tactic Name: ampere_fp16x2_hcudnn_fp16x2_128x32_relu_large_nn_v1 Tactic: -5172391392092686714
[03/24/2023-12:56:34] [V] [TRT] Tactic: -5172391392092686714 Time: 0.617472
[03/24/2023-12:56:34] [V] [TRT] Conv_15 + Relu_16 Set Tactic Name: ampere_fp16x2_hcudnn_fp16x2_128x32_relu_small_nn_v1 Tactic: -4374269919094467161
[03/24/2023-12:56:34] [V] [TRT] Tactic: -4374269919094467161 Time: 0.605312
[03/24/2023-12:56:34] [V] [TRT] Conv_15 + Relu_16 Set Tactic Name: ampere_fp16x2_hcudnn_winograd_fp16x2_128x128_ldg1_ldg4_relu_tile148t_nt_v1 Tactic: -4083394051665370953
[03/24/2023-12:56:34] [V] [TRT] Tactic: -4083394051665370953 Time: 0.311424
[03/24/2023-12:56:34] [V] [TRT] Conv_15 + Relu_16 Set Tactic Name: ampere_fp16x2_hcudnn_fp16x2_128x128_relu_small_nn_v1 Tactic: -1546027692247304867
[03/24/2023-12:56:34] [V] [TRT] Tactic: -1546027692247304867 Time: 0.677888
[03/24/2023-12:56:34] [V] [TRT] Fastest Tactic: -4083394051665370953 Time: 0.311424
[03/24/2023-12:56:34] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: -4083394051665370953
[03/24/2023-12:56:34] [V] [TRT] *************** Autotuning format combination: Half(1036800,1:8,5760,32) -> Float(4147200,32400,180,1) ***************
[03/24/2023-12:56:34] [V] [TRT] --------------- Timing Runner: Conv_15 + Relu_16 (CudnnConvolution)
[03/24/2023-12:56:34] [V] [TRT] CudnnConvolution has no valid tactics for this config, skipping
[03/24/2023-12:56:34] [V] [TRT] --------------- Timing Runner: Conv_15 + Relu_16 (CaskConvolution)
[03/24/2023-12:56:34] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[03/24/2023-12:56:34] [V] [TRT] *************** Autotuning format combination: Half(1036800,1:8,5760,32) -> Half(518400,1:8,2880,16) ***************
[03/24/2023-12:56:34] [V] [TRT] --------------- Timing Runner: Conv_15 + Relu_16 (CudaDepthwiseConvolution)
[03/24/2023-12:56:34] [V] [TRT] CudaDepthwiseConvolution has no valid tactics for this config, skipping
[03/24/2023-12:56:34] [V] [TRT] --------------- Timing Runner: Conv_15 + Relu_16 (CudnnConvolution)
[03/24/2023-12:56:34] [V] [TRT] Tactic: 0 Time: 1.75795
[03/24/2023-12:56:34] [V] [TRT] Tactic: 1 Time: 3.3161
[03/24/2023-12:56:34] [V] [TRT] Tactic: 2 Time: 2.16115
[03/24/2023-12:56:34] [V] [TRT] Tactic: 6 Time: 0.699264
[03/24/2023-12:56:34] [V] [TRT] Tactic: 56 Time: 1.75718
[03/24/2023-12:56:34] [V] [TRT] Tactic: 58 Time: 2.16115
[03/24/2023-12:56:34] [V] [TRT] Tactic: 62 Time: 0.699008
[03/24/2023-12:56:34] [V] [TRT] Fastest Tactic: 62 Time: 0.699008
[03/24/2023-12:56:34] [V] [TRT] --------------- Timing Runner: Conv_15 + Relu_16 (CaskConvolution)
[03/24/2023-12:56:34] [V] [TRT] Conv_15 + Relu_16 Set Tactic Name: ampere_h16816cudnn_256x128_ldg8_relu_exp_medium_nhwc_tn_v1 Tactic: 254850674756030979
[03/24/2023-12:56:34] [V] [TRT] Tactic: 254850674756030979 Time: 0.13376
[03/24/2023-12:56:34] [V] [TRT] Conv_15 + Relu_16 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x128x32_stage3_warpsize4x2x1_g1_tensor16x8x16_t1r3s3 Tactic: 328038211831149625
[03/24/2023-12:56:34] [V] [TRT] Tactic: 328038211831149625 Time: 0.126464
[03/24/2023-12:56:34] [V] [TRT] Conv_15 + Relu_16 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x64x64_stage3_warpsize2x2x1_g1_tensor16x8x16_t1r3s3 Tactic: 411553864378931917
[03/24/2023-12:56:34] [V] [TRT] Tactic: 411553864378931917 Time: 0.119168
[03/24/2023-12:56:34] [V] [TRT] Conv_15 + Relu_16 Set Tactic Name: sm75_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x128x32_stage1_warpsize4x2x1_g1_tensor16x8x8_t1r3s3 Tactic: 864841579020773074
[03/24/2023-12:56:34] [V] [TRT] Tactic: 864841579020773074 Time: 0.158208
[03/24/2023-12:56:34] [V] [TRT] Conv_15 + Relu_16 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x128x32_stage4_warpsize2x2x1_g1_tensor16x8x16 Tactic: 1011057357468998345
[03/24/2023-12:56:34] [V] [TRT] Tactic: 1011057357468998345 Time: 0.105856
[03/24/2023-12:56:34] [V] [TRT] Conv_15 + Relu_16 Set Tactic Name: sm75_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x64x32_stage1_warpsize4x1x1_g1_tensor16x8x8 Tactic: 1013168150133367738
[03/24/2023-12:56:34] [V] [TRT] Tactic: 1013168150133367738 Time: 0.164736
[03/24/2023-12:56:34] [V] [TRT] Conv_15 + Relu_16 Set Tactic Name: ampere_h16816cudnn_256x128_ldg8_relu_exp_stages_64x3_small_nhwc_tn_v1 Tactic: 1016009564074305832
[03/24/2023-12:56:34] [V] [TRT] Tactic: 1016009564074305832 Time: 0.12928
[03/24/2023-12:56:34] [V] [TRT] Conv_15 + Relu_16 Set Tactic Name: sm75_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x128x32_stage1_warpsize2x2x1_g1_tensor16x8x8 Tactic: 1067227531433278814
[03/24/2023-12:56:34] [V] [TRT] Tactic: 1067227531433278814 Time: 0.147584
[03/24/2023-12:56:34] [V] [TRT] Conv_15 + Relu_16 Set Tactic Name: ampere_h1688cudnn_128x128_ldg8_relu_exp_medium_nhwc_tn_v1 Tactic: 1156328698016730421
[03/24/2023-12:56:34] [V] [TRT] Tactic: 1156328698016730421 Time: 0.163584
[03/24/2023-12:56:34] [V] [TRT] Conv_15 + Relu_16 Set Tactic Name: sm75_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x128x32_stage1_warpsize2x2x1_g1_tensor16x8x8 Tactic: 1579845938601132607
[03/24/2023-12:56:34] [V] [TRT] Tactic: 1579845938601132607 Time: 0.149632
[03/24/2023-12:56:34] [V] [TRT] Conv_15 + Relu_16 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x128x32_stage5_warpsize2x2x1_g1_tensor16x8x16_t1r3s3 Tactic: 1723736032573714698
[03/24/2023-12:56:34] [V] [TRT] Tactic: 1723736032573714698 Time: 0.118016
[03/24/2023-12:56:34] [V] [TRT] Conv_15 + Relu_16 Set Tactic Name: sm75_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x32x32_stage1_warpsize4x1x1_g1_tensor16x8x8 Tactic: 1796821236841789338
[03/24/2023-12:56:34] [V] [TRT] Tactic: 1796821236841789338 Time: 0.219136
[03/24/2023-12:56:34] [V] [TRT] Conv_15 + Relu_16 Set Tactic Name: ampere_h16816cudnn_128x64_ldg8_relu_exp_stages_64x4_medium_nhwc_tn_v1 Tactic: 1832046141070096030
[03/24/2023-12:56:34] [V] [TRT] Tactic: 1832046141070096030 Time: 0.115456
[03/24/2023-12:56:34] [V] [TRT] Conv_15 + Relu_16 Set Tactic Name: ampere_h16816cudnn_128x64_sliced1x2_ldg8_relu_exp_stages_64x3_small_nhwc_tn_v1 Tactic: 1838082074606840426
[03/24/2023-12:56:34] [V] [TRT] Tactic: 1838082074606840426 Time: 0.105984
[03/24/2023-12:56:34] [V] [TRT] Conv_15 + Relu_16 Set Tactic Name: ampere_h16816cudnn_64x64_sliced1x2_ldg8_relu_exp_stages_64x5_small_nhwc_tn_v1 Tactic: 1899296423087490472
[03/24/2023-12:56:34] [V] [TRT] Tactic: 1899296423087490472 Time: 0.140032
[03/24/2023-12:56:34] [V] [TRT] Conv_15 + Relu_16 Set Tactic Name: sm75_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x32x32_stage1_warpsize4x1x1_g1_tensor16x8x8 Tactic: 1948263663414159978
[03/24/2023-12:56:34] [V] [TRT] Tactic: 1948263663414159978 Time: 0.187776
[03/24/2023-12:56:34] [V] [TRT] Conv_15 + Relu_16 Set Tactic Name: sm75_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x256x64_stage1_warpsize1x4x2_g1_tensor16x8x8 Tactic: 2027733232253711640
[03/24/2023-12:56:34] [V] [TRT] Tactic: 2027733232253711640 Time: 0.215552
[03/24/2023-12:56:34] [V] [TRT] Conv_15 + Relu_16 Set Tactic Name: sm75_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x64x32_stage1_warpsize2x2x1_g1_tensor16x8x8_t1r3s3 Tactic: 2154731107061273008
[03/24/2023-12:56:34] [V] [TRT] Tactic: 2154731107061273008 Time: 0.156544
[03/24/2023-12:56:34] [V] [TRT] Conv_15 + Relu_16 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x64x64_stage3_warpsize2x2x1_g1_tensor16x8x16 Tactic: 2428167804343994714
[03/24/2023-12:56:34] [V] [TRT] Tactic: 2428167804343994714 Time: 0.115712
[03/24/2023-12:56:34] [V] [TRT] Conv_15 + Relu_16 Set Tactic Name: ampere_h16816cudnn_128x128_ldg8_relu_exp_medium_nhwc_tn_v1 Tactic: 2541579301352125276
[03/24/2023-12:56:34] [V] [TRT] Tactic: 2541579301352125276 Time: 0.108672
[03/24/2023-12:56:34] [V] [TRT] Conv_15 + Relu_16 Set Tactic Name: ampere_h16816cudnn_64x64_sliced1x2_ldg8_relu_exp_stages_64x6_small_nhwc_tn_v1 Tactic: 2657157263811141609
[03/24/2023-12:56:34] [V] [TRT] Tactic: 2657157263811141609 Time: 0.140928
[03/24/2023-12:56:34] [V] [TRT] Conv_15 + Relu_16 Set Tactic Name: ampere_h16816cudnn_64x128_sliced1x2_ldg8_relu_exp_stages_64x4_large_nhwc_tn_v1 Tactic: 2819719497590964443
[03/24/2023-12:56:34] [V] [TRT] Tactic: 2819719497590964443 Time: 0.110976
[03/24/2023-12:56:34] [V] [TRT] Conv_15 + Relu_16 Set Tactic Name: ampere_h16816cudnn_128x64_sliced1x2_ldg8_relu_exp_stages_64x3_medium_nhwc_tn_v1 Tactic: 2968605903460894194
[03/24/2023-12:56:34] [V] [TRT] Tactic: 2968605903460894194 Time: 0.10688
[03/24/2023-12:56:34] [V] [TRT] Conv_15 + Relu_16 Set Tactic Name: ampere_h16816cudnn_128x128_ldg8_relu_exp_large_nhwc_tn_v1 Tactic: 2986078304285316765
[03/24/2023-12:56:34] [V] [TRT] Tactic: 2986078304285316765 Time: 0.110336
[03/24/2023-12:56:34] [V] [TRT] Conv_15 + Relu_16 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x256x64_stage3_warpsize1x4x1_g1_tensor16x8x16 Tactic: 3016308193087082166
[03/24/2023-12:56:34] [V] [TRT] Tactic: 3016308193087082166 Time: 0.167936
[03/24/2023-12:56:34] [V] [TRT] Conv_15 + Relu_16 Set Tactic Name: ampere_h16816cudnn_256x64_ldg8_relu_exp_stages_64x3_large_nhwc_tn_v1 Tactic: 3221382575080507859
[03/24/2023-12:56:34] [V] [TRT] Tactic: 3221382575080507859 Time: 0.108544
[03/24/2023-12:56:34] [V] [TRT] Conv_15 + Relu_16 Set Tactic Name: ampere_h16816cudnn_128x128_ldg8_relu_exp_stages_64x3_medium_nhwc_tn_v1 Tactic: 3362537467505018070
[03/24/2023-12:56:34] [V] [TRT] Tactic: 3362537467505018070 Time: 0.105472
[03/24/2023-12:56:34] [V] [TRT] Conv_15 + Relu_16 Set Tactic Name: sm75_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x64x32_stage1_warpsize4x1x1_g1_tensor16x8x8_t1r3s3 Tactic: 3464689803495983377
[03/24/2023-12:56:34] [V] [TRT] Tactic: 3464689803495983377 Time: 0.154496
[03/24/2023-12:56:34] [V] [TRT] Conv_15 + Relu_16 Set Tactic Name: ampere_h1688cudnn_256x128_ldg8_relu_exp_medium_nhwc_tn_v1 Tactic: 3513075359009385578
[03/24/2023-12:56:34] [V] [TRT] Tactic: 3513075359009385578 Time: 0.164352
[03/24/2023-12:56:34] [V] [TRT] Conv_15 + Relu_16 Set Tactic Name: ampere_h16816cudnn_128x64_ldg8_relu_exp_stages_64x4_large_nhwc_tn_v1 Tactic: 3573559043797674382
[03/24/2023-12:56:34] [V] [TRT] Tactic: 3573559043797674382 Time: 0.117504
[03/24/2023-12:56:34] [V] [TRT] Conv_15 + Relu_16 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x64x64_stage4_warpsize2x2x1_g1_tensor16x8x16_t1r3s3 Tactic: 3591970081995419777
[03/24/2023-12:56:34] [V] [TRT] Tactic: 3591970081995419777 Time: 0.139392
[03/24/2023-12:56:34] [V] [TRT] Conv_15 + Relu_16 Set Tactic Name: sm75_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x128x32_stage1_warpsize2x2x1_g1_tensor16x8x8_t1r3s3 Tactic: 3636831327753843771
[03/24/2023-12:56:34] [V] [TRT] Tactic: 3636831327753843771 Time: 0.125824
[03/24/2023-12:56:34] [V] [TRT] Conv_15 + Relu_16 Set Tactic Name: ampere_h1688cudnn_128x128_ldg8_relu_exp_small_nhwc_tn_v1 Tactic: 3704534001553878387
[03/24/2023-12:56:34] [V] [TRT] Tactic: 3704534001553878387 Time: 0.15808
[03/24/2023-12:56:34] [V] [TRT] Conv_15 + Relu_16 Set Tactic Name: ampere_h16816cudnn_64x128_ldg8_relu_exp_stages_64x4_small_nhwc_tn_v1 Tactic: 4278315135102886928
[03/24/2023-12:56:34] [V] [TRT] Tactic: 4278315135102886928 Time: 0.10944
[03/24/2023-12:56:34] [V] [TRT] Conv_15 + Relu_16 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x32x32_stage4_warpsize4x1x1_g1_tensor16x8x16_t1r3s3 Tactic: 4503233883285355107
[03/24/2023-12:56:34] [V] [TRT] Tactic: 4503233883285355107 Time: 0.152832
[03/24/2023-12:56:34] [V] [TRT] Conv_15 + Relu_16 Set Tactic Name: ampere_h16816cudnn_256x64_ldg8_relu_exp_stages_64x3_medium_nhwc_tn_v1 Tactic: 4540505769798915372
[03/24/2023-12:56:34] [V] [TRT] Tactic: 4540505769798915372 Time: 0.108672
[03/24/2023-12:56:34] [V] [TRT] Conv_15 + Relu_16 Set Tactic Name: ampere_h16816cudnn_256x64_sliced1x2_ldg8_relu_exp_small_nhwc_tn_v1 Tactic: 4802447371470387646
[03/24/2023-12:56:34] [V] [TRT] Tactic: 4802447371470387646 Time: 0.134016
[03/24/2023-12:56:34] [V] [TRT] Conv_15 + Relu_16 Set Tactic Name: ampere_h16816cudnn_256x128_ldg8_relu_exp_small_nhwc_tn_v1 Tactic: 5059676457552313631
[03/24/2023-12:56:34] [V] [TRT] Tactic: 5059676457552313631 Time: 0.130304
[03/24/2023-12:56:34] [V] [TRT] Conv_15 + Relu_16 Set Tactic Name: sm75_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x128x64_stage1_warpsize2x2x1_g1_tensor16x8x8_t1r3s3 Tactic: 5263029549013613567
[03/24/2023-12:56:34] [V] [TRT] Tactic: 5263029549013613567 Time: 0.118656
[03/24/2023-12:56:34] [V] [TRT] Conv_15 + Relu_16 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x64x64_stage4_warpsize2x2x1_g1_tensor16x8x16 Tactic: 5368829646735632944
[03/24/2023-12:56:34] [V] [TRT] Tactic: 5368829646735632944 Time: 0.13952
[03/24/2023-12:56:34] [V] [TRT] Conv_15 + Relu_16 Set Tactic Name: ampere_h1688cudnn_256x64_sliced1x2_ldg8_relu_exp_small_nhwc_tn_v1 Tactic: 5398999388616959893
[03/24/2023-12:56:34] [V] [TRT] Tactic: 5398999388616959893 Time: 0.14272
[03/24/2023-12:56:34] [V] [TRT] Conv_15 + Relu_16 Set Tactic Name: sm75_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x256x32_stage1_warpsize2x4x1_g1_tensor16x8x8_t1r3s3 Tactic: 5506334059535811602
[03/24/2023-12:56:34] [V] [TRT] Tactic: 5506334059535811602 Time: 0.223872
[03/24/2023-12:56:34] [V] [TRT] Conv_15 + Relu_16 Set Tactic Name: ampere_h16816cudnn_64x128_sliced1x2_ldg8_relu_exp_stages_64x3_large_nhwc_tn_v1 Tactic: 5746691132547383910
[03/24/2023-12:56:34] [V] [TRT] Tactic: 5746691132547383910 Time: 0.113152
[03/24/2023-12:56:34] [V] [TRT] Conv_15 + Relu_16 Set Tactic Name: ampere_h16816cudnn_256x64_ldg8_relu_exp_large_nhwc_tn_v1 Tactic: 5770170567977052602
[03/24/2023-12:56:34] [V] [TRT] Tactic: 5770170567977052602 Time: 0.13312
[03/24/2023-12:56:34] [V] [TRT] Conv_15 + Relu_16 Set Tactic Name: sm75_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x32x64_stage1_warpsize2x1x2_g1_tensor16x8x8_t1r3s3 Tactic: 5932046018238429951
[03/24/2023-12:56:34] [V] [TRT] Tactic: 5932046018238429951 Time: 0.192512
[03/24/2023-12:56:34] [V] [TRT] Conv_15 + Relu_16 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x64x32_stage3_warpsize4x1x1_g1_tensor16x8x16_t1r3s3 Tactic: 5953552212833506549
[03/24/2023-12:56:34] [V] [TRT] Tactic: 5953552212833506549 Time: 0.102784
[03/24/2023-12:56:34] [V] [TRT] Conv_15 + Relu_16 Set Tactic Name: ampere_h16816cudnn_64x128_ldg8_relu_exp_stages_64x3_small_nhwc_tn_v1 Tactic: 6034364043891107501
[03/24/2023-12:56:34] [V] [TRT] Tactic: 6034364043891107501 Time: 0.11456
[03/24/2023-12:56:34] [V] [TRT] Conv_15 + Relu_16 Set Tactic Name: ampere_h16816cudnn_64x64_ldg8_relu_exp_stages_64x5_large_nhwc_tn_v1 Tactic: 6074229447555668232
[03/24/2023-12:56:34] [V] [TRT] Tactic: 6074229447555668232 Time: 0.154496
[03/24/2023-12:56:34] [V] [TRT] Conv_15 + Relu_16 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x64x64_stage3_warpsize2x2x1_g1_tensor16x8x16 Tactic: 6154447660803990543
[03/24/2023-12:56:34] [V] [TRT] Tactic: 6154447660803990543 Time: 0.118656
[03/24/2023-12:56:34] [V] [TRT] Conv_15 + Relu_16 Set Tactic Name: sm75_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x32x64_stage1_warpsize2x1x2_g1_tensor16x8x8 Tactic: 6195603576432354734
[03/24/2023-12:56:34] [V] [TRT] Tactic: 6195603576432354734 Time: 0.196352
[03/24/2023-12:56:34] [V] [TRT] Conv_15 + Relu_16 Set Tactic Name: sm75_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x32x32_stage1_warpsize4x1x1_g1_tensor16x8x8_t1r3s3 Tactic: 6252808259936499253
[03/24/2023-12:56:34] [V] [TRT] Tactic: 6252808259936499253 Time: 0.187264
[03/24/2023-12:56:34] [V] [TRT] Conv_15 + Relu_16 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x128x64_stage3_warpsize2x2x1_g1_tensor16x8x16 Tactic: 6325769668000961702
[03/24/2023-12:56:34] [V] [TRT] Tactic: 6325769668000961702 Time: 0.105472
[03/24/2023-12:56:34] [V] [TRT] Conv_15 + Relu_16 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x32x64_stage5_warpsize2x2x1_g1_tensor16x8x16 Tactic: 6350273239113254096
[03/24/2023-12:56:34] [V] [TRT] Tactic: 6350273239113254096 Time: 0.208
[03/24/2023-12:56:34] [V] [TRT] Conv_15 + Relu_16 Set Tactic Name: ampere_h16816cudnn_128x128_ldg8_relu_exp_stages_64x3_small_nhwc_tn_v1 Tactic: 6377497238381488891
[03/24/2023-12:56:34] [V] [TRT] Tactic: 6377497238381488891 Time: 0.10624
[03/24/2023-12:56:34] [V] [TRT] Conv_15 + Relu_16 Set Tactic Name: sm75_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x64x64_stage1_warpsize2x2x1_g1_tensor16x8x8 Tactic: 6408235920257988861
[03/24/2023-12:56:34] [V] [TRT] Tactic: 6408235920257988861 Time: 0.158592
[03/24/2023-12:56:34] [V] [TRT] Conv_15 + Relu_16 Set Tactic Name: ampere_h16816cudnn_128x64_ldg8_relu_exp_stages_64x3_large_nhwc_tn_v1 Tactic: 6446388116965632819
[03/24/2023-12:56:34] [V] [TRT] Tactic: 6446388116965632819 Time: 0.112896
[03/24/2023-12:56:34] [V] [TRT] Conv_15 + Relu_16 Set Tactic Name: ampere_h16816cudnn_128x64_sliced1x2_ldg8_relu_exp_stages_64x4_medium_nhwc_tn_v1 Tactic: 6468794451065529747
[03/24/2023-12:56:34] [V] [TRT] Tactic: 6468794451065529747 Time: 0.109568
[03/24/2023-12:56:34] [V] [TRT] Conv_15 + Relu_16 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x128x64_stage3_warpsize4x2x1_g1_tensor16x8x16 Tactic: 6509152032538119080
[03/24/2023-12:56:34] [V] [TRT] Tactic: 6509152032538119080 Time: 0.128896
[03/24/2023-12:56:34] [V] [TRT] Conv_15 + Relu_16 Set Tactic Name: ampere_h1688cudnn_256x128_ldg8_relu_exp_large_nhwc_tn_v1 Tactic: 6642277870194067185
[03/24/2023-12:56:34] [V] [TRT] Tactic: 6642277870194067185 Time: 0.166272
[03/24/2023-12:56:34] [V] [TRT] Conv_15 + Relu_16 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x256x64_stage3_warpsize1x4x1_g1_tensor16x8x16 Tactic: 6703181542003057635
[03/24/2023-12:56:34] [V] [TRT] Tactic: 6703181542003057635 Time: 0.172672
[03/24/2023-12:56:34] [V] [TRT] Conv_15 + Relu_16 Set Tactic Name: ampere_h16816cudnn_64x64_ldg8_relu_exp_stages_64x5_medium_nhwc_tn_v1 Tactic: 6859477213531075460
[03/24/2023-12:56:34] [V] [TRT] Tactic: 6859477213531075460 Time: 0.154368
[03/24/2023-12:56:34] [V] [TRT] Conv_15 + Relu_16 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x128x32_stage4_warpsize2x2x1_g1_tensor16x8x16_t1r3s3 Tactic: 6972489290272968208
[03/24/2023-12:56:34] [V] [TRT] Tactic: 6972489290272968208 Time: 0.096768
[03/24/2023-12:56:34] [V] [TRT] Conv_15 + Relu_16 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x128x32_stage3_warpsize4x2x1_g1_tensor16x8x16 Tactic: 6979044990896381511
[03/24/2023-12:56:34] [V] [TRT] Tactic: 6979044990896381511 Time: 0.125952
[03/24/2023-12:56:34] [V] [TRT] Conv_15 + Relu_16 Set Tactic Name: ampere_h1688cudnn_256x64_ldg8_relu_exp_medium_nhwc_tn_v1 Tactic: 7216571380637776659
[03/24/2023-12:56:34] [V] [TRT] Tactic: 7216571380637776659 Time: 0.20352
[03/24/2023-12:56:34] [V] [TRT] Conv_15 + Relu_16 Set Tactic Name: ampere_h16816cudnn_128x64_ldg8_relu_exp_stages_64x3_medium_nhwc_tn_v1 Tactic: 7609923741161019135
[03/24/2023-12:56:34] [V] [TRT] Tactic: 7609923741161019135 Time: 0.11328
[03/24/2023-12:56:34] [V] [TRT] Conv_15 + Relu_16 Set Tactic Name: sm75_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x64x32_stage1_warpsize2x2x1_g1_tensor16x8x8 Tactic: 7612687199567064086
[03/24/2023-12:56:34] [V] [TRT] Tactic: 7612687199567064086 Time: 0.164352
[03/24/2023-12:56:34] [V] [TRT] Conv_15 + Relu_16 Set Tactic Name: ampere_h16816cudnn_64x64_ldg8_relu_exp_stages_64x6_large_nhwc_tn_v1 Tactic: 7705739241028240201
[03/24/2023-12:56:34] [V] [TRT] Tactic: 7705739241028240201 Time: 0.164608
[03/24/2023-12:56:34] [V] [TRT] Conv_15 + Relu_16 Set Tactic Name: sm75_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x128x32_stage1_warpsize2x2x1_g1_tensor16x8x8 Tactic: 7729555994715864793
[03/24/2023-12:56:34] [V] [TRT] Tactic: 7729555994715864793 Time: 0.164992
[03/24/2023-12:56:34] [V] [TRT] Conv_15 + Relu_16 Set Tactic Name: sm75_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x64x64_stage1_warpsize2x2x1_g1_tensor16x8x8_t1r3s3 Tactic: 7849296535223586261
[03/24/2023-12:56:34] [V] [TRT] Tactic: 7849296535223586261 Time: 0.157568
[03/24/2023-12:56:34] [V] [TRT] Conv_15 + Relu_16 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x256x32_stage3_warpsize2x4x1_g1_tensor16x8x16 Tactic: 8072087735545283117
[03/24/2023-12:56:34] [V] [TRT] Tactic: 8072087735545283117 Time: 0.1856
[03/24/2023-12:56:34] [V] [TRT] Conv_15 + Relu_16 Set Tactic Name: ampere_h16816cudnn_64x64_sliced1x2_ldg8_relu_exp_stages_64x5_medium_nhwc_tn_v1 Tactic: 8101703987960976805
[03/24/2023-12:56:34] [V] [TRT] Tactic: 8101703987960976805 Time: 0.140928
[03/24/2023-12:56:34] [V] [TRT] Conv_15 + Relu_16 Set Tactic Name: ampere_h16816cudnn_128x64_sliced1x2_ldg8_relu_exp_stages_64x4_small_nhwc_tn_v1 Tactic: 8170606396342855895
[03/24/2023-12:56:34] [V] [TRT] Tactic: 8170606396342855895 Time: 0.105088
[03/24/2023-12:56:34] [V] [TRT] Conv_15 + Relu_16 Set Tactic Name: sm75_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x32x64_stage1_warpsize2x1x2_g1_tensor16x8x8 Tactic: 8455608235315878803
[03/24/2023-12:56:34] [V] [TRT] Tactic: 8455608235315878803 Time: 0.212736
[03/24/2023-12:56:34] [V] [TRT] Conv_15 + Relu_16 Set Tactic Name: sm75_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x64x64_stage1_warpsize2x2x1_g1_tensor16x8x8 Tactic: 8668812313058150080
[03/24/2023-12:56:34] [V] [TRT] Tactic: 8668812313058150080 Time: 0.16768
[03/24/2023-12:56:34] [V] [TRT] Conv_15 + Relu_16 Set Tactic Name: ampere_h1688cudnn_256x64_ldg8_relu_exp_small_nhwc_tn_v1 Tactic: 8839784824303350101
[03/24/2023-12:56:34] [V] [TRT] Tactic: 8839784824303350101 Time: 0.18688
[03/24/2023-12:56:34] [V] [TRT] Conv_15 + Relu_16 Set Tactic Name: ampere_h16816cudnn_64x64_sliced1x2_ldg8_relu_exp_stages_64x5_large_nhwc_tn_v1 Tactic: -9217371357561775773
[03/24/2023-12:56:34] [V] [TRT] Tactic: -9217371357561775773 Time: 0.140672
[03/24/2023-12:56:34] [V] [TRT] Conv_15 + Relu_16 Set Tactic Name: ampere_h16816cudnn_256x64_sliced1x2_ldg8_relu_exp_medium_nhwc_tn_v1 Tactic: -9009272790678027912
[03/24/2023-12:56:34] [V] [TRT] Tactic: -9009272790678027912 Time: 0.1504
[03/24/2023-12:56:34] [V] [TRT] Conv_15 + Relu_16 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x32x32_stage4_warpsize4x1x1_g1_tensor16x8x16 Tactic: -8985224497679592364
[03/24/2023-12:56:34] [V] [TRT] Tactic: -8985224497679592364 Time: 0.152576
[03/24/2023-12:56:34] [V] [TRT] Conv_15 + Relu_16 Set Tactic Name: ampere_h16816cudnn_128x64_sliced1x2_ldg8_relu_exp_stages_64x3_large_nhwc_tn_v1 Tactic: -8949544755481315679
[03/24/2023-12:56:34] [V] [TRT] Tactic: -8949544755481315679 Time: 0.107776
[03/24/2023-12:56:34] [V] [TRT] Conv_15 + Relu_16 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x64x64_stage3_warpsize4x1x1_g1_tensor16x8x16_t1r3s3 Tactic: -8867999442759527766
[03/24/2023-12:56:34] [V] [TRT] Tactic: -8867999442759527766 Time: 0.114432
[03/24/2023-12:56:34] [V] [TRT] Conv_15 + Relu_16 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x128x64_stage3_warpsize2x2x1_g1_tensor16x8x16 Tactic: -8759929675070720385
[03/24/2023-12:56:35] [V] [TRT] Tactic: -8759929675070720385 Time: 0.104192
[03/24/2023-12:56:35] [V] [TRT] Conv_15 + Relu_16 Set Tactic Name: ampere_h16816cudnn_64x64_ldg8_relu_exp_stages_64x6_medium_nhwc_tn_v1 Tactic: -8604374562669615024
[03/24/2023-12:56:35] [V] [TRT] Tactic: -8604374562669615024 Time: 0.161408
[03/24/2023-12:56:35] [V] [TRT] Conv_15 + Relu_16 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x128x64_stage3_warpsize4x2x1_g1_tensor16x8x16 Tactic: -8362347876645295759
[03/24/2023-12:56:35] [V] [TRT] Tactic: -8362347876645295759 Time: 0.128384
[03/24/2023-12:56:35] [V] [TRT] Conv_15 + Relu_16 Set Tactic Name: sm75_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x128x32_stage1_warpsize4x2x1_g1_tensor16x8x8 Tactic: -8254009616492665198
[03/24/2023-12:56:35] [V] [TRT] Tactic: -8254009616492665198 Time: 0.155648
[03/24/2023-12:56:35] [V] [TRT] Conv_15 + Relu_16 Set Tactic Name: ampere_h16816cudnn_256x128_ldg8_relu_exp_stages_64x3_large_nhwc_tn_v1 Tactic: -7757610000269494813
[03/24/2023-12:56:35] [V] [TRT] Tactic: -7757610000269494813 Time: 0.130944
[03/24/2023-12:56:35] [V] [TRT] Conv_15 + Relu_16 Set Tactic Name: sm75_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x128x32_stage1_warpsize4x2x1_g1_tensor16x8x8 Tactic: -7615325597099025933
[03/24/2023-12:56:35] [V] [TRT] Tactic: -7615325597099025933 Time: 0.163712
[03/24/2023-12:56:35] [V] [TRT] Conv_15 + Relu_16 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x64x64_stage3_warpsize4x1x1_g1_tensor16x8x16 Tactic: -6917689122519989488
[03/24/2023-12:56:35] [V] [TRT] Tactic: -6917689122519989488 Time: 0.115712
[03/24/2023-12:56:35] [V] [TRT] Conv_15 + Relu_16 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x32x64_stage5_warpsize2x2x1_g1_tensor16x8x16_t1r3s3 Tactic: -6902925267326201166
[03/24/2023-12:56:35] [V] [TRT] Tactic: -6902925267326201166 Time: 0.204672
[03/24/2023-12:56:35] [V] [TRT] Conv_15 + Relu_16 Set Tactic Name: ampere_h16816cudnn_64x128_ldg8_relu_exp_stages_64x4_large_nhwc_tn_v1 Tactic: -6840588038605932325
[03/24/2023-12:56:35] [V] [TRT] Tactic: -6840588038605932325 Time: 0.110848
[03/24/2023-12:56:35] [V] [TRT] Conv_15 + Relu_16 Set Tactic Name: sm75_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x32x32_stage1_warpsize4x1x1_g1_tensor16x8x8 Tactic: -6828337260021572283
[03/24/2023-12:56:35] [V] [TRT] Tactic: -6828337260021572283 Time: 0.236544
[03/24/2023-12:56:35] [V] [TRT] Conv_15 + Relu_16 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x256x32_stage3_warpsize2x4x1_g1_tensor16x8x16 Tactic: -6799856376604253964
[03/24/2023-12:56:35] [V] [TRT] Tactic: -6799856376604253964 Time: 0.18432
[03/24/2023-12:56:35] [V] [TRT] Conv_15 + Relu_16 Set Tactic Name: sm75_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x32x32_stage1_warpsize4x1x1_g1_tensor16x8x8 Tactic: -6711815420995272523
[03/24/2023-12:56:35] [V] [TRT] Tactic: -6711815420995272523 Time: 0.208512
[03/24/2023-12:56:35] [V] [TRT] Conv_15 + Relu_16 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x32x32_stage4_warpsize4x1x1_g1_tensor16x8x16_t1r3s3 Tactic: -6625722781282978136
[03/24/2023-12:56:35] [V] [TRT] Tactic: -6625722781282978136 Time: 0.16768
[03/24/2023-12:56:35] [V] [TRT] Conv_15 + Relu_16 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x64x32_stage3_warpsize4x1x1_g1_tensor16x8x16 Tactic: -6525498856028268801
[03/24/2023-12:56:35] [V] [TRT] Tactic: -6525498856028268801 Time: 0.113152
[03/24/2023-12:56:35] [V] [TRT] Conv_15 + Relu_16 Set Tactic Name: sm75_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x256x64_stage1_warpsize1x4x2_g1_tensor16x8x8 Tactic: -6489479581011009593
[03/24/2023-12:56:35] [V] [TRT] Tactic: -6489479581011009593 Time: 0.21184
[03/24/2023-12:56:35] [V] [TRT] Conv_15 + Relu_16 Set Tactic Name: ampere_h16816cudnn_64x64_sliced1x2_ldg8_relu_exp_stages_64x6_medium_nhwc_tn_v1 Tactic: -6356316196810535311
[03/24/2023-12:56:35] [V] [TRT] Tactic: -6356316196810535311 Time: 0.152832
[03/24/2023-12:56:35] [V] [TRT] Conv_15 + Relu_16 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x32x32_stage4_warpsize4x1x1_g1_tensor16x8x16 Tactic: -6324345858751792783
[03/24/2023-12:56:35] [V] [TRT] Tactic: -6324345858751792783 Time: 0.168192
[03/24/2023-12:56:35] [V] [TRT] Conv_15 + Relu_16 Set Tactic Name: sm75_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x256x64_stage1_warpsize1x4x2_g1_tensor16x8x8_t1r3s3 Tactic: -6320761427625651496
[03/24/2023-12:56:35] [V] [TRT] Tactic: -6320761427625651496 Time: 0.211328
[03/24/2023-12:56:35] [V] [TRT] Conv_15 + Relu_16 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x256x32_stage3_warpsize2x4x1_g1_tensor16x8x16_t1r3s3 Tactic: -6262400699544994312
[03/24/2023-12:56:35] [V] [TRT] Tactic: -6262400699544994312 Time: 0.182144
[03/24/2023-12:56:35] [V] [TRT] Conv_15 + Relu_16 Set Tactic Name: ampere_h1688cudnn_128x128_ldg8_relu_exp_large_nhwc_tn_v1 Tactic: -6257787336162086472
[03/24/2023-12:56:35] [V] [TRT] Tactic: -6257787336162086472 Time: 0.164352
[03/24/2023-12:56:35] [V] [TRT] Conv_15 + Relu_16 Set Tactic Name: sm75_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x128x64_stage1_warpsize2x2x1_g1_tensor16x8x8 Tactic: -6080892721161662420
[03/24/2023-12:56:35] [V] [TRT] Tactic: -6080892721161662420 Time: 0.119552
[03/24/2023-12:56:35] [V] [TRT] Conv_15 + Relu_16 Set Tactic Name: ampere_h16816cudnn_128x64_ldg8_relu_exp_stages_64x4_small_nhwc_tn_v1 Tactic: -6063766379489217211
[03/24/2023-12:56:35] [V] [TRT] Tactic: -6063766379489217211 Time: 0.113792
[03/24/2023-12:56:35] [V] [TRT] Conv_15 + Relu_16 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x128x32_stage5_warpsize2x2x1_g1_tensor16x8x16 Tactic: -5777580938094193096
[03/24/2023-12:56:35] [V] [TRT] Tactic: -5777580938094193096 Time: 0.10752
[03/24/2023-12:56:35] [V] [TRT] Conv_15 + Relu_16 Set Tactic Name: sm75_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x128x64_stage1_warpsize2x2x1_g1_tensor16x8x8 Tactic: -5710735840878760115
[03/24/2023-12:56:35] [V] [TRT] Tactic: -5710735840878760115 Time: 0.1248
[03/24/2023-12:56:35] [V] [TRT] Conv_15 + Relu_16 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x128x32_stage3_warpsize4x2x1_g1_tensor16x8x16 Tactic: -5657273398217409378
[03/24/2023-12:56:35] [V] [TRT] Tactic: -5657273398217409378 Time: 0.129152
[03/24/2023-12:56:35] [V] [TRT] Conv_15 + Relu_16 Set Tactic Name: sm75_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x128x32_stage1_warpsize2x2x1_g1_tensor16x8x8_t1r3s3 Tactic: -5546257196173962281
[03/24/2023-12:56:35] [V] [TRT] Tactic: -5546257196173962281 Time: 0.15808
[03/24/2023-12:56:35] [V] [TRT] Conv_15 + Relu_16 Set Tactic Name: ampere_h16816cudnn_128x128_ldg8_relu_exp_small_nhwc_tn_v1 Tactic: -5530886555766748586
[03/24/2023-12:56:35] [V] [TRT] Tactic: -5530886555766748586 Time: 0.107648
[03/24/2023-12:56:35] [V] [TRT] Conv_15 + Relu_16 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x64x32_stage5_warpsize2x2x1_g1_tensor16x8x16_t1r3s3 Tactic: -5422685219138380548
[03/24/2023-12:56:35] [V] [TRT] Tactic: -5422685219138380548 Time: 0.116352
[03/24/2023-12:56:35] [V] [TRT] Conv_15 + Relu_16 Set Tactic Name: ampere_h16816cudnn_256x64_ldg8_relu_exp_stages_64x3_small_nhwc_tn_v1 Tactic: -5261787675443473128
[03/24/2023-12:56:35] [V] [TRT] Tactic: -5261787675443473128 Time: 0.10752
[03/24/2023-12:56:35] [V] [TRT] Conv_15 + Relu_16 Set Tactic Name: sm75_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x64x32_stage1_warpsize4x1x1_g1_tensor16x8x8 Tactic: -5198219374380660379
[03/24/2023-12:56:35] [V] [TRT] Tactic: -5198219374380660379 Time: 0.158208
[03/24/2023-12:56:35] [V] [TRT] Conv_15 + Relu_16 Set Tactic Name: ampere_h16816cudnn_64x128_sliced1x2_ldg8_relu_exp_stages_64x3_medium_nhwc_tn_v1 Tactic: -5161596964442251102
[03/24/2023-12:56:35] [V] [TRT] Tactic: -5161596964442251102 Time: 0.112128
[03/24/2023-12:56:35] [V] [TRT] Conv_15 + Relu_16 Set Tactic Name: ampere_h16816cudnn_64x128_ldg8_relu_exp_stages_64x3_medium_nhwc_tn_v1 Tactic: -5127240325355316006
[03/24/2023-12:56:35] [V] [TRT] Tactic: -5127240325355316006 Time: 0.114816
[03/24/2023-12:56:35] [V] [TRT] Conv_15 + Relu_16 Set Tactic Name: ampere_h16816cudnn_256x128_ldg8_relu_exp_stages_64x3_medium_nhwc_tn_v1 Tactic: -5109582882231362997
[03/24/2023-12:56:35] [V] [TRT] Tactic: -5109582882231362997 Time: 0.130304
[03/24/2023-12:56:35] [V] [TRT] Conv_15 + Relu_16 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x64x32_stage5_warpsize2x2x1_g1_tensor16x8x16 Tactic: -4825567853927730435
[03/24/2023-12:56:35] [V] [TRT] Tactic: -4825567853927730435 Time: 0.1216
[03/24/2023-12:56:35] [V] [TRT] Conv_15 + Relu_16 Set Tactic Name: ampere_h16816cudnn_64x128_sliced1x2_ldg8_relu_exp_stages_64x4_small_nhwc_tn_v1 Tactic: -4796511246675321840
[03/24/2023-12:56:35] [V] [TRT] Tactic: -4796511246675321840 Time: 0.10752
[03/24/2023-12:56:35] [V] [TRT] Conv_15 + Relu_16 Set Tactic Name: ampere_h16816cudnn_64x64_sliced1x2_ldg8_relu_exp_stages_64x6_large_nhwc_tn_v1 Tactic: -4706569565442112734
[03/24/2023-12:56:35] [V] [TRT] Tactic: -4706569565442112734 Time: 0.153472
[03/24/2023-12:56:35] [V] [TRT] Conv_15 + Relu_16 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x128x64_stage3_warpsize2x2x1_g1_tensor16x8x16_t1r3s3 Tactic: -4566599693570369588
[03/24/2023-12:56:35] [V] [TRT] Tactic: -4566599693570369588 Time: 0.1056
[03/24/2023-12:56:35] [V] [TRT] Conv_15 + Relu_16 Set Tactic Name: ampere_h16816cudnn_128x128_ldg8_relu_exp_stages_64x3_large_nhwc_tn_v1 Tactic: -4409144516525410768
[03/24/2023-12:56:35] [V] [TRT] Tactic: -4409144516525410768 Time: 0.1056
[03/24/2023-12:56:35] [V] [TRT] Conv_15 + Relu_16 Set Tactic Name: ampere_h16816cudnn_128x64_ldg8_relu_exp_stages_64x3_small_nhwc_tn_v1 Tactic: -4379519430184503304
[03/24/2023-12:56:35] [V] [TRT] Tactic: -4379519430184503304 Time: 0.112256
[03/24/2023-12:56:35] [V] [TRT] Conv_15 + Relu_16 Set Tactic Name: ampere_h1688cudnn_256x128_ldg8_relu_exp_small_nhwc_tn_v1 Tactic: -4152066959007262150
[03/24/2023-12:56:35] [V] [TRT] Tactic: -4152066959007262150 Time: 0.151808
[03/24/2023-12:56:35] [V] [TRT] Conv_15 + Relu_16 Set Tactic Name: ampere_h16816cudnn_64x128_ldg8_relu_exp_stages_64x4_medium_nhwc_tn_v1 Tactic: -4021926646879732549
[03/24/2023-12:56:35] [V] [TRT] Tactic: -4021926646879732549 Time: 0.109312
[03/24/2023-12:56:35] [V] [TRT] Conv_15 + Relu_16 Set Tactic Name: ampere_h16816cudnn_64x128_sliced1x2_ldg8_relu_exp_stages_64x4_medium_nhwc_tn_v1 Tactic: -3987638434926559037
[03/24/2023-12:56:35] [V] [TRT] Tactic: -3987638434926559037 Time: 0.106752
[03/24/2023-12:56:35] [V] [TRT] Conv_15 + Relu_16 Set Tactic Name: ampere_h1688cudnn_256x64_sliced1x2_ldg8_relu_exp_medium_nhwc_tn_v1 Tactic: -3905653247016903130
[03/24/2023-12:56:35] [V] [TRT] Tactic: -3905653247016903130 Time: 0.157696
[03/24/2023-12:56:35] [V] [TRT] Conv_15 + Relu_16 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x64x32_stage5_warpsize2x2x1_g1_tensor16x8x16 Tactic: -3903974568488493144
[03/24/2023-12:56:35] [V] [TRT] Tactic: -3903974568488493144 Time: 0.111616
[03/24/2023-12:56:35] [V] [TRT] Conv_15 + Relu_16 Set Tactic Name: ampere_h16816cudnn_64x128_ldg8_relu_exp_stages_64x3_large_nhwc_tn_v1 Tactic: -3895429239811098010
[03/24/2023-12:56:35] [V] [TRT] Tactic: -3895429239811098010 Time: 0.114944
[03/24/2023-12:56:35] [V] [TRT] Conv_15 + Relu_16 Set Tactic Name: ampere_h16816cudnn_256x64_ldg8_relu_exp_small_nhwc_tn_v1 Tactic: -3864869056275745423
[03/24/2023-12:56:35] [V] [TRT] Tactic: -3864869056275745423 Time: 0.12608
[03/24/2023-12:56:35] [V] [TRT] Conv_15 + Relu_16 Set Tactic Name: sm75_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x32x32_stage1_warpsize4x1x1_g1_tensor16x8x8_t1r3s3 Tactic: -3784342055748695733
[03/24/2023-12:56:35] [V] [TRT] Tactic: -3784342055748695733 Time: 0.217088
[03/24/2023-12:56:35] [V] [TRT] Conv_15 + Relu_16 Set Tactic Name: ampere_h16816cudnn_64x64_ldg8_relu_exp_stages_64x5_small_nhwc_tn_v1 Tactic: -3601464762214218301
[03/24/2023-12:56:35] [V] [TRT] Tactic: -3601464762214218301 Time: 0.154624
[03/24/2023-12:56:35] [V] [TRT] Conv_15 + Relu_16 Set Tactic Name: sm75_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x64x32_stage1_warpsize2x2x1_g1_tensor16x8x8 Tactic: -3425274793298557239
[03/24/2023-12:56:35] [V] [TRT] Tactic: -3425274793298557239 Time: 0.155264
[03/24/2023-12:56:35] [V] [TRT] Conv_15 + Relu_16 Set Tactic Name: ampere_h1688cudnn_256x64_sliced1x2_ldg8_relu_exp_large_nhwc_tn_v1 Tactic: -3412636942650049698
[03/24/2023-12:56:35] [V] [TRT] Tactic: -3412636942650049698 Time: 0.159616
[03/24/2023-12:56:35] [V] [TRT] Conv_15 + Relu_16 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x64x32_stage3_warpsize4x1x1_g1_tensor16x8x16 Tactic: -3338665856053412950
[03/24/2023-12:56:35] [V] [TRT] Tactic: -3338665856053412950 Time: 0.103296
[03/24/2023-12:56:35] [V] [TRT] Conv_15 + Relu_16 Set Tactic Name: sm75_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x128x32_stage1_warpsize2x2x1_g1_tensor16x8x8 Tactic: -3271955096576257018
[03/24/2023-12:56:35] [V] [TRT] Tactic: -3271955096576257018 Time: 0.160384
[03/24/2023-12:56:35] [V] [TRT] Conv_15 + Relu_16 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x128x64_stage3_warpsize4x2x1_g1_tensor16x8x16_t1r3s3 Tactic: -3243541398692466074
[03/24/2023-12:56:35] [V] [TRT] Tactic: -3243541398692466074 Time: 0.128256
[03/24/2023-12:56:35] [V] [TRT] Conv_15 + Relu_16 Set Tactic Name: ampere_h16816cudnn_64x128_sliced1x2_ldg8_relu_exp_stages_64x3_small_nhwc_tn_v1 Tactic: -3058330359340425555
[03/24/2023-12:56:35] [V] [TRT] Tactic: -3058330359340425555 Time: 0.112256
[03/24/2023-12:56:35] [V] [TRT] Conv_15 + Relu_16 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x256x64_stage3_warpsize1x4x1_g1_tensor16x8x16_t1r3s3 Tactic: -2899647483672319239
[03/24/2023-12:56:35] [V] [TRT] Tactic: -2899647483672319239 Time: 0.172032
[03/24/2023-12:56:35] [V] [TRT] Conv_15 + Relu_16 Set Tactic Name: ampere_h16816cudnn_256x64_sliced1x2_ldg8_relu_exp_large_nhwc_tn_v1 Tactic: -2816084650627734155
[03/24/2023-12:56:35] [V] [TRT] Tactic: -2816084650627734155 Time: 0.152448
[03/24/2023-12:56:35] [V] [TRT] Conv_15 + Relu_16 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x128x32_stage5_warpsize2x2x1_g1_tensor16x8x16 Tactic: -2662892962457732243
[03/24/2023-12:56:35] [V] [TRT] Tactic: -2662892962457732243 Time: 0.110592
[03/24/2023-12:56:35] [V] [TRT] Conv_15 + Relu_16 Set Tactic Name: ampere_h16816cudnn_256x128_ldg8_relu_exp_large_nhwc_tn_v1 Tactic: -2559894581585337900
[03/24/2023-12:56:35] [V] [TRT] Tactic: -2559894581585337900 Time: 0.133504
[03/24/2023-12:56:35] [V] [TRT] Conv_15 + Relu_16 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x32x32_stage4_warpsize4x1x1_g1_tensor16x8x16 Tactic: -2530740716768816092
[03/24/2023-12:56:35] [V] [TRT] Tactic: -2530740716768816092 Time: 0.148736
[03/24/2023-12:56:35] [V] [TRT] Conv_15 + Relu_16 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x128x32_stage4_warpsize2x2x1_g1_tensor16x8x16 Tactic: -2332828394978346992
[03/24/2023-12:56:35] [V] [TRT] Tactic: -2332828394978346992 Time: 0.098304
[03/24/2023-12:56:35] [V] [TRT] Conv_15 + Relu_16 Set Tactic Name: ampere_h1688cudnn_256x64_ldg8_relu_exp_large_nhwc_tn_v1 Tactic: -2241736083352441442
[03/24/2023-12:56:35] [V] [TRT] Tactic: -2241736083352441442 Time: 0.202752
[03/24/2023-12:56:35] [V] [TRT] Conv_15 + Relu_16 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x32x64_stage5_warpsize2x2x1_g1_tensor16x8x16 Tactic: -2161909437867201546
[03/24/2023-12:56:35] [V] [TRT] Tactic: -2161909437867201546 Time: 0.20352
[03/24/2023-12:56:35] [V] [TRT] Conv_15 + Relu_16 Set Tactic Name: ampere_h16816cudnn_256x64_ldg8_relu_exp_medium_nhwc_tn_v1 Tactic: -1985778916402815946
[03/24/2023-12:56:35] [V] [TRT] Tactic: -1985778916402815946 Time: 0.131072
[03/24/2023-12:56:35] [V] [TRT] Conv_15 + Relu_16 Set Tactic Name: sm75_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x256x32_stage1_warpsize2x4x1_g1_tensor16x8x8 Tactic: -1708101578041178688
[03/24/2023-12:56:35] [V] [TRT] Tactic: -1708101578041178688 Time: 0.231168
[03/24/2023-12:56:35] [V] [TRT] Conv_15 + Relu_16 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x64x64_stage3_warpsize4x1x1_g1_tensor16x8x16 Tactic: -1502788097503482299
[03/24/2023-12:56:35] [V] [TRT] Tactic: -1502788097503482299 Time: 0.115584
[03/24/2023-12:56:35] [V] [TRT] Conv_15 + Relu_16 Set Tactic Name: ampere_h16816cudnn_128x64_sliced1x2_ldg8_relu_exp_stages_64x4_large_nhwc_tn_v1 Tactic: -1500496213132463076
[03/24/2023-12:56:35] [V] [TRT] Tactic: -1500496213132463076 Time: 0.113792
[03/24/2023-12:56:35] [V] [TRT] Conv_15 + Relu_16 Set Tactic Name: ampere_h16816cudnn_64x64_ldg8_relu_exp_stages_64x6_small_nhwc_tn_v1 Tactic: -1099247066487349374
[03/24/2023-12:56:35] [V] [TRT] Tactic: -1099247066487349374 Time: 0.149376
[03/24/2023-12:56:35] [V] [TRT] Conv_15 + Relu_16 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x64x64_stage4_warpsize2x2x1_g1_tensor16x8x16 Tactic: -910286698936744682
[03/24/2023-12:56:35] [V] [TRT] Tactic: -910286698936744682 Time: 0.141568
[03/24/2023-12:56:35] [V] [TRT] Conv_15 + Relu_16 Set Tactic Name: sm75_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x256x32_stage1_warpsize2x4x1_g1_tensor16x8x8 Tactic: -907287437357565279
[03/24/2023-12:56:35] [V] [TRT] Tactic: -907287437357565279 Time: 0.225024
[03/24/2023-12:56:35] [V] [TRT] Conv_15 + Relu_16 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x32x32_stage4_warpsize4x1x1_g1_tensor16x8x16 Tactic: -606726295133751039
[03/24/2023-12:56:35] [V] [TRT] Tactic: -606726295133751039 Time: 0.166912
[03/24/2023-12:56:35] [V] [TRT] Fastest Tactic: 6972489290272968208 Time: 0.096768
[03/24/2023-12:56:35] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: 6972489290272968208
[03/24/2023-12:56:35] [V] [TRT] *************** Autotuning format combination: Half(518400,1:16,2880,16) -> Half(259200,1:16,1440,8) ***************
[03/24/2023-12:56:35] [V] [TRT] --------------- Timing Runner: Conv_15 + Relu_16 (CudnnConvolution)
[03/24/2023-12:56:35] [V] [TRT] CudnnConvolution has no valid tactics for this config, skipping
[03/24/2023-12:56:35] [V] [TRT] --------------- Timing Runner: Conv_15 + Relu_16 (CaskConvolution)
[03/24/2023-12:56:35] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[03/24/2023-12:56:35] [V] [TRT] =============== Computing costs for 
[03/24/2023-12:56:35] [V] [TRT] *************** Autotuning format combination: Float(4147200,32400,180,1) -> Float(4147200,32400,180,1) ***************
[03/24/2023-12:56:35] [V] [TRT] --------------- Timing Runner: Conv_17 + Relu_18 (CudaDepthwiseConvolution)
[03/24/2023-12:56:35] [V] [TRT] CudaDepthwiseConvolution has no valid tactics for this config, skipping
[03/24/2023-12:56:35] [V] [TRT] --------------- Timing Runner: Conv_17 + Relu_18 (FusedConvActConvolution)
[03/24/2023-12:56:35] [V] [TRT] Tactic: 524287 Time: 0.620544
[03/24/2023-12:56:35] [V] [TRT] Tactic: 720895 Time: 0.595968
[03/24/2023-12:56:35] [V] [TRT] Tactic: 983039 Time: 0.574976
[03/24/2023-12:56:35] [V] [TRT] Tactic: 1048575 Time: 0.633728
[03/24/2023-12:56:35] [V] [TRT] Tactic: 1703935 Time: 0.604288
[03/24/2023-12:56:35] [V] [TRT] Tactic: 1769471 Time: 0.7072
[03/24/2023-12:56:35] [V] [TRT] Tactic: 1966079 Time: 0.66432
[03/24/2023-12:56:35] [V] [TRT] Tactic: 2031615 Time: 0.627712
[03/24/2023-12:56:35] [V] [TRT] Tactic: 2228223 Time: 0.638208
[03/24/2023-12:56:35] [V] [TRT] Tactic: 2424831 Time: 0.702592
[03/24/2023-12:56:35] [V] [TRT] Tactic: 2621439 Time: 0.614528
[03/24/2023-12:56:36] [V] [TRT] Tactic: 2752511 Time: 0.61952
[03/24/2023-12:56:36] [V] [TRT] Tactic: 2818047 Time: 0.62592
[03/24/2023-12:56:36] [V] [TRT] Tactic: 2883583 Time: 0.681472
[03/24/2023-12:56:36] [V] [TRT] Tactic: 3014655 Time: 0.628608
[03/24/2023-12:56:36] [V] [TRT] Tactic: 3145727 Time: 0.597376
[03/24/2023-12:56:36] [V] [TRT] Tactic: 3473407 Time: 0.631424
[03/24/2023-12:56:36] [V] [TRT] Tactic: 3604479 Time: 0.617344
[03/24/2023-12:56:36] [V] [TRT] Tactic: 3735551 Time: 0.632064
[03/24/2023-12:56:36] [V] [TRT] Tactic: 4390911 Time: 0.727424
[03/24/2023-12:56:36] [V] [TRT] Tactic: 5046271 Time: 0.598272
[03/24/2023-12:56:36] [V] [TRT] Tactic: 5963775 Time: 0.682624
[03/24/2023-12:56:36] [V] [TRT] Tactic: 6160383 Time: 0.626432
[03/24/2023-12:56:36] [V] [TRT] Tactic: 6488063 Time: 0.619264
[03/24/2023-12:56:36] [V] [TRT] Tactic: 6881279 Time: 0.671744
[03/24/2023-12:56:36] [V] [TRT] Tactic: 7274495 Time: 0.63104
[03/24/2023-12:56:36] [V] [TRT] Tactic: 7864319 Time: 0.609792
[03/24/2023-12:56:36] [V] [TRT] Tactic: 7995391 Time: 0.617728
[03/24/2023-12:56:36] [V] [TRT] Tactic: 8585215 Time: 0.638208
[03/24/2023-12:56:36] [V] [TRT] Tactic: 8847359 Time: 0.619264
[03/24/2023-12:56:36] [V] [TRT] Tactic: 8978431 Time: 0.684032
[03/24/2023-12:56:36] [V] [TRT] Tactic: 9043967 Time: 0.60224
[03/24/2023-12:56:36] [V] [TRT] Tactic: 9175039 Time: 0.617728
[03/24/2023-12:56:36] [V] [TRT] Tactic: 9502719 Time: 0.727424
[03/24/2023-12:56:36] [V] [TRT] Tactic: 9830399 Time: 0.648832
[03/24/2023-12:56:36] [V] [TRT] Tactic: 9961471 Time: 0.704256
[03/24/2023-12:56:37] [V] [TRT] Tactic: 10027007 Time: 0.603648
[03/24/2023-12:56:37] [V] [TRT] Tactic: 10092543 Time: 0.727936
[03/24/2023-12:56:37] [V] [TRT] Tactic: 10289151 Time: 0.664704
[03/24/2023-12:56:37] [V] [TRT] Tactic: 10485759 Time: 0.5824
[03/24/2023-12:56:37] [V] [TRT] Tactic: 10682367 Time: 0.609152
[03/24/2023-12:56:37] [V] [TRT] Tactic: 10813439 Time: 0.591616
[03/24/2023-12:56:37] [V] [TRT] Fastest Tactic: 983039 Time: 0.574976
[03/24/2023-12:56:37] [V] [TRT] --------------- Timing Runner: Conv_17 + Relu_18 (CudnnConvolution)
[03/24/2023-12:56:37] [V] [TRT] Tactic: 0 Time: 0.815232
[03/24/2023-12:56:37] [V] [TRT] Tactic: 1 Time: 0.17856
[03/24/2023-12:56:37] [V] [TRT] Tactic: 2 Time: 0.926592
[03/24/2023-12:56:37] [V] [TRT] Tactic: 4 skipped. Scratch requested: 8725266432, available: 4294967296
[03/24/2023-12:56:37] [V] [TRT] Tactic: 5 Time: 2.45453
[03/24/2023-12:56:37] [V] [TRT] Tactic: 6 Time: 0.357376
[03/24/2023-12:56:37] [V] [TRT] Tactic: 56 Time: 0.815872
[03/24/2023-12:56:37] [V] [TRT] Tactic: 57 Time: 0.178176
[03/24/2023-12:56:37] [V] [TRT] Tactic: 58 Time: 0.924672
[03/24/2023-12:56:37] [V] [TRT] Tactic: 60 skipped. Scratch requested: 8725266432, available: 4294967296
[03/24/2023-12:56:37] [V] [TRT] Tactic: 61 Time: 2.4585
[03/24/2023-12:56:37] [V] [TRT] Tactic: 62 Time: 0.358016
[03/24/2023-12:56:37] [V] [TRT] Tactic: 112 Time: 0.815616
[03/24/2023-12:56:37] [V] [TRT] Tactic: 113 Time: 0.614656
[03/24/2023-12:56:37] [V] [TRT] Tactic: 114 Time: 0.9248
[03/24/2023-12:56:37] [V] [TRT] Tactic: 116 skipped. Scratch requested: 8725266432, available: 4294967296
[03/24/2023-12:56:37] [V] [TRT] Tactic: 117 Time: 2.45606
[03/24/2023-12:56:37] [V] [TRT] Tactic: 118 Time: 0.357376
[03/24/2023-12:56:37] [V] [TRT] Fastest Tactic: 57 Time: 0.178176
[03/24/2023-12:56:37] [V] [TRT] Setting workspace to 8725266432enables more tactics for profiling
[03/24/2023-12:56:37] [V] [TRT] --------------- Timing Runner: Conv_17 + Relu_18 (CaskConvolution)
[03/24/2023-12:56:37] [V] [TRT] Conv_17 + Relu_18 Set Tactic Name: ampere_scudnn_128x64_relu_small_nn_v1 Tactic: 4549827808004681195
[03/24/2023-12:56:37] [V] [TRT] Tactic: 4549827808004681195 Time: 0.577024
[03/24/2023-12:56:37] [V] [TRT] Conv_17 + Relu_18 Set Tactic Name: ampere_scudnn_128x128_relu_small_nn_v1 Tactic: 5779835512569528575
[03/24/2023-12:56:37] [V] [TRT] Tactic: 5779835512569528575 Time: 0.656896
[03/24/2023-12:56:37] [V] [TRT] Conv_17 + Relu_18 Set Tactic Name: ampere_scudnn_128x128_relu_xregs_large_nn_v1 Tactic: 6053873026024413720
[03/24/2023-12:56:37] [V] [TRT] Tactic: 6053873026024413720 Time: 0.686336
[03/24/2023-12:56:37] [V] [TRT] Conv_17 + Relu_18 Set Tactic Name: ampere_scudnn_128x64_relu_xregs_large_nn_v1 Tactic: 6767548733843469815
[03/24/2023-12:56:37] [V] [TRT] Tactic: 6767548733843469815 Time: 0.5696
[03/24/2023-12:56:37] [V] [TRT] Conv_17 + Relu_18 Set Tactic Name: ampere_scudnn_128x32_relu_small_nn_v1 Tactic: -6313876406580483184
[03/24/2023-12:56:37] [V] [TRT] Tactic: -6313876406580483184 Time: 0.627968
[03/24/2023-12:56:37] [V] [TRT] Conv_17 + Relu_18 Set Tactic Name: ampere_scudnn_128x128_relu_medium_nn_v1 Tactic: -1123676555321336786
[03/24/2023-12:56:37] [V] [TRT] Tactic: -1123676555321336786 Time: 0.65728
[03/24/2023-12:56:37] [V] [TRT] Conv_17 + Relu_18 Set Tactic Name: ampere_scudnn_128x64_relu_medium_nn_v1 Tactic: -701551393537224327
[03/24/2023-12:56:37] [V] [TRT] Tactic: -701551393537224327 Time: 0.583168
[03/24/2023-12:56:37] [V] [TRT] Fastest Tactic: 6767548733843469815 Time: 0.5696
[03/24/2023-12:56:37] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CudnnConvolution Tactic: 57
[03/24/2023-12:56:37] [V] [TRT] *************** Autotuning format combination: Float(4147200,1,23040,128) -> Float(4147200,1,23040,128) ***************
[03/24/2023-12:56:37] [V] [TRT] --------------- Timing Runner: Conv_17 + Relu_18 (CudnnConvolution)
[03/24/2023-12:56:37] [V] [TRT] CudnnConvolution has no valid tactics for this config, skipping
[03/24/2023-12:56:37] [V] [TRT] --------------- Timing Runner: Conv_17 + Relu_18 (CaskConvolution)
[03/24/2023-12:56:37] [V] [TRT] Conv_17 + Relu_18 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize64x128x8_stage3_warpsize1x4x1_g1_ffma_t1r3s3 Tactic: 2086609538387166260
[03/24/2023-12:56:37] [V] [TRT] Tactic: 2086609538387166260 Time: 0.549888
[03/24/2023-12:56:37] [V] [TRT] Conv_17 + Relu_18 Set Tactic Name: ampere_scudnn_128x64_sliced1x2_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: 2860655430572478466
[03/24/2023-12:56:37] [V] [TRT] Tactic: 2860655430572478466 Time: 0.562048
[03/24/2023-12:56:37] [V] [TRT] Conv_17 + Relu_18 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize64x128x8_stage3_warpsize1x4x1_g1_ffma Tactic: 3239733199291090177
[03/24/2023-12:56:37] [V] [TRT] Tactic: 3239733199291090177 Time: 0.548352
[03/24/2023-12:56:37] [V] [TRT] Conv_17 + Relu_18 Set Tactic Name: ampere_scudnn_128x32_sliced1x4_ldg4_relu_exp_medium_nhwc_tn_v1 Tactic: 4474630279712975759
[03/24/2023-12:56:37] [V] [TRT] Tactic: 4474630279712975759 Time: 0.569856
[03/24/2023-12:56:37] [V] [TRT] Conv_17 + Relu_18 Set Tactic Name: ampere_scudnn_128x32_sliced1x4_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: 4479823862704990365
[03/24/2023-12:56:37] [V] [TRT] Tactic: 4479823862704990365 Time: 0.566016
[03/24/2023-12:56:37] [V] [TRT] Conv_17 + Relu_18 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize64x256x8_stage3_warpsize1x4x1_g1_ffma Tactic: 4517590677127196184
[03/24/2023-12:56:37] [V] [TRT] Tactic: 4517590677127196184 Time: 1.3312
[03/24/2023-12:56:37] [V] [TRT] Conv_17 + Relu_18 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize128x128x8_stage3_warpsize2x4x1_g1_ffma_t1r3s3 Tactic: 4634080872644479428
[03/24/2023-12:56:37] [V] [TRT] Tactic: 4634080872644479428 Time: 0.663936
[03/24/2023-12:56:37] [V] [TRT] Conv_17 + Relu_18 Set Tactic Name: ampere_scudnn_128x64_sliced1x2_ldg4_relu_exp_medium_nhwc_tn_v1 Tactic: 4696204239951173149
[03/24/2023-12:56:37] [V] [TRT] Tactic: 4696204239951173149 Time: 0.56192
[03/24/2023-12:56:37] [V] [TRT] Conv_17 + Relu_18 Set Tactic Name: ampere_scudnn_128x128_relu_exp_small_nhwc_tn_v1 Tactic: 5778138195697110003
[03/24/2023-12:56:37] [V] [TRT] Tactic: 5778138195697110003 Time: 0.654464
[03/24/2023-12:56:37] [V] [TRT] Conv_17 + Relu_18 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize256x128x8_stage3_warpsize2x4x1_g1_ffma Tactic: 6310198979346901507
[03/24/2023-12:56:37] [V] [TRT] Tactic: 6310198979346901507 Time: 0.915072
[03/24/2023-12:56:37] [V] [TRT] Conv_17 + Relu_18 Set Tactic Name: ampere_scudnn_128x128_ldg4_relu_exp_large_nhwc_tn_v1 Tactic: 7155825427510256858
[03/24/2023-12:56:37] [V] [TRT] Tactic: 7155825427510256858 Time: 0.660096
[03/24/2023-12:56:37] [V] [TRT] Conv_17 + Relu_18 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize128x64x8_stage3_warpsize1x4x1_g1_ffma Tactic: 7222247112373541608
[03/24/2023-12:56:37] [V] [TRT] Tactic: 7222247112373541608 Time: 0.694144
[03/24/2023-12:56:37] [V] [TRT] Conv_17 + Relu_18 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize128x128x8_stage3_warpsize2x4x1_g1_ffma Tactic: 7472640475524677095
[03/24/2023-12:56:37] [V] [TRT] Tactic: 7472640475524677095 Time: 0.675712
[03/24/2023-12:56:37] [V] [TRT] Conv_17 + Relu_18 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize128x256x8_stage3_warpsize2x4x1_g1_ffma Tactic: 8498373915030836990
[03/24/2023-12:56:38] [V] [TRT] Tactic: 8498373915030836990 Time: 1.32531
[03/24/2023-12:56:38] [V] [TRT] Conv_17 + Relu_18 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize256x64x8_stage3_warpsize1x4x1_g1_ffma Tactic: 8869697132622550639
[03/24/2023-12:56:38] [V] [TRT] Tactic: 8869697132622550639 Time: 1.01248
[03/24/2023-12:56:38] [V] [TRT] Conv_17 + Relu_18 Set Tactic Name: ampere_scudnn_128x128_ldg4_relu_exp_medium_nhwc_tn_v1 Tactic: 8918020581761223752
[03/24/2023-12:56:38] [V] [TRT] Tactic: 8918020581761223752 Time: 0.653056
[03/24/2023-12:56:38] [V] [TRT] Conv_17 + Relu_18 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize256x128x8_stage3_warpsize2x4x1_g1_ffma_t1r3s3 Tactic: -8937725997228636978
[03/24/2023-12:56:38] [V] [TRT] Tactic: -8937725997228636978 Time: 0.87936
[03/24/2023-12:56:38] [V] [TRT] Conv_17 + Relu_18 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize128x256x8_stage3_warpsize2x4x1_g1_ffma_t1r3s3 Tactic: -8833858409138163072
[03/24/2023-12:56:38] [V] [TRT] Tactic: -8833858409138163072 Time: 1.29971
[03/24/2023-12:56:38] [V] [TRT] Conv_17 + Relu_18 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize64x64x8_stage3_warpsize1x4x1_g1_ffma_t1r3s3 Tactic: -7989138351613022500
[03/24/2023-12:56:38] [V] [TRT] Tactic: -7989138351613022500 Time: 0.554112
[03/24/2023-12:56:38] [V] [TRT] Conv_17 + Relu_18 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize256x128x8_stage3_warpsize2x4x1_g1_ffma Tactic: -7872883691240863058
[03/24/2023-12:56:38] [V] [TRT] Tactic: -7872883691240863058 Time: 0.913792
[03/24/2023-12:56:38] [V] [TRT] Conv_17 + Relu_18 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize128x128x8_stage3_warpsize2x4x1_g1_ffma Tactic: -6729618519651721910
[03/24/2023-12:56:38] [V] [TRT] Tactic: -6729618519651721910 Time: 0.668288
[03/24/2023-12:56:38] [V] [TRT] Conv_17 + Relu_18 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize256x64x8_stage3_warpsize1x4x1_g1_ffma Tactic: -5893833996418445881
[03/24/2023-12:56:38] [V] [TRT] Tactic: -5893833996418445881 Time: 0.987648
[03/24/2023-12:56:38] [V] [TRT] Conv_17 + Relu_18 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize128x256x8_stage3_warpsize2x4x1_g1_ffma Tactic: -5701562095007058349
[03/24/2023-12:56:38] [V] [TRT] Tactic: -5701562095007058349 Time: 1.30765
[03/24/2023-12:56:38] [V] [TRT] Conv_17 + Relu_18 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize128x64x8_stage3_warpsize1x4x1_g1_ffma Tactic: -5685503422376017600
[03/24/2023-12:56:38] [V] [TRT] Tactic: -5685503422376017600 Time: 0.670592
[03/24/2023-12:56:38] [V] [TRT] Conv_17 + Relu_18 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize64x64x8_stage3_warpsize1x4x1_g1_ffma Tactic: -5521125187060117489
[03/24/2023-12:56:38] [V] [TRT] Tactic: -5521125187060117489 Time: 0.601472
[03/24/2023-12:56:38] [V] [TRT] Conv_17 + Relu_18 Set Tactic Name: ampere_scudnn_128x64_sliced1x2_ldg4_relu_exp_large_nhwc_tn_v1 Tactic: -4756382386362004279
[03/24/2023-12:56:38] [V] [TRT] Tactic: -4756382386362004279 Time: 0.554496
[03/24/2023-12:56:38] [V] [TRT] Conv_17 + Relu_18 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize64x64x8_stage3_warpsize1x4x1_g1_ffma Tactic: -4615000974950361663
[03/24/2023-12:56:38] [V] [TRT] Tactic: -4615000974950361663 Time: 0.574592
[03/24/2023-12:56:38] [V] [TRT] Conv_17 + Relu_18 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize256x64x8_stage3_warpsize1x4x1_g1_ffma_t1r3s3 Tactic: -4314913710375142296
[03/24/2023-12:56:38] [V] [TRT] Tactic: -4314913710375142296 Time: 0.950528
[03/24/2023-12:56:38] [V] [TRT] Conv_17 + Relu_18 Set Tactic Name: ampere_scudnn_128x128_relu_exp_large_nhwc_tn_v1 Tactic: -3855385237722507464
[03/24/2023-12:56:38] [V] [TRT] Tactic: -3855385237722507464 Time: 0.658432
[03/24/2023-12:56:38] [V] [TRT] Conv_17 + Relu_18 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize128x64x8_stage3_warpsize1x4x1_g1_ffma_t1r3s3 Tactic: -3697587361057948972
[03/24/2023-12:56:38] [V] [TRT] Tactic: -3697587361057948972 Time: 0.673792
[03/24/2023-12:56:38] [V] [TRT] Conv_17 + Relu_18 Set Tactic Name: ampere_scudnn_128x128_relu_exp_medium_nhwc_tn_v1 Tactic: -2809379259463049391
[03/24/2023-12:56:38] [V] [TRT] Tactic: -2809379259463049391 Time: 0.658432
[03/24/2023-12:56:38] [V] [TRT] Conv_17 + Relu_18 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize64x256x8_stage3_warpsize1x4x1_g1_ffma_t1r3s3 Tactic: -2747929399988666512
[03/24/2023-12:56:38] [V] [TRT] Tactic: -2747929399988666512 Time: 1.29805
[03/24/2023-12:56:38] [V] [TRT] Conv_17 + Relu_18 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize64x256x8_stage3_warpsize1x4x1_g1_ffma Tactic: -1472061967969061456
[03/24/2023-12:56:38] [V] [TRT] Tactic: -1472061967969061456 Time: 1.32864
[03/24/2023-12:56:38] [V] [TRT] Conv_17 + Relu_18 Set Tactic Name: ampere_scudnn_128x128_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: -504296718212024303
[03/24/2023-12:56:38] [V] [TRT] Tactic: -504296718212024303 Time: 0.652032
[03/24/2023-12:56:38] [V] [TRT] Conv_17 + Relu_18 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize64x128x8_stage3_warpsize1x4x1_g1_ffma Tactic: -444093195553988951
[03/24/2023-12:56:38] [V] [TRT] Tactic: -444093195553988951 Time: 0.575872
[03/24/2023-12:56:38] [V] [TRT] Fastest Tactic: 3239733199291090177 Time: 0.548352
[03/24/2023-12:56:38] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: 3239733199291090177
[03/24/2023-12:56:38] [V] [TRT] *************** Autotuning format combination: Float(1036800,1:4,5760,32) -> Float(1036800,1:4,5760,32) ***************
[03/24/2023-12:56:38] [V] [TRT] --------------- Timing Runner: Conv_17 + Relu_18 (CudnnConvolution)
[03/24/2023-12:56:38] [V] [TRT] CudnnConvolution has no valid tactics for this config, skipping
[03/24/2023-12:56:38] [V] [TRT] --------------- Timing Runner: Conv_17 + Relu_18 (CaskConvolution)
[03/24/2023-12:56:38] [V] [TRT] Conv_17 + Relu_18 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize64x128x32_stage5_warpsize2x2x1_g1_tensor16x8x8 Tactic: 1237784342446422381
[03/24/2023-12:56:38] [V] [TRT] Tactic: 1237784342446422381 Time: 0.139648
[03/24/2023-12:56:38] [V] [TRT] Conv_17 + Relu_18 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x64x32_stage5_warpsize2x2x1_g1_tensor16x8x8 Tactic: 1426562292875733922
[03/24/2023-12:56:38] [V] [TRT] Tactic: 1426562292875733922 Time: 0.146304
[03/24/2023-12:56:38] [V] [TRT] Conv_17 + Relu_18 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize64x128x8_stage3_warpsize1x4x1_g1_ffma_t1r3s3 Tactic: 2086609538387166260
[03/24/2023-12:56:38] [V] [TRT] Tactic: 2086609538387166260 Time: 0.549888
[03/24/2023-12:56:38] [V] [TRT] Conv_17 + Relu_18 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize256x128x32_stage3_warpsize4x2x1_g1_tensor16x8x8_t1r3s3 Tactic: 2388153022056233219
[03/24/2023-12:56:38] [V] [TRT] Tactic: 2388153022056233219 Time: 0.143616
[03/24/2023-12:56:38] [V] [TRT] Conv_17 + Relu_18 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x128x32_stage4_warpsize2x2x1_g1_tensor16x8x8 Tactic: 2716437853123234317
[03/24/2023-12:56:38] [V] [TRT] Tactic: 2716437853123234317 Time: 0.1184
[03/24/2023-12:56:38] [V] [TRT] Conv_17 + Relu_18 Set Tactic Name: ampere_scudnn_128x64_sliced1x2_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: 2860655430572478466
[03/24/2023-12:56:38] [V] [TRT] Tactic: 2860655430572478466 Time: 0.562048
[03/24/2023-12:56:38] [V] [TRT] Conv_17 + Relu_18 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize64x128x8_stage3_warpsize1x4x1_g1_ffma Tactic: 3239733199291090177
[03/24/2023-12:56:38] [V] [TRT] Tactic: 3239733199291090177 Time: 0.54784
[03/24/2023-12:56:38] [V] [TRT] Conv_17 + Relu_18 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize64x64x64_stage4_warpsize2x2x1_g1_tensor16x8x8_t1r3s3 Tactic: 3278852197192504305
[03/24/2023-12:56:38] [V] [TRT] Tactic: 3278852197192504305 Time: 0.172416
[03/24/2023-12:56:38] [V] [TRT] Conv_17 + Relu_18 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize256x128x32_stage3_warpsize4x2x1_g1_tensor16x8x8 Tactic: 3904690393614050557
[03/24/2023-12:56:38] [V] [TRT] Tactic: 3904690393614050557 Time: 0.180224
[03/24/2023-12:56:38] [V] [TRT] Conv_17 + Relu_18 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize64x64x64_stage4_warpsize2x2x1_g1_tensor16x8x8 Tactic: 4061115162338989075
[03/24/2023-12:56:38] [V] [TRT] Tactic: 4061115162338989075 Time: 0.182912
[03/24/2023-12:56:38] [V] [TRT] Conv_17 + Relu_18 Set Tactic Name: ampere_scudnn_128x32_sliced1x4_ldg4_relu_exp_medium_nhwc_tn_v1 Tactic: 4474630279712975759
[03/24/2023-12:56:38] [V] [TRT] Tactic: 4474630279712975759 Time: 0.569856
[03/24/2023-12:56:38] [V] [TRT] Conv_17 + Relu_18 Set Tactic Name: ampere_scudnn_128x32_sliced1x4_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: 4479823862704990365
[03/24/2023-12:56:38] [V] [TRT] Tactic: 4479823862704990365 Time: 0.5664
[03/24/2023-12:56:38] [V] [TRT] Conv_17 + Relu_18 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize64x256x8_stage3_warpsize1x4x1_g1_ffma Tactic: 4517590677127196184
[03/24/2023-12:56:38] [V] [TRT] Tactic: 4517590677127196184 Time: 1.33082
[03/24/2023-12:56:38] [V] [TRT] Conv_17 + Relu_18 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize128x128x8_stage3_warpsize2x4x1_g1_ffma_t1r3s3 Tactic: 4634080872644479428
[03/24/2023-12:56:38] [V] [TRT] Tactic: 4634080872644479428 Time: 0.662912
[03/24/2023-12:56:38] [V] [TRT] Conv_17 + Relu_18 Set Tactic Name: ampere_scudnn_128x64_sliced1x2_ldg4_relu_exp_medium_nhwc_tn_v1 Tactic: 4696204239951173149
[03/24/2023-12:56:38] [V] [TRT] Tactic: 4696204239951173149 Time: 0.56192
[03/24/2023-12:56:38] [V] [TRT] Conv_17 + Relu_18 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x256x32_stage3_warpsize2x4x1_g1_tensor16x8x8 Tactic: 5200329514761435342
[03/24/2023-12:56:38] [V] [TRT] Tactic: 5200329514761435342 Time: 0.19776
[03/24/2023-12:56:38] [V] [TRT] Conv_17 + Relu_18 Set Tactic Name: ampere_scudnn_128x128_relu_exp_small_nhwc_tn_v1 Tactic: 5778138195697110003
[03/24/2023-12:56:38] [V] [TRT] Tactic: 5778138195697110003 Time: 0.654336
[03/24/2023-12:56:38] [V] [TRT] Conv_17 + Relu_18 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize256x128x8_stage3_warpsize2x4x1_g1_ffma Tactic: 6310198979346901507
[03/24/2023-12:56:38] [V] [TRT] Tactic: 6310198979346901507 Time: 0.915072
[03/24/2023-12:56:38] [V] [TRT] Conv_17 + Relu_18 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x256x32_stage3_warpsize2x4x1_g1_tensor16x8x8_t1r3s3 Tactic: 7011693366046809027
[03/24/2023-12:56:38] [V] [TRT] Tactic: 7011693366046809027 Time: 0.19328
[03/24/2023-12:56:38] [V] [TRT] Conv_17 + Relu_18 Set Tactic Name: ampere_scudnn_128x128_ldg4_relu_exp_large_nhwc_tn_v1 Tactic: 7155825427510256858
[03/24/2023-12:56:38] [V] [TRT] Tactic: 7155825427510256858 Time: 0.65984
[03/24/2023-12:56:38] [V] [TRT] Conv_17 + Relu_18 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize128x64x8_stage3_warpsize1x4x1_g1_ffma Tactic: 7222247112373541608
[03/24/2023-12:56:38] [V] [TRT] Tactic: 7222247112373541608 Time: 0.692992
[03/24/2023-12:56:38] [V] [TRT] Conv_17 + Relu_18 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x128x16_stage4_warpsize2x2x1_g1_tensor16x8x8 Tactic: 7342025736444949634
[03/24/2023-12:56:38] [V] [TRT] Tactic: 7342025736444949634 Time: 0.13696
[03/24/2023-12:56:38] [V] [TRT] Conv_17 + Relu_18 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize64x128x32_stage5_warpsize2x2x1_g1_tensor16x8x8 Tactic: 7347365539922924600
[03/24/2023-12:56:38] [V] [TRT] Tactic: 7347365539922924600 Time: 0.129024
[03/24/2023-12:56:38] [V] [TRT] Conv_17 + Relu_18 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x64x32_stage5_warpsize2x2x1_g1_tensor16x8x8 Tactic: 7428197830878119671
[03/24/2023-12:56:38] [V] [TRT] Tactic: 7428197830878119671 Time: 0.135424
[03/24/2023-12:56:38] [V] [TRT] Conv_17 + Relu_18 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize64x32x64_stage5_warpsize2x2x1_g1_tensor16x8x8_t1r3s3 Tactic: 7465323447915168822
[03/24/2023-12:56:38] [V] [TRT] Tactic: 7465323447915168822 Time: 0.241536
[03/24/2023-12:56:38] [V] [TRT] Conv_17 + Relu_18 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize128x128x8_stage3_warpsize2x4x1_g1_ffma Tactic: 7472640475524677095
[03/24/2023-12:56:38] [V] [TRT] Tactic: 7472640475524677095 Time: 0.675712
[03/24/2023-12:56:38] [V] [TRT] Conv_17 + Relu_18 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize64x32x64_stage5_warpsize2x2x1_g1_tensor16x8x8 Tactic: 7938223790021272801
[03/24/2023-12:56:38] [V] [TRT] Tactic: 7938223790021272801 Time: 0.255488
[03/24/2023-12:56:38] [V] [TRT] Conv_17 + Relu_18 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize128x256x8_stage3_warpsize2x4x1_g1_ffma Tactic: 8498373915030836990
[03/24/2023-12:56:38] [V] [TRT] Tactic: 8498373915030836990 Time: 1.32595
[03/24/2023-12:56:38] [V] [TRT] Conv_17 + Relu_18 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x64x32_stage5_warpsize2x2x1_g1_tensor16x8x8_t1r3s3 Tactic: 8836645772682419994
[03/24/2023-12:56:38] [V] [TRT] Tactic: 8836645772682419994 Time: 0.129536
[03/24/2023-12:56:38] [V] [TRT] Conv_17 + Relu_18 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize256x64x8_stage3_warpsize1x4x1_g1_ffma Tactic: 8869697132622550639
[03/24/2023-12:56:38] [V] [TRT] Tactic: 8869697132622550639 Time: 1.01299
[03/24/2023-12:56:38] [V] [TRT] Conv_17 + Relu_18 Set Tactic Name: ampere_scudnn_128x128_ldg4_relu_exp_medium_nhwc_tn_v1 Tactic: 8918020581761223752
[03/24/2023-12:56:38] [V] [TRT] Tactic: 8918020581761223752 Time: 0.652928
[03/24/2023-12:56:38] [V] [TRT] Conv_17 + Relu_18 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize64x64x64_stage4_warpsize2x2x1_g1_tensor16x8x8 Tactic: -9114138070928278731
[03/24/2023-12:56:38] [V] [TRT] Tactic: -9114138070928278731 Time: 0.180224
[03/24/2023-12:56:38] [V] [TRT] Conv_17 + Relu_18 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize256x128x8_stage3_warpsize2x4x1_g1_ffma_t1r3s3 Tactic: -8937725997228636978
[03/24/2023-12:56:38] [V] [TRT] Tactic: -8937725997228636978 Time: 0.88064
[03/24/2023-12:56:38] [V] [TRT] Conv_17 + Relu_18 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize128x256x8_stage3_warpsize2x4x1_g1_ffma_t1r3s3 Tactic: -8833858409138163072
[03/24/2023-12:56:38] [V] [TRT] Tactic: -8833858409138163072 Time: 1.30202
[03/24/2023-12:56:38] [V] [TRT] Conv_17 + Relu_18 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize64x64x8_stage3_warpsize1x4x1_g1_ffma_t1r3s3 Tactic: -7989138351613022500
[03/24/2023-12:56:38] [V] [TRT] Tactic: -7989138351613022500 Time: 0.553856
[03/24/2023-12:56:38] [V] [TRT] Conv_17 + Relu_18 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize256x128x8_stage3_warpsize2x4x1_g1_ffma Tactic: -7872883691240863058
[03/24/2023-12:56:38] [V] [TRT] Tactic: -7872883691240863058 Time: 0.912256
[03/24/2023-12:56:38] [V] [TRT] Conv_17 + Relu_18 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x256x32_stage3_warpsize2x4x1_g1_tensor16x8x8 Tactic: -7382359095196034537
[03/24/2023-12:56:38] [V] [TRT] Tactic: -7382359095196034537 Time: 0.200704
[03/24/2023-12:56:38] [V] [TRT] Conv_17 + Relu_18 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x128x16_stage4_warpsize2x2x1_g1_tensor16x8x8_t1r3s3 Tactic: -7377458734869418330
[03/24/2023-12:56:39] [V] [TRT] Tactic: -7377458734869418330 Time: 0.125184
[03/24/2023-12:56:39] [V] [TRT] Conv_17 + Relu_18 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize128x128x8_stage3_warpsize2x4x1_g1_ffma Tactic: -6729618519651721910
[03/24/2023-12:56:39] [V] [TRT] Tactic: -6729618519651721910 Time: 0.667648
[03/24/2023-12:56:39] [V] [TRT] Conv_17 + Relu_18 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize256x64x32_stage3_warpsize4x2x1_g1_tensor16x8x8_t1r3s3 Tactic: -6223854811627385844
[03/24/2023-12:56:39] [V] [TRT] Tactic: -6223854811627385844 Time: 0.12608
[03/24/2023-12:56:39] [V] [TRT] Conv_17 + Relu_18 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize256x64x8_stage3_warpsize1x4x1_g1_ffma Tactic: -5893833996418445881
[03/24/2023-12:56:39] [V] [TRT] Tactic: -5893833996418445881 Time: 0.984704
[03/24/2023-12:56:39] [V] [TRT] Conv_17 + Relu_18 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize128x256x8_stage3_warpsize2x4x1_g1_ffma Tactic: -5701562095007058349
[03/24/2023-12:56:39] [V] [TRT] Tactic: -5701562095007058349 Time: 1.30867
[03/24/2023-12:56:39] [V] [TRT] Conv_17 + Relu_18 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize128x64x8_stage3_warpsize1x4x1_g1_ffma Tactic: -5685503422376017600
[03/24/2023-12:56:39] [V] [TRT] Tactic: -5685503422376017600 Time: 0.670848
[03/24/2023-12:56:39] [V] [TRT] Conv_17 + Relu_18 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize64x64x8_stage3_warpsize1x4x1_g1_ffma Tactic: -5521125187060117489
[03/24/2023-12:56:39] [V] [TRT] Tactic: -5521125187060117489 Time: 0.601216
[03/24/2023-12:56:39] [V] [TRT] Conv_17 + Relu_18 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x128x16_stage4_warpsize2x2x1_g1_tensor16x8x8 Tactic: -5457304872213719461
[03/24/2023-12:56:39] [V] [TRT] Tactic: -5457304872213719461 Time: 0.12864
[03/24/2023-12:56:39] [V] [TRT] Conv_17 + Relu_18 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x64x64_stage3_warpsize2x2x1_g1_tensor16x8x8 Tactic: -5441054706931585554
[03/24/2023-12:56:39] [V] [TRT] Tactic: -5441054706931585554 Time: 0.145664
[03/24/2023-12:56:39] [V] [TRT] Conv_17 + Relu_18 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize256x64x32_stage3_warpsize4x2x1_g1_tensor16x8x8 Tactic: -5043603702497465467
[03/24/2023-12:56:39] [V] [TRT] Tactic: -5043603702497465467 Time: 0.151424
[03/24/2023-12:56:39] [V] [TRT] Conv_17 + Relu_18 Set Tactic Name: ampere_scudnn_128x64_sliced1x2_ldg4_relu_exp_large_nhwc_tn_v1 Tactic: -4756382386362004279
[03/24/2023-12:56:39] [V] [TRT] Tactic: -4756382386362004279 Time: 0.554368
[03/24/2023-12:56:39] [V] [TRT] Conv_17 + Relu_18 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize64x64x8_stage3_warpsize1x4x1_g1_ffma Tactic: -4615000974950361663
[03/24/2023-12:56:39] [V] [TRT] Tactic: -4615000974950361663 Time: 0.574592
[03/24/2023-12:56:39] [V] [TRT] Conv_17 + Relu_18 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x64x64_stage3_warpsize2x2x1_g1_tensor16x8x8 Tactic: -4564655677311401797
[03/24/2023-12:56:39] [V] [TRT] Tactic: -4564655677311401797 Time: 0.146944
[03/24/2023-12:56:39] [V] [TRT] Conv_17 + Relu_18 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize256x64x8_stage3_warpsize1x4x1_g1_ffma_t1r3s3 Tactic: -4314913710375142296
[03/24/2023-12:56:39] [V] [TRT] Tactic: -4314913710375142296 Time: 0.950272
[03/24/2023-12:56:39] [V] [TRT] Conv_17 + Relu_18 Set Tactic Name: ampere_scudnn_128x128_relu_exp_large_nhwc_tn_v1 Tactic: -3855385237722507464
[03/24/2023-12:56:39] [V] [TRT] Tactic: -3855385237722507464 Time: 0.658048
[03/24/2023-12:56:39] [V] [TRT] Conv_17 + Relu_18 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize128x64x8_stage3_warpsize1x4x1_g1_ffma_t1r3s3 Tactic: -3697587361057948972
[03/24/2023-12:56:39] [V] [TRT] Tactic: -3697587361057948972 Time: 0.672512
[03/24/2023-12:56:39] [V] [TRT] Conv_17 + Relu_18 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize256x64x32_stage3_warpsize4x2x1_g1_tensor16x8x8 Tactic: -3540975627865078064
[03/24/2023-12:56:39] [V] [TRT] Tactic: -3540975627865078064 Time: 0.133632
[03/24/2023-12:56:39] [V] [TRT] Conv_17 + Relu_18 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize64x128x32_stage5_warpsize2x2x1_g1_tensor16x8x8_t1r3s3 Tactic: -3151804561246216835
[03/24/2023-12:56:39] [V] [TRT] Tactic: -3151804561246216835 Time: 0.127488
[03/24/2023-12:56:39] [V] [TRT] Conv_17 + Relu_18 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize64x32x64_stage5_warpsize2x2x1_g1_tensor16x8x8 Tactic: -2885165284206163001
[03/24/2023-12:56:39] [V] [TRT] Tactic: -2885165284206163001 Time: 0.268288
[03/24/2023-12:56:39] [V] [TRT] Conv_17 + Relu_18 Set Tactic Name: ampere_scudnn_128x128_relu_exp_medium_nhwc_tn_v1 Tactic: -2809379259463049391
[03/24/2023-12:56:39] [V] [TRT] Tactic: -2809379259463049391 Time: 0.657408
[03/24/2023-12:56:39] [V] [TRT] Conv_17 + Relu_18 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x128x32_stage4_warpsize2x2x1_g1_tensor16x8x8_t1r3s3 Tactic: -2801041895330778813
[03/24/2023-12:56:39] [V] [TRT] Tactic: -2801041895330778813 Time: 0.128512
[03/24/2023-12:56:39] [V] [TRT] Conv_17 + Relu_18 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize64x256x8_stage3_warpsize1x4x1_g1_ffma_t1r3s3 Tactic: -2747929399988666512
[03/24/2023-12:56:39] [V] [TRT] Tactic: -2747929399988666512 Time: 1.29728
[03/24/2023-12:56:39] [V] [TRT] Conv_17 + Relu_18 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize256x128x32_stage3_warpsize4x2x1_g1_tensor16x8x8 Tactic: -1758690179295738332
[03/24/2023-12:56:39] [V] [TRT] Tactic: -1758690179295738332 Time: 0.14976
[03/24/2023-12:56:39] [V] [TRT] Conv_17 + Relu_18 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x64x64_stage3_warpsize2x2x1_g1_tensor16x8x8_t1r3s3 Tactic: -1484546572846226796
[03/24/2023-12:56:39] [V] [TRT] Tactic: -1484546572846226796 Time: 0.14208
[03/24/2023-12:56:39] [V] [TRT] Conv_17 + Relu_18 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize64x256x8_stage3_warpsize1x4x1_g1_ffma Tactic: -1472061967969061456
[03/24/2023-12:56:39] [V] [TRT] Tactic: -1472061967969061456 Time: 1.32966
[03/24/2023-12:56:39] [V] [TRT] Conv_17 + Relu_18 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x128x32_stage4_warpsize2x2x1_g1_tensor16x8x8 Tactic: -858667497925695276
[03/24/2023-12:56:39] [V] [TRT] Tactic: -858667497925695276 Time: 0.186496
[03/24/2023-12:56:39] [V] [TRT] Conv_17 + Relu_18 Set Tactic Name: ampere_scudnn_128x128_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: -504296718212024303
[03/24/2023-12:56:39] [V] [TRT] Tactic: -504296718212024303 Time: 0.6528
[03/24/2023-12:56:39] [V] [TRT] Conv_17 + Relu_18 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize64x128x8_stage3_warpsize1x4x1_g1_ffma Tactic: -444093195553988951
[03/24/2023-12:56:39] [V] [TRT] Tactic: -444093195553988951 Time: 0.575488
[03/24/2023-12:56:39] [V] [TRT] Fastest Tactic: 2716437853123234317 Time: 0.1184
[03/24/2023-12:56:39] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: 2716437853123234317
[03/24/2023-12:56:39] [V] [TRT] *************** Autotuning format combination: Half(4147200,32400,180,1) -> Half(4147200,32400,180,1) ***************
[03/24/2023-12:56:39] [V] [TRT] --------------- Timing Runner: Conv_17 + Relu_18 (CudnnConvolution)
[03/24/2023-12:56:39] [V] [TRT] Tactic: 0 Time: 0.776704
[03/24/2023-12:56:39] [V] [TRT] Tactic: 1 Time: 0.687872
[03/24/2023-12:56:39] [V] [TRT] Tactic: 2 Time: 0.87552
[03/24/2023-12:56:39] [V] [TRT] Tactic: 4 skipped. Scratch requested: 8725266432, available: 4294967296
[03/24/2023-12:56:39] [V] [TRT] Tactic: 5 Time: 2.4416
[03/24/2023-12:56:39] [V] [TRT] Tactic: 6 Time: 0.398336
[03/24/2023-12:56:39] [V] [TRT] Tactic: 56 Time: 0.776704
[03/24/2023-12:56:39] [V] [TRT] Tactic: 58 Time: 0.875008
[03/24/2023-12:56:39] [V] [TRT] Tactic: 60 skipped. Scratch requested: 8725266432, available: 4294967296
[03/24/2023-12:56:39] [V] [TRT] Tactic: 61 Time: 2.44672
[03/24/2023-12:56:39] [V] [TRT] Tactic: 62 Time: 0.398208
[03/24/2023-12:56:39] [V] [TRT] Fastest Tactic: 62 Time: 0.398208
[03/24/2023-12:56:39] [V] [TRT] Setting workspace to 8725266432enables more tactics for profiling
[03/24/2023-12:56:39] [V] [TRT] --------------- Timing Runner: Conv_17 + Relu_18 (CaskConvolution)
[03/24/2023-12:56:39] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[03/24/2023-12:56:39] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CudnnConvolution Tactic: 62
[03/24/2023-12:56:39] [V] [TRT] *************** Autotuning format combination: Half(2073600,32400:2,180,1) -> Half(2073600,32400:2,180,1) ***************
[03/24/2023-12:56:39] [V] [TRT] --------------- Timing Runner: Conv_17 + Relu_18 (FusedConvActConvolution)
[03/24/2023-12:56:39] [V] [TRT] Tactic: 524287 Time: 0.264064
[03/24/2023-12:56:39] [V] [TRT] Tactic: 720895 Time: 0.22144
[03/24/2023-12:56:39] [V] [TRT] Tactic: 983039 Time: 0.238464
[03/24/2023-12:56:39] [V] [TRT] Tactic: 1048575 Time: 0.267904
[03/24/2023-12:56:39] [V] [TRT] Tactic: 1703935 Time: 0.252928
[03/24/2023-12:56:39] [V] [TRT] Tactic: 1769471 Time: 0.292736
[03/24/2023-12:56:39] [V] [TRT] Tactic: 1966079 Time: 0.253568
[03/24/2023-12:56:39] [V] [TRT] Tactic: 2031615 Time: 0.230144
[03/24/2023-12:56:39] [V] [TRT] Tactic: 2228223 Time: 0.275456
[03/24/2023-12:56:39] [V] [TRT] Tactic: 2424831 Time: 0.340992
[03/24/2023-12:56:39] [V] [TRT] Tactic: 2621439 Time: 0.265216
[03/24/2023-12:56:39] [V] [TRT] Tactic: 2752511 Time: 0.250752
[03/24/2023-12:56:39] [V] [TRT] Tactic: 2818047 Time: 0.292736
[03/24/2023-12:56:39] [V] [TRT] Tactic: 2883583 Time: 0.31168
[03/24/2023-12:56:39] [V] [TRT] Tactic: 3014655 Time: 0.252288
[03/24/2023-12:56:39] [V] [TRT] Tactic: 3145727 Time: 0.238208
[03/24/2023-12:56:40] [V] [TRT] Tactic: 3473407 Time: 0.2688
[03/24/2023-12:56:40] [V] [TRT] Tactic: 3604479 Time: 0.2624
[03/24/2023-12:56:40] [V] [TRT] Tactic: 3735551 Time: 0.253312
[03/24/2023-12:56:40] [V] [TRT] Tactic: 4390911 Time: 0.264704
[03/24/2023-12:56:40] [V] [TRT] Tactic: 5046271 Time: 0.252032
[03/24/2023-12:56:40] [V] [TRT] Tactic: 5963775 Time: 0.254848
[03/24/2023-12:56:40] [V] [TRT] Tactic: 6160383 Time: 0.263936
[03/24/2023-12:56:40] [V] [TRT] Tactic: 6488063 Time: 0.260864
[03/24/2023-12:56:40] [V] [TRT] Tactic: 6881279 Time: 0.264064
[03/24/2023-12:56:40] [V] [TRT] Tactic: 7274495 Time: 0.272768
[03/24/2023-12:56:40] [V] [TRT] Tactic: 7864319 Time: 0.269952
[03/24/2023-12:56:40] [V] [TRT] Tactic: 7995391 Time: 0.269952
[03/24/2023-12:56:40] [V] [TRT] Tactic: 8585215 Time: 0.264064
[03/24/2023-12:56:40] [V] [TRT] Tactic: 8847359 Time: 0.27072
[03/24/2023-12:56:40] [V] [TRT] Tactic: 8978431 Time: 0.252416
[03/24/2023-12:56:40] [V] [TRT] Tactic: 9043967 Time: 0.250496
[03/24/2023-12:56:40] [V] [TRT] Tactic: 9175039 Time: 0.262656
[03/24/2023-12:56:40] [V] [TRT] Tactic: 9502719 Time: 0.261632
[03/24/2023-12:56:40] [V] [TRT] Tactic: 9830399 Time: 0.265088
[03/24/2023-12:56:40] [V] [TRT] Tactic: 9961471 Time: 0.349824
[03/24/2023-12:56:40] [V] [TRT] Tactic: 10027007 Time: 0.24768
[03/24/2023-12:56:40] [V] [TRT] Tactic: 10092543 Time: 0.264576
[03/24/2023-12:56:40] [V] [TRT] Tactic: 10289151 Time: 0.253696
[03/24/2023-12:56:40] [V] [TRT] Tactic: 10485759 Time: 0.242688
[03/24/2023-12:56:40] [V] [TRT] Tactic: 10682367 Time: 0.279936
[03/24/2023-12:56:40] [V] [TRT] Tactic: 10813439 Time: 0.266752
[03/24/2023-12:56:40] [V] [TRT] Fastest Tactic: 720895 Time: 0.22144
[03/24/2023-12:56:40] [V] [TRT] --------------- Timing Runner: Conv_17 + Relu_18 (CudnnConvolution)
[03/24/2023-12:56:40] [V] [TRT] CudnnConvolution has no valid tactics for this config, skipping
[03/24/2023-12:56:40] [V] [TRT] --------------- Timing Runner: Conv_17 + Relu_18 (CaskConvolution)
[03/24/2023-12:56:40] [V] [TRT] Conv_17 + Relu_18 Set Tactic Name: ampere_fp16x2_hcudnn_fp16x2_128x32_relu_medium_nn_v1 Tactic: 2195670545862694453
[03/24/2023-12:56:40] [V] [TRT] Tactic: 2195670545862694453 Time: 0.313728
[03/24/2023-12:56:40] [V] [TRT] Conv_17 + Relu_18 Set Tactic Name: ampere_fp16x2_hcudnn_fp16x2_128x64_relu_large_nn_v1 Tactic: 3419182076704469245
[03/24/2023-12:56:40] [V] [TRT] Tactic: 3419182076704469245 Time: 0.303232
[03/24/2023-12:56:40] [V] [TRT] Conv_17 + Relu_18 Set Tactic Name: ampere_fp16x2_hcudnn_fp16x2_128x128_relu_medium_nn_v1 Tactic: 3891805945559659536
[03/24/2023-12:56:40] [V] [TRT] Tactic: 3891805945559659536 Time: 0.345088
[03/24/2023-12:56:40] [V] [TRT] Conv_17 + Relu_18 Set Tactic Name: ampere_fp16x2_hcudnn_fp16x2_128x64_relu_medium_nn_v1 Tactic: 5548126322150286555
[03/24/2023-12:56:40] [V] [TRT] Tactic: 5548126322150286555 Time: 0.299904
[03/24/2023-12:56:40] [V] [TRT] Conv_17 + Relu_18 Set Tactic Name: ampere_fp16x2_hcudnn_fp16x2_128x64_relu_small_nn_v1 Tactic: 6057304366605292508
[03/24/2023-12:56:40] [V] [TRT] Tactic: 6057304366605292508 Time: 0.294016
[03/24/2023-12:56:40] [V] [TRT] Conv_17 + Relu_18 Set Tactic Name: ampere_fp16x2_hcudnn_fp16x2_128x128_relu_large_nn_v1 Tactic: -7928611605886347652
[03/24/2023-12:56:40] [V] [TRT] Tactic: -7928611605886347652 Time: 0.356224
[03/24/2023-12:56:40] [V] [TRT] Conv_17 + Relu_18 Set Tactic Name: ampere_fp16x2_hcudnn_fp16x2_128x32_relu_large_nn_v1 Tactic: -5172391392092686714
[03/24/2023-12:56:40] [V] [TRT] Tactic: -5172391392092686714 Time: 0.31616
[03/24/2023-12:56:40] [V] [TRT] Conv_17 + Relu_18 Set Tactic Name: ampere_fp16x2_hcudnn_fp16x2_128x32_relu_small_nn_v1 Tactic: -4374269919094467161
[03/24/2023-12:56:40] [V] [TRT] Tactic: -4374269919094467161 Time: 0.310272
[03/24/2023-12:56:40] [V] [TRT] Conv_17 + Relu_18 Set Tactic Name: ampere_fp16x2_hcudnn_winograd_fp16x2_128x128_ldg1_ldg4_relu_tile148t_nt_v1 Tactic: -4083394051665370953
[03/24/2023-12:56:40] [V] [TRT] Tactic: -4083394051665370953 Time: 0.166656
[03/24/2023-12:56:40] [V] [TRT] Conv_17 + Relu_18 Set Tactic Name: ampere_fp16x2_hcudnn_fp16x2_128x128_relu_small_nn_v1 Tactic: -1546027692247304867
[03/24/2023-12:56:40] [V] [TRT] Tactic: -1546027692247304867 Time: 0.34816
[03/24/2023-12:56:40] [V] [TRT] Fastest Tactic: -4083394051665370953 Time: 0.166656
[03/24/2023-12:56:40] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: -4083394051665370953
[03/24/2023-12:56:40] [V] [TRT] *************** Autotuning format combination: Half(518400,1:8,2880,16) -> Float(4147200,32400,180,1) ***************
[03/24/2023-12:56:40] [V] [TRT] --------------- Timing Runner: Conv_17 + Relu_18 (CudnnConvolution)
[03/24/2023-12:56:40] [V] [TRT] CudnnConvolution has no valid tactics for this config, skipping
[03/24/2023-12:56:40] [V] [TRT] --------------- Timing Runner: Conv_17 + Relu_18 (CaskConvolution)
[03/24/2023-12:56:40] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[03/24/2023-12:56:40] [V] [TRT] *************** Autotuning format combination: Half(518400,1:8,2880,16) -> Half(518400,1:8,2880,16) ***************
[03/24/2023-12:56:40] [V] [TRT] --------------- Timing Runner: Conv_17 + Relu_18 (CudaDepthwiseConvolution)
[03/24/2023-12:56:40] [V] [TRT] CudaDepthwiseConvolution has no valid tactics for this config, skipping
[03/24/2023-12:56:40] [V] [TRT] --------------- Timing Runner: Conv_17 + Relu_18 (CudnnConvolution)
[03/24/2023-12:56:40] [V] [TRT] Tactic: 0 Time: 0.903296
[03/24/2023-12:56:40] [V] [TRT] Tactic: 1 Time: 1.76678
[03/24/2023-12:56:40] [V] [TRT] Tactic: 2 Time: 1.10976
[03/24/2023-12:56:40] [V] [TRT] Tactic: 6 Time: 0.392064
[03/24/2023-12:56:40] [V] [TRT] Tactic: 56 Time: 0.903296
[03/24/2023-12:56:40] [V] [TRT] Tactic: 58 Time: 1.10963
[03/24/2023-12:56:40] [V] [TRT] Tactic: 62 Time: 0.392192
[03/24/2023-12:56:40] [V] [TRT] Fastest Tactic: 6 Time: 0.392064
[03/24/2023-12:56:40] [V] [TRT] --------------- Timing Runner: Conv_17 + Relu_18 (CaskConvolution)
[03/24/2023-12:56:40] [V] [TRT] Conv_17 + Relu_18 Set Tactic Name: ampere_h16816cudnn_256x128_ldg8_relu_exp_medium_nhwc_tn_v1 Tactic: 254850674756030979
[03/24/2023-12:56:40] [V] [TRT] Tactic: 254850674756030979 Time: 0.076416
[03/24/2023-12:56:40] [V] [TRT] Conv_17 + Relu_18 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x128x32_stage3_warpsize4x2x1_g1_tensor16x8x16_t1r3s3 Tactic: 328038211831149625
[03/24/2023-12:56:40] [V] [TRT] Tactic: 328038211831149625 Time: 0.071936
[03/24/2023-12:56:40] [V] [TRT] Conv_17 + Relu_18 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x64x64_stage3_warpsize2x2x1_g1_tensor16x8x16_t1r3s3 Tactic: 411553864378931917
[03/24/2023-12:56:40] [V] [TRT] Tactic: 411553864378931917 Time: 0.070656
[03/24/2023-12:56:40] [V] [TRT] Conv_17 + Relu_18 Set Tactic Name: sm75_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x128x32_stage1_warpsize4x2x1_g1_tensor16x8x8_t1r3s3 Tactic: 864841579020773074
[03/24/2023-12:56:40] [V] [TRT] Tactic: 864841579020773074 Time: 0.086016
[03/24/2023-12:56:40] [V] [TRT] Conv_17 + Relu_18 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x128x32_stage4_warpsize2x2x1_g1_tensor16x8x16 Tactic: 1011057357468998345
[03/24/2023-12:56:40] [V] [TRT] Tactic: 1011057357468998345 Time: 0.061312
[03/24/2023-12:56:40] [V] [TRT] Conv_17 + Relu_18 Set Tactic Name: sm75_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x64x32_stage1_warpsize4x1x1_g1_tensor16x8x8 Tactic: 1013168150133367738
[03/24/2023-12:56:40] [V] [TRT] Tactic: 1013168150133367738 Time: 0.084736
[03/24/2023-12:56:40] [V] [TRT] Conv_17 + Relu_18 Set Tactic Name: ampere_h16816cudnn_256x128_ldg8_relu_exp_stages_64x3_small_nhwc_tn_v1 Tactic: 1016009564074305832
[03/24/2023-12:56:40] [V] [TRT] Tactic: 1016009564074305832 Time: 0.07488
[03/24/2023-12:56:40] [V] [TRT] Conv_17 + Relu_18 Set Tactic Name: sm75_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x128x32_stage1_warpsize2x2x1_g1_tensor16x8x8 Tactic: 1067227531433278814
[03/24/2023-12:56:40] [V] [TRT] Tactic: 1067227531433278814 Time: 0.07616
[03/24/2023-12:56:40] [V] [TRT] Conv_17 + Relu_18 Set Tactic Name: ampere_h1688cudnn_128x128_ldg8_relu_exp_medium_nhwc_tn_v1 Tactic: 1156328698016730421
[03/24/2023-12:56:40] [V] [TRT] Tactic: 1156328698016730421 Time: 0.090368
[03/24/2023-12:56:40] [V] [TRT] Conv_17 + Relu_18 Set Tactic Name: sm75_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x128x32_stage1_warpsize2x2x1_g1_tensor16x8x8 Tactic: 1579845938601132607
[03/24/2023-12:56:40] [V] [TRT] Tactic: 1579845938601132607 Time: 0.077568
[03/24/2023-12:56:40] [V] [TRT] Conv_17 + Relu_18 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x128x32_stage5_warpsize2x2x1_g1_tensor16x8x16_t1r3s3 Tactic: 1723736032573714698
[03/24/2023-12:56:40] [V] [TRT] Tactic: 1723736032573714698 Time: 0.071552
[03/24/2023-12:56:40] [V] [TRT] Conv_17 + Relu_18 Set Tactic Name: sm75_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x32x32_stage1_warpsize4x1x1_g1_tensor16x8x8 Tactic: 1796821236841789338
[03/24/2023-12:56:40] [V] [TRT] Tactic: 1796821236841789338 Time: 0.1152
[03/24/2023-12:56:40] [V] [TRT] Conv_17 + Relu_18 Set Tactic Name: ampere_h16816cudnn_128x64_ldg8_relu_exp_stages_64x4_medium_nhwc_tn_v1 Tactic: 1832046141070096030
[03/24/2023-12:56:40] [V] [TRT] Tactic: 1832046141070096030 Time: 0.070656
[03/24/2023-12:56:40] [V] [TRT] Conv_17 + Relu_18 Set Tactic Name: ampere_h16816cudnn_128x64_sliced1x2_ldg8_relu_exp_stages_64x3_small_nhwc_tn_v1 Tactic: 1838082074606840426
[03/24/2023-12:56:40] [V] [TRT] Tactic: 1838082074606840426 Time: 0.060288
[03/24/2023-12:56:40] [V] [TRT] Conv_17 + Relu_18 Set Tactic Name: ampere_h16816cudnn_64x64_sliced1x2_ldg8_relu_exp_stages_64x5_small_nhwc_tn_v1 Tactic: 1899296423087490472
[03/24/2023-12:56:40] [V] [TRT] Tactic: 1899296423087490472 Time: 0.08448
[03/24/2023-12:56:40] [V] [TRT] Conv_17 + Relu_18 Set Tactic Name: sm75_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x32x32_stage1_warpsize4x1x1_g1_tensor16x8x8 Tactic: 1948263663414159978
[03/24/2023-12:56:40] [V] [TRT] Tactic: 1948263663414159978 Time: 0.10048
[03/24/2023-12:56:40] [V] [TRT] Conv_17 + Relu_18 Set Tactic Name: sm75_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x256x64_stage1_warpsize1x4x2_g1_tensor16x8x8 Tactic: 2027733232253711640
[03/24/2023-12:56:40] [V] [TRT] Tactic: 2027733232253711640 Time: 0.11904
[03/24/2023-12:56:40] [V] [TRT] Conv_17 + Relu_18 Set Tactic Name: sm75_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x64x32_stage1_warpsize2x2x1_g1_tensor16x8x8_t1r3s3 Tactic: 2154731107061273008
[03/24/2023-12:56:40] [V] [TRT] Tactic: 2154731107061273008 Time: 0.081024
[03/24/2023-12:56:40] [V] [TRT] Conv_17 + Relu_18 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x64x64_stage3_warpsize2x2x1_g1_tensor16x8x16 Tactic: 2428167804343994714
[03/24/2023-12:56:40] [V] [TRT] Tactic: 2428167804343994714 Time: 0.069632
[03/24/2023-12:56:40] [V] [TRT] Conv_17 + Relu_18 Set Tactic Name: ampere_h16816cudnn_128x128_ldg8_relu_exp_medium_nhwc_tn_v1 Tactic: 2541579301352125276
[03/24/2023-12:56:40] [V] [TRT] Tactic: 2541579301352125276 Time: 0.061312
[03/24/2023-12:56:40] [V] [TRT] Conv_17 + Relu_18 Set Tactic Name: ampere_h16816cudnn_64x64_sliced1x2_ldg8_relu_exp_stages_64x6_small_nhwc_tn_v1 Tactic: 2657157263811141609
[03/24/2023-12:56:40] [V] [TRT] Tactic: 2657157263811141609 Time: 0.091904
[03/24/2023-12:56:40] [V] [TRT] Conv_17 + Relu_18 Set Tactic Name: ampere_h16816cudnn_64x128_sliced1x2_ldg8_relu_exp_stages_64x4_large_nhwc_tn_v1 Tactic: 2819719497590964443
[03/24/2023-12:56:40] [V] [TRT] Tactic: 2819719497590964443 Time: 0.071424
[03/24/2023-12:56:40] [V] [TRT] Conv_17 + Relu_18 Set Tactic Name: ampere_h16816cudnn_128x64_sliced1x2_ldg8_relu_exp_stages_64x3_medium_nhwc_tn_v1 Tactic: 2968605903460894194
[03/24/2023-12:56:40] [V] [TRT] Tactic: 2968605903460894194 Time: 0.061568
[03/24/2023-12:56:40] [V] [TRT] Conv_17 + Relu_18 Set Tactic Name: ampere_h16816cudnn_128x128_ldg8_relu_exp_large_nhwc_tn_v1 Tactic: 2986078304285316765
[03/24/2023-12:56:40] [V] [TRT] Tactic: 2986078304285316765 Time: 0.061696
[03/24/2023-12:56:40] [V] [TRT] Conv_17 + Relu_18 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x256x64_stage3_warpsize1x4x1_g1_tensor16x8x16 Tactic: 3016308193087082166
[03/24/2023-12:56:41] [V] [TRT] Tactic: 3016308193087082166 Time: 0.100224
[03/24/2023-12:56:41] [V] [TRT] Conv_17 + Relu_18 Set Tactic Name: ampere_h16816cudnn_256x64_ldg8_relu_exp_stages_64x3_large_nhwc_tn_v1 Tactic: 3221382575080507859
[03/24/2023-12:56:41] [V] [TRT] Tactic: 3221382575080507859 Time: 0.065024
[03/24/2023-12:56:41] [V] [TRT] Conv_17 + Relu_18 Set Tactic Name: ampere_h16816cudnn_128x128_ldg8_relu_exp_stages_64x3_medium_nhwc_tn_v1 Tactic: 3362537467505018070
[03/24/2023-12:56:41] [V] [TRT] Tactic: 3362537467505018070 Time: 0.063232
[03/24/2023-12:56:41] [V] [TRT] Conv_17 + Relu_18 Set Tactic Name: sm75_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x64x32_stage1_warpsize4x1x1_g1_tensor16x8x8_t1r3s3 Tactic: 3464689803495983377
[03/24/2023-12:56:41] [V] [TRT] Tactic: 3464689803495983377 Time: 0.07872
[03/24/2023-12:56:41] [V] [TRT] Conv_17 + Relu_18 Set Tactic Name: ampere_h1688cudnn_256x128_ldg8_relu_exp_medium_nhwc_tn_v1 Tactic: 3513075359009385578
[03/24/2023-12:56:41] [V] [TRT] Tactic: 3513075359009385578 Time: 0.091392
[03/24/2023-12:56:41] [V] [TRT] Conv_17 + Relu_18 Set Tactic Name: ampere_h16816cudnn_128x64_ldg8_relu_exp_stages_64x4_large_nhwc_tn_v1 Tactic: 3573559043797674382
[03/24/2023-12:56:41] [V] [TRT] Tactic: 3573559043797674382 Time: 0.07168
[03/24/2023-12:56:41] [V] [TRT] Conv_17 + Relu_18 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x64x64_stage4_warpsize2x2x1_g1_tensor16x8x16_t1r3s3 Tactic: 3591970081995419777
[03/24/2023-12:56:41] [V] [TRT] Tactic: 3591970081995419777 Time: 0.083456
[03/24/2023-12:56:41] [V] [TRT] Conv_17 + Relu_18 Set Tactic Name: sm75_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x128x32_stage1_warpsize2x2x1_g1_tensor16x8x8_t1r3s3 Tactic: 3636831327753843771
[03/24/2023-12:56:41] [V] [TRT] Tactic: 3636831327753843771 Time: 0.068352
[03/24/2023-12:56:41] [V] [TRT] Conv_17 + Relu_18 Set Tactic Name: ampere_h1688cudnn_128x128_ldg8_relu_exp_small_nhwc_tn_v1 Tactic: 3704534001553878387
[03/24/2023-12:56:41] [V] [TRT] Tactic: 3704534001553878387 Time: 0.086656
[03/24/2023-12:56:41] [V] [TRT] Conv_17 + Relu_18 Set Tactic Name: ampere_h16816cudnn_64x128_ldg8_relu_exp_stages_64x4_small_nhwc_tn_v1 Tactic: 4278315135102886928
[03/24/2023-12:56:41] [V] [TRT] Tactic: 4278315135102886928 Time: 0.067072
[03/24/2023-12:56:41] [V] [TRT] Conv_17 + Relu_18 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x32x32_stage4_warpsize4x1x1_g1_tensor16x8x16_t1r3s3 Tactic: 4503233883285355107
[03/24/2023-12:56:41] [V] [TRT] Tactic: 4503233883285355107 Time: 0.0864
[03/24/2023-12:56:41] [V] [TRT] Conv_17 + Relu_18 Set Tactic Name: ampere_h16816cudnn_256x64_ldg8_relu_exp_stages_64x3_medium_nhwc_tn_v1 Tactic: 4540505769798915372
[03/24/2023-12:56:41] [V] [TRT] Tactic: 4540505769798915372 Time: 0.064512
[03/24/2023-12:56:41] [V] [TRT] Conv_17 + Relu_18 Set Tactic Name: ampere_h16816cudnn_256x64_sliced1x2_ldg8_relu_exp_small_nhwc_tn_v1 Tactic: 4802447371470387646
[03/24/2023-12:56:41] [V] [TRT] Tactic: 4802447371470387646 Time: 0.075776
[03/24/2023-12:56:41] [V] [TRT] Conv_17 + Relu_18 Set Tactic Name: ampere_h16816cudnn_256x128_ldg8_relu_exp_small_nhwc_tn_v1 Tactic: 5059676457552313631
[03/24/2023-12:56:41] [V] [TRT] Tactic: 5059676457552313631 Time: 0.07488
[03/24/2023-12:56:41] [V] [TRT] Conv_17 + Relu_18 Set Tactic Name: sm75_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x128x64_stage1_warpsize2x2x1_g1_tensor16x8x8_t1r3s3 Tactic: 5263029549013613567
[03/24/2023-12:56:41] [V] [TRT] Tactic: 5263029549013613567 Time: 0.06656
[03/24/2023-12:56:41] [V] [TRT] Conv_17 + Relu_18 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x64x64_stage4_warpsize2x2x1_g1_tensor16x8x16 Tactic: 5368829646735632944
[03/24/2023-12:56:41] [V] [TRT] Tactic: 5368829646735632944 Time: 0.084224
[03/24/2023-12:56:41] [V] [TRT] Conv_17 + Relu_18 Set Tactic Name: ampere_h1688cudnn_256x64_sliced1x2_ldg8_relu_exp_small_nhwc_tn_v1 Tactic: 5398999388616959893
[03/24/2023-12:56:41] [V] [TRT] Tactic: 5398999388616959893 Time: 0.079872
[03/24/2023-12:56:41] [V] [TRT] Conv_17 + Relu_18 Set Tactic Name: sm75_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x256x32_stage1_warpsize2x4x1_g1_tensor16x8x8_t1r3s3 Tactic: 5506334059535811602
[03/24/2023-12:56:41] [V] [TRT] Tactic: 5506334059535811602 Time: 0.119808
[03/24/2023-12:56:41] [V] [TRT] Conv_17 + Relu_18 Set Tactic Name: ampere_h16816cudnn_64x128_sliced1x2_ldg8_relu_exp_stages_64x3_large_nhwc_tn_v1 Tactic: 5746691132547383910
[03/24/2023-12:56:41] [V] [TRT] Tactic: 5746691132547383910 Time: 0.06656
[03/24/2023-12:56:41] [V] [TRT] Conv_17 + Relu_18 Set Tactic Name: ampere_h16816cudnn_256x64_ldg8_relu_exp_large_nhwc_tn_v1 Tactic: 5770170567977052602
[03/24/2023-12:56:41] [V] [TRT] Tactic: 5770170567977052602 Time: 0.0736
[03/24/2023-12:56:41] [V] [TRT] Conv_17 + Relu_18 Set Tactic Name: sm75_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x32x64_stage1_warpsize2x1x2_g1_tensor16x8x8_t1r3s3 Tactic: 5932046018238429951
[03/24/2023-12:56:41] [V] [TRT] Tactic: 5932046018238429951 Time: 0.103808
[03/24/2023-12:56:41] [V] [TRT] Conv_17 + Relu_18 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x64x32_stage3_warpsize4x1x1_g1_tensor16x8x16_t1r3s3 Tactic: 5953552212833506549
[03/24/2023-12:56:41] [V] [TRT] Tactic: 5953552212833506549 Time: 0.06016
[03/24/2023-12:56:41] [V] [TRT] Conv_17 + Relu_18 Set Tactic Name: ampere_h16816cudnn_64x128_ldg8_relu_exp_stages_64x3_small_nhwc_tn_v1 Tactic: 6034364043891107501
[03/24/2023-12:56:41] [V] [TRT] Tactic: 6034364043891107501 Time: 0.07232
[03/24/2023-12:56:41] [V] [TRT] Conv_17 + Relu_18 Set Tactic Name: ampere_h16816cudnn_64x64_ldg8_relu_exp_stages_64x5_large_nhwc_tn_v1 Tactic: 6074229447555668232
[03/24/2023-12:56:41] [V] [TRT] Tactic: 6074229447555668232 Time: 0.092032
[03/24/2023-12:56:41] [V] [TRT] Conv_17 + Relu_18 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x64x64_stage3_warpsize2x2x1_g1_tensor16x8x16 Tactic: 6154447660803990543
[03/24/2023-12:56:41] [V] [TRT] Tactic: 6154447660803990543 Time: 0.071808
[03/24/2023-12:56:41] [V] [TRT] Conv_17 + Relu_18 Set Tactic Name: sm75_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x32x64_stage1_warpsize2x1x2_g1_tensor16x8x8 Tactic: 6195603576432354734
[03/24/2023-12:56:41] [V] [TRT] Tactic: 6195603576432354734 Time: 0.10496
[03/24/2023-12:56:41] [V] [TRT] Conv_17 + Relu_18 Set Tactic Name: sm75_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x32x32_stage1_warpsize4x1x1_g1_tensor16x8x8_t1r3s3 Tactic: 6252808259936499253
[03/24/2023-12:56:41] [V] [TRT] Tactic: 6252808259936499253 Time: 0.099968
[03/24/2023-12:56:41] [V] [TRT] Conv_17 + Relu_18 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x128x64_stage3_warpsize2x2x1_g1_tensor16x8x16 Tactic: 6325769668000961702
[03/24/2023-12:56:41] [V] [TRT] Tactic: 6325769668000961702 Time: 0.06528
[03/24/2023-12:56:41] [V] [TRT] Conv_17 + Relu_18 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x32x64_stage5_warpsize2x2x1_g1_tensor16x8x16 Tactic: 6350273239113254096
[03/24/2023-12:56:41] [V] [TRT] Tactic: 6350273239113254096 Time: 0.122112
[03/24/2023-12:56:41] [V] [TRT] Conv_17 + Relu_18 Set Tactic Name: ampere_h16816cudnn_128x128_ldg8_relu_exp_stages_64x3_small_nhwc_tn_v1 Tactic: 6377497238381488891
[03/24/2023-12:56:41] [V] [TRT] Tactic: 6377497238381488891 Time: 0.063488
[03/24/2023-12:56:41] [V] [TRT] Conv_17 + Relu_18 Set Tactic Name: sm75_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x64x64_stage1_warpsize2x2x1_g1_tensor16x8x8 Tactic: 6408235920257988861
[03/24/2023-12:56:41] [V] [TRT] Tactic: 6408235920257988861 Time: 0.086144
[03/24/2023-12:56:41] [V] [TRT] Conv_17 + Relu_18 Set Tactic Name: ampere_h16816cudnn_128x64_ldg8_relu_exp_stages_64x3_large_nhwc_tn_v1 Tactic: 6446388116965632819
[03/24/2023-12:56:41] [V] [TRT] Tactic: 6446388116965632819 Time: 0.065152
[03/24/2023-12:56:41] [V] [TRT] Conv_17 + Relu_18 Set Tactic Name: ampere_h16816cudnn_128x64_sliced1x2_ldg8_relu_exp_stages_64x4_medium_nhwc_tn_v1 Tactic: 6468794451065529747
[03/24/2023-12:56:41] [V] [TRT] Tactic: 6468794451065529747 Time: 0.068864
[03/24/2023-12:56:41] [V] [TRT] Conv_17 + Relu_18 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x128x64_stage3_warpsize4x2x1_g1_tensor16x8x16 Tactic: 6509152032538119080
[03/24/2023-12:56:41] [V] [TRT] Tactic: 6509152032538119080 Time: 0.075392
[03/24/2023-12:56:41] [V] [TRT] Conv_17 + Relu_18 Set Tactic Name: ampere_h1688cudnn_256x128_ldg8_relu_exp_large_nhwc_tn_v1 Tactic: 6642277870194067185
[03/24/2023-12:56:41] [V] [TRT] Tactic: 6642277870194067185 Time: 0.092288
[03/24/2023-12:56:41] [V] [TRT] Conv_17 + Relu_18 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x256x64_stage3_warpsize1x4x1_g1_tensor16x8x16 Tactic: 6703181542003057635
[03/24/2023-12:56:41] [V] [TRT] Tactic: 6703181542003057635 Time: 0.100352
[03/24/2023-12:56:41] [V] [TRT] Conv_17 + Relu_18 Set Tactic Name: ampere_h16816cudnn_64x64_ldg8_relu_exp_stages_64x5_medium_nhwc_tn_v1 Tactic: 6859477213531075460
[03/24/2023-12:56:41] [V] [TRT] Tactic: 6859477213531075460 Time: 0.091008
[03/24/2023-12:56:41] [V] [TRT] Conv_17 + Relu_18 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x128x32_stage4_warpsize2x2x1_g1_tensor16x8x16_t1r3s3 Tactic: 6972489290272968208
[03/24/2023-12:56:41] [V] [TRT] Tactic: 6972489290272968208 Time: 0.05632
[03/24/2023-12:56:41] [V] [TRT] Conv_17 + Relu_18 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x128x32_stage3_warpsize4x2x1_g1_tensor16x8x16 Tactic: 6979044990896381511
[03/24/2023-12:56:41] [V] [TRT] Tactic: 6979044990896381511 Time: 0.072192
[03/24/2023-12:56:41] [V] [TRT] Conv_17 + Relu_18 Set Tactic Name: ampere_h1688cudnn_256x64_ldg8_relu_exp_medium_nhwc_tn_v1 Tactic: 7216571380637776659
[03/24/2023-12:56:41] [V] [TRT] Tactic: 7216571380637776659 Time: 0.106752
[03/24/2023-12:56:41] [V] [TRT] Conv_17 + Relu_18 Set Tactic Name: ampere_h16816cudnn_128x64_ldg8_relu_exp_stages_64x3_medium_nhwc_tn_v1 Tactic: 7609923741161019135
[03/24/2023-12:56:41] [V] [TRT] Tactic: 7609923741161019135 Time: 0.067456
[03/24/2023-12:56:41] [V] [TRT] Conv_17 + Relu_18 Set Tactic Name: sm75_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x64x32_stage1_warpsize2x2x1_g1_tensor16x8x8 Tactic: 7612687199567064086
[03/24/2023-12:56:41] [V] [TRT] Tactic: 7612687199567064086 Time: 0.08576
[03/24/2023-12:56:41] [V] [TRT] Conv_17 + Relu_18 Set Tactic Name: ampere_h16816cudnn_64x64_ldg8_relu_exp_stages_64x6_large_nhwc_tn_v1 Tactic: 7705739241028240201
[03/24/2023-12:56:41] [V] [TRT] Tactic: 7705739241028240201 Time: 0.10176
[03/24/2023-12:56:41] [V] [TRT] Conv_17 + Relu_18 Set Tactic Name: sm75_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x128x32_stage1_warpsize2x2x1_g1_tensor16x8x8 Tactic: 7729555994715864793
[03/24/2023-12:56:41] [V] [TRT] Tactic: 7729555994715864793 Time: 0.084608
[03/24/2023-12:56:41] [V] [TRT] Conv_17 + Relu_18 Set Tactic Name: sm75_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x64x64_stage1_warpsize2x2x1_g1_tensor16x8x8_t1r3s3 Tactic: 7849296535223586261
[03/24/2023-12:56:41] [V] [TRT] Tactic: 7849296535223586261 Time: 0.085632
[03/24/2023-12:56:41] [V] [TRT] Conv_17 + Relu_18 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x256x32_stage3_warpsize2x4x1_g1_tensor16x8x16 Tactic: 8072087735545283117
[03/24/2023-12:56:41] [V] [TRT] Tactic: 8072087735545283117 Time: 0.103424
[03/24/2023-12:56:41] [V] [TRT] Conv_17 + Relu_18 Set Tactic Name: ampere_h16816cudnn_64x64_sliced1x2_ldg8_relu_exp_stages_64x5_medium_nhwc_tn_v1 Tactic: 8101703987960976805
[03/24/2023-12:56:41] [V] [TRT] Tactic: 8101703987960976805 Time: 0.08512
[03/24/2023-12:56:41] [V] [TRT] Conv_17 + Relu_18 Set Tactic Name: ampere_h16816cudnn_128x64_sliced1x2_ldg8_relu_exp_stages_64x4_small_nhwc_tn_v1 Tactic: 8170606396342855895
[03/24/2023-12:56:41] [V] [TRT] Tactic: 8170606396342855895 Time: 0.06656
[03/24/2023-12:56:41] [V] [TRT] Conv_17 + Relu_18 Set Tactic Name: sm75_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x32x64_stage1_warpsize2x1x2_g1_tensor16x8x8 Tactic: 8455608235315878803
[03/24/2023-12:56:41] [V] [TRT] Tactic: 8455608235315878803 Time: 0.113536
[03/24/2023-12:56:41] [V] [TRT] Conv_17 + Relu_18 Set Tactic Name: sm75_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x64x64_stage1_warpsize2x2x1_g1_tensor16x8x8 Tactic: 8668812313058150080
[03/24/2023-12:56:41] [V] [TRT] Tactic: 8668812313058150080 Time: 0.090752
[03/24/2023-12:56:41] [V] [TRT] Conv_17 + Relu_18 Set Tactic Name: ampere_h1688cudnn_256x64_ldg8_relu_exp_small_nhwc_tn_v1 Tactic: 8839784824303350101
[03/24/2023-12:56:41] [V] [TRT] Tactic: 8839784824303350101 Time: 0.09984
[03/24/2023-12:56:41] [V] [TRT] Conv_17 + Relu_18 Set Tactic Name: ampere_h16816cudnn_64x64_sliced1x2_ldg8_relu_exp_stages_64x5_large_nhwc_tn_v1 Tactic: -9217371357561775773
[03/24/2023-12:56:41] [V] [TRT] Tactic: -9217371357561775773 Time: 0.085504
[03/24/2023-12:56:41] [V] [TRT] Conv_17 + Relu_18 Set Tactic Name: ampere_h16816cudnn_256x64_sliced1x2_ldg8_relu_exp_medium_nhwc_tn_v1 Tactic: -9009272790678027912
[03/24/2023-12:56:41] [V] [TRT] Tactic: -9009272790678027912 Time: 0.083456
[03/24/2023-12:56:41] [V] [TRT] Conv_17 + Relu_18 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x32x32_stage4_warpsize4x1x1_g1_tensor16x8x16 Tactic: -8985224497679592364
[03/24/2023-12:56:41] [V] [TRT] Tactic: -8985224497679592364 Time: 0.08576
[03/24/2023-12:56:41] [V] [TRT] Conv_17 + Relu_18 Set Tactic Name: ampere_h16816cudnn_128x64_sliced1x2_ldg8_relu_exp_stages_64x3_large_nhwc_tn_v1 Tactic: -8949544755481315679
[03/24/2023-12:56:41] [V] [TRT] Tactic: -8949544755481315679 Time: 0.062208
[03/24/2023-12:56:41] [V] [TRT] Conv_17 + Relu_18 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x64x64_stage3_warpsize4x1x1_g1_tensor16x8x16_t1r3s3 Tactic: -8867999442759527766
[03/24/2023-12:56:41] [V] [TRT] Tactic: -8867999442759527766 Time: 0.071296
[03/24/2023-12:56:41] [V] [TRT] Conv_17 + Relu_18 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x128x64_stage3_warpsize2x2x1_g1_tensor16x8x16 Tactic: -8759929675070720385
[03/24/2023-12:56:41] [V] [TRT] Tactic: -8759929675070720385 Time: 0.063104
[03/24/2023-12:56:41] [V] [TRT] Conv_17 + Relu_18 Set Tactic Name: ampere_h16816cudnn_64x64_ldg8_relu_exp_stages_64x6_medium_nhwc_tn_v1 Tactic: -8604374562669615024
[03/24/2023-12:56:41] [V] [TRT] Tactic: -8604374562669615024 Time: 0.099328
[03/24/2023-12:56:41] [V] [TRT] Conv_17 + Relu_18 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x128x64_stage3_warpsize4x2x1_g1_tensor16x8x16 Tactic: -8362347876645295759
[03/24/2023-12:56:41] [V] [TRT] Tactic: -8362347876645295759 Time: 0.0736
[03/24/2023-12:56:41] [V] [TRT] Conv_17 + Relu_18 Set Tactic Name: sm75_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x128x32_stage1_warpsize4x2x1_g1_tensor16x8x8 Tactic: -8254009616492665198
[03/24/2023-12:56:41] [V] [TRT] Tactic: -8254009616492665198 Time: 0.084736
[03/24/2023-12:56:41] [V] [TRT] Conv_17 + Relu_18 Set Tactic Name: ampere_h16816cudnn_256x128_ldg8_relu_exp_stages_64x3_large_nhwc_tn_v1 Tactic: -7757610000269494813
[03/24/2023-12:56:41] [V] [TRT] Tactic: -7757610000269494813 Time: 0.075648
[03/24/2023-12:56:41] [V] [TRT] Conv_17 + Relu_18 Set Tactic Name: sm75_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x128x32_stage1_warpsize4x2x1_g1_tensor16x8x8 Tactic: -7615325597099025933
[03/24/2023-12:56:41] [V] [TRT] Tactic: -7615325597099025933 Time: 0.08832
[03/24/2023-12:56:41] [V] [TRT] Conv_17 + Relu_18 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x64x64_stage3_warpsize4x1x1_g1_tensor16x8x16 Tactic: -6917689122519989488
[03/24/2023-12:56:41] [V] [TRT] Tactic: -6917689122519989488 Time: 0.070272
[03/24/2023-12:56:41] [V] [TRT] Conv_17 + Relu_18 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x32x64_stage5_warpsize2x2x1_g1_tensor16x8x16_t1r3s3 Tactic: -6902925267326201166
[03/24/2023-12:56:41] [V] [TRT] Tactic: -6902925267326201166 Time: 0.118144
[03/24/2023-12:56:41] [V] [TRT] Conv_17 + Relu_18 Set Tactic Name: ampere_h16816cudnn_64x128_ldg8_relu_exp_stages_64x4_large_nhwc_tn_v1 Tactic: -6840588038605932325
[03/24/2023-12:56:41] [V] [TRT] Tactic: -6840588038605932325 Time: 0.06784
[03/24/2023-12:56:41] [V] [TRT] Conv_17 + Relu_18 Set Tactic Name: sm75_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x32x32_stage1_warpsize4x1x1_g1_tensor16x8x8 Tactic: -6828337260021572283
[03/24/2023-12:56:41] [V] [TRT] Tactic: -6828337260021572283 Time: 0.123904
[03/24/2023-12:56:41] [V] [TRT] Conv_17 + Relu_18 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x256x32_stage3_warpsize2x4x1_g1_tensor16x8x16 Tactic: -6799856376604253964
[03/24/2023-12:56:41] [V] [TRT] Tactic: -6799856376604253964 Time: 0.103296
[03/24/2023-12:56:41] [V] [TRT] Conv_17 + Relu_18 Set Tactic Name: sm75_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x32x32_stage1_warpsize4x1x1_g1_tensor16x8x8 Tactic: -6711815420995272523
[03/24/2023-12:56:41] [V] [TRT] Tactic: -6711815420995272523 Time: 0.11008
[03/24/2023-12:56:41] [V] [TRT] Conv_17 + Relu_18 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x32x32_stage4_warpsize4x1x1_g1_tensor16x8x16_t1r3s3 Tactic: -6625722781282978136
[03/24/2023-12:56:41] [V] [TRT] Tactic: -6625722781282978136 Time: 0.095104
[03/24/2023-12:56:41] [V] [TRT] Conv_17 + Relu_18 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x64x32_stage3_warpsize4x1x1_g1_tensor16x8x16 Tactic: -6525498856028268801
[03/24/2023-12:56:41] [V] [TRT] Tactic: -6525498856028268801 Time: 0.064384
[03/24/2023-12:56:41] [V] [TRT] Conv_17 + Relu_18 Set Tactic Name: sm75_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x256x64_stage1_warpsize1x4x2_g1_tensor16x8x8 Tactic: -6489479581011009593
[03/24/2023-12:56:41] [V] [TRT] Tactic: -6489479581011009593 Time: 0.118144
[03/24/2023-12:56:41] [V] [TRT] Conv_17 + Relu_18 Set Tactic Name: ampere_h16816cudnn_64x64_sliced1x2_ldg8_relu_exp_stages_64x6_medium_nhwc_tn_v1 Tactic: -6356316196810535311
[03/24/2023-12:56:41] [V] [TRT] Tactic: -6356316196810535311 Time: 0.098176
[03/24/2023-12:56:41] [V] [TRT] Conv_17 + Relu_18 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x32x32_stage4_warpsize4x1x1_g1_tensor16x8x16 Tactic: -6324345858751792783
[03/24/2023-12:56:41] [V] [TRT] Tactic: -6324345858751792783 Time: 0.095744
[03/24/2023-12:56:41] [V] [TRT] Conv_17 + Relu_18 Set Tactic Name: sm75_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x256x64_stage1_warpsize1x4x2_g1_tensor16x8x8_t1r3s3 Tactic: -6320761427625651496
[03/24/2023-12:56:41] [V] [TRT] Tactic: -6320761427625651496 Time: 0.116992
[03/24/2023-12:56:41] [V] [TRT] Conv_17 + Relu_18 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x256x32_stage3_warpsize2x4x1_g1_tensor16x8x16_t1r3s3 Tactic: -6262400699544994312
[03/24/2023-12:56:41] [V] [TRT] Tactic: -6262400699544994312 Time: 0.101888
[03/24/2023-12:56:41] [V] [TRT] Conv_17 + Relu_18 Set Tactic Name: ampere_h1688cudnn_128x128_ldg8_relu_exp_large_nhwc_tn_v1 Tactic: -6257787336162086472
[03/24/2023-12:56:41] [V] [TRT] Tactic: -6257787336162086472 Time: 0.090624
[03/24/2023-12:56:41] [V] [TRT] Conv_17 + Relu_18 Set Tactic Name: sm75_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x128x64_stage1_warpsize2x2x1_g1_tensor16x8x8 Tactic: -6080892721161662420
[03/24/2023-12:56:41] [V] [TRT] Tactic: -6080892721161662420 Time: 0.0672
[03/24/2023-12:56:41] [V] [TRT] Conv_17 + Relu_18 Set Tactic Name: ampere_h16816cudnn_128x64_ldg8_relu_exp_stages_64x4_small_nhwc_tn_v1 Tactic: -6063766379489217211
[03/24/2023-12:56:41] [V] [TRT] Tactic: -6063766379489217211 Time: 0.06848
[03/24/2023-12:56:41] [V] [TRT] Conv_17 + Relu_18 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x128x32_stage5_warpsize2x2x1_g1_tensor16x8x16 Tactic: -5777580938094193096
[03/24/2023-12:56:41] [V] [TRT] Tactic: -5777580938094193096 Time: 0.067584
[03/24/2023-12:56:41] [V] [TRT] Conv_17 + Relu_18 Set Tactic Name: sm75_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x128x64_stage1_warpsize2x2x1_g1_tensor16x8x8 Tactic: -5710735840878760115
[03/24/2023-12:56:41] [V] [TRT] Tactic: -5710735840878760115 Time: 0.069632
[03/24/2023-12:56:41] [V] [TRT] Conv_17 + Relu_18 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x128x32_stage3_warpsize4x2x1_g1_tensor16x8x16 Tactic: -5657273398217409378
[03/24/2023-12:56:41] [V] [TRT] Tactic: -5657273398217409378 Time: 0.07296
[03/24/2023-12:56:41] [V] [TRT] Conv_17 + Relu_18 Set Tactic Name: sm75_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x128x32_stage1_warpsize2x2x1_g1_tensor16x8x8_t1r3s3 Tactic: -5546257196173962281
[03/24/2023-12:56:41] [V] [TRT] Tactic: -5546257196173962281 Time: 0.080896
[03/24/2023-12:56:41] [V] [TRT] Conv_17 + Relu_18 Set Tactic Name: ampere_h16816cudnn_128x128_ldg8_relu_exp_small_nhwc_tn_v1 Tactic: -5530886555766748586
[03/24/2023-12:56:41] [V] [TRT] Tactic: -5530886555766748586 Time: 0.060416
[03/24/2023-12:56:41] [V] [TRT] Conv_17 + Relu_18 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x64x32_stage5_warpsize2x2x1_g1_tensor16x8x16_t1r3s3 Tactic: -5422685219138380548
[03/24/2023-12:56:41] [V] [TRT] Tactic: -5422685219138380548 Time: 0.068608
[03/24/2023-12:56:41] [V] [TRT] Conv_17 + Relu_18 Set Tactic Name: ampere_h16816cudnn_256x64_ldg8_relu_exp_stages_64x3_small_nhwc_tn_v1 Tactic: -5261787675443473128
[03/24/2023-12:56:41] [V] [TRT] Tactic: -5261787675443473128 Time: 0.064512
[03/24/2023-12:56:41] [V] [TRT] Conv_17 + Relu_18 Set Tactic Name: sm75_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x64x32_stage1_warpsize4x1x1_g1_tensor16x8x8 Tactic: -5198219374380660379
[03/24/2023-12:56:41] [V] [TRT] Tactic: -5198219374380660379 Time: 0.07936
[03/24/2023-12:56:41] [V] [TRT] Conv_17 + Relu_18 Set Tactic Name: ampere_h16816cudnn_64x128_sliced1x2_ldg8_relu_exp_stages_64x3_medium_nhwc_tn_v1 Tactic: -5161596964442251102
[03/24/2023-12:56:41] [V] [TRT] Tactic: -5161596964442251102 Time: 0.065792
[03/24/2023-12:56:41] [V] [TRT] Conv_17 + Relu_18 Set Tactic Name: ampere_h16816cudnn_64x128_ldg8_relu_exp_stages_64x3_medium_nhwc_tn_v1 Tactic: -5127240325355316006
[03/24/2023-12:56:41] [V] [TRT] Tactic: -5127240325355316006 Time: 0.073216
[03/24/2023-12:56:41] [V] [TRT] Conv_17 + Relu_18 Set Tactic Name: ampere_h16816cudnn_256x128_ldg8_relu_exp_stages_64x3_medium_nhwc_tn_v1 Tactic: -5109582882231362997
[03/24/2023-12:56:41] [V] [TRT] Tactic: -5109582882231362997 Time: 0.075776
[03/24/2023-12:56:41] [V] [TRT] Conv_17 + Relu_18 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x64x32_stage5_warpsize2x2x1_g1_tensor16x8x16 Tactic: -4825567853927730435
[03/24/2023-12:56:41] [V] [TRT] Tactic: -4825567853927730435 Time: 0.073216
[03/24/2023-12:56:41] [V] [TRT] Conv_17 + Relu_18 Set Tactic Name: ampere_h16816cudnn_64x128_sliced1x2_ldg8_relu_exp_stages_64x4_small_nhwc_tn_v1 Tactic: -4796511246675321840
[03/24/2023-12:56:41] [V] [TRT] Tactic: -4796511246675321840 Time: 0.06976
[03/24/2023-12:56:41] [V] [TRT] Conv_17 + Relu_18 Set Tactic Name: ampere_h16816cudnn_64x64_sliced1x2_ldg8_relu_exp_stages_64x6_large_nhwc_tn_v1 Tactic: -4706569565442112734
[03/24/2023-12:56:41] [V] [TRT] Tactic: -4706569565442112734 Time: 0.099328
[03/24/2023-12:56:41] [V] [TRT] Conv_17 + Relu_18 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x128x64_stage3_warpsize2x2x1_g1_tensor16x8x16_t1r3s3 Tactic: -4566599693570369588
[03/24/2023-12:56:41] [V] [TRT] Tactic: -4566599693570369588 Time: 0.064896
[03/24/2023-12:56:41] [V] [TRT] Conv_17 + Relu_18 Set Tactic Name: ampere_h16816cudnn_128x128_ldg8_relu_exp_stages_64x3_large_nhwc_tn_v1 Tactic: -4409144516525410768
[03/24/2023-12:56:41] [V] [TRT] Tactic: -4409144516525410768 Time: 0.063488
[03/24/2023-12:56:41] [V] [TRT] Conv_17 + Relu_18 Set Tactic Name: ampere_h16816cudnn_128x64_ldg8_relu_exp_stages_64x3_small_nhwc_tn_v1 Tactic: -4379519430184503304
[03/24/2023-12:56:41] [V] [TRT] Tactic: -4379519430184503304 Time: 0.064512
[03/24/2023-12:56:41] [V] [TRT] Conv_17 + Relu_18 Set Tactic Name: ampere_h1688cudnn_256x128_ldg8_relu_exp_small_nhwc_tn_v1 Tactic: -4152066959007262150
[03/24/2023-12:56:41] [V] [TRT] Tactic: -4152066959007262150 Time: 0.085632
[03/24/2023-12:56:41] [V] [TRT] Conv_17 + Relu_18 Set Tactic Name: ampere_h16816cudnn_64x128_ldg8_relu_exp_stages_64x4_medium_nhwc_tn_v1 Tactic: -4021926646879732549
[03/24/2023-12:56:41] [V] [TRT] Tactic: -4021926646879732549 Time: 0.067456
[03/24/2023-12:56:41] [V] [TRT] Conv_17 + Relu_18 Set Tactic Name: ampere_h16816cudnn_64x128_sliced1x2_ldg8_relu_exp_stages_64x4_medium_nhwc_tn_v1 Tactic: -3987638434926559037
[03/24/2023-12:56:41] [V] [TRT] Tactic: -3987638434926559037 Time: 0.06976
[03/24/2023-12:56:41] [V] [TRT] Conv_17 + Relu_18 Set Tactic Name: ampere_h1688cudnn_256x64_sliced1x2_ldg8_relu_exp_medium_nhwc_tn_v1 Tactic: -3905653247016903130
[03/24/2023-12:56:41] [V] [TRT] Tactic: -3905653247016903130 Time: 0.088064
[03/24/2023-12:56:41] [V] [TRT] Conv_17 + Relu_18 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x64x32_stage5_warpsize2x2x1_g1_tensor16x8x16 Tactic: -3903974568488493144
[03/24/2023-12:56:41] [V] [TRT] Tactic: -3903974568488493144 Time: 0.065664
[03/24/2023-12:56:41] [V] [TRT] Conv_17 + Relu_18 Set Tactic Name: ampere_h16816cudnn_64x128_ldg8_relu_exp_stages_64x3_large_nhwc_tn_v1 Tactic: -3895429239811098010
[03/24/2023-12:56:41] [V] [TRT] Tactic: -3895429239811098010 Time: 0.073344
[03/24/2023-12:56:41] [V] [TRT] Conv_17 + Relu_18 Set Tactic Name: ampere_h16816cudnn_256x64_ldg8_relu_exp_small_nhwc_tn_v1 Tactic: -3864869056275745423
[03/24/2023-12:56:41] [V] [TRT] Tactic: -3864869056275745423 Time: 0.0704
[03/24/2023-12:56:41] [V] [TRT] Conv_17 + Relu_18 Set Tactic Name: sm75_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x32x32_stage1_warpsize4x1x1_g1_tensor16x8x8_t1r3s3 Tactic: -3784342055748695733
[03/24/2023-12:56:41] [V] [TRT] Tactic: -3784342055748695733 Time: 0.11456
[03/24/2023-12:56:41] [V] [TRT] Conv_17 + Relu_18 Set Tactic Name: ampere_h16816cudnn_64x64_ldg8_relu_exp_stages_64x5_small_nhwc_tn_v1 Tactic: -3601464762214218301
[03/24/2023-12:56:41] [V] [TRT] Tactic: -3601464762214218301 Time: 0.090752
[03/24/2023-12:56:41] [V] [TRT] Conv_17 + Relu_18 Set Tactic Name: sm75_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x64x32_stage1_warpsize2x2x1_g1_tensor16x8x8 Tactic: -3425274793298557239
[03/24/2023-12:56:41] [V] [TRT] Tactic: -3425274793298557239 Time: 0.08128
[03/24/2023-12:56:41] [V] [TRT] Conv_17 + Relu_18 Set Tactic Name: ampere_h1688cudnn_256x64_sliced1x2_ldg8_relu_exp_large_nhwc_tn_v1 Tactic: -3412636942650049698
[03/24/2023-12:56:41] [V] [TRT] Tactic: -3412636942650049698 Time: 0.088832
[03/24/2023-12:56:41] [V] [TRT] Conv_17 + Relu_18 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x64x32_stage3_warpsize4x1x1_g1_tensor16x8x16 Tactic: -3338665856053412950
[03/24/2023-12:56:41] [V] [TRT] Tactic: -3338665856053412950 Time: 0.060672
[03/24/2023-12:56:41] [V] [TRT] Conv_17 + Relu_18 Set Tactic Name: sm75_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x128x32_stage1_warpsize2x2x1_g1_tensor16x8x8 Tactic: -3271955096576257018
[03/24/2023-12:56:41] [V] [TRT] Tactic: -3271955096576257018 Time: 0.082176
[03/24/2023-12:56:41] [V] [TRT] Conv_17 + Relu_18 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x128x64_stage3_warpsize4x2x1_g1_tensor16x8x16_t1r3s3 Tactic: -3243541398692466074
[03/24/2023-12:56:41] [V] [TRT] Tactic: -3243541398692466074 Time: 0.074752
[03/24/2023-12:56:41] [V] [TRT] Conv_17 + Relu_18 Set Tactic Name: ampere_h16816cudnn_64x128_sliced1x2_ldg8_relu_exp_stages_64x3_small_nhwc_tn_v1 Tactic: -3058330359340425555
[03/24/2023-12:56:41] [V] [TRT] Tactic: -3058330359340425555 Time: 0.065536
[03/24/2023-12:56:41] [V] [TRT] Conv_17 + Relu_18 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x256x64_stage3_warpsize1x4x1_g1_tensor16x8x16_t1r3s3 Tactic: -2899647483672319239
[03/24/2023-12:56:41] [V] [TRT] Tactic: -2899647483672319239 Time: 0.100096
[03/24/2023-12:56:41] [V] [TRT] Conv_17 + Relu_18 Set Tactic Name: ampere_h16816cudnn_256x64_sliced1x2_ldg8_relu_exp_large_nhwc_tn_v1 Tactic: -2816084650627734155
[03/24/2023-12:56:41] [V] [TRT] Tactic: -2816084650627734155 Time: 0.084736
[03/24/2023-12:56:41] [V] [TRT] Conv_17 + Relu_18 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x128x32_stage5_warpsize2x2x1_g1_tensor16x8x16 Tactic: -2662892962457732243
[03/24/2023-12:56:41] [V] [TRT] Tactic: -2662892962457732243 Time: 0.06784
[03/24/2023-12:56:41] [V] [TRT] Conv_17 + Relu_18 Set Tactic Name: ampere_h16816cudnn_256x128_ldg8_relu_exp_large_nhwc_tn_v1 Tactic: -2559894581585337900
[03/24/2023-12:56:41] [V] [TRT] Tactic: -2559894581585337900 Time: 0.076672
[03/24/2023-12:56:41] [V] [TRT] Conv_17 + Relu_18 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x32x32_stage4_warpsize4x1x1_g1_tensor16x8x16 Tactic: -2530740716768816092
[03/24/2023-12:56:41] [V] [TRT] Tactic: -2530740716768816092 Time: 0.085376
[03/24/2023-12:56:41] [V] [TRT] Conv_17 + Relu_18 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x128x32_stage4_warpsize2x2x1_g1_tensor16x8x16 Tactic: -2332828394978346992
[03/24/2023-12:56:41] [V] [TRT] Tactic: -2332828394978346992 Time: 0.057344
[03/24/2023-12:56:41] [V] [TRT] Conv_17 + Relu_18 Set Tactic Name: ampere_h1688cudnn_256x64_ldg8_relu_exp_large_nhwc_tn_v1 Tactic: -2241736083352441442
[03/24/2023-12:56:41] [V] [TRT] Tactic: -2241736083352441442 Time: 0.10752
[03/24/2023-12:56:41] [V] [TRT] Conv_17 + Relu_18 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x32x64_stage5_warpsize2x2x1_g1_tensor16x8x16 Tactic: -2161909437867201546
[03/24/2023-12:56:41] [V] [TRT] Tactic: -2161909437867201546 Time: 0.118144
[03/24/2023-12:56:41] [V] [TRT] Conv_17 + Relu_18 Set Tactic Name: ampere_h16816cudnn_256x64_ldg8_relu_exp_medium_nhwc_tn_v1 Tactic: -1985778916402815946
[03/24/2023-12:56:41] [V] [TRT] Tactic: -1985778916402815946 Time: 0.07296
[03/24/2023-12:56:41] [V] [TRT] Conv_17 + Relu_18 Set Tactic Name: sm75_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x256x32_stage1_warpsize2x4x1_g1_tensor16x8x8 Tactic: -1708101578041178688
[03/24/2023-12:56:41] [V] [TRT] Tactic: -1708101578041178688 Time: 0.12288
[03/24/2023-12:56:41] [V] [TRT] Conv_17 + Relu_18 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x64x64_stage3_warpsize4x1x1_g1_tensor16x8x16 Tactic: -1502788097503482299
[03/24/2023-12:56:41] [V] [TRT] Tactic: -1502788097503482299 Time: 0.071808
[03/24/2023-12:56:41] [V] [TRT] Conv_17 + Relu_18 Set Tactic Name: ampere_h16816cudnn_128x64_sliced1x2_ldg8_relu_exp_stages_64x4_large_nhwc_tn_v1 Tactic: -1500496213132463076
[03/24/2023-12:56:41] [V] [TRT] Tactic: -1500496213132463076 Time: 0.071552
[03/24/2023-12:56:41] [V] [TRT] Conv_17 + Relu_18 Set Tactic Name: ampere_h16816cudnn_64x64_ldg8_relu_exp_stages_64x6_small_nhwc_tn_v1 Tactic: -1099247066487349374
[03/24/2023-12:56:41] [V] [TRT] Tactic: -1099247066487349374 Time: 0.093184
[03/24/2023-12:56:41] [V] [TRT] Conv_17 + Relu_18 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x64x64_stage4_warpsize2x2x1_g1_tensor16x8x16 Tactic: -910286698936744682
[03/24/2023-12:56:41] [V] [TRT] Tactic: -910286698936744682 Time: 0.08576
[03/24/2023-12:56:41] [V] [TRT] Conv_17 + Relu_18 Set Tactic Name: sm75_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x256x32_stage1_warpsize2x4x1_g1_tensor16x8x8 Tactic: -907287437357565279
[03/24/2023-12:56:41] [V] [TRT] Tactic: -907287437357565279 Time: 0.119936
[03/24/2023-12:56:41] [V] [TRT] Conv_17 + Relu_18 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x32x32_stage4_warpsize4x1x1_g1_tensor16x8x16 Tactic: -606726295133751039
[03/24/2023-12:56:41] [V] [TRT] Tactic: -606726295133751039 Time: 0.094592
[03/24/2023-12:56:41] [V] [TRT] Fastest Tactic: 6972489290272968208 Time: 0.05632
[03/24/2023-12:56:41] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: 6972489290272968208
[03/24/2023-12:56:41] [V] [TRT] *************** Autotuning format combination: Half(259200,1:16,1440,8) -> Half(259200,1:16,1440,8) ***************
[03/24/2023-12:56:41] [V] [TRT] --------------- Timing Runner: Conv_17 + Relu_18 (CudnnConvolution)
[03/24/2023-12:56:41] [V] [TRT] CudnnConvolution has no valid tactics for this config, skipping
[03/24/2023-12:56:41] [V] [TRT] --------------- Timing Runner: Conv_17 + Relu_18 (CaskConvolution)
[03/24/2023-12:56:41] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[03/24/2023-12:56:41] [V] [TRT] =============== Computing costs for 
[03/24/2023-12:56:41] [V] [TRT] *************** Autotuning format combination: Float(4147200,32400,180,1) -> Float(4147200,32400,180,1) ***************
[03/24/2023-12:56:41] [V] [TRT] *************** Autotuning format combination: Float(4147200,1,23040,128) -> Float(4147200,1,23040,128) ***************
[03/24/2023-12:56:41] [V] [TRT] *************** Autotuning format combination: Float(1036800,1:4,5760,32) -> Float(1036800,1:4,5760,32) ***************
[03/24/2023-12:56:41] [V] [TRT] *************** Autotuning format combination: Half(4147200,32400,180,1) -> Half(4147200,32400,180,1) ***************
[03/24/2023-12:56:41] [V] [TRT] *************** Autotuning format combination: Half(2073600,32400:2,180,1) -> Half(2073600,32400:2,180,1) ***************
[03/24/2023-12:56:41] [V] [TRT] *************** Autotuning format combination: Half(518400,1:8,2880,16) -> Float(4147200,32400,180,1) ***************
[03/24/2023-12:56:41] [V] [TRT] *************** Autotuning format combination: Half(518400,1:8,2880,16) -> Half(518400,1:8,2880,16) ***************
[03/24/2023-12:56:41] [V] [TRT] *************** Autotuning format combination: Half(259200,1:16,1440,8) -> Half(259200,1:16,1440,8) ***************
[03/24/2023-12:56:41] [V] [TRT] =============== Computing costs for 
[03/24/2023-12:56:41] [V] [TRT] *************** Autotuning format combination: Float(4147200,32400,180,1) -> Float(4147200,32400,180,1) ***************
[03/24/2023-12:56:41] [V] [TRT] *************** Autotuning format combination: Float(4147200,1,23040,128) -> Float(4147200,1,23040,128) ***************
[03/24/2023-12:56:41] [V] [TRT] *************** Autotuning format combination: Float(1036800,1:4,5760,32) -> Float(1036800,1:4,5760,32) ***************
[03/24/2023-12:56:41] [V] [TRT] *************** Autotuning format combination: Half(4147200,32400,180,1) -> Half(4147200,32400,180,1) ***************
[03/24/2023-12:56:41] [V] [TRT] *************** Autotuning format combination: Half(2073600,32400:2,180,1) -> Half(2073600,32400:2,180,1) ***************
[03/24/2023-12:56:41] [V] [TRT] *************** Autotuning format combination: Half(518400,1:8,2880,16) -> Float(4147200,32400,180,1) ***************
[03/24/2023-12:56:41] [V] [TRT] *************** Autotuning format combination: Half(518400,1:8,2880,16) -> Half(518400,1:8,2880,16) ***************
[03/24/2023-12:56:41] [V] [TRT] *************** Autotuning format combination: Half(259200,1:16,1440,8) -> Half(259200,1:16,1440,8) ***************
[03/24/2023-12:56:41] [V] [TRT] =============== Computing costs for 
[03/24/2023-12:56:41] [V] [TRT] *************** Autotuning format combination: Float(4147200,32400,180,1) -> Float(4147200,32400,180,1) ***************
[03/24/2023-12:56:41] [V] [TRT] *************** Autotuning format combination: Float(4147200,1,23040,128) -> Float(4147200,1,23040,128) ***************
[03/24/2023-12:56:41] [V] [TRT] *************** Autotuning format combination: Float(1036800,1:4,5760,32) -> Float(1036800,1:4,5760,32) ***************
[03/24/2023-12:56:41] [V] [TRT] *************** Autotuning format combination: Half(4147200,32400,180,1) -> Half(4147200,32400,180,1) ***************
[03/24/2023-12:56:41] [V] [TRT] *************** Autotuning format combination: Half(2073600,32400:2,180,1) -> Half(2073600,32400:2,180,1) ***************
[03/24/2023-12:56:41] [V] [TRT] *************** Autotuning format combination: Half(518400,1:8,2880,16) -> Float(4147200,32400,180,1) ***************
[03/24/2023-12:56:41] [V] [TRT] *************** Autotuning format combination: Half(518400,1:8,2880,16) -> Half(518400,1:8,2880,16) ***************
[03/24/2023-12:56:41] [V] [TRT] *************** Autotuning format combination: Half(259200,1:16,1440,8) -> Half(259200,1:16,1440,8) ***************
[03/24/2023-12:56:41] [V] [TRT] =============== Computing costs for 
[03/24/2023-12:56:41] [V] [TRT] *************** Autotuning format combination: Float(4147200,32400,180,1) -> Float(4147200,32400,180,1) ***************
[03/24/2023-12:56:41] [V] [TRT] *************** Autotuning format combination: Float(4147200,1,23040,128) -> Float(4147200,1,23040,128) ***************
[03/24/2023-12:56:42] [V] [TRT] *************** Autotuning format combination: Float(1036800,1:4,5760,32) -> Float(1036800,1:4,5760,32) ***************
[03/24/2023-12:56:42] [V] [TRT] *************** Autotuning format combination: Half(4147200,32400,180,1) -> Half(4147200,32400,180,1) ***************
[03/24/2023-12:56:42] [V] [TRT] *************** Autotuning format combination: Half(2073600,32400:2,180,1) -> Half(2073600,32400:2,180,1) ***************
[03/24/2023-12:56:42] [V] [TRT] *************** Autotuning format combination: Half(518400,1:8,2880,16) -> Float(4147200,32400,180,1) ***************
[03/24/2023-12:56:42] [V] [TRT] *************** Autotuning format combination: Half(518400,1:8,2880,16) -> Half(518400,1:8,2880,16) ***************
[03/24/2023-12:56:42] [V] [TRT] *************** Autotuning format combination: Half(259200,1:16,1440,8) -> Half(259200,1:16,1440,8) ***************
[03/24/2023-12:56:42] [V] [TRT] =============== Computing costs for 
[03/24/2023-12:56:42] [V] [TRT] *************** Autotuning format combination: Float(4147200,32400,180,1) -> Float(16588800,32400,180,1) ***************
[03/24/2023-12:56:42] [V] [TRT] --------------- Timing Runner: Conv_27 + Relu_28 (CudaDepthwiseConvolution)
[03/24/2023-12:56:42] [V] [TRT] CudaDepthwiseConvolution has no valid tactics for this config, skipping
[03/24/2023-12:56:42] [V] [TRT] --------------- Timing Runner: Conv_27 + Relu_28 (FusedConvActConvolution)
[03/24/2023-12:56:42] [V] [TRT] Tactic: 589823 Time: 0.459776
[03/24/2023-12:56:42] [V] [TRT] Tactic: 655359 Time: 0.361728
[03/24/2023-12:56:42] [V] [TRT] Tactic: 786431 Time: 0.34432
[03/24/2023-12:56:42] [V] [TRT] Tactic: 851967 Time: 0.371584
[03/24/2023-12:56:42] [V] [TRT] Tactic: 1179647 Time: 0.35968
[03/24/2023-12:56:42] [V] [TRT] Tactic: 1310719 Time: 0.449024
[03/24/2023-12:56:42] [V] [TRT] Tactic: 1376255 Time: 0.358784
[03/24/2023-12:56:42] [V] [TRT] Tactic: 1441791 Time: 0.469504
[03/24/2023-12:56:42] [V] [TRT] Tactic: 1507327 Time: 0.341888
[03/24/2023-12:56:42] [V] [TRT] Tactic: 1638399 Time: 0.36928
[03/24/2023-12:56:42] [V] [TRT] Tactic: 1835007 Time: 0.373888
[03/24/2023-12:56:42] [V] [TRT] Tactic: 1900543 Time: 0.384256
[03/24/2023-12:56:42] [V] [TRT] Tactic: 2097151 Time: 0.374912
[03/24/2023-12:56:42] [V] [TRT] Tactic: 2162687 Time: 0.369792
[03/24/2023-12:56:42] [V] [TRT] Tactic: 2293759 Time: 0.381824
[03/24/2023-12:56:42] [V] [TRT] Tactic: 2359295 Time: 0.32
[03/24/2023-12:56:42] [V] [TRT] Tactic: 2686975 Time: 0.360448
[03/24/2023-12:56:42] [V] [TRT] Tactic: 3080191 Time: 0.340608
[03/24/2023-12:56:42] [V] [TRT] Tactic: 3342335 Time: 0.34304
[03/24/2023-12:56:42] [V] [TRT] Tactic: 3407871 Time: 0.340608
[03/24/2023-12:56:42] [V] [TRT] Tactic: 3538943 Time: 0.330496
[03/24/2023-12:56:42] [V] [TRT] Tactic: 3670015 Time: 0.436352
[03/24/2023-12:56:42] [V] [TRT] Tactic: 3932159 Time: 0.363904
[03/24/2023-12:56:42] [V] [TRT] Tactic: 3997695 Time: 0.344192
[03/24/2023-12:56:42] [V] [TRT] Tactic: 4063231 Time: 0.360704
[03/24/2023-12:56:42] [V] [TRT] Tactic: 4194303 Time: 0.322048
[03/24/2023-12:56:42] [V] [TRT] Tactic: 4259839 Time: 0.35328
[03/24/2023-12:56:42] [V] [TRT] Tactic: 4325375 Time: 0.315264
[03/24/2023-12:56:42] [V] [TRT] Tactic: 4521983 Time: 0.379648
[03/24/2023-12:56:42] [V] [TRT] Tactic: 4587519 Time: 0.311168
[03/24/2023-12:56:42] [V] [TRT] Tactic: 4653055 Time: 0.34432
[03/24/2023-12:56:42] [V] [TRT] Tactic: 4915199 Time: 0.320128
[03/24/2023-12:56:42] [V] [TRT] Tactic: 4980735 Time: 0.326272
[03/24/2023-12:56:42] [V] [TRT] Tactic: 5177343 Time: 0.373632
[03/24/2023-12:56:42] [V] [TRT] Tactic: 5242879 Time: 0.34048
[03/24/2023-12:56:42] [V] [TRT] Tactic: 5373951 Time: 0.443136
[03/24/2023-12:56:42] [V] [TRT] Tactic: 5439487 Time: 0.561408
[03/24/2023-12:56:43] [V] [TRT] Tactic: 5570559 Time: 0.347264
[03/24/2023-12:56:43] [V] [TRT] Tactic: 5636095 Time: 0.359424
[03/24/2023-12:56:43] [V] [TRT] Tactic: 5701631 Time: 0.395392
[03/24/2023-12:56:43] [V] [TRT] Tactic: 5767167 Time: 1.46637
[03/24/2023-12:56:43] [V] [TRT] Tactic: 5832703 Time: 0.33408
[03/24/2023-12:56:43] [V] [TRT] Tactic: 5898239 Time: 0.339968
[03/24/2023-12:56:43] [V] [TRT] Tactic: 6029311 Time: 0.3744
[03/24/2023-12:56:43] [V] [TRT] Tactic: 6225919 Time: 0.340224
[03/24/2023-12:56:43] [V] [TRT] Tactic: 6291455 Time: 0.359168
[03/24/2023-12:56:43] [V] [TRT] Tactic: 6422527 Time: 0.341504
[03/24/2023-12:56:43] [V] [TRT] Tactic: 6750207 Time: 0.40192
[03/24/2023-12:56:43] [V] [TRT] Tactic: 6815743 Time: 0.415104
[03/24/2023-12:56:43] [V] [TRT] Tactic: 6946815 Time: 0.51584
[03/24/2023-12:56:43] [V] [TRT] Tactic: 7012351 Time: 0.3744
[03/24/2023-12:56:43] [V] [TRT] Tactic: 7077887 Time: 0.32896
[03/24/2023-12:56:43] [V] [TRT] Tactic: 7143423 Time: 0.552704
[03/24/2023-12:56:43] [V] [TRT] Tactic: 7208959 Time: 0.349952
[03/24/2023-12:56:43] [V] [TRT] Tactic: 7340031 Time: 0.348928
[03/24/2023-12:56:43] [V] [TRT] Tactic: 7405567 Time: 0.353408
[03/24/2023-12:56:43] [V] [TRT] Tactic: 7536639 Time: 0.458496
[03/24/2023-12:56:43] [V] [TRT] Tactic: 7602175 Time: 0.357248
[03/24/2023-12:56:43] [V] [TRT] Tactic: 7733247 Time: 0.318848
[03/24/2023-12:56:43] [V] [TRT] Tactic: 7798783 Time: 0.346112
[03/24/2023-12:56:43] [V] [TRT] Tactic: 8191999 Time: 0.492032
[03/24/2023-12:56:43] [V] [TRT] Tactic: 8257535 Time: 0.346752
[03/24/2023-12:56:43] [V] [TRT] Tactic: 8323071 Time: 0.39168
[03/24/2023-12:56:43] [V] [TRT] Tactic: 8650751 Time: 0.397824
[03/24/2023-12:56:43] [V] [TRT] Tactic: 8716287 Time: 0.434304
[03/24/2023-12:56:43] [V] [TRT] Tactic: 9109503 Time: 0.38144
[03/24/2023-12:56:43] [V] [TRT] Tactic: 9568255 Time: 0.320384
[03/24/2023-12:56:43] [V] [TRT] Tactic: 9895935 Time: 0.322048
[03/24/2023-12:56:43] [V] [TRT] Tactic: 10223615 Time: 0.360704
[03/24/2023-12:56:43] [V] [TRT] Tactic: 10354687 Time: 0.345728
[03/24/2023-12:56:43] [V] [TRT] Tactic: 10551295 Time: 0.432128
[03/24/2023-12:56:43] [V] [TRT] Tactic: 10747903 Time: 0.312192
[03/24/2023-12:56:44] [V] [TRT] Tactic: 10944511 Time: 0.326528
[03/24/2023-12:56:44] [V] [TRT] Fastest Tactic: 4587519 Time: 0.311168
[03/24/2023-12:56:44] [V] [TRT] --------------- Timing Runner: Conv_27 + Relu_28 (CudnnConvolution)
[03/24/2023-12:56:44] [V] [TRT] Tactic: 0 Time: 0.299136
[03/24/2023-12:56:44] [V] [TRT] Tactic: 1 Time: 0.191744
[03/24/2023-12:56:44] [V] [TRT] Tactic: 2 Time: 0.37504
[03/24/2023-12:56:44] [V] [TRT] Tactic: 4 skipped. Scratch requested: 17381851136, available: 4294967296
[03/24/2023-12:56:44] [V] [TRT] Tactic: 5 Time: 0.494208
[03/24/2023-12:56:44] [V] [TRT] Tactic: 56 Time: 0.29952
[03/24/2023-12:56:44] [V] [TRT] Tactic: 57 Time: 0.191104
[03/24/2023-12:56:44] [V] [TRT] Tactic: 58 Time: 0.374656
[03/24/2023-12:56:44] [V] [TRT] Tactic: 60 skipped. Scratch requested: 17381851136, available: 4294967296
[03/24/2023-12:56:44] [V] [TRT] Tactic: 61 Time: 0.492032
[03/24/2023-12:56:44] [V] [TRT] Tactic: 112 Time: 0.299136
[03/24/2023-12:56:44] [V] [TRT] Tactic: 113 Time: 0.243968
[03/24/2023-12:56:44] [V] [TRT] Tactic: 114 Time: 0.374784
[03/24/2023-12:56:44] [V] [TRT] Tactic: 116 skipped. Scratch requested: 17381851136, available: 4294967296
[03/24/2023-12:56:44] [V] [TRT] Tactic: 117 Time: 0.494208
[03/24/2023-12:56:44] [V] [TRT] Fastest Tactic: 57 Time: 0.191104
[03/24/2023-12:56:44] [V] [TRT] Setting workspace to 17381851136enables more tactics for profiling
[03/24/2023-12:56:44] [V] [TRT] --------------- Timing Runner: Conv_27 + Relu_28 (CublasConvolution)
[03/24/2023-12:56:44] [V] [TRT] CublasConvolution has no valid tactics for this config, skipping
[03/24/2023-12:56:44] [V] [TRT] --------------- Timing Runner: Conv_27 + Relu_28 (CaskConvolution)
[03/24/2023-12:56:44] [V] [TRT] Conv_27 + Relu_28 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_tf32f32_f32_nchwkrsc_nchw_tilesize64x128x32_stage5_warpsize2x2x1_g1_tensor16x8x8_t1r1s1_aligna4_alignc4 Tactic: 621442388677115936
[03/24/2023-12:56:44] [V] [TRT] Tactic: 621442388677115936 Time: 0.137216
[03/24/2023-12:56:44] [V] [TRT] Conv_27 + Relu_28 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_tf32f32_f32_nchwkrsc_nchw_tilesize64x32x64_stage5_warpsize2x2x1_g1_tensor16x8x8_simple_t1r1s1_aligna4_alignc4 Tactic: 697756878388249475
[03/24/2023-12:56:44] [V] [TRT] Tactic: 697756878388249475 Time: 0.209408
[03/24/2023-12:56:44] [V] [TRT] Conv_27 + Relu_28 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_tf32f32_f32_nchwkrsc_nchw_tilesize128x64x32_stage5_warpsize2x2x1_g1_tensor16x8x8_simple_t1r1s1_aligna4_alignc4 Tactic: 1159272950022995759
[03/24/2023-12:56:44] [V] [TRT] Tactic: 1159272950022995759 Time: 0.132608
[03/24/2023-12:56:44] [V] [TRT] Conv_27 + Relu_28 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_tf32f32_f32_nchwkrsc_nchw_tilesize64x32x64_stage5_warpsize2x2x1_g1_tensor16x8x8_t1r1s1_aligna4_alignc4 Tactic: 1327459216264546184
[03/24/2023-12:56:44] [V] [TRT] Tactic: 1327459216264546184 Time: 0.267008
[03/24/2023-12:56:44] [V] [TRT] Conv_27 + Relu_28 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_tf32f32_f32_nchwkrsc_nchw_tilesize128x256x32_stage3_warpsize2x4x1_g1_tensor16x8x8_simple_t1r1s1_aligna4_alignc4 Tactic: 2310520233542099555
[03/24/2023-12:56:44] [V] [TRT] Tactic: 2310520233542099555 Time: 0.107136
[03/24/2023-12:56:44] [V] [TRT] Conv_27 + Relu_28 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_tf32f32_f32_nchwkrsc_nchw_tilesize128x64x32_stage5_warpsize2x2x1_g1_tensor16x8x8_t1r1s1_aligna4_alignc4 Tactic: 4032904638566464623
[03/24/2023-12:56:44] [V] [TRT] Tactic: 4032904638566464623 Time: 0.145536
[03/24/2023-12:56:44] [V] [TRT] Conv_27 + Relu_28 Set Tactic Name: ampere_scudnn_128x64_relu_small_nn_v1 Tactic: 4549827808004681195
[03/24/2023-12:56:44] [V] [TRT] Tactic: 4549827808004681195 Time: 0.144768
[03/24/2023-12:56:44] [V] [TRT] Conv_27 + Relu_28 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_tf32f32_f32_nchwkrsc_nchw_tilesize128x64x64_stage3_warpsize2x2x1_g1_tensor16x8x8_t1r1s1_aligna4_alignc4 Tactic: 4918658762935651592
[03/24/2023-12:56:44] [V] [TRT] Tactic: 4918658762935651592 Time: 0.196352
[03/24/2023-12:56:44] [V] [TRT] Conv_27 + Relu_28 Set Tactic Name: ampere_scudnn_128x128_relu_small_nn_v1 Tactic: 5779835512569528575
[03/24/2023-12:56:44] [V] [TRT] Tactic: 5779835512569528575 Time: 0.139648
[03/24/2023-12:56:44] [V] [TRT] Conv_27 + Relu_28 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_tf32f32_f32_nchwkrsc_nchw_tilesize256x128x32_stage3_warpsize4x2x1_g1_tensor16x8x8_t1r1s1_aligna4_alignc4 Tactic: 5837905844602864231
[03/24/2023-12:56:44] [V] [TRT] Tactic: 5837905844602864231 Time: 0.127616
[03/24/2023-12:56:44] [V] [TRT] Conv_27 + Relu_28 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_tf32f32_f32_nchwkrsc_nchw_tilesize128x128x32_stage4_warpsize2x2x1_g1_tensor16x8x8_simple_t1r1s1_aligna4_alignc4 Tactic: 6166883504066133838
[03/24/2023-12:56:44] [V] [TRT] Tactic: 6166883504066133838 Time: 0.143488
[03/24/2023-12:56:44] [V] [TRT] Conv_27 + Relu_28 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_tf32f32_f32_nchwkrsc_nchw_tilesize256x64x32_stage3_warpsize4x2x1_g1_tensor16x8x8_t1r1s1_aligna4_alignc4 Tactic: 6210049212073459059
[03/24/2023-12:56:44] [V] [TRT] Tactic: 6210049212073459059 Time: 0.109568
[03/24/2023-12:56:44] [V] [TRT] Conv_27 + Relu_28 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_tf32f32_f32_nchwkrsc_nchw_tilesize128x64x64_stage3_warpsize2x2x1_g1_tensor16x8x8_simple_t1r1s1_aligna4_alignc4 Tactic: 6500866402607985231
[03/24/2023-12:56:44] [V] [TRT] Tactic: 6500866402607985231 Time: 0.153856
[03/24/2023-12:56:44] [V] [TRT] Conv_27 + Relu_28 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_tf32f32_f32_nchwkrsc_nchw_tilesize256x64x32_stage3_warpsize4x2x1_g1_tensor16x8x8_simple_t1r1s1_aligna4_alignc4 Tactic: 6723161876874263939
[03/24/2023-12:56:44] [V] [TRT] Tactic: 6723161876874263939 Time: 0.099584
[03/24/2023-12:56:44] [V] [TRT] Conv_27 + Relu_28 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_tf32f32_f32_nchwkrsc_nchw_tilesize64x128x32_stage5_warpsize2x2x1_g1_tensor16x8x8_simple_t1r1s1_aligna4_alignc4 Tactic: 6868013466259746979
[03/24/2023-12:56:44] [V] [TRT] Tactic: 6868013466259746979 Time: 0.114432
[03/24/2023-12:56:44] [V] [TRT] Conv_27 + Relu_28 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_tf32f32_f32_nchwkrsc_nchw_tilesize64x64x64_stage4_warpsize2x2x1_g1_tensor16x8x8_simple_t1r1s1_aligna4_alignc4 Tactic: 6901214267543238617
[03/24/2023-12:56:44] [V] [TRT] Tactic: 6901214267543238617 Time: 0.155648
[03/24/2023-12:56:44] [V] [TRT] Conv_27 + Relu_28 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_tf32f32_f32_nchwkrsc_nchw_tilesize128x128x32_stage4_warpsize2x2x1_g1_tensor16x8x8_t1r1s1_aligna4_alignc4 Tactic: 8048119769507926928
[03/24/2023-12:56:44] [V] [TRT] Tactic: 8048119769507926928 Time: 0.14592
[03/24/2023-12:56:44] [V] [TRT] Conv_27 + Relu_28 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_tf32f32_f32_nchwkrsc_nchw_tilesize128x128x16_stage4_warpsize2x2x1_g1_tensor16x8x8_t1r1s1_aligna4_alignc4 Tactic: 9151672657204310840
[03/24/2023-12:56:44] [V] [TRT] Tactic: 9151672657204310840 Time: 0.108544
[03/24/2023-12:56:44] [V] [TRT] Conv_27 + Relu_28 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_tf32f32_f32_nchwkrsc_nchw_tilesize256x128x32_stage3_warpsize4x2x1_g1_tensor16x8x8_simple_t1r1s1_aligna4_alignc4 Tactic: -8877086111929938764
[03/24/2023-12:56:44] [V] [TRT] Tactic: -8877086111929938764 Time: 0.118144
[03/24/2023-12:56:44] [V] [TRT] Conv_27 + Relu_28 Set Tactic Name: ampere_scudnn_128x32_relu_interior_nn_v1 Tactic: -7491730084094677098
[03/24/2023-12:56:44] [V] [TRT] Tactic: -7491730084094677098 Time: 0.155008
[03/24/2023-12:56:44] [V] [TRT] Conv_27 + Relu_28 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_tf32f32_f32_nchwkrsc_nchw_tilesize128x128x16_stage4_warpsize2x2x1_g1_tensor16x8x8_simple_t1r1s1_aligna4_alignc4 Tactic: -6622064180404051845
[03/24/2023-12:56:44] [V] [TRT] Tactic: -6622064180404051845 Time: 0.10688
[03/24/2023-12:56:44] [V] [TRT] Conv_27 + Relu_28 Set Tactic Name: ampere_scudnn_128x32_relu_small_nn_v1 Tactic: -6313876406580483184
[03/24/2023-12:56:44] [V] [TRT] Tactic: -6313876406580483184 Time: 0.164224
[03/24/2023-12:56:44] [V] [TRT] Conv_27 + Relu_28 Set Tactic Name: ampere_scudnn_128x128_relu_interior_nn_v1 Tactic: -6273689210331812572
[03/24/2023-12:56:44] [V] [TRT] Tactic: -6273689210331812572 Time: 0.13888
[03/24/2023-12:56:44] [V] [TRT] Conv_27 + Relu_28 Set Tactic Name: ampere_scudnn_128x64_relu_interior_nn_v1 Tactic: -4337126844824617177
[03/24/2023-12:56:44] [V] [TRT] Tactic: -4337126844824617177 Time: 0.139648
[03/24/2023-12:56:44] [V] [TRT] Conv_27 + Relu_28 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_tf32f32_f32_nchwkrsc_nchw_tilesize128x256x32_stage3_warpsize2x4x1_g1_tensor16x8x8_t1r1s1_aligna4_alignc4 Tactic: -2777237991111865351
[03/24/2023-12:56:44] [V] [TRT] Tactic: -2777237991111865351 Time: 0.106624
[03/24/2023-12:56:44] [V] [TRT] Conv_27 + Relu_28 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_tf32f32_f32_nchwkrsc_nchw_tilesize64x64x64_stage4_warpsize2x2x1_g1_tensor16x8x8_t1r1s1_aligna4_alignc4 Tactic: -1349585930542925704
[03/24/2023-12:56:44] [V] [TRT] Tactic: -1349585930542925704 Time: 0.186752
[03/24/2023-12:56:44] [V] [TRT] Conv_27 + Relu_28 Set Tactic Name: ampere_scudnn_128x128_relu_medium_nn_v1 Tactic: -1123676555321336786
[03/24/2023-12:56:44] [V] [TRT] Tactic: -1123676555321336786 Time: 0.14016
[03/24/2023-12:56:44] [V] [TRT] Conv_27 + Relu_28 Set Tactic Name: ampere_scudnn_128x64_relu_medium_nn_v1 Tactic: -701551393537224327
[03/24/2023-12:56:44] [V] [TRT] Tactic: -701551393537224327 Time: 0.145664
[03/24/2023-12:56:44] [V] [TRT] Fastest Tactic: 6723161876874263939 Time: 0.099584
[03/24/2023-12:56:44] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: 6723161876874263939
[03/24/2023-12:56:44] [V] [TRT] *************** Autotuning format combination: Float(4147200,1,23040,128) -> Float(16588800,1,92160,512) ***************
[03/24/2023-12:56:44] [V] [TRT] --------------- Timing Runner: Conv_27 + Relu_28 (CudnnConvolution)
[03/24/2023-12:56:44] [V] [TRT] CudnnConvolution has no valid tactics for this config, skipping
[03/24/2023-12:56:44] [V] [TRT] --------------- Timing Runner: Conv_27 + Relu_28 (CublasConvolution)
[03/24/2023-12:56:44] [V] [TRT] CublasConvolution has no valid tactics for this config, skipping
[03/24/2023-12:56:44] [V] [TRT] --------------- Timing Runner: Conv_27 + Relu_28 (CaskConvolution)
[03/24/2023-12:56:44] [V] [TRT] Conv_27 + Relu_28 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize256x128x8_stage3_warpsize2x4x1_g1_ffma_t1r1s1 Tactic: 676988335020687107
[03/24/2023-12:56:44] [V] [TRT] Tactic: 676988335020687107 Time: 0.180992
[03/24/2023-12:56:44] [V] [TRT] Conv_27 + Relu_28 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize128x256x8_stage3_warpsize2x4x1_g1_ffma_t1r1s1 Tactic: 1149579359391877453
[03/24/2023-12:56:44] [V] [TRT] Tactic: 1149579359391877453 Time: 0.179584
[03/24/2023-12:56:44] [V] [TRT] Conv_27 + Relu_28 Set Tactic Name: ampere_scudnn_128x128_relu_exp_interior_nhwc_tn_v1 Tactic: 1663866669559596164
[03/24/2023-12:56:44] [V] [TRT] Tactic: 1663866669559596164 Time: 0.139008
[03/24/2023-12:56:44] [V] [TRT] Conv_27 + Relu_28 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize64x64x8_stage3_warpsize1x4x1_g1_ffma_t1r1s1 Tactic: 1995961315573863697
[03/24/2023-12:56:44] [V] [TRT] Tactic: 1995961315573863697 Time: 0.136832
[03/24/2023-12:56:44] [V] [TRT] Conv_27 + Relu_28 Set Tactic Name: ampere_scudnn_128x64_sliced1x2_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: 2860655430572478466
[03/24/2023-12:56:44] [V] [TRT] Tactic: 2860655430572478466 Time: 0.143488
[03/24/2023-12:56:44] [V] [TRT] Conv_27 + Relu_28 Set Tactic Name: ampere_scudnn_128x32_sliced1x4_ldg4_relu_exp_medium_nhwc_tn_v1 Tactic: 4474630279712975759
[03/24/2023-12:56:44] [V] [TRT] Tactic: 4474630279712975759 Time: 0.150528
[03/24/2023-12:56:44] [V] [TRT] Conv_27 + Relu_28 Set Tactic Name: ampere_scudnn_128x32_sliced1x4_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: 4479823862704990365
[03/24/2023-12:56:44] [V] [TRT] Tactic: 4479823862704990365 Time: 0.149632
[03/24/2023-12:56:44] [V] [TRT] Conv_27 + Relu_28 Set Tactic Name: ampere_scudnn_128x64_sliced1x2_ldg4_relu_exp_medium_nhwc_tn_v1 Tactic: 4696204239951173149
[03/24/2023-12:56:44] [V] [TRT] Tactic: 4696204239951173149 Time: 0.144256
[03/24/2023-12:56:44] [V] [TRT] Conv_27 + Relu_28 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize128x64x8_stage3_warpsize1x4x1_g1_ffma_t1r1s1 Tactic: 5061046663754203417
[03/24/2023-12:56:44] [V] [TRT] Tactic: 5061046663754203417 Time: 0.153216
[03/24/2023-12:56:44] [V] [TRT] Conv_27 + Relu_28 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize256x64x8_stage3_warpsize1x4x1_g1_ffma_t1r1s1 Tactic: 5660369513040054181
[03/24/2023-12:56:44] [V] [TRT] Tactic: 5660369513040054181 Time: 0.193024
[03/24/2023-12:56:44] [V] [TRT] Conv_27 + Relu_28 Set Tactic Name: ampere_scudnn_128x128_relu_exp_small_nhwc_tn_v1 Tactic: 5778138195697110003
[03/24/2023-12:56:44] [V] [TRT] Tactic: 5778138195697110003 Time: 0.139264
[03/24/2023-12:56:44] [V] [TRT] Conv_27 + Relu_28 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize64x256x8_stage3_warpsize1x4x1_g1_ffma_t1r1s1 Tactic: 6002893715742835901
[03/24/2023-12:56:44] [V] [TRT] Tactic: 6002893715742835901 Time: 0.179712
[03/24/2023-12:56:44] [V] [TRT] Conv_27 + Relu_28 Set Tactic Name: ampere_scudnn_128x128_ldg4_relu_exp_medium_nhwc_tn_v1 Tactic: 8918020581761223752
[03/24/2023-12:56:44] [V] [TRT] Tactic: 8918020581761223752 Time: 0.137984
[03/24/2023-12:56:44] [V] [TRT] Conv_27 + Relu_28 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize64x128x8_stage3_warpsize1x4x1_g1_ffma_t1r1s1 Tactic: -7609160790790750215
[03/24/2023-12:56:44] [V] [TRT] Tactic: -7609160790790750215 Time: 0.14208
[03/24/2023-12:56:44] [V] [TRT] Conv_27 + Relu_28 Set Tactic Name: ampere_scudnn_128x64_sliced1x2_ldg4_relu_exp_interior_nhwc_tn_v1 Tactic: -5905193483742532701
[03/24/2023-12:56:44] [V] [TRT] Tactic: -5905193483742532701 Time: 0.139392
[03/24/2023-12:56:44] [V] [TRT] Conv_27 + Relu_28 Set Tactic Name: ampere_scudnn_128x32_sliced1x4_ldg4_relu_exp_interior_nhwc_tn_v1 Tactic: -4035591156787122265
[03/24/2023-12:56:44] [V] [TRT] Tactic: -4035591156787122265 Time: 0.148352
[03/24/2023-12:56:44] [V] [TRT] Conv_27 + Relu_28 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize128x128x8_stage3_warpsize2x4x1_g1_ffma_t1r1s1 Tactic: -3829074795144908279
[03/24/2023-12:56:44] [V] [TRT] Tactic: -3829074795144908279 Time: 0.153344
[03/24/2023-12:56:44] [V] [TRT] Conv_27 + Relu_28 Set Tactic Name: ampere_scudnn_128x128_relu_exp_medium_nhwc_tn_v1 Tactic: -2809379259463049391
[03/24/2023-12:56:44] [V] [TRT] Tactic: -2809379259463049391 Time: 0.139392
[03/24/2023-12:56:44] [V] [TRT] Conv_27 + Relu_28 Set Tactic Name: ampere_scudnn_128x128_ldg4_relu_exp_interior_nhwc_tn_v1 Tactic: -1985235291706575900
[03/24/2023-12:56:44] [V] [TRT] Tactic: -1985235291706575900 Time: 0.138368
[03/24/2023-12:56:44] [V] [TRT] Conv_27 + Relu_28 Set Tactic Name: ampere_scudnn_128x128_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: -504296718212024303
[03/24/2023-12:56:44] [V] [TRT] Tactic: -504296718212024303 Time: 0.138368
[03/24/2023-12:56:44] [V] [TRT] Fastest Tactic: 1995961315573863697 Time: 0.136832
[03/24/2023-12:56:44] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: 1995961315573863697
[03/24/2023-12:56:44] [V] [TRT] *************** Autotuning format combination: Float(1036800,1:4,5760,32) -> Float(4147200,1:4,23040,128) ***************
[03/24/2023-12:56:44] [V] [TRT] --------------- Timing Runner: Conv_27 + Relu_28 (CudnnConvolution)
[03/24/2023-12:56:44] [V] [TRT] CudnnConvolution has no valid tactics for this config, skipping
[03/24/2023-12:56:44] [V] [TRT] --------------- Timing Runner: Conv_27 + Relu_28 (CublasConvolution)
[03/24/2023-12:56:44] [V] [TRT] CublasConvolution has no valid tactics for this config, skipping
[03/24/2023-12:56:44] [V] [TRT] --------------- Timing Runner: Conv_27 + Relu_28 (CaskConvolution)
[03/24/2023-12:56:44] [V] [TRT] Conv_27 + Relu_28 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize256x128x8_stage3_warpsize2x4x1_g1_ffma_t1r1s1 Tactic: 676988335020687107
[03/24/2023-12:56:44] [V] [TRT] Tactic: 676988335020687107 Time: 0.180864
[03/24/2023-12:56:44] [V] [TRT] Conv_27 + Relu_28 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize128x256x8_stage3_warpsize2x4x1_g1_ffma_t1r1s1 Tactic: 1149579359391877453
[03/24/2023-12:56:44] [V] [TRT] Tactic: 1149579359391877453 Time: 0.1792
[03/24/2023-12:56:44] [V] [TRT] Conv_27 + Relu_28 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x128x16_stage4_warpsize2x2x1_g1_tensor16x8x8_t1r1s1 Tactic: 1373022415249282411
[03/24/2023-12:56:44] [V] [TRT] Tactic: 1373022415249282411 Time: 0.058496
[03/24/2023-12:56:44] [V] [TRT] Conv_27 + Relu_28 Set Tactic Name: ampere_scudnn_128x128_relu_exp_interior_nhwc_tn_v1 Tactic: 1663866669559596164
[03/24/2023-12:56:44] [V] [TRT] Tactic: 1663866669559596164 Time: 0.138752
[03/24/2023-12:56:44] [V] [TRT] Conv_27 + Relu_28 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize64x64x8_stage3_warpsize1x4x1_g1_ffma_t1r1s1 Tactic: 1995961315573863697
[03/24/2023-12:56:44] [V] [TRT] Tactic: 1995961315573863697 Time: 0.136832
[03/24/2023-12:56:44] [V] [TRT] Conv_27 + Relu_28 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize256x64x32_stage3_warpsize4x2x1_g1_tensor16x8x8_t1r1s1 Tactic: 2536540085349545921
[03/24/2023-12:56:44] [V] [TRT] Tactic: 2536540085349545921 Time: 0.060928
[03/24/2023-12:56:44] [V] [TRT] Conv_27 + Relu_28 Set Tactic Name: ampere_scudnn_128x64_sliced1x2_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: 2860655430572478466
[03/24/2023-12:56:44] [V] [TRT] Tactic: 2860655430572478466 Time: 0.143744
[03/24/2023-12:56:44] [V] [TRT] Conv_27 + Relu_28 Set Tactic Name: ampere_scudnn_128x32_sliced1x4_ldg4_relu_exp_medium_nhwc_tn_v1 Tactic: 4474630279712975759
[03/24/2023-12:56:44] [V] [TRT] Tactic: 4474630279712975759 Time: 0.150656
[03/24/2023-12:56:44] [V] [TRT] Conv_27 + Relu_28 Set Tactic Name: ampere_scudnn_128x32_sliced1x4_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: 4479823862704990365
[03/24/2023-12:56:44] [V] [TRT] Tactic: 4479823862704990365 Time: 0.149376
[03/24/2023-12:56:44] [V] [TRT] Conv_27 + Relu_28 Set Tactic Name: ampere_scudnn_128x64_sliced1x2_ldg4_relu_exp_medium_nhwc_tn_v1 Tactic: 4696204239951173149
[03/24/2023-12:56:44] [V] [TRT] Tactic: 4696204239951173149 Time: 0.143872
[03/24/2023-12:56:44] [V] [TRT] Conv_27 + Relu_28 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize128x64x8_stage3_warpsize1x4x1_g1_ffma_t1r1s1 Tactic: 5061046663754203417
[03/24/2023-12:56:44] [V] [TRT] Tactic: 5061046663754203417 Time: 0.153088
[03/24/2023-12:56:44] [V] [TRT] Conv_27 + Relu_28 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize256x64x8_stage3_warpsize1x4x1_g1_ffma_t1r1s1 Tactic: 5660369513040054181
[03/24/2023-12:56:44] [V] [TRT] Tactic: 5660369513040054181 Time: 0.19328
[03/24/2023-12:56:44] [V] [TRT] Conv_27 + Relu_28 Set Tactic Name: ampere_scudnn_128x128_relu_exp_small_nhwc_tn_v1 Tactic: 5778138195697110003
[03/24/2023-12:56:44] [V] [TRT] Tactic: 5778138195697110003 Time: 0.139264
[03/24/2023-12:56:44] [V] [TRT] Conv_27 + Relu_28 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize64x256x8_stage3_warpsize1x4x1_g1_ffma_t1r1s1 Tactic: 6002893715742835901
[03/24/2023-12:56:44] [V] [TRT] Tactic: 6002893715742835901 Time: 0.178816
[03/24/2023-12:56:44] [V] [TRT] Conv_27 + Relu_28 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x128x32_stage4_warpsize2x2x1_g1_tensor16x8x8_t1r1s1 Tactic: 6031243482516294286
[03/24/2023-12:56:44] [V] [TRT] Tactic: 6031243482516294286 Time: 0.064384
[03/24/2023-12:56:44] [V] [TRT] Conv_27 + Relu_28 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize64x128x32_stage5_warpsize2x2x1_g1_tensor16x8x8_t1r1s1 Tactic: 6832381412128253616
[03/24/2023-12:56:44] [V] [TRT] Tactic: 6832381412128253616 Time: 0.06976
[03/24/2023-12:56:44] [V] [TRT] Conv_27 + Relu_28 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x64x64_stage3_warpsize2x2x1_g1_tensor16x8x8_t1r1s1 Tactic: 7058864664858220889
[03/24/2023-12:56:44] [V] [TRT] Tactic: 7058864664858220889 Time: 0.081152
[03/24/2023-12:56:44] [V] [TRT] Conv_27 + Relu_28 Set Tactic Name: ampere_scudnn_128x128_ldg4_relu_exp_medium_nhwc_tn_v1 Tactic: 8918020581761223752
[03/24/2023-12:56:44] [V] [TRT] Tactic: 8918020581761223752 Time: 0.138112
[03/24/2023-12:56:44] [V] [TRT] Conv_27 + Relu_28 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize64x128x8_stage3_warpsize1x4x1_g1_ffma_t1r1s1 Tactic: -7609160790790750215
[03/24/2023-12:56:44] [V] [TRT] Tactic: -7609160790790750215 Time: 0.141952
[03/24/2023-12:56:44] [V] [TRT] Conv_27 + Relu_28 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize64x64x64_stage4_warpsize2x2x1_g1_tensor16x8x8_t1r1s1 Tactic: -6407735577805887428
[03/24/2023-12:56:44] [V] [TRT] Tactic: -6407735577805887428 Time: 0.094848
[03/24/2023-12:56:44] [V] [TRT] Conv_27 + Relu_28 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize256x128x32_stage3_warpsize4x2x1_g1_tensor16x8x8_t1r1s1 Tactic: -6073218138311523634
[03/24/2023-12:56:44] [V] [TRT] Tactic: -6073218138311523634 Time: 0.06144
[03/24/2023-12:56:44] [V] [TRT] Conv_27 + Relu_28 Set Tactic Name: ampere_scudnn_128x64_sliced1x2_ldg4_relu_exp_interior_nhwc_tn_v1 Tactic: -5905193483742532701
[03/24/2023-12:56:44] [V] [TRT] Tactic: -5905193483742532701 Time: 0.139264
[03/24/2023-12:56:44] [V] [TRT] Conv_27 + Relu_28 Set Tactic Name: ampere_scudnn_128x32_sliced1x4_ldg4_relu_exp_interior_nhwc_tn_v1 Tactic: -4035591156787122265
[03/24/2023-12:56:44] [V] [TRT] Tactic: -4035591156787122265 Time: 0.148224
[03/24/2023-12:56:44] [V] [TRT] Conv_27 + Relu_28 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize128x128x8_stage3_warpsize2x4x1_g1_ffma_t1r1s1 Tactic: -3829074795144908279
[03/24/2023-12:56:44] [V] [TRT] Tactic: -3829074795144908279 Time: 0.153216
[03/24/2023-12:56:44] [V] [TRT] Conv_27 + Relu_28 Set Tactic Name: ampere_scudnn_128x128_relu_exp_medium_nhwc_tn_v1 Tactic: -2809379259463049391
[03/24/2023-12:56:44] [V] [TRT] Tactic: -2809379259463049391 Time: 0.139776
[03/24/2023-12:56:44] [V] [TRT] Conv_27 + Relu_28 Set Tactic Name: ampere_scudnn_128x128_ldg4_relu_exp_interior_nhwc_tn_v1 Tactic: -1985235291706575900
[03/24/2023-12:56:44] [V] [TRT] Tactic: -1985235291706575900 Time: 0.13824
[03/24/2023-12:56:44] [V] [TRT] Conv_27 + Relu_28 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x256x32_stage3_warpsize2x4x1_g1_tensor16x8x8_t1r1s1 Tactic: -1450865838092804082
[03/24/2023-12:56:44] [V] [TRT] Tactic: -1450865838092804082 Time: 0.060288
[03/24/2023-12:56:44] [V] [TRT] Conv_27 + Relu_28 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize64x32x64_stage5_warpsize2x2x1_g1_tensor16x8x8_t1r1s1 Tactic: -1366318165940453381
[03/24/2023-12:56:44] [V] [TRT] Tactic: -1366318165940453381 Time: 0.142848
[03/24/2023-12:56:44] [V] [TRT] Conv_27 + Relu_28 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x64x32_stage5_warpsize2x2x1_g1_tensor16x8x8_t1r1s1 Tactic: -1138876066247138089
[03/24/2023-12:56:44] [V] [TRT] Tactic: -1138876066247138089 Time: 0.0736
[03/24/2023-12:56:44] [V] [TRT] Conv_27 + Relu_28 Set Tactic Name: ampere_scudnn_128x128_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: -504296718212024303
[03/24/2023-12:56:44] [V] [TRT] Tactic: -504296718212024303 Time: 0.138368
[03/24/2023-12:56:44] [V] [TRT] Fastest Tactic: 1373022415249282411 Time: 0.058496
[03/24/2023-12:56:44] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: 1373022415249282411
[03/24/2023-12:56:44] [V] [TRT] *************** Autotuning format combination: Half(4147200,32400,180,1) -> Half(16588800,32400,180,1) ***************
[03/24/2023-12:56:44] [V] [TRT] --------------- Timing Runner: Conv_27 + Relu_28 (CudnnConvolution)
[03/24/2023-12:56:44] [V] [TRT] Tactic: 0 Time: 0.249728
[03/24/2023-12:56:44] [V] [TRT] Tactic: 1 Time: 0.200704
[03/24/2023-12:56:44] [V] [TRT] Tactic: 2 Time: 0.323584
[03/24/2023-12:56:44] [V] [TRT] Tactic: 4 skipped. Scratch requested: 17381851136, available: 4294967296
[03/24/2023-12:56:44] [V] [TRT] Tactic: 5 Time: 0.443136
[03/24/2023-12:56:44] [V] [TRT] Tactic: 56 Time: 0.250112
[03/24/2023-12:56:44] [V] [TRT] Tactic: 58 Time: 0.324224
[03/24/2023-12:56:44] [V] [TRT] Tactic: 60 skipped. Scratch requested: 17381851136, available: 4294967296
[03/24/2023-12:56:44] [V] [TRT] Tactic: 61 Time: 0.440448
[03/24/2023-12:56:44] [V] [TRT] Fastest Tactic: 1 Time: 0.200704
[03/24/2023-12:56:44] [V] [TRT] Setting workspace to 17381851136enables more tactics for profiling
[03/24/2023-12:56:44] [V] [TRT] --------------- Timing Runner: Conv_27 + Relu_28 (CublasConvolution)
[03/24/2023-12:56:44] [V] [TRT] CublasConvolution has no valid tactics for this config, skipping
[03/24/2023-12:56:44] [V] [TRT] --------------- Timing Runner: Conv_27 + Relu_28 (CaskConvolution)
[03/24/2023-12:56:44] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[03/24/2023-12:56:44] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CudnnConvolution Tactic: 1
[03/24/2023-12:56:44] [V] [TRT] *************** Autotuning format combination: Half(2073600,32400:2,180,1) -> Half(16588800,32400,180,1) ***************
[03/24/2023-12:56:44] [V] [TRT] --------------- Timing Runner: Conv_27 + Relu_28 (CaskConvolution)
[03/24/2023-12:56:44] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[03/24/2023-12:56:44] [V] [TRT] *************** Autotuning format combination: Half(2073600,32400:2,180,1) -> Half(8294400,32400:2,180,1) ***************
[03/24/2023-12:56:44] [V] [TRT] --------------- Timing Runner: Conv_27 + Relu_28 (FusedConvActConvolution)
[03/24/2023-12:56:44] [V] [TRT] Tactic: 589823 Time: 0.182784
[03/24/2023-12:56:44] [V] [TRT] Tactic: 655359 Time: 0.177024
[03/24/2023-12:56:44] [V] [TRT] Tactic: 786431 Time: 0.190976
[03/24/2023-12:56:44] [V] [TRT] Tactic: 851967 Time: 0.174848
[03/24/2023-12:56:44] [V] [TRT] Tactic: 1179647 Time: 0.178688
[03/24/2023-12:56:44] [V] [TRT] Tactic: 1310719 Time: 0.26944
[03/24/2023-12:56:44] [V] [TRT] Tactic: 1376255 Time: 0.176512
[03/24/2023-12:56:44] [V] [TRT] Tactic: 1441791 Time: 0.182656
[03/24/2023-12:56:44] [V] [TRT] Tactic: 1507327 Time: 0.169344
[03/24/2023-12:56:44] [V] [TRT] Tactic: 1638399 Time: 0.185728
[03/24/2023-12:56:44] [V] [TRT] Tactic: 1835007 Time: 0.1888
[03/24/2023-12:56:45] [V] [TRT] Tactic: 1900543 Time: 0.155776
[03/24/2023-12:56:45] [V] [TRT] Tactic: 2097151 Time: 0.229376
[03/24/2023-12:56:45] [V] [TRT] Tactic: 2162687 Time: 0.158592
[03/24/2023-12:56:45] [V] [TRT] Tactic: 2293759 Time: 0.157184
[03/24/2023-12:56:45] [V] [TRT] Tactic: 2359295 Time: 0.153088
[03/24/2023-12:56:45] [V] [TRT] Tactic: 2686975 Time: 0.15744
[03/24/2023-12:56:45] [V] [TRT] Tactic: 3080191 Time: 0.16128
[03/24/2023-12:56:45] [V] [TRT] Tactic: 3342335 Time: 0.1728
[03/24/2023-12:56:45] [V] [TRT] Tactic: 3407871 Time: 0.151168
[03/24/2023-12:56:45] [V] [TRT] Tactic: 3538943 Time: 0.159744
[03/24/2023-12:56:45] [V] [TRT] Tactic: 3670015 Time: 0.161024
[03/24/2023-12:56:45] [V] [TRT] Tactic: 3932159 Time: 0.154112
[03/24/2023-12:56:45] [V] [TRT] Tactic: 3997695 Time: 0.198784
[03/24/2023-12:56:45] [V] [TRT] Tactic: 4063231 Time: 0.17856
[03/24/2023-12:56:45] [V] [TRT] Tactic: 4194303 Time: 0.172672
[03/24/2023-12:56:45] [V] [TRT] Tactic: 4259839 Time: 0.212096
[03/24/2023-12:56:45] [V] [TRT] Tactic: 4325375 Time: 0.163328
[03/24/2023-12:56:45] [V] [TRT] Tactic: 4521983 Time: 0.158976
[03/24/2023-12:56:45] [V] [TRT] Tactic: 4587519 Time: 0.183808
[03/24/2023-12:56:45] [V] [TRT] Tactic: 4653055 Time: 0.179072
[03/24/2023-12:56:45] [V] [TRT] Tactic: 4915199 Time: 0.182016
[03/24/2023-12:56:45] [V] [TRT] Tactic: 4980735 Time: 0.15616
[03/24/2023-12:56:45] [V] [TRT] Tactic: 5177343 Time: 0.187008
[03/24/2023-12:56:45] [V] [TRT] Tactic: 5242879 Time: 0.153088
[03/24/2023-12:56:45] [V] [TRT] Tactic: 5373951 Time: 0.221952
[03/24/2023-12:56:45] [V] [TRT] Tactic: 5439487 Time: 0.276608
[03/24/2023-12:56:45] [V] [TRT] Tactic: 5570559 Time: 0.168704
[03/24/2023-12:56:45] [V] [TRT] Tactic: 5636095 Time: 0.178304
[03/24/2023-12:56:45] [V] [TRT] Tactic: 5701631 Time: 0.168192
[03/24/2023-12:56:45] [V] [TRT] Tactic: 5767167 Time: 0.74304
[03/24/2023-12:56:45] [V] [TRT] Tactic: 5832703 Time: 0.1536
[03/24/2023-12:56:45] [V] [TRT] Tactic: 5898239 Time: 0.177792
[03/24/2023-12:56:45] [V] [TRT] Tactic: 6029311 Time: 0.157312
[03/24/2023-12:56:45] [V] [TRT] Tactic: 6225919 Time: 0.164992
[03/24/2023-12:56:45] [V] [TRT] Tactic: 6291455 Time: 0.179072
[03/24/2023-12:56:45] [V] [TRT] Tactic: 6422527 Time: 0.154752
[03/24/2023-12:56:45] [V] [TRT] Tactic: 6750207 Time: 0.210816
[03/24/2023-12:56:45] [V] [TRT] Tactic: 6815743 Time: 0.19712
[03/24/2023-12:56:45] [V] [TRT] Tactic: 6946815 Time: 0.256
[03/24/2023-12:56:45] [V] [TRT] Tactic: 7012351 Time: 0.22912
[03/24/2023-12:56:45] [V] [TRT] Tactic: 7077887 Time: 0.157312
[03/24/2023-12:56:45] [V] [TRT] Tactic: 7143423 Time: 0.269312
[03/24/2023-12:56:45] [V] [TRT] Tactic: 7208959 Time: 0.163712
[03/24/2023-12:56:45] [V] [TRT] Tactic: 7340031 Time: 0.174592
[03/24/2023-12:56:45] [V] [TRT] Tactic: 7405567 Time: 0.164096
[03/24/2023-12:56:45] [V] [TRT] Tactic: 7536639 Time: 0.199936
[03/24/2023-12:56:45] [V] [TRT] Tactic: 7602175 Time: 0.184448
[03/24/2023-12:56:45] [V] [TRT] Tactic: 7733247 Time: 0.173952
[03/24/2023-12:56:45] [V] [TRT] Tactic: 7798783 Time: 0.190592
[03/24/2023-12:56:45] [V] [TRT] Tactic: 8191999 Time: 0.23808
[03/24/2023-12:56:45] [V] [TRT] Tactic: 8257535 Time: 0.193536
[03/24/2023-12:56:45] [V] [TRT] Tactic: 8323071 Time: 0.194816
[03/24/2023-12:56:45] [V] [TRT] Tactic: 8650751 Time: 0.204416
[03/24/2023-12:56:45] [V] [TRT] Tactic: 8716287 Time: 0.21568
[03/24/2023-12:56:46] [V] [TRT] Tactic: 9109503 Time: 0.234624
[03/24/2023-12:56:46] [V] [TRT] Tactic: 9568255 Time: 0.182016
[03/24/2023-12:56:46] [V] [TRT] Tactic: 9895935 Time: 0.173056
[03/24/2023-12:56:46] [V] [TRT] Tactic: 10223615 Time: 0.157312
[03/24/2023-12:56:46] [V] [TRT] Tactic: 10354687 Time: 0.188672
[03/24/2023-12:56:46] [V] [TRT] Tactic: 10551295 Time: 0.199168
[03/24/2023-12:56:46] [V] [TRT] Tactic: 10747903 Time: 0.168576
[03/24/2023-12:56:46] [V] [TRT] Tactic: 10944511 Time: 0.156416
[03/24/2023-12:56:46] [V] [TRT] Fastest Tactic: 3407871 Time: 0.151168
[03/24/2023-12:56:46] [V] [TRT] --------------- Timing Runner: Conv_27 + Relu_28 (CudnnConvolution)
[03/24/2023-12:56:46] [V] [TRT] CudnnConvolution has no valid tactics for this config, skipping
[03/24/2023-12:56:46] [V] [TRT] --------------- Timing Runner: Conv_27 + Relu_28 (CublasConvolution)
[03/24/2023-12:56:46] [V] [TRT] CublasConvolution has no valid tactics for this config, skipping
[03/24/2023-12:56:46] [V] [TRT] --------------- Timing Runner: Conv_27 + Relu_28 (CaskConvolution)
[03/24/2023-12:56:46] [V] [TRT] Conv_27 + Relu_28 Set Tactic Name: ampere_fp16x2_hcudnn_fp16x2_128x32_relu_medium_nn_v1 Tactic: 2195670545862694453
[03/24/2023-12:56:46] [V] [TRT] Tactic: 2195670545862694453 Time: 0.085504
[03/24/2023-12:56:46] [V] [TRT] Conv_27 + Relu_28 Set Tactic Name: ampere_fp16x2_hcudnn_fp16x2_128x128_relu_medium_nn_v1 Tactic: 3891805945559659536
[03/24/2023-12:56:46] [V] [TRT] Tactic: 3891805945559659536 Time: 0.090496
[03/24/2023-12:56:46] [V] [TRT] Conv_27 + Relu_28 Set Tactic Name: ampere_fp16x2_hcudnn_fp16x2_128x64_relu_interior_nn_v1 Tactic: 4418200634486186714
[03/24/2023-12:56:46] [V] [TRT] Tactic: 4418200634486186714 Time: 0.078848
[03/24/2023-12:56:46] [V] [TRT] Conv_27 + Relu_28 Set Tactic Name: ampere_fp16x2_hcudnn_fp16x2_128x64_relu_medium_nn_v1 Tactic: 5548126322150286555
[03/24/2023-12:56:46] [V] [TRT] Tactic: 5548126322150286555 Time: 0.079872
[03/24/2023-12:56:46] [V] [TRT] Conv_27 + Relu_28 Set Tactic Name: ampere_fp16x2_hcudnn_fp16x2_128x64_relu_small_nn_v1 Tactic: 6057304366605292508
[03/24/2023-12:56:46] [V] [TRT] Tactic: 6057304366605292508 Time: 0.079872
[03/24/2023-12:56:46] [V] [TRT] Conv_27 + Relu_28 Set Tactic Name: ampere_fp16x2_hcudnn_fp16x2_128x32_relu_interior_nn_v1 Tactic: 7392644644614664811
[03/24/2023-12:56:46] [V] [TRT] Tactic: 7392644644614664811 Time: 0.08192
[03/24/2023-12:56:46] [V] [TRT] Conv_27 + Relu_28 Set Tactic Name: ampere_fp16x2_hcudnn_fp16x2_128x128_relu_interior_nn_v1 Tactic: -4884039206922900293
[03/24/2023-12:56:46] [V] [TRT] Tactic: -4884039206922900293 Time: 0.077824
[03/24/2023-12:56:46] [V] [TRT] Conv_27 + Relu_28 Set Tactic Name: ampere_fp16x2_hcudnn_fp16x2_128x32_relu_small_nn_v1 Tactic: -4374269919094467161
[03/24/2023-12:56:46] [V] [TRT] Tactic: -4374269919094467161 Time: 0.084096
[03/24/2023-12:56:46] [V] [TRT] Conv_27 + Relu_28 Set Tactic Name: ampere_fp16x2_hcudnn_fp16x2_128x128_relu_small_nn_v1 Tactic: -1546027692247304867
[03/24/2023-12:56:46] [V] [TRT] Tactic: -1546027692247304867 Time: 0.09152
[03/24/2023-12:56:46] [V] [TRT] Fastest Tactic: -4884039206922900293 Time: 0.077824
[03/24/2023-12:56:46] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: -4884039206922900293
[03/24/2023-12:56:46] [V] [TRT] *************** Autotuning format combination: Half(518400,1:8,2880,16) -> Float(16588800,32400,180,1) ***************
[03/24/2023-12:56:46] [V] [TRT] --------------- Timing Runner: Conv_27 + Relu_28 (CudnnConvolution)
[03/24/2023-12:56:46] [V] [TRT] CudnnConvolution has no valid tactics for this config, skipping
[03/24/2023-12:56:46] [V] [TRT] --------------- Timing Runner: Conv_27 + Relu_28 (CublasConvolution)
[03/24/2023-12:56:46] [V] [TRT] CublasConvolution has no valid tactics for this config, skipping
[03/24/2023-12:56:46] [V] [TRT] --------------- Timing Runner: Conv_27 + Relu_28 (CaskConvolution)
[03/24/2023-12:56:46] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[03/24/2023-12:56:46] [V] [TRT] *************** Autotuning format combination: Half(518400,1:8,2880,16) -> Half(2073600,1:8,11520,64) ***************
[03/24/2023-12:56:46] [V] [TRT] --------------- Timing Runner: Conv_27 + Relu_28 (CudaDepthwiseConvolution)
[03/24/2023-12:56:46] [V] [TRT] CudaDepthwiseConvolution has no valid tactics for this config, skipping
[03/24/2023-12:56:46] [V] [TRT] --------------- Timing Runner: Conv_27 + Relu_28 (CudnnConvolution)
[03/24/2023-12:56:46] [V] [TRT] Tactic: 0 Time: 0.281472
[03/24/2023-12:56:46] [V] [TRT] Tactic: 1 Time: 0.38528
[03/24/2023-12:56:46] [V] [TRT] Tactic: 2 Time: 0.327296
[03/24/2023-12:56:46] [V] [TRT] Tactic: 56 Time: 0.2816
[03/24/2023-12:56:46] [V] [TRT] Tactic: 58 Time: 0.32704
[03/24/2023-12:56:46] [V] [TRT] Fastest Tactic: 0 Time: 0.281472
[03/24/2023-12:56:46] [V] [TRT] --------------- Timing Runner: Conv_27 + Relu_28 (CublasConvolution)
[03/24/2023-12:56:46] [V] [TRT] CublasConvolution has no valid tactics for this config, skipping
[03/24/2023-12:56:46] [V] [TRT] --------------- Timing Runner: Conv_27 + Relu_28 (CaskConvolution)
[03/24/2023-12:56:46] [V] [TRT] Conv_27 + Relu_28 Set Tactic Name: ampere_h16816cudnn_256x128_ldg8_relu_exp_medium_nhwc_tn_v1 Tactic: 254850674756030979
[03/24/2023-12:56:46] [V] [TRT] Tactic: 254850674756030979 Time: 0.03584
[03/24/2023-12:56:46] [V] [TRT] Conv_27 + Relu_28 Set Tactic Name: ampere_h16816cudnn_256x128_ldg8_relu_exp_stages_64x3_small_nhwc_tn_v1 Tactic: 1016009564074305832
[03/24/2023-12:56:46] [V] [TRT] Tactic: 1016009564074305832 Time: 0.038144
[03/24/2023-12:56:46] [V] [TRT] Conv_27 + Relu_28 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x64x64_stage3_warpsize4x1x1_g1_tensor16x8x16_t1r1s1 Tactic: 1044128949445110119
[03/24/2023-12:56:46] [V] [TRT] Tactic: 1044128949445110119 Time: 0.043008
[03/24/2023-12:56:46] [V] [TRT] Conv_27 + Relu_28 Set Tactic Name: ampere_h1688cudnn_128x128_ldg8_relu_exp_medium_nhwc_tn_v1 Tactic: 1156328698016730421
[03/24/2023-12:56:46] [V] [TRT] Tactic: 1156328698016730421 Time: 0.036352
[03/24/2023-12:56:46] [V] [TRT] Conv_27 + Relu_28 Set Tactic Name: ampere_h1688cudnn_256x64_ldg8_relu_exp_interior_nhwc_tn_v1 Tactic: 1362727228442059924
[03/24/2023-12:56:46] [V] [TRT] Tactic: 1362727228442059924 Time: 0.037888
[03/24/2023-12:56:46] [V] [TRT] Conv_27 + Relu_28 Set Tactic Name: ampere_h16816cudnn_64x128_sliced1x2_ldg8_relu_exp_stages_64x4_interior_nhwc_tn_v1 Tactic: 1576319725282257846
[03/24/2023-12:56:46] [V] [TRT] Tactic: 1576319725282257846 Time: 0.057344
[03/24/2023-12:56:46] [V] [TRT] Conv_27 + Relu_28 Set Tactic Name: ampere_h16816cudnn_128x64_ldg8_relu_exp_stages_64x4_medium_nhwc_tn_v1 Tactic: 1832046141070096030
[03/24/2023-12:56:46] [V] [TRT] Tactic: 1832046141070096030 Time: 0.056704
[03/24/2023-12:56:46] [V] [TRT] Conv_27 + Relu_28 Set Tactic Name: ampere_h16816cudnn_128x64_sliced1x2_ldg8_relu_exp_stages_64x3_small_nhwc_tn_v1 Tactic: 1838082074606840426
[03/24/2023-12:56:46] [V] [TRT] Tactic: 1838082074606840426 Time: 0.043008
[03/24/2023-12:56:46] [V] [TRT] Conv_27 + Relu_28 Set Tactic Name: ampere_h16816cudnn_64x64_sliced1x2_ldg8_relu_exp_stages_64x5_small_nhwc_tn_v1 Tactic: 1899296423087490472
[03/24/2023-12:56:46] [V] [TRT] Tactic: 1899296423087490472 Time: 0.064512
[03/24/2023-12:56:46] [V] [TRT] Conv_27 + Relu_28 Set Tactic Name: ampere_h16816cudnn_64x128_sliced1x2_ldg8_relu_exp_stages_64x3_interior_nhwc_tn_v1 Tactic: 2238656696610018305
[03/24/2023-12:56:46] [V] [TRT] Tactic: 2238656696610018305 Time: 0.041984
[03/24/2023-12:56:46] [V] [TRT] Conv_27 + Relu_28 Set Tactic Name: sm75_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x256x64_stage1_warpsize1x4x2_g1_tensor16x8x8_t1r1s1 Tactic: 2511830168590723349
[03/24/2023-12:56:46] [V] [TRT] Tactic: 2511830168590723349 Time: 0.036736
[03/24/2023-12:56:46] [V] [TRT] Conv_27 + Relu_28 Set Tactic Name: ampere_h16816cudnn_128x128_ldg8_relu_exp_medium_nhwc_tn_v1 Tactic: 2541579301352125276
[03/24/2023-12:56:46] [V] [TRT] Tactic: 2541579301352125276 Time: 0.033536
[03/24/2023-12:56:46] [V] [TRT] Conv_27 + Relu_28 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x256x32_stage3_warpsize2x4x1_g1_tensor16x8x16_t1r1s1 Tactic: 2559328254295148085
[03/24/2023-12:56:46] [V] [TRT] Tactic: 2559328254295148085 Time: 0.032384
[03/24/2023-12:56:46] [V] [TRT] Conv_27 + Relu_28 Set Tactic Name: ampere_h16816cudnn_64x64_sliced1x2_ldg8_relu_exp_stages_64x6_small_nhwc_tn_v1 Tactic: 2657157263811141609
[03/24/2023-12:56:46] [V] [TRT] Tactic: 2657157263811141609 Time: 0.089472
[03/24/2023-12:56:46] [V] [TRT] Conv_27 + Relu_28 Set Tactic Name: ampere_h16816cudnn_128x64_sliced1x2_ldg8_relu_exp_stages_64x3_medium_nhwc_tn_v1 Tactic: 2968605903460894194
[03/24/2023-12:56:46] [V] [TRT] Tactic: 2968605903460894194 Time: 0.043264
[03/24/2023-12:56:46] [V] [TRT] Conv_27 + Relu_28 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x32x64_stage5_warpsize2x2x1_g1_tensor16x8x16_t1r1s1 Tactic: 3071479995783211391
[03/24/2023-12:56:46] [V] [TRT] Tactic: 3071479995783211391 Time: 0.063488
[03/24/2023-12:56:46] [V] [TRT] Conv_27 + Relu_28 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x32x32_stage4_warpsize4x1x1_g1_tensor16x8x16_t1r1s1 Tactic: 3359475309458902373
[03/24/2023-12:56:46] [V] [TRT] Tactic: 3359475309458902373 Time: 0.041216
[03/24/2023-12:56:46] [V] [TRT] Conv_27 + Relu_28 Set Tactic Name: ampere_h16816cudnn_128x128_ldg8_relu_exp_stages_64x3_medium_nhwc_tn_v1 Tactic: 3362537467505018070
[03/24/2023-12:56:46] [V] [TRT] Tactic: 3362537467505018070 Time: 0.038144
[03/24/2023-12:56:46] [V] [TRT] Conv_27 + Relu_28 Set Tactic Name: ampere_h1688cudnn_256x128_ldg8_relu_exp_medium_nhwc_tn_v1 Tactic: 3513075359009385578
[03/24/2023-12:56:46] [V] [TRT] Tactic: 3513075359009385578 Time: 0.037888
[03/24/2023-12:56:46] [V] [TRT] Conv_27 + Relu_28 Set Tactic Name: ampere_h1688cudnn_128x128_ldg8_relu_exp_small_nhwc_tn_v1 Tactic: 3704534001553878387
[03/24/2023-12:56:46] [V] [TRT] Tactic: 3704534001553878387 Time: 0.035712
[03/24/2023-12:56:46] [V] [TRT] Conv_27 + Relu_28 Set Tactic Name: sm75_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x128x32_stage1_warpsize2x2x1_g1_tensor16x8x8_t1r1s1 Tactic: 4149021101886580762
[03/24/2023-12:56:46] [V] [TRT] Tactic: 4149021101886580762 Time: 0.031616
[03/24/2023-12:56:46] [V] [TRT] Conv_27 + Relu_28 Set Tactic Name: ampere_h16816cudnn_64x128_ldg8_relu_exp_stages_64x4_small_nhwc_tn_v1 Tactic: 4278315135102886928
[03/24/2023-12:56:46] [V] [TRT] Tactic: 4278315135102886928 Time: 0.050432
[03/24/2023-12:56:46] [V] [TRT] Conv_27 + Relu_28 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x64x32_stage5_warpsize2x2x1_g1_tensor16x8x16_t1r1s1 Tactic: 4480294673430783793
[03/24/2023-12:56:46] [V] [TRT] Tactic: 4480294673430783793 Time: 0.034816
[03/24/2023-12:56:46] [V] [TRT] Conv_27 + Relu_28 Set Tactic Name: ampere_h16816cudnn_256x64_ldg8_relu_exp_stages_64x3_medium_nhwc_tn_v1 Tactic: 4540505769798915372
[03/24/2023-12:56:46] [V] [TRT] Tactic: 4540505769798915372 Time: 0.043008
[03/24/2023-12:56:46] [V] [TRT] Conv_27 + Relu_28 Set Tactic Name: ampere_h1688cudnn_256x128_ldg8_relu_exp_interior_nhwc_tn_v1 Tactic: 4571819373777460444
[03/24/2023-12:56:46] [V] [TRT] Tactic: 4571819373777460444 Time: 0.03648
[03/24/2023-12:56:46] [V] [TRT] Conv_27 + Relu_28 Set Tactic Name: sm75_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x32x32_stage1_warpsize4x1x1_g1_tensor16x8x8_t1r1s1 Tactic: 4749226340913476230
[03/24/2023-12:56:46] [V] [TRT] Tactic: 4749226340913476230 Time: 0.0416
[03/24/2023-12:56:46] [V] [TRT] Conv_27 + Relu_28 Set Tactic Name: ampere_h16816cudnn_256x64_sliced1x2_ldg8_relu_exp_small_nhwc_tn_v1 Tactic: 4802447371470387646
[03/24/2023-12:56:46] [V] [TRT] Tactic: 4802447371470387646 Time: 0.045952
[03/24/2023-12:56:46] [V] [TRT] Conv_27 + Relu_28 Set Tactic Name: ampere_h16816cudnn_256x128_ldg8_relu_exp_small_nhwc_tn_v1 Tactic: 5059676457552313631
[03/24/2023-12:56:46] [V] [TRT] Tactic: 5059676457552313631 Time: 0.035712
[03/24/2023-12:56:46] [V] [TRT] Conv_27 + Relu_28 Set Tactic Name: ampere_h16816cudnn_256x128_ldg8_relu_exp_stages_64x3_interior_nhwc_tn_v1 Tactic: 5070322914990170527
[03/24/2023-12:56:46] [V] [TRT] Tactic: 5070322914990170527 Time: 0.036992
[03/24/2023-12:56:46] [V] [TRT] Conv_27 + Relu_28 Set Tactic Name: ampere_h16816cudnn_128x128_ldg8_relu_exp_interior_nhwc_tn_v1 Tactic: 5205510332404400949
[03/24/2023-12:56:46] [V] [TRT] Tactic: 5205510332404400949 Time: 0.03328
[03/24/2023-12:56:46] [V] [TRT] Conv_27 + Relu_28 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x128x64_stage3_warpsize2x2x1_g1_tensor16x8x16_t1r1s1 Tactic: 5346855796032465921
[03/24/2023-12:56:46] [V] [TRT] Tactic: 5346855796032465921 Time: 0.038784
[03/24/2023-12:56:46] [V] [TRT] Conv_27 + Relu_28 Set Tactic Name: ampere_h1688cudnn_256x64_sliced1x2_ldg8_relu_exp_small_nhwc_tn_v1 Tactic: 5398999388616959893
[03/24/2023-12:56:46] [V] [TRT] Tactic: 5398999388616959893 Time: 0.04736
[03/24/2023-12:56:46] [V] [TRT] Conv_27 + Relu_28 Set Tactic Name: ampere_h16816cudnn_64x128_ldg8_relu_exp_stages_64x3_small_nhwc_tn_v1 Tactic: 6034364043891107501
[03/24/2023-12:56:46] [V] [TRT] Tactic: 6034364043891107501 Time: 0.041856
[03/24/2023-12:56:46] [V] [TRT] Conv_27 + Relu_28 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x128x64_stage3_warpsize4x2x1_g1_tensor16x8x16_t1r1s1 Tactic: 6372404953297521067
[03/24/2023-12:56:46] [V] [TRT] Tactic: 6372404953297521067 Time: 0.036096
[03/24/2023-12:56:46] [V] [TRT] Conv_27 + Relu_28 Set Tactic Name: ampere_h16816cudnn_128x128_ldg8_relu_exp_stages_64x3_small_nhwc_tn_v1 Tactic: 6377497238381488891
[03/24/2023-12:56:46] [V] [TRT] Tactic: 6377497238381488891 Time: 0.03776
[03/24/2023-12:56:46] [V] [TRT] Conv_27 + Relu_28 Set Tactic Name: ampere_h16816cudnn_128x64_sliced1x2_ldg8_relu_exp_stages_64x4_medium_nhwc_tn_v1 Tactic: 6468794451065529747
[03/24/2023-12:56:46] [V] [TRT] Tactic: 6468794451065529747 Time: 0.06208
[03/24/2023-12:56:46] [V] [TRT] Conv_27 + Relu_28 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x256x64_stage3_warpsize1x4x1_g1_tensor16x8x16_t1r1s1 Tactic: 6724319788728799540
[03/24/2023-12:56:46] [V] [TRT] Tactic: 6724319788728799540 Time: 0.041984
[03/24/2023-12:56:46] [V] [TRT] Conv_27 + Relu_28 Set Tactic Name: ampere_h16816cudnn_64x64_ldg8_relu_exp_stages_64x5_medium_nhwc_tn_v1 Tactic: 6859477213531075460
[03/24/2023-12:56:46] [V] [TRT] Tactic: 6859477213531075460 Time: 0.064512
[03/24/2023-12:56:46] [V] [TRT] Conv_27 + Relu_28 Set Tactic Name: ampere_h1688cudnn_256x64_ldg8_relu_exp_medium_nhwc_tn_v1 Tactic: 7216571380637776659
[03/24/2023-12:56:46] [V] [TRT] Tactic: 7216571380637776659 Time: 0.039808
[03/24/2023-12:56:46] [V] [TRT] Conv_27 + Relu_28 Set Tactic Name: ampere_h16816cudnn_128x64_ldg8_relu_exp_stages_64x3_medium_nhwc_tn_v1 Tactic: 7609923741161019135
[03/24/2023-12:56:46] [V] [TRT] Tactic: 7609923741161019135 Time: 0.04288
[03/24/2023-12:56:46] [V] [TRT] Conv_27 + Relu_28 Set Tactic Name: ampere_h16816cudnn_256x64_ldg8_relu_exp_stages_64x3_interior_nhwc_tn_v1 Tactic: 8095507026323593899
[03/24/2023-12:56:46] [V] [TRT] Tactic: 8095507026323593899 Time: 0.041344
[03/24/2023-12:56:46] [V] [TRT] Conv_27 + Relu_28 Set Tactic Name: ampere_h16816cudnn_64x64_sliced1x2_ldg8_relu_exp_stages_64x5_medium_nhwc_tn_v1 Tactic: 8101703987960976805
[03/24/2023-12:56:46] [V] [TRT] Tactic: 8101703987960976805 Time: 0.064768
[03/24/2023-12:56:46] [V] [TRT] Conv_27 + Relu_28 Set Tactic Name: ampere_h16816cudnn_128x64_sliced1x2_ldg8_relu_exp_stages_64x4_small_nhwc_tn_v1 Tactic: 8170606396342855895
[03/24/2023-12:56:46] [V] [TRT] Tactic: 8170606396342855895 Time: 0.060544
[03/24/2023-12:56:46] [V] [TRT] Conv_27 + Relu_28 Set Tactic Name: ampere_h1688cudnn_256x64_sliced1x2_ldg8_relu_exp_interior_nhwc_tn_v1 Tactic: 8764780417487154889
[03/24/2023-12:56:46] [V] [TRT] Tactic: 8764780417487154889 Time: 0.046464
[03/24/2023-12:56:46] [V] [TRT] Conv_27 + Relu_28 Set Tactic Name: ampere_h1688cudnn_256x64_ldg8_relu_exp_small_nhwc_tn_v1 Tactic: 8839784824303350101
[03/24/2023-12:56:46] [V] [TRT] Tactic: 8839784824303350101 Time: 0.038272
[03/24/2023-12:56:46] [V] [TRT] Conv_27 + Relu_28 Set Tactic Name: ampere_h16816cudnn_256x64_sliced1x2_ldg8_relu_exp_medium_nhwc_tn_v1 Tactic: -9009272790678027912
[03/24/2023-12:56:46] [V] [TRT] Tactic: -9009272790678027912 Time: 0.047104
[03/24/2023-12:56:46] [V] [TRT] Conv_27 + Relu_28 Set Tactic Name: sm75_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x128x32_stage1_warpsize4x2x1_g1_tensor16x8x8_t1r1s1 Tactic: -8749513212655756001
[03/24/2023-12:56:46] [V] [TRT] Tactic: -8749513212655756001 Time: 0.03584
[03/24/2023-12:56:46] [V] [TRT] Conv_27 + Relu_28 Set Tactic Name: ampere_h16816cudnn_64x64_ldg8_relu_exp_stages_64x6_medium_nhwc_tn_v1 Tactic: -8604374562669615024
[03/24/2023-12:56:46] [V] [TRT] Tactic: -8604374562669615024 Time: 0.0832
[03/24/2023-12:56:46] [V] [TRT] Conv_27 + Relu_28 Set Tactic Name: ampere_h16816cudnn_256x128_ldg8_relu_exp_interior_nhwc_tn_v1 Tactic: -8280443484414412687
[03/24/2023-12:56:46] [V] [TRT] Tactic: -8280443484414412687 Time: 0.03456
[03/24/2023-12:56:46] [V] [TRT] Conv_27 + Relu_28 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x128x32_stage3_warpsize4x2x1_g1_tensor16x8x16_t1r1s1 Tactic: -8205952393017864204
[03/24/2023-12:56:46] [V] [TRT] Tactic: -8205952393017864204 Time: 0.032256
[03/24/2023-12:56:46] [V] [TRT] Conv_27 + Relu_28 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x64x64_stage3_warpsize2x2x1_g1_tensor16x8x16_t1r1s1 Tactic: -8131857373260504832
[03/24/2023-12:56:46] [V] [TRT] Tactic: -8131857373260504832 Time: 0.035584
[03/24/2023-12:56:46] [V] [TRT] Conv_27 + Relu_28 Set Tactic Name: sm75_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x64x32_stage1_warpsize2x2x1_g1_tensor16x8x8_t1r1s1 Tactic: -7533167286135592323
[03/24/2023-12:56:46] [V] [TRT] Tactic: -7533167286135592323 Time: 0.032
[03/24/2023-12:56:46] [V] [TRT] Conv_27 + Relu_28 Set Tactic Name: ampere_h16816cudnn_64x64_sliced1x2_ldg8_relu_exp_stages_64x6_interior_nhwc_tn_v1 Tactic: -7410012245391920273
[03/24/2023-12:56:46] [V] [TRT] Tactic: -7410012245391920273 Time: 0.08512
[03/24/2023-12:56:46] [V] [TRT] Conv_27 + Relu_28 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x128x32_stage5_warpsize2x2x1_g1_tensor16x8x16_t1r1s1 Tactic: -7099920365135295801
[03/24/2023-12:56:46] [V] [TRT] Tactic: -7099920365135295801 Time: 0.034944
[03/24/2023-12:56:46] [V] [TRT] Conv_27 + Relu_28 Set Tactic Name: ampere_h16816cudnn_64x64_ldg8_relu_exp_stages_64x6_interior_nhwc_tn_v1 Tactic: -7089118800560870395
[03/24/2023-12:56:46] [V] [TRT] Tactic: -7089118800560870395 Time: 0.074496
[03/24/2023-12:56:46] [V] [TRT] Conv_27 + Relu_28 Set Tactic Name: ampere_h16816cudnn_64x64_sliced1x2_ldg8_relu_exp_stages_64x6_medium_nhwc_tn_v1 Tactic: -6356316196810535311
[03/24/2023-12:56:46] [V] [TRT] Tactic: -6356316196810535311 Time: 0.094464
[03/24/2023-12:56:46] [V] [TRT] Conv_27 + Relu_28 Set Tactic Name: ampere_h16816cudnn_128x64_ldg8_relu_exp_stages_64x4_small_nhwc_tn_v1 Tactic: -6063766379489217211
[03/24/2023-12:56:46] [V] [TRT] Tactic: -6063766379489217211 Time: 0.055552
[03/24/2023-12:56:46] [V] [TRT] Conv_27 + Relu_28 Set Tactic Name: ampere_h16816cudnn_128x128_ldg8_relu_exp_small_nhwc_tn_v1 Tactic: -5530886555766748586
[03/24/2023-12:56:46] [V] [TRT] Tactic: -5530886555766748586 Time: 0.033536
[03/24/2023-12:56:46] [V] [TRT] Conv_27 + Relu_28 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x32x32_stage4_warpsize4x1x1_g1_tensor16x8x16_t1r1s1 Tactic: -5409588854490562130
[03/24/2023-12:56:46] [V] [TRT] Tactic: -5409588854490562130 Time: 0.037632
[03/24/2023-12:56:46] [V] [TRT] Conv_27 + Relu_28 Set Tactic Name: ampere_h16816cudnn_256x64_ldg8_relu_exp_stages_64x3_small_nhwc_tn_v1 Tactic: -5261787675443473128
[03/24/2023-12:56:46] [V] [TRT] Tactic: -5261787675443473128 Time: 0.043008
[03/24/2023-12:56:46] [V] [TRT] Conv_27 + Relu_28 Set Tactic Name: ampere_h16816cudnn_64x128_sliced1x2_ldg8_relu_exp_stages_64x3_medium_nhwc_tn_v1 Tactic: -5161596964442251102
[03/24/2023-12:56:46] [V] [TRT] Tactic: -5161596964442251102 Time: 0.042112
[03/24/2023-12:56:46] [V] [TRT] Conv_27 + Relu_28 Set Tactic Name: ampere_h16816cudnn_64x128_ldg8_relu_exp_stages_64x3_medium_nhwc_tn_v1 Tactic: -5127240325355316006
[03/24/2023-12:56:46] [V] [TRT] Tactic: -5127240325355316006 Time: 0.041856
[03/24/2023-12:56:46] [V] [TRT] Conv_27 + Relu_28 Set Tactic Name: sm75_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x128x32_stage1_warpsize2x2x1_g1_tensor16x8x8_t1r1s1 Tactic: -5121883532434354186
[03/24/2023-12:56:46] [V] [TRT] Tactic: -5121883532434354186 Time: 0.02816
[03/24/2023-12:56:46] [V] [TRT] Conv_27 + Relu_28 Set Tactic Name: ampere_h16816cudnn_256x128_ldg8_relu_exp_stages_64x3_medium_nhwc_tn_v1 Tactic: -5109582882231362997
[03/24/2023-12:56:46] [V] [TRT] Tactic: -5109582882231362997 Time: 0.038784
[03/24/2023-12:56:46] [V] [TRT] Conv_27 + Relu_28 Set Tactic Name: sm75_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x64x32_stage1_warpsize4x1x1_g1_tensor16x8x8_t1r1s1 Tactic: -5006039300385557796
[03/24/2023-12:56:46] [V] [TRT] Tactic: -5006039300385557796 Time: 0.034816
[03/24/2023-12:56:46] [V] [TRT] Conv_27 + Relu_28 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x64x64_stage4_warpsize2x2x1_g1_tensor16x8x16_t1r1s1 Tactic: -4950923835688973492
[03/24/2023-12:56:46] [V] [TRT] Tactic: -4950923835688973492 Time: 0.042752
[03/24/2023-12:56:46] [V] [TRT] Conv_27 + Relu_28 Set Tactic Name: ampere_h16816cudnn_64x128_sliced1x2_ldg8_relu_exp_stages_64x4_small_nhwc_tn_v1 Tactic: -4796511246675321840
[03/24/2023-12:56:46] [V] [TRT] Tactic: -4796511246675321840 Time: 0.058368
[03/24/2023-12:56:46] [V] [TRT] Conv_27 + Relu_28 Set Tactic Name: ampere_h16816cudnn_64x64_sliced1x2_ldg8_relu_exp_stages_64x5_interior_nhwc_tn_v1 Tactic: -4548822885169694805
[03/24/2023-12:56:46] [V] [TRT] Tactic: -4548822885169694805 Time: 0.062336
[03/24/2023-12:56:46] [V] [TRT] Conv_27 + Relu_28 Set Tactic Name: ampere_h16816cudnn_128x64_ldg8_relu_exp_stages_64x3_small_nhwc_tn_v1 Tactic: -4379519430184503304
[03/24/2023-12:56:46] [V] [TRT] Tactic: -4379519430184503304 Time: 0.04288
[03/24/2023-12:56:46] [V] [TRT] Conv_27 + Relu_28 Set Tactic Name: sm75_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x128x64_stage1_warpsize2x2x1_g1_tensor16x8x8_t1r1s1 Tactic: -4352168563838861262
[03/24/2023-12:56:46] [V] [TRT] Tactic: -4352168563838861262 Time: 0.032384
[03/24/2023-12:56:46] [V] [TRT] Conv_27 + Relu_28 Set Tactic Name: ampere_h16816cudnn_64x64_ldg8_relu_exp_stages_64x5_interior_nhwc_tn_v1 Tactic: -4293222705763522367
[03/24/2023-12:56:46] [V] [TRT] Tactic: -4293222705763522367 Time: 0.05952
[03/24/2023-12:56:46] [V] [TRT] Conv_27 + Relu_28 Set Tactic Name: ampere_h1688cudnn_256x128_ldg8_relu_exp_small_nhwc_tn_v1 Tactic: -4152066959007262150
[03/24/2023-12:56:46] [V] [TRT] Tactic: -4152066959007262150 Time: 0.036992
[03/24/2023-12:56:46] [V] [TRT] Conv_27 + Relu_28 Set Tactic Name: sm75_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x256x32_stage1_warpsize2x4x1_g1_tensor16x8x8_t1r1s1 Tactic: -4109084522508697633
[03/24/2023-12:56:46] [V] [TRT] Tactic: -4109084522508697633 Time: 0.03392
[03/24/2023-12:56:46] [V] [TRT] Conv_27 + Relu_28 Set Tactic Name: ampere_h16816cudnn_64x128_ldg8_relu_exp_stages_64x4_medium_nhwc_tn_v1 Tactic: -4021926646879732549
[03/24/2023-12:56:46] [V] [TRT] Tactic: -4021926646879732549 Time: 0.051456
[03/24/2023-12:56:46] [V] [TRT] Conv_27 + Relu_28 Set Tactic Name: ampere_h16816cudnn_64x128_sliced1x2_ldg8_relu_exp_stages_64x4_medium_nhwc_tn_v1 Tactic: -3987638434926559037
[03/24/2023-12:56:46] [V] [TRT] Tactic: -3987638434926559037 Time: 0.05952
[03/24/2023-12:56:46] [V] [TRT] Conv_27 + Relu_28 Set Tactic Name: ampere_h1688cudnn_256x64_sliced1x2_ldg8_relu_exp_medium_nhwc_tn_v1 Tactic: -3905653247016903130
[03/24/2023-12:56:46] [V] [TRT] Tactic: -3905653247016903130 Time: 0.04864
[03/24/2023-12:56:46] [V] [TRT] Conv_27 + Relu_28 Set Tactic Name: ampere_h16816cudnn_256x64_ldg8_relu_exp_interior_nhwc_tn_v1 Tactic: -3903342530518878192
[03/24/2023-12:56:46] [V] [TRT] Tactic: -3903342530518878192 Time: 0.036352
[03/24/2023-12:56:46] [V] [TRT] Conv_27 + Relu_28 Set Tactic Name: ampere_h16816cudnn_256x64_ldg8_relu_exp_small_nhwc_tn_v1 Tactic: -3864869056275745423
[03/24/2023-12:56:46] [V] [TRT] Tactic: -3864869056275745423 Time: 0.03968
[03/24/2023-12:56:46] [V] [TRT] Conv_27 + Relu_28 Set Tactic Name: ampere_h16816cudnn_64x64_ldg8_relu_exp_stages_64x5_small_nhwc_tn_v1 Tactic: -3601464762214218301
[03/24/2023-12:56:46] [V] [TRT] Tactic: -3601464762214218301 Time: 0.062976
[03/24/2023-12:56:46] [V] [TRT] Conv_27 + Relu_28 Set Tactic Name: ampere_h16816cudnn_64x128_sliced1x2_ldg8_relu_exp_stages_64x3_small_nhwc_tn_v1 Tactic: -3058330359340425555
[03/24/2023-12:56:46] [V] [TRT] Tactic: -3058330359340425555 Time: 0.042624
[03/24/2023-12:56:46] [V] [TRT] Conv_27 + Relu_28 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x64x32_stage3_warpsize4x1x1_g1_tensor16x8x16_t1r1s1 Tactic: -2878731503146438856
[03/24/2023-12:56:46] [V] [TRT] Tactic: -2878731503146438856 Time: 0.030592
[03/24/2023-12:56:46] [V] [TRT] Conv_27 + Relu_28 Set Tactic Name: sm75_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x32x64_stage1_warpsize2x1x2_g1_tensor16x8x8_t1r1s1 Tactic: -2827934362840121038
[03/24/2023-12:56:46] [V] [TRT] Tactic: -2827934362840121038 Time: 0.046208
[03/24/2023-12:56:46] [V] [TRT] Conv_27 + Relu_28 Set Tactic Name: ampere_h16816cudnn_128x128_ldg8_relu_exp_stages_64x3_interior_nhwc_tn_v1 Tactic: -2602982885923184927
[03/24/2023-12:56:46] [V] [TRT] Tactic: -2602982885923184927 Time: 0.036864
[03/24/2023-12:56:46] [V] [TRT] Conv_27 + Relu_28 Set Tactic Name: sm75_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x32x32_stage1_warpsize4x1x1_g1_tensor16x8x8_t1r1s1 Tactic: -2569977342077121032
[03/24/2023-12:56:46] [V] [TRT] Tactic: -2569977342077121032 Time: 0.04032
[03/24/2023-12:56:46] [V] [TRT] Conv_27 + Relu_28 Set Tactic Name: ampere_h16816cudnn_256x64_sliced1x2_ldg8_relu_exp_interior_nhwc_tn_v1 Tactic: -2353603993968373338
[03/24/2023-12:56:46] [V] [TRT] Tactic: -2353603993968373338 Time: 0.044288
[03/24/2023-12:56:46] [V] [TRT] Conv_27 + Relu_28 Set Tactic Name: ampere_h16816cudnn_128x64_sliced1x2_ldg8_relu_exp_stages_64x4_interior_nhwc_tn_v1 Tactic: -2032577876140256150
[03/24/2023-12:56:46] [V] [TRT] Tactic: -2032577876140256150 Time: 0.058368
[03/24/2023-12:56:46] [V] [TRT] Conv_27 + Relu_28 Set Tactic Name: ampere_h16816cudnn_64x128_ldg8_relu_exp_stages_64x3_interior_nhwc_tn_v1 Tactic: -2003055242756584050
[03/24/2023-12:56:46] [V] [TRT] Tactic: -2003055242756584050 Time: 0.040832
[03/24/2023-12:56:46] [V] [TRT] Conv_27 + Relu_28 Set Tactic Name: ampere_h16816cudnn_256x64_ldg8_relu_exp_medium_nhwc_tn_v1 Tactic: -1985778916402815946
[03/24/2023-12:56:46] [V] [TRT] Tactic: -1985778916402815946 Time: 0.039936
[03/24/2023-12:56:46] [V] [TRT] Conv_27 + Relu_28 Set Tactic Name: sm75_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x64x64_stage1_warpsize2x2x1_g1_tensor16x8x8_t1r1s1 Tactic: -1838109259315759592
[03/24/2023-12:56:46] [V] [TRT] Tactic: -1838109259315759592 Time: 0.03584
[03/24/2023-12:56:46] [V] [TRT] Conv_27 + Relu_28 Set Tactic Name: ampere_h16816cudnn_128x64_sliced1x2_ldg8_relu_exp_stages_64x3_interior_nhwc_tn_v1 Tactic: -1640527254204634147
[03/24/2023-12:56:46] [V] [TRT] Tactic: -1640527254204634147 Time: 0.041984
[03/24/2023-12:56:46] [V] [TRT] Conv_27 + Relu_28 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x128x32_stage4_warpsize2x2x1_g1_tensor16x8x16_t1r1s1 Tactic: -1562548049711204899
[03/24/2023-12:56:46] [V] [TRT] Tactic: -1562548049711204899 Time: 0.029184
[03/24/2023-12:56:46] [V] [TRT] Conv_27 + Relu_28 Set Tactic Name: ampere_h16816cudnn_64x128_ldg8_relu_exp_stages_64x4_interior_nhwc_tn_v1 Tactic: -1242202084391243207
[03/24/2023-12:56:46] [V] [TRT] Tactic: -1242202084391243207 Time: 0.048256
[03/24/2023-12:56:46] [V] [TRT] Conv_27 + Relu_28 Set Tactic Name: ampere_h16816cudnn_64x64_ldg8_relu_exp_stages_64x6_small_nhwc_tn_v1 Tactic: -1099247066487349374
[03/24/2023-12:56:46] [V] [TRT] Tactic: -1099247066487349374 Time: 0.079104
[03/24/2023-12:56:46] [V] [TRT] Conv_27 + Relu_28 Set Tactic Name: ampere_h16816cudnn_128x64_ldg8_relu_exp_stages_64x4_interior_nhwc_tn_v1 Tactic: -1038291877007553549
[03/24/2023-12:56:46] [V] [TRT] Tactic: -1038291877007553549 Time: 0.052736
[03/24/2023-12:56:46] [V] [TRT] Conv_27 + Relu_28 Set Tactic Name: ampere_h1688cudnn_128x128_ldg8_relu_exp_interior_nhwc_tn_v1 Tactic: -406984317033388136
[03/24/2023-12:56:47] [V] [TRT] Tactic: -406984317033388136 Time: 0.034688
[03/24/2023-12:56:47] [V] [TRT] Conv_27 + Relu_28 Set Tactic Name: ampere_h16816cudnn_128x64_ldg8_relu_exp_stages_64x3_interior_nhwc_tn_v1 Tactic: -331499326992534460
[03/24/2023-12:56:47] [V] [TRT] Tactic: -331499326992534460 Time: 0.042112
[03/24/2023-12:56:47] [V] [TRT] Fastest Tactic: -5121883532434354186 Time: 0.02816
[03/24/2023-12:56:47] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: -5121883532434354186
[03/24/2023-12:56:47] [V] [TRT] *************** Autotuning format combination: Half(259200,1:16,1440,8) -> Half(1036800,1:16,5760,32) ***************
[03/24/2023-12:56:47] [V] [TRT] --------------- Timing Runner: Conv_27 + Relu_28 (CudnnConvolution)
[03/24/2023-12:56:47] [V] [TRT] CudnnConvolution has no valid tactics for this config, skipping
[03/24/2023-12:56:47] [V] [TRT] --------------- Timing Runner: Conv_27 + Relu_28 (CublasConvolution)
[03/24/2023-12:56:47] [V] [TRT] CublasConvolution has no valid tactics for this config, skipping
[03/24/2023-12:56:47] [V] [TRT] --------------- Timing Runner: Conv_27 + Relu_28 (CaskConvolution)
[03/24/2023-12:56:47] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[03/24/2023-12:56:47] [V] [TRT] =============== Computing costs for 
[03/24/2023-12:56:47] [V] [TRT] *************** Autotuning format combination: Float(4147200,32400,180,1) -> Float(2073600,8100,90,1) ***************
[03/24/2023-12:56:47] [V] [TRT] --------------- Timing Runner: Conv_44 + Relu_45 (CudaDepthwiseConvolution)
[03/24/2023-12:56:47] [V] [TRT] CudaDepthwiseConvolution has no valid tactics for this config, skipping
[03/24/2023-12:56:47] [V] [TRT] --------------- Timing Runner: Conv_44 + Relu_45 (FusedConvActConvolution)
[03/24/2023-12:56:47] [V] [TRT] Tactic: 458751 Time: 0.420352
[03/24/2023-12:56:47] [V] [TRT] Fastest Tactic: 458751 Time: 0.420352
[03/24/2023-12:56:47] [V] [TRT] --------------- Timing Runner: Conv_44 + Relu_45 (CudnnConvolution)
[03/24/2023-12:56:47] [V] [TRT] Tactic: 0 Time: 0.501504
[03/24/2023-12:56:47] [V] [TRT] Tactic: 1 Time: 0.13184
[03/24/2023-12:56:47] [V] [TRT] Tactic: 2 Time: 0.55488
[03/24/2023-12:56:47] [V] [TRT] Tactic: 5 Time: 4.40077
[03/24/2023-12:56:47] [V] [TRT] Tactic: 56 Time: 0.501888
[03/24/2023-12:56:47] [V] [TRT] Tactic: 57 Time: 0.131712
[03/24/2023-12:56:47] [V] [TRT] Tactic: 58 Time: 0.55552
[03/24/2023-12:56:47] [V] [TRT] Tactic: 61 Time: 4.39974
[03/24/2023-12:56:47] [V] [TRT] Tactic: 112 Time: 0.50112
[03/24/2023-12:56:47] [V] [TRT] Tactic: 113 Time: 0.377984
[03/24/2023-12:56:47] [V] [TRT] Tactic: 114 Time: 0.554752
[03/24/2023-12:56:47] [V] [TRT] Tactic: 117 Time: 4.39987
[03/24/2023-12:56:47] [V] [TRT] Fastest Tactic: 57 Time: 0.131712
[03/24/2023-12:56:47] [V] [TRT] --------------- Timing Runner: Conv_44 + Relu_45 (CaskConvolution)
[03/24/2023-12:56:47] [V] [TRT] Conv_44 + Relu_45 Set Tactic Name: ampere_scudnn_128x64_relu_small_nn_v1 Tactic: 4549827808004681195
[03/24/2023-12:56:47] [V] [TRT] Tactic: 4549827808004681195 Time: 0.354816
[03/24/2023-12:56:47] [V] [TRT] Conv_44 + Relu_45 Set Tactic Name: ampere_scudnn_128x128_relu_small_nn_v1 Tactic: 5779835512569528575
[03/24/2023-12:56:47] [V] [TRT] Tactic: 5779835512569528575 Time: 0.443392
[03/24/2023-12:56:47] [V] [TRT] Conv_44 + Relu_45 Set Tactic Name: ampere_scudnn_128x128_relu_xregs_large_nn_v1 Tactic: 6053873026024413720
[03/24/2023-12:56:47] [V] [TRT] Tactic: 6053873026024413720 Time: 0.460544
[03/24/2023-12:56:47] [V] [TRT] Conv_44 + Relu_45 Set Tactic Name: ampere_scudnn_128x64_relu_xregs_large_nn_v1 Tactic: 6767548733843469815
[03/24/2023-12:56:47] [V] [TRT] Tactic: 6767548733843469815 Time: 0.35456
[03/24/2023-12:56:47] [V] [TRT] Conv_44 + Relu_45 Set Tactic Name: ampere_scudnn_128x32_relu_small_nn_v1 Tactic: -6313876406580483184
[03/24/2023-12:56:47] [V] [TRT] Tactic: -6313876406580483184 Time: 0.397312
[03/24/2023-12:56:47] [V] [TRT] Conv_44 + Relu_45 Set Tactic Name: ampere_scudnn_128x128_relu_medium_nn_v1 Tactic: -1123676555321336786
[03/24/2023-12:56:47] [V] [TRT] Tactic: -1123676555321336786 Time: 0.442752
[03/24/2023-12:56:47] [V] [TRT] Conv_44 + Relu_45 Set Tactic Name: ampere_scudnn_128x64_relu_medium_nn_v1 Tactic: -701551393537224327
[03/24/2023-12:56:47] [V] [TRT] Tactic: -701551393537224327 Time: 0.361344
[03/24/2023-12:56:47] [V] [TRT] Fastest Tactic: 6767548733843469815 Time: 0.35456
[03/24/2023-12:56:47] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CudnnConvolution Tactic: 57
[03/24/2023-12:56:47] [V] [TRT] *************** Autotuning format combination: Float(4147200,1,23040,128) -> Float(2073600,1,23040,256) ***************
[03/24/2023-12:56:47] [V] [TRT] --------------- Timing Runner: Conv_44 + Relu_45 (CudnnConvolution)
[03/24/2023-12:56:47] [V] [TRT] CudnnConvolution has no valid tactics for this config, skipping
[03/24/2023-12:56:47] [V] [TRT] --------------- Timing Runner: Conv_44 + Relu_45 (CaskConvolution)
[03/24/2023-12:56:47] [V] [TRT] Conv_44 + Relu_45 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize64x128x8_stage3_warpsize1x4x1_g1_ffma_t1r3s3 Tactic: 2086609538387166260
[03/24/2023-12:56:47] [V] [TRT] Tactic: 2086609538387166260 Time: 0.335872
[03/24/2023-12:56:47] [V] [TRT] Conv_44 + Relu_45 Set Tactic Name: ampere_scudnn_128x64_sliced1x2_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: 2860655430572478466
[03/24/2023-12:56:47] [V] [TRT] Tactic: 2860655430572478466 Time: 0.341248
[03/24/2023-12:56:47] [V] [TRT] Conv_44 + Relu_45 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize64x128x8_stage3_warpsize1x4x1_g1_ffma Tactic: 3239733199291090177
[03/24/2023-12:56:47] [V] [TRT] Tactic: 3239733199291090177 Time: 0.33408
[03/24/2023-12:56:47] [V] [TRT] Conv_44 + Relu_45 Set Tactic Name: ampere_scudnn_128x32_sliced1x4_ldg4_relu_exp_medium_nhwc_tn_v1 Tactic: 4474630279712975759
[03/24/2023-12:56:47] [V] [TRT] Tactic: 4474630279712975759 Time: 0.290816
[03/24/2023-12:56:47] [V] [TRT] Conv_44 + Relu_45 Set Tactic Name: ampere_scudnn_128x32_sliced1x4_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: 4479823862704990365
[03/24/2023-12:56:47] [V] [TRT] Tactic: 4479823862704990365 Time: 0.289152
[03/24/2023-12:56:47] [V] [TRT] Conv_44 + Relu_45 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize64x256x8_stage3_warpsize1x4x1_g1_ffma Tactic: 4517590677127196184
[03/24/2023-12:56:47] [V] [TRT] Tactic: 4517590677127196184 Time: 0.455552
[03/24/2023-12:56:47] [V] [TRT] Conv_44 + Relu_45 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize128x128x8_stage3_warpsize2x4x1_g1_ffma_t1r3s3 Tactic: 4634080872644479428
[03/24/2023-12:56:47] [V] [TRT] Tactic: 4634080872644479428 Time: 0.443136
[03/24/2023-12:56:47] [V] [TRT] Conv_44 + Relu_45 Set Tactic Name: ampere_scudnn_128x64_sliced1x2_ldg4_relu_exp_medium_nhwc_tn_v1 Tactic: 4696204239951173149
[03/24/2023-12:56:47] [V] [TRT] Tactic: 4696204239951173149 Time: 0.341504
[03/24/2023-12:56:47] [V] [TRT] Conv_44 + Relu_45 Set Tactic Name: ampere_scudnn_128x128_relu_exp_small_nhwc_tn_v1 Tactic: 5778138195697110003
[03/24/2023-12:56:47] [V] [TRT] Tactic: 5778138195697110003 Time: 0.440832
[03/24/2023-12:56:47] [V] [TRT] Conv_44 + Relu_45 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize256x128x8_stage3_warpsize2x4x1_g1_ffma Tactic: 6310198979346901507
[03/24/2023-12:56:47] [V] [TRT] Tactic: 6310198979346901507 Time: 0.463104
[03/24/2023-12:56:47] [V] [TRT] Conv_44 + Relu_45 Set Tactic Name: ampere_scudnn_128x128_ldg4_relu_exp_large_nhwc_tn_v1 Tactic: 7155825427510256858
[03/24/2023-12:56:47] [V] [TRT] Tactic: 7155825427510256858 Time: 0.444288
[03/24/2023-12:56:47] [V] [TRT] Conv_44 + Relu_45 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize128x64x8_stage3_warpsize1x4x1_g1_ffma Tactic: 7222247112373541608
[03/24/2023-12:56:47] [V] [TRT] Tactic: 7222247112373541608 Time: 0.46336
[03/24/2023-12:56:47] [V] [TRT] Conv_44 + Relu_45 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize128x128x8_stage3_warpsize2x4x1_g1_ffma Tactic: 7472640475524677095
[03/24/2023-12:56:47] [V] [TRT] Tactic: 7472640475524677095 Time: 0.451968
[03/24/2023-12:56:47] [V] [TRT] Conv_44 + Relu_45 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize128x256x8_stage3_warpsize2x4x1_g1_ffma Tactic: 8498373915030836990
[03/24/2023-12:56:47] [V] [TRT] Tactic: 8498373915030836990 Time: 0.449024
[03/24/2023-12:56:47] [V] [TRT] Conv_44 + Relu_45 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize256x64x8_stage3_warpsize1x4x1_g1_ffma Tactic: 8869697132622550639
[03/24/2023-12:56:47] [V] [TRT] Tactic: 8869697132622550639 Time: 0.5152
[03/24/2023-12:56:47] [V] [TRT] Conv_44 + Relu_45 Set Tactic Name: ampere_scudnn_128x128_ldg4_relu_exp_medium_nhwc_tn_v1 Tactic: 8918020581761223752
[03/24/2023-12:56:47] [V] [TRT] Tactic: 8918020581761223752 Time: 0.439168
[03/24/2023-12:56:47] [V] [TRT] Conv_44 + Relu_45 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize256x128x8_stage3_warpsize2x4x1_g1_ffma_t1r3s3 Tactic: -8937725997228636978
[03/24/2023-12:56:47] [V] [TRT] Tactic: -8937725997228636978 Time: 0.444288
[03/24/2023-12:56:47] [V] [TRT] Conv_44 + Relu_45 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize128x256x8_stage3_warpsize2x4x1_g1_ffma_t1r3s3 Tactic: -8833858409138163072
[03/24/2023-12:56:47] [V] [TRT] Tactic: -8833858409138163072 Time: 0.444288
[03/24/2023-12:56:47] [V] [TRT] Conv_44 + Relu_45 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize64x64x8_stage3_warpsize1x4x1_g1_ffma_t1r3s3 Tactic: -7989138351613022500
[03/24/2023-12:56:47] [V] [TRT] Tactic: -7989138351613022500 Time: 0.28352
[03/24/2023-12:56:47] [V] [TRT] Conv_44 + Relu_45 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize256x128x8_stage3_warpsize2x4x1_g1_ffma Tactic: -7872883691240863058
[03/24/2023-12:56:47] [V] [TRT] Tactic: -7872883691240863058 Time: 0.460288
[03/24/2023-12:56:47] [V] [TRT] Conv_44 + Relu_45 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize128x128x8_stage3_warpsize2x4x1_g1_ffma Tactic: -6729618519651721910
[03/24/2023-12:56:47] [V] [TRT] Tactic: -6729618519651721910 Time: 0.446592
[03/24/2023-12:56:47] [V] [TRT] Conv_44 + Relu_45 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize256x64x8_stage3_warpsize1x4x1_g1_ffma Tactic: -5893833996418445881
[03/24/2023-12:56:47] [V] [TRT] Tactic: -5893833996418445881 Time: 0.500096
[03/24/2023-12:56:47] [V] [TRT] Conv_44 + Relu_45 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize128x256x8_stage3_warpsize2x4x1_g1_ffma Tactic: -5701562095007058349
[03/24/2023-12:56:47] [V] [TRT] Tactic: -5701562095007058349 Time: 0.44288
[03/24/2023-12:56:47] [V] [TRT] Conv_44 + Relu_45 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize128x64x8_stage3_warpsize1x4x1_g1_ffma Tactic: -5685503422376017600
[03/24/2023-12:56:47] [V] [TRT] Tactic: -5685503422376017600 Time: 0.449152
[03/24/2023-12:56:47] [V] [TRT] Conv_44 + Relu_45 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize64x64x8_stage3_warpsize1x4x1_g1_ffma Tactic: -5521125187060117489
[03/24/2023-12:56:47] [V] [TRT] Tactic: -5521125187060117489 Time: 0.308096
[03/24/2023-12:56:47] [V] [TRT] Conv_44 + Relu_45 Set Tactic Name: ampere_scudnn_128x64_sliced1x2_ldg4_relu_exp_large_nhwc_tn_v1 Tactic: -4756382386362004279
[03/24/2023-12:56:47] [V] [TRT] Tactic: -4756382386362004279 Time: 0.336896
[03/24/2023-12:56:47] [V] [TRT] Conv_44 + Relu_45 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize64x64x8_stage3_warpsize1x4x1_g1_ffma Tactic: -4615000974950361663
[03/24/2023-12:56:47] [V] [TRT] Tactic: -4615000974950361663 Time: 0.294016
[03/24/2023-12:56:47] [V] [TRT] Conv_44 + Relu_45 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize256x64x8_stage3_warpsize1x4x1_g1_ffma_t1r3s3 Tactic: -4314913710375142296
[03/24/2023-12:56:47] [V] [TRT] Tactic: -4314913710375142296 Time: 0.483584
[03/24/2023-12:56:47] [V] [TRT] Conv_44 + Relu_45 Set Tactic Name: ampere_scudnn_128x128_relu_exp_large_nhwc_tn_v1 Tactic: -3855385237722507464
[03/24/2023-12:56:47] [V] [TRT] Tactic: -3855385237722507464 Time: 0.44352
[03/24/2023-12:56:47] [V] [TRT] Conv_44 + Relu_45 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize128x64x8_stage3_warpsize1x4x1_g1_ffma_t1r3s3 Tactic: -3697587361057948972
[03/24/2023-12:56:47] [V] [TRT] Tactic: -3697587361057948972 Time: 0.449152
[03/24/2023-12:56:47] [V] [TRT] Conv_44 + Relu_45 Set Tactic Name: ampere_scudnn_128x128_relu_exp_medium_nhwc_tn_v1 Tactic: -2809379259463049391
[03/24/2023-12:56:47] [V] [TRT] Tactic: -2809379259463049391 Time: 0.441984
[03/24/2023-12:56:47] [V] [TRT] Conv_44 + Relu_45 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize64x256x8_stage3_warpsize1x4x1_g1_ffma_t1r3s3 Tactic: -2747929399988666512
[03/24/2023-12:56:47] [V] [TRT] Tactic: -2747929399988666512 Time: 0.44416
[03/24/2023-12:56:47] [V] [TRT] Conv_44 + Relu_45 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize64x256x8_stage3_warpsize1x4x1_g1_ffma Tactic: -1472061967969061456
[03/24/2023-12:56:47] [V] [TRT] Tactic: -1472061967969061456 Time: 0.452352
[03/24/2023-12:56:47] [V] [TRT] Conv_44 + Relu_45 Set Tactic Name: ampere_scudnn_128x128_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: -504296718212024303
[03/24/2023-12:56:47] [V] [TRT] Tactic: -504296718212024303 Time: 0.43968
[03/24/2023-12:56:47] [V] [TRT] Conv_44 + Relu_45 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize64x128x8_stage3_warpsize1x4x1_g1_ffma Tactic: -444093195553988951
[03/24/2023-12:56:47] [V] [TRT] Tactic: -444093195553988951 Time: 0.349184
[03/24/2023-12:56:47] [V] [TRT] Fastest Tactic: -7989138351613022500 Time: 0.28352
[03/24/2023-12:56:47] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: -7989138351613022500
[03/24/2023-12:56:47] [V] [TRT] *************** Autotuning format combination: Float(1036800,1:4,5760,32) -> Float(518400,1:4,5760,64) ***************
[03/24/2023-12:56:47] [V] [TRT] --------------- Timing Runner: Conv_44 + Relu_45 (CudnnConvolution)
[03/24/2023-12:56:47] [V] [TRT] CudnnConvolution has no valid tactics for this config, skipping
[03/24/2023-12:56:47] [V] [TRT] --------------- Timing Runner: Conv_44 + Relu_45 (CaskConvolution)
[03/24/2023-12:56:47] [V] [TRT] Conv_44 + Relu_45 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize64x128x32_stage5_warpsize2x2x1_g1_tensor16x8x8 Tactic: 1237784342446422381
[03/24/2023-12:56:47] [V] [TRT] Tactic: 1237784342446422381 Time: 0.084864
[03/24/2023-12:56:47] [V] [TRT] Conv_44 + Relu_45 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x64x32_stage5_warpsize2x2x1_g1_tensor16x8x8 Tactic: 1426562292875733922
[03/24/2023-12:56:47] [V] [TRT] Tactic: 1426562292875733922 Time: 0.089472
[03/24/2023-12:56:48] [V] [TRT] Conv_44 + Relu_45 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize64x128x8_stage3_warpsize1x4x1_g1_ffma_t1r3s3 Tactic: 2086609538387166260
[03/24/2023-12:56:48] [V] [TRT] Tactic: 2086609538387166260 Time: 0.33472
[03/24/2023-12:56:48] [V] [TRT] Conv_44 + Relu_45 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize256x128x32_stage3_warpsize4x2x1_g1_tensor16x8x8_t1r3s3 Tactic: 2388153022056233219
[03/24/2023-12:56:48] [V] [TRT] Tactic: 2388153022056233219 Time: 0.074752
[03/24/2023-12:56:48] [V] [TRT] Conv_44 + Relu_45 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x128x32_stage4_warpsize2x2x1_g1_tensor16x8x8 Tactic: 2716437853123234317
[03/24/2023-12:56:48] [V] [TRT] Tactic: 2716437853123234317 Time: 0.080384
[03/24/2023-12:56:48] [V] [TRT] Conv_44 + Relu_45 Set Tactic Name: ampere_scudnn_128x64_sliced1x2_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: 2860655430572478466
[03/24/2023-12:56:48] [V] [TRT] Tactic: 2860655430572478466 Time: 0.340992
[03/24/2023-12:56:48] [V] [TRT] Conv_44 + Relu_45 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize64x128x8_stage3_warpsize1x4x1_g1_ffma Tactic: 3239733199291090177
[03/24/2023-12:56:48] [V] [TRT] Tactic: 3239733199291090177 Time: 0.333952
[03/24/2023-12:56:48] [V] [TRT] Conv_44 + Relu_45 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize64x64x64_stage4_warpsize2x2x1_g1_tensor16x8x8_t1r3s3 Tactic: 3278852197192504305
[03/24/2023-12:56:48] [V] [TRT] Tactic: 3278852197192504305 Time: 0.089088
[03/24/2023-12:56:48] [V] [TRT] Conv_44 + Relu_45 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize256x128x32_stage3_warpsize4x2x1_g1_tensor16x8x8 Tactic: 3904690393614050557
[03/24/2023-12:56:48] [V] [TRT] Tactic: 3904690393614050557 Time: 0.092672
[03/24/2023-12:56:48] [V] [TRT] Conv_44 + Relu_45 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize64x64x64_stage4_warpsize2x2x1_g1_tensor16x8x8 Tactic: 4061115162338989075
[03/24/2023-12:56:48] [V] [TRT] Tactic: 4061115162338989075 Time: 0.095104
[03/24/2023-12:56:48] [V] [TRT] Conv_44 + Relu_45 Set Tactic Name: ampere_scudnn_128x32_sliced1x4_ldg4_relu_exp_medium_nhwc_tn_v1 Tactic: 4474630279712975759
[03/24/2023-12:56:48] [V] [TRT] Tactic: 4474630279712975759 Time: 0.291072
[03/24/2023-12:56:48] [V] [TRT] Conv_44 + Relu_45 Set Tactic Name: ampere_scudnn_128x32_sliced1x4_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: 4479823862704990365
[03/24/2023-12:56:48] [V] [TRT] Tactic: 4479823862704990365 Time: 0.289408
[03/24/2023-12:56:48] [V] [TRT] Conv_44 + Relu_45 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize64x256x8_stage3_warpsize1x4x1_g1_ffma Tactic: 4517590677127196184
[03/24/2023-12:56:48] [V] [TRT] Tactic: 4517590677127196184 Time: 0.455936
[03/24/2023-12:56:48] [V] [TRT] Conv_44 + Relu_45 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize128x128x8_stage3_warpsize2x4x1_g1_ffma_t1r3s3 Tactic: 4634080872644479428
[03/24/2023-12:56:48] [V] [TRT] Tactic: 4634080872644479428 Time: 0.443264
[03/24/2023-12:56:48] [V] [TRT] Conv_44 + Relu_45 Set Tactic Name: ampere_scudnn_128x64_sliced1x2_ldg4_relu_exp_medium_nhwc_tn_v1 Tactic: 4696204239951173149
[03/24/2023-12:56:48] [V] [TRT] Tactic: 4696204239951173149 Time: 0.34112
[03/24/2023-12:56:48] [V] [TRT] Conv_44 + Relu_45 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x256x32_stage3_warpsize2x4x1_g1_tensor16x8x8 Tactic: 5200329514761435342
[03/24/2023-12:56:48] [V] [TRT] Tactic: 5200329514761435342 Time: 0.07168
[03/24/2023-12:56:48] [V] [TRT] Conv_44 + Relu_45 Set Tactic Name: ampere_scudnn_128x128_relu_exp_small_nhwc_tn_v1 Tactic: 5778138195697110003
[03/24/2023-12:56:48] [V] [TRT] Tactic: 5778138195697110003 Time: 0.440576
[03/24/2023-12:56:48] [V] [TRT] Conv_44 + Relu_45 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize256x128x8_stage3_warpsize2x4x1_g1_ffma Tactic: 6310198979346901507
[03/24/2023-12:56:48] [V] [TRT] Tactic: 6310198979346901507 Time: 0.463744
[03/24/2023-12:56:48] [V] [TRT] Conv_44 + Relu_45 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x256x32_stage3_warpsize2x4x1_g1_tensor16x8x8_t1r3s3 Tactic: 7011693366046809027
[03/24/2023-12:56:48] [V] [TRT] Tactic: 7011693366046809027 Time: 0.070656
[03/24/2023-12:56:48] [V] [TRT] Conv_44 + Relu_45 Set Tactic Name: ampere_scudnn_128x128_ldg4_relu_exp_large_nhwc_tn_v1 Tactic: 7155825427510256858
[03/24/2023-12:56:48] [V] [TRT] Tactic: 7155825427510256858 Time: 0.444544
[03/24/2023-12:56:48] [V] [TRT] Conv_44 + Relu_45 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize128x64x8_stage3_warpsize1x4x1_g1_ffma Tactic: 7222247112373541608
[03/24/2023-12:56:48] [V] [TRT] Tactic: 7222247112373541608 Time: 0.46336
[03/24/2023-12:56:48] [V] [TRT] Conv_44 + Relu_45 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x128x16_stage4_warpsize2x2x1_g1_tensor16x8x8 Tactic: 7342025736444949634
[03/24/2023-12:56:48] [V] [TRT] Tactic: 7342025736444949634 Time: 0.0864
[03/24/2023-12:56:48] [V] [TRT] Conv_44 + Relu_45 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize64x128x32_stage5_warpsize2x2x1_g1_tensor16x8x8 Tactic: 7347365539922924600
[03/24/2023-12:56:48] [V] [TRT] Tactic: 7347365539922924600 Time: 0.07808
[03/24/2023-12:56:48] [V] [TRT] Conv_44 + Relu_45 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x64x32_stage5_warpsize2x2x1_g1_tensor16x8x8 Tactic: 7428197830878119671
[03/24/2023-12:56:48] [V] [TRT] Tactic: 7428197830878119671 Time: 0.082304
[03/24/2023-12:56:48] [V] [TRT] Conv_44 + Relu_45 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize64x32x64_stage5_warpsize2x2x1_g1_tensor16x8x8_t1r3s3 Tactic: 7465323447915168822
[03/24/2023-12:56:48] [V] [TRT] Tactic: 7465323447915168822 Time: 0.128128
[03/24/2023-12:56:48] [V] [TRT] Conv_44 + Relu_45 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize128x128x8_stage3_warpsize2x4x1_g1_ffma Tactic: 7472640475524677095
[03/24/2023-12:56:48] [V] [TRT] Tactic: 7472640475524677095 Time: 0.451968
[03/24/2023-12:56:48] [V] [TRT] Conv_44 + Relu_45 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize64x32x64_stage5_warpsize2x2x1_g1_tensor16x8x8 Tactic: 7938223790021272801
[03/24/2023-12:56:48] [V] [TRT] Tactic: 7938223790021272801 Time: 0.134656
[03/24/2023-12:56:48] [V] [TRT] Conv_44 + Relu_45 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize128x256x8_stage3_warpsize2x4x1_g1_ffma Tactic: 8498373915030836990
[03/24/2023-12:56:48] [V] [TRT] Tactic: 8498373915030836990 Time: 0.449024
[03/24/2023-12:56:48] [V] [TRT] Conv_44 + Relu_45 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x64x32_stage5_warpsize2x2x1_g1_tensor16x8x8_t1r3s3 Tactic: 8836645772682419994
[03/24/2023-12:56:48] [V] [TRT] Tactic: 8836645772682419994 Time: 0.079104
[03/24/2023-12:56:48] [V] [TRT] Conv_44 + Relu_45 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize256x64x8_stage3_warpsize1x4x1_g1_ffma Tactic: 8869697132622550639
[03/24/2023-12:56:48] [V] [TRT] Tactic: 8869697132622550639 Time: 0.515712
[03/24/2023-12:56:48] [V] [TRT] Conv_44 + Relu_45 Set Tactic Name: ampere_scudnn_128x128_ldg4_relu_exp_medium_nhwc_tn_v1 Tactic: 8918020581761223752
[03/24/2023-12:56:48] [V] [TRT] Tactic: 8918020581761223752 Time: 0.438912
[03/24/2023-12:56:48] [V] [TRT] Conv_44 + Relu_45 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize64x64x64_stage4_warpsize2x2x1_g1_tensor16x8x8 Tactic: -9114138070928278731
[03/24/2023-12:56:48] [V] [TRT] Tactic: -9114138070928278731 Time: 0.092928
[03/24/2023-12:56:48] [V] [TRT] Conv_44 + Relu_45 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize256x128x8_stage3_warpsize2x4x1_g1_ffma_t1r3s3 Tactic: -8937725997228636978
[03/24/2023-12:56:48] [V] [TRT] Tactic: -8937725997228636978 Time: 0.444544
[03/24/2023-12:56:48] [V] [TRT] Conv_44 + Relu_45 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize128x256x8_stage3_warpsize2x4x1_g1_ffma_t1r3s3 Tactic: -8833858409138163072
[03/24/2023-12:56:48] [V] [TRT] Tactic: -8833858409138163072 Time: 0.444288
[03/24/2023-12:56:48] [V] [TRT] Conv_44 + Relu_45 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize64x64x8_stage3_warpsize1x4x1_g1_ffma_t1r3s3 Tactic: -7989138351613022500
[03/24/2023-12:56:48] [V] [TRT] Tactic: -7989138351613022500 Time: 0.283776
[03/24/2023-12:56:48] [V] [TRT] Conv_44 + Relu_45 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize256x128x8_stage3_warpsize2x4x1_g1_ffma Tactic: -7872883691240863058
[03/24/2023-12:56:48] [V] [TRT] Tactic: -7872883691240863058 Time: 0.460032
[03/24/2023-12:56:48] [V] [TRT] Conv_44 + Relu_45 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x256x32_stage3_warpsize2x4x1_g1_tensor16x8x8 Tactic: -7382359095196034537
[03/24/2023-12:56:48] [V] [TRT] Tactic: -7382359095196034537 Time: 0.0736
[03/24/2023-12:56:48] [V] [TRT] Conv_44 + Relu_45 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x128x16_stage4_warpsize2x2x1_g1_tensor16x8x8_t1r3s3 Tactic: -7377458734869418330
[03/24/2023-12:56:48] [V] [TRT] Tactic: -7377458734869418330 Time: 0.082176
[03/24/2023-12:56:48] [V] [TRT] Conv_44 + Relu_45 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize128x128x8_stage3_warpsize2x4x1_g1_ffma Tactic: -6729618519651721910
[03/24/2023-12:56:48] [V] [TRT] Tactic: -6729618519651721910 Time: 0.446592
[03/24/2023-12:56:48] [V] [TRT] Conv_44 + Relu_45 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize256x64x32_stage3_warpsize4x2x1_g1_tensor16x8x8_t1r3s3 Tactic: -6223854811627385844
[03/24/2023-12:56:48] [V] [TRT] Tactic: -6223854811627385844 Time: 0.084736
[03/24/2023-12:56:48] [V] [TRT] Conv_44 + Relu_45 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize256x64x8_stage3_warpsize1x4x1_g1_ffma Tactic: -5893833996418445881
[03/24/2023-12:56:48] [V] [TRT] Tactic: -5893833996418445881 Time: 0.499968
[03/24/2023-12:56:48] [V] [TRT] Conv_44 + Relu_45 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize128x256x8_stage3_warpsize2x4x1_g1_ffma Tactic: -5701562095007058349
[03/24/2023-12:56:48] [V] [TRT] Tactic: -5701562095007058349 Time: 0.44352
[03/24/2023-12:56:48] [V] [TRT] Conv_44 + Relu_45 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize128x64x8_stage3_warpsize1x4x1_g1_ffma Tactic: -5685503422376017600
[03/24/2023-12:56:48] [V] [TRT] Tactic: -5685503422376017600 Time: 0.449024
[03/24/2023-12:56:48] [V] [TRT] Conv_44 + Relu_45 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize64x64x8_stage3_warpsize1x4x1_g1_ffma Tactic: -5521125187060117489
[03/24/2023-12:56:48] [V] [TRT] Tactic: -5521125187060117489 Time: 0.308096
[03/24/2023-12:56:48] [V] [TRT] Conv_44 + Relu_45 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x128x16_stage4_warpsize2x2x1_g1_tensor16x8x8 Tactic: -5457304872213719461
[03/24/2023-12:56:48] [V] [TRT] Tactic: -5457304872213719461 Time: 0.08384
[03/24/2023-12:56:48] [V] [TRT] Conv_44 + Relu_45 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x64x64_stage3_warpsize2x2x1_g1_tensor16x8x8 Tactic: -5441054706931585554
[03/24/2023-12:56:48] [V] [TRT] Tactic: -5441054706931585554 Time: 0.087168
[03/24/2023-12:56:48] [V] [TRT] Conv_44 + Relu_45 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize256x64x32_stage3_warpsize4x2x1_g1_tensor16x8x8 Tactic: -5043603702497465467
[03/24/2023-12:56:48] [V] [TRT] Tactic: -5043603702497465467 Time: 0.102656
[03/24/2023-12:56:48] [V] [TRT] Conv_44 + Relu_45 Set Tactic Name: ampere_scudnn_128x64_sliced1x2_ldg4_relu_exp_large_nhwc_tn_v1 Tactic: -4756382386362004279
[03/24/2023-12:56:48] [V] [TRT] Tactic: -4756382386362004279 Time: 0.336768
[03/24/2023-12:56:48] [V] [TRT] Conv_44 + Relu_45 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize64x64x8_stage3_warpsize1x4x1_g1_ffma Tactic: -4615000974950361663
[03/24/2023-12:56:48] [V] [TRT] Tactic: -4615000974950361663 Time: 0.294016
[03/24/2023-12:56:48] [V] [TRT] Conv_44 + Relu_45 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x64x64_stage3_warpsize2x2x1_g1_tensor16x8x8 Tactic: -4564655677311401797
[03/24/2023-12:56:48] [V] [TRT] Tactic: -4564655677311401797 Time: 0.08704
[03/24/2023-12:56:48] [V] [TRT] Conv_44 + Relu_45 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize256x64x8_stage3_warpsize1x4x1_g1_ffma_t1r3s3 Tactic: -4314913710375142296
[03/24/2023-12:56:48] [V] [TRT] Tactic: -4314913710375142296 Time: 0.48384
[03/24/2023-12:56:48] [V] [TRT] Conv_44 + Relu_45 Set Tactic Name: ampere_scudnn_128x128_relu_exp_large_nhwc_tn_v1 Tactic: -3855385237722507464
[03/24/2023-12:56:48] [V] [TRT] Tactic: -3855385237722507464 Time: 0.443648
[03/24/2023-12:56:48] [V] [TRT] Conv_44 + Relu_45 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize128x64x8_stage3_warpsize1x4x1_g1_ffma_t1r3s3 Tactic: -3697587361057948972
[03/24/2023-12:56:48] [V] [TRT] Tactic: -3697587361057948972 Time: 0.449664
[03/24/2023-12:56:48] [V] [TRT] Conv_44 + Relu_45 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize256x64x32_stage3_warpsize4x2x1_g1_tensor16x8x8 Tactic: -3540975627865078064
[03/24/2023-12:56:48] [V] [TRT] Tactic: -3540975627865078064 Time: 0.090112
[03/24/2023-12:56:48] [V] [TRT] Conv_44 + Relu_45 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize64x128x32_stage5_warpsize2x2x1_g1_tensor16x8x8_t1r3s3 Tactic: -3151804561246216835
[03/24/2023-12:56:48] [V] [TRT] Tactic: -3151804561246216835 Time: 0.077056
[03/24/2023-12:56:48] [V] [TRT] Conv_44 + Relu_45 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize64x32x64_stage5_warpsize2x2x1_g1_tensor16x8x8 Tactic: -2885165284206163001
[03/24/2023-12:56:48] [V] [TRT] Tactic: -2885165284206163001 Time: 0.142848
[03/24/2023-12:56:48] [V] [TRT] Conv_44 + Relu_45 Set Tactic Name: ampere_scudnn_128x128_relu_exp_medium_nhwc_tn_v1 Tactic: -2809379259463049391
[03/24/2023-12:56:48] [V] [TRT] Tactic: -2809379259463049391 Time: 0.442496
[03/24/2023-12:56:48] [V] [TRT] Conv_44 + Relu_45 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x128x32_stage4_warpsize2x2x1_g1_tensor16x8x8_t1r3s3 Tactic: -2801041895330778813
[03/24/2023-12:56:48] [V] [TRT] Tactic: -2801041895330778813 Time: 0.087168
[03/24/2023-12:56:48] [V] [TRT] Conv_44 + Relu_45 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize64x256x8_stage3_warpsize1x4x1_g1_ffma_t1r3s3 Tactic: -2747929399988666512
[03/24/2023-12:56:48] [V] [TRT] Tactic: -2747929399988666512 Time: 0.444928
[03/24/2023-12:56:48] [V] [TRT] Conv_44 + Relu_45 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize256x128x32_stage3_warpsize4x2x1_g1_tensor16x8x8 Tactic: -1758690179295738332
[03/24/2023-12:56:48] [V] [TRT] Tactic: -1758690179295738332 Time: 0.078336
[03/24/2023-12:56:48] [V] [TRT] Conv_44 + Relu_45 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x64x64_stage3_warpsize2x2x1_g1_tensor16x8x8_t1r3s3 Tactic: -1484546572846226796
[03/24/2023-12:56:48] [V] [TRT] Tactic: -1484546572846226796 Time: 0.082816
[03/24/2023-12:56:48] [V] [TRT] Conv_44 + Relu_45 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize64x256x8_stage3_warpsize1x4x1_g1_ffma Tactic: -1472061967969061456
[03/24/2023-12:56:48] [V] [TRT] Tactic: -1472061967969061456 Time: 0.453376
[03/24/2023-12:56:48] [V] [TRT] Conv_44 + Relu_45 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x128x32_stage4_warpsize2x2x1_g1_tensor16x8x8 Tactic: -858667497925695276
[03/24/2023-12:56:48] [V] [TRT] Tactic: -858667497925695276 Time: 0.125696
[03/24/2023-12:56:48] [V] [TRT] Conv_44 + Relu_45 Set Tactic Name: ampere_scudnn_128x128_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: -504296718212024303
[03/24/2023-12:56:48] [V] [TRT] Tactic: -504296718212024303 Time: 0.440192
[03/24/2023-12:56:48] [V] [TRT] Conv_44 + Relu_45 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize64x128x8_stage3_warpsize1x4x1_g1_ffma Tactic: -444093195553988951
[03/24/2023-12:56:48] [V] [TRT] Tactic: -444093195553988951 Time: 0.349568
[03/24/2023-12:56:48] [V] [TRT] Fastest Tactic: 7011693366046809027 Time: 0.070656
[03/24/2023-12:56:48] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: 7011693366046809027
[03/24/2023-12:56:48] [V] [TRT] *************** Autotuning format combination: Half(4147200,32400,180,1) -> Half(2073600,8100,90,1) ***************
[03/24/2023-12:56:48] [V] [TRT] --------------- Timing Runner: Conv_44 + Relu_45 (CudnnConvolution)
[03/24/2023-12:56:48] [V] [TRT] Tactic: 0 Time: 0.491648
[03/24/2023-12:56:48] [V] [TRT] Tactic: 1 Time: 0.41216
[03/24/2023-12:56:48] [V] [TRT] Tactic: 2 Time: 0.526208
[03/24/2023-12:56:48] [V] [TRT] Tactic: 5 Time: 4.39437
[03/24/2023-12:56:48] [V] [TRT] Tactic: 56 Time: 0.491392
[03/24/2023-12:56:48] [V] [TRT] Tactic: 58 Time: 0.526208
[03/24/2023-12:56:48] [V] [TRT] Tactic: 61 Time: 4.39181
[03/24/2023-12:56:48] [V] [TRT] Fastest Tactic: 1 Time: 0.41216
[03/24/2023-12:56:48] [V] [TRT] --------------- Timing Runner: Conv_44 + Relu_45 (CaskConvolution)
[03/24/2023-12:56:48] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[03/24/2023-12:56:48] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CudnnConvolution Tactic: 1
[03/24/2023-12:56:48] [V] [TRT] *************** Autotuning format combination: Half(2073600,32400:2,180,1) -> Half(1036800,8100:2,90,1) ***************
[03/24/2023-12:56:48] [V] [TRT] --------------- Timing Runner: Conv_44 + Relu_45 (FusedConvActConvolution)
[03/24/2023-12:56:48] [V] [TRT] Tactic: 458751 Time: 0.195456
[03/24/2023-12:56:48] [V] [TRT] Fastest Tactic: 458751 Time: 0.195456
[03/24/2023-12:56:48] [V] [TRT] --------------- Timing Runner: Conv_44 + Relu_45 (CudnnConvolution)
[03/24/2023-12:56:48] [V] [TRT] CudnnConvolution has no valid tactics for this config, skipping
[03/24/2023-12:56:48] [V] [TRT] --------------- Timing Runner: Conv_44 + Relu_45 (CaskConvolution)
[03/24/2023-12:56:48] [V] [TRT] Conv_44 + Relu_45 Set Tactic Name: ampere_fp16x2_hcudnn_fp16x2_128x32_relu_medium_nn_v1 Tactic: 2195670545862694453
[03/24/2023-12:56:48] [V] [TRT] Tactic: 2195670545862694453 Time: 0.195712
[03/24/2023-12:56:48] [V] [TRT] Conv_44 + Relu_45 Set Tactic Name: ampere_fp16x2_hcudnn_fp16x2_128x64_relu_large_nn_v1 Tactic: 3419182076704469245
[03/24/2023-12:56:48] [V] [TRT] Tactic: 3419182076704469245 Time: 0.190464
[03/24/2023-12:56:48] [V] [TRT] Conv_44 + Relu_45 Set Tactic Name: ampere_fp16x2_hcudnn_fp16x2_128x128_relu_medium_nn_v1 Tactic: 3891805945559659536
[03/24/2023-12:56:48] [V] [TRT] Tactic: 3891805945559659536 Time: 0.232576
[03/24/2023-12:56:48] [V] [TRT] Conv_44 + Relu_45 Set Tactic Name: ampere_fp16x2_hcudnn_fp16x2_128x64_relu_medium_nn_v1 Tactic: 5548126322150286555
[03/24/2023-12:56:48] [V] [TRT] Tactic: 5548126322150286555 Time: 0.18816
[03/24/2023-12:56:48] [V] [TRT] Conv_44 + Relu_45 Set Tactic Name: ampere_fp16x2_hcudnn_fp16x2_128x64_relu_small_nn_v1 Tactic: 6057304366605292508
[03/24/2023-12:56:48] [V] [TRT] Tactic: 6057304366605292508 Time: 0.183424
[03/24/2023-12:56:48] [V] [TRT] Conv_44 + Relu_45 Set Tactic Name: ampere_fp16x2_hcudnn_fp16x2_128x128_relu_large_nn_v1 Tactic: -7928611605886347652
[03/24/2023-12:56:48] [V] [TRT] Tactic: -7928611605886347652 Time: 0.239744
[03/24/2023-12:56:48] [V] [TRT] Conv_44 + Relu_45 Set Tactic Name: ampere_fp16x2_hcudnn_fp16x2_128x32_relu_large_nn_v1 Tactic: -5172391392092686714
[03/24/2023-12:56:48] [V] [TRT] Tactic: -5172391392092686714 Time: 0.197632
[03/24/2023-12:56:48] [V] [TRT] Conv_44 + Relu_45 Set Tactic Name: ampere_fp16x2_hcudnn_fp16x2_128x32_relu_small_nn_v1 Tactic: -4374269919094467161
[03/24/2023-12:56:48] [V] [TRT] Tactic: -4374269919094467161 Time: 0.19136
[03/24/2023-12:56:48] [V] [TRT] Conv_44 + Relu_45 Set Tactic Name: ampere_fp16x2_hcudnn_fp16x2_128x128_relu_small_nn_v1 Tactic: -1546027692247304867
[03/24/2023-12:56:48] [V] [TRT] Tactic: -1546027692247304867 Time: 0.234368
[03/24/2023-12:56:48] [V] [TRT] Fastest Tactic: 6057304366605292508 Time: 0.183424
[03/24/2023-12:56:48] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: 6057304366605292508
[03/24/2023-12:56:48] [V] [TRT] *************** Autotuning format combination: Half(518400,1:8,2880,16) -> Float(2073600,8100,90,1) ***************
[03/24/2023-12:56:48] [V] [TRT] --------------- Timing Runner: Conv_44 + Relu_45 (CudnnConvolution)
[03/24/2023-12:56:48] [V] [TRT] CudnnConvolution has no valid tactics for this config, skipping
[03/24/2023-12:56:49] [V] [TRT] --------------- Timing Runner: Conv_44 + Relu_45 (CaskConvolution)
[03/24/2023-12:56:49] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[03/24/2023-12:56:49] [V] [TRT] *************** Autotuning format combination: Half(518400,1:8,2880,16) -> Half(259200,1:8,2880,32) ***************
[03/24/2023-12:56:49] [V] [TRT] --------------- Timing Runner: Conv_44 + Relu_45 (CudaDepthwiseConvolution)
[03/24/2023-12:56:49] [V] [TRT] CudaDepthwiseConvolution has no valid tactics for this config, skipping
[03/24/2023-12:56:49] [V] [TRT] --------------- Timing Runner: Conv_44 + Relu_45 (CudnnConvolution)
[03/24/2023-12:56:49] [V] [TRT] Tactic: 0 Time: 0.548224
[03/24/2023-12:56:49] [V] [TRT] Tactic: 1 Time: 0.961536
[03/24/2023-12:56:49] [V] [TRT] Tactic: 2 Time: 0.585344
[03/24/2023-12:56:49] [V] [TRT] Tactic: 56 Time: 0.547456
[03/24/2023-12:56:49] [V] [TRT] Tactic: 58 Time: 0.585728
[03/24/2023-12:56:49] [V] [TRT] Fastest Tactic: 56 Time: 0.547456
[03/24/2023-12:56:49] [V] [TRT] --------------- Timing Runner: Conv_44 + Relu_45 (CaskConvolution)
[03/24/2023-12:56:49] [V] [TRT] Conv_44 + Relu_45 Set Tactic Name: ampere_h16816cudnn_256x128_ldg8_relu_exp_medium_nhwc_tn_v1 Tactic: 254850674756030979
[03/24/2023-12:56:49] [V] [TRT] Tactic: 254850674756030979 Time: 0.041984
[03/24/2023-12:56:49] [V] [TRT] Conv_44 + Relu_45 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x128x32_stage3_warpsize4x2x1_g1_tensor16x8x16_t1r3s3 Tactic: 328038211831149625
[03/24/2023-12:56:49] [V] [TRT] Tactic: 328038211831149625 Time: 0.03968
[03/24/2023-12:56:49] [V] [TRT] Conv_44 + Relu_45 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x64x64_stage3_warpsize2x2x1_g1_tensor16x8x16_t1r3s3 Tactic: 411553864378931917
[03/24/2023-12:56:49] [V] [TRT] Tactic: 411553864378931917 Time: 0.047104
[03/24/2023-12:56:49] [V] [TRT] Conv_44 + Relu_45 Set Tactic Name: sm75_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x128x32_stage1_warpsize4x2x1_g1_tensor16x8x8_t1r3s3 Tactic: 864841579020773074
[03/24/2023-12:56:49] [V] [TRT] Tactic: 864841579020773074 Time: 0.046592
[03/24/2023-12:56:49] [V] [TRT] Conv_44 + Relu_45 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x128x32_stage4_warpsize2x2x1_g1_tensor16x8x16 Tactic: 1011057357468998345
[03/24/2023-12:56:49] [V] [TRT] Tactic: 1011057357468998345 Time: 0.043904
[03/24/2023-12:56:49] [V] [TRT] Conv_44 + Relu_45 Set Tactic Name: sm75_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x64x32_stage1_warpsize4x1x1_g1_tensor16x8x8 Tactic: 1013168150133367738
[03/24/2023-12:56:49] [V] [TRT] Tactic: 1013168150133367738 Time: 0.05632
[03/24/2023-12:56:49] [V] [TRT] Conv_44 + Relu_45 Set Tactic Name: ampere_h16816cudnn_256x128_ldg8_relu_exp_stages_64x3_small_nhwc_tn_v1 Tactic: 1016009564074305832
[03/24/2023-12:56:49] [V] [TRT] Tactic: 1016009564074305832 Time: 0.04096
[03/24/2023-12:56:49] [V] [TRT] Conv_44 + Relu_45 Set Tactic Name: sm75_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x128x32_stage1_warpsize2x2x1_g1_tensor16x8x8 Tactic: 1067227531433278814
[03/24/2023-12:56:49] [V] [TRT] Tactic: 1067227531433278814 Time: 0.050176
[03/24/2023-12:56:49] [V] [TRT] Conv_44 + Relu_45 Set Tactic Name: ampere_h1688cudnn_128x128_ldg8_relu_exp_medium_nhwc_tn_v1 Tactic: 1156328698016730421
[03/24/2023-12:56:49] [V] [TRT] Tactic: 1156328698016730421 Time: 0.049152
[03/24/2023-12:56:49] [V] [TRT] Conv_44 + Relu_45 Set Tactic Name: sm75_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x128x32_stage1_warpsize2x2x1_g1_tensor16x8x8 Tactic: 1579845938601132607
[03/24/2023-12:56:49] [V] [TRT] Tactic: 1579845938601132607 Time: 0.048128
[03/24/2023-12:56:49] [V] [TRT] Conv_44 + Relu_45 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x128x32_stage5_warpsize2x2x1_g1_tensor16x8x16_t1r3s3 Tactic: 1723736032573714698
[03/24/2023-12:56:49] [V] [TRT] Tactic: 1723736032573714698 Time: 0.04736
[03/24/2023-12:56:49] [V] [TRT] Conv_44 + Relu_45 Set Tactic Name: sm75_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x32x32_stage1_warpsize4x1x1_g1_tensor16x8x8 Tactic: 1796821236841789338
[03/24/2023-12:56:49] [V] [TRT] Tactic: 1796821236841789338 Time: 0.073088
[03/24/2023-12:56:49] [V] [TRT] Conv_44 + Relu_45 Set Tactic Name: ampere_h16816cudnn_128x64_ldg8_relu_exp_stages_64x4_medium_nhwc_tn_v1 Tactic: 1832046141070096030
[03/24/2023-12:56:49] [V] [TRT] Tactic: 1832046141070096030 Time: 0.044032
[03/24/2023-12:56:49] [V] [TRT] Conv_44 + Relu_45 Set Tactic Name: ampere_h16816cudnn_128x64_sliced1x2_ldg8_relu_exp_stages_64x3_small_nhwc_tn_v1 Tactic: 1838082074606840426
[03/24/2023-12:56:49] [V] [TRT] Tactic: 1838082074606840426 Time: 0.041344
[03/24/2023-12:56:49] [V] [TRT] Conv_44 + Relu_45 Set Tactic Name: ampere_h16816cudnn_64x64_sliced1x2_ldg8_relu_exp_stages_64x5_small_nhwc_tn_v1 Tactic: 1899296423087490472
[03/24/2023-12:56:49] [V] [TRT] Tactic: 1899296423087490472 Time: 0.053888
[03/24/2023-12:56:49] [V] [TRT] Conv_44 + Relu_45 Set Tactic Name: sm75_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x32x32_stage1_warpsize4x1x1_g1_tensor16x8x8 Tactic: 1948263663414159978
[03/24/2023-12:56:49] [V] [TRT] Tactic: 1948263663414159978 Time: 0.065408
[03/24/2023-12:56:49] [V] [TRT] Conv_44 + Relu_45 Set Tactic Name: sm75_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x256x64_stage1_warpsize1x4x2_g1_tensor16x8x8 Tactic: 2027733232253711640
[03/24/2023-12:56:49] [V] [TRT] Tactic: 2027733232253711640 Time: 0.056448
[03/24/2023-12:56:49] [V] [TRT] Conv_44 + Relu_45 Set Tactic Name: sm75_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x64x32_stage1_warpsize2x2x1_g1_tensor16x8x8_t1r3s3 Tactic: 2154731107061273008
[03/24/2023-12:56:49] [V] [TRT] Tactic: 2154731107061273008 Time: 0.052224
[03/24/2023-12:56:49] [V] [TRT] Conv_44 + Relu_45 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x64x64_stage3_warpsize2x2x1_g1_tensor16x8x16 Tactic: 2428167804343994714
[03/24/2023-12:56:49] [V] [TRT] Tactic: 2428167804343994714 Time: 0.043392
[03/24/2023-12:56:49] [V] [TRT] Conv_44 + Relu_45 Set Tactic Name: ampere_h16816cudnn_128x128_ldg8_relu_exp_medium_nhwc_tn_v1 Tactic: 2541579301352125276
[03/24/2023-12:56:49] [V] [TRT] Tactic: 2541579301352125276 Time: 0.044032
[03/24/2023-12:56:49] [V] [TRT] Conv_44 + Relu_45 Set Tactic Name: ampere_h16816cudnn_64x64_sliced1x2_ldg8_relu_exp_stages_64x6_small_nhwc_tn_v1 Tactic: 2657157263811141609
[03/24/2023-12:56:49] [V] [TRT] Tactic: 2657157263811141609 Time: 0.051328
[03/24/2023-12:56:49] [V] [TRT] Conv_44 + Relu_45 Set Tactic Name: ampere_h16816cudnn_64x128_sliced1x2_ldg8_relu_exp_stages_64x4_large_nhwc_tn_v1 Tactic: 2819719497590964443
[03/24/2023-12:56:49] [V] [TRT] Tactic: 2819719497590964443 Time: 0.045056
[03/24/2023-12:56:49] [V] [TRT] Conv_44 + Relu_45 Set Tactic Name: ampere_h16816cudnn_128x64_sliced1x2_ldg8_relu_exp_stages_64x3_medium_nhwc_tn_v1 Tactic: 2968605903460894194
[03/24/2023-12:56:49] [V] [TRT] Tactic: 2968605903460894194 Time: 0.04224
[03/24/2023-12:56:49] [V] [TRT] Conv_44 + Relu_45 Set Tactic Name: ampere_h16816cudnn_128x128_ldg8_relu_exp_large_nhwc_tn_v1 Tactic: 2986078304285316765
[03/24/2023-12:56:49] [V] [TRT] Tactic: 2986078304285316765 Time: 0.044544
[03/24/2023-12:56:49] [V] [TRT] Conv_44 + Relu_45 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x256x64_stage3_warpsize1x4x1_g1_tensor16x8x16 Tactic: 3016308193087082166
[03/24/2023-12:56:49] [V] [TRT] Tactic: 3016308193087082166 Time: 0.048128
[03/24/2023-12:56:49] [V] [TRT] Conv_44 + Relu_45 Set Tactic Name: ampere_h16816cudnn_256x64_ldg8_relu_exp_stages_64x3_large_nhwc_tn_v1 Tactic: 3221382575080507859
[03/24/2023-12:56:49] [V] [TRT] Tactic: 3221382575080507859 Time: 0.046208
[03/24/2023-12:56:49] [V] [TRT] Conv_44 + Relu_45 Set Tactic Name: ampere_h16816cudnn_128x128_ldg8_relu_exp_stages_64x3_medium_nhwc_tn_v1 Tactic: 3362537467505018070
[03/24/2023-12:56:49] [V] [TRT] Tactic: 3362537467505018070 Time: 0.044672
[03/24/2023-12:56:49] [V] [TRT] Conv_44 + Relu_45 Set Tactic Name: sm75_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x64x32_stage1_warpsize4x1x1_g1_tensor16x8x8_t1r3s3 Tactic: 3464689803495983377
[03/24/2023-12:56:49] [V] [TRT] Tactic: 3464689803495983377 Time: 0.053504
[03/24/2023-12:56:49] [V] [TRT] Conv_44 + Relu_45 Set Tactic Name: ampere_h1688cudnn_256x128_ldg8_relu_exp_medium_nhwc_tn_v1 Tactic: 3513075359009385578
[03/24/2023-12:56:49] [V] [TRT] Tactic: 3513075359009385578 Time: 0.049152
[03/24/2023-12:56:49] [V] [TRT] Conv_44 + Relu_45 Set Tactic Name: ampere_h16816cudnn_128x64_ldg8_relu_exp_stages_64x4_large_nhwc_tn_v1 Tactic: 3573559043797674382
[03/24/2023-12:56:49] [V] [TRT] Tactic: 3573559043797674382 Time: 0.045056
[03/24/2023-12:56:49] [V] [TRT] Conv_44 + Relu_45 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x64x64_stage4_warpsize2x2x1_g1_tensor16x8x16_t1r3s3 Tactic: 3591970081995419777
[03/24/2023-12:56:49] [V] [TRT] Tactic: 3591970081995419777 Time: 0.049792
[03/24/2023-12:56:49] [V] [TRT] Conv_44 + Relu_45 Set Tactic Name: sm75_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x128x32_stage1_warpsize2x2x1_g1_tensor16x8x8_t1r3s3 Tactic: 3636831327753843771
[03/24/2023-12:56:49] [V] [TRT] Tactic: 3636831327753843771 Time: 0.048384
[03/24/2023-12:56:49] [V] [TRT] Conv_44 + Relu_45 Set Tactic Name: ampere_h1688cudnn_128x128_ldg8_relu_exp_small_nhwc_tn_v1 Tactic: 3704534001553878387
[03/24/2023-12:56:49] [V] [TRT] Tactic: 3704534001553878387 Time: 0.047488
[03/24/2023-12:56:49] [V] [TRT] Conv_44 + Relu_45 Set Tactic Name: ampere_h16816cudnn_64x128_ldg8_relu_exp_stages_64x4_small_nhwc_tn_v1 Tactic: 4278315135102886928
[03/24/2023-12:56:49] [V] [TRT] Tactic: 4278315135102886928 Time: 0.042752
[03/24/2023-12:56:49] [V] [TRT] Conv_44 + Relu_45 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x32x32_stage4_warpsize4x1x1_g1_tensor16x8x16_t1r3s3 Tactic: 4503233883285355107
[03/24/2023-12:56:49] [V] [TRT] Tactic: 4503233883285355107 Time: 0.055936
[03/24/2023-12:56:49] [V] [TRT] Conv_44 + Relu_45 Set Tactic Name: ampere_h16816cudnn_256x64_ldg8_relu_exp_stages_64x3_medium_nhwc_tn_v1 Tactic: 4540505769798915372
[03/24/2023-12:56:49] [V] [TRT] Tactic: 4540505769798915372 Time: 0.04608
[03/24/2023-12:56:49] [V] [TRT] Conv_44 + Relu_45 Set Tactic Name: ampere_h16816cudnn_256x64_sliced1x2_ldg8_relu_exp_small_nhwc_tn_v1 Tactic: 4802447371470387646
[03/24/2023-12:56:49] [V] [TRT] Tactic: 4802447371470387646 Time: 0.056704
[03/24/2023-12:56:49] [V] [TRT] Conv_44 + Relu_45 Set Tactic Name: ampere_h16816cudnn_256x128_ldg8_relu_exp_small_nhwc_tn_v1 Tactic: 5059676457552313631
[03/24/2023-12:56:49] [V] [TRT] Tactic: 5059676457552313631 Time: 0.04096
[03/24/2023-12:56:49] [V] [TRT] Conv_44 + Relu_45 Set Tactic Name: sm75_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x128x64_stage1_warpsize2x2x1_g1_tensor16x8x8_t1r3s3 Tactic: 5263029549013613567
[03/24/2023-12:56:49] [V] [TRT] Tactic: 5263029549013613567 Time: 0.047104
[03/24/2023-12:56:49] [V] [TRT] Conv_44 + Relu_45 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x64x64_stage4_warpsize2x2x1_g1_tensor16x8x16 Tactic: 5368829646735632944
[03/24/2023-12:56:49] [V] [TRT] Tactic: 5368829646735632944 Time: 0.050048
[03/24/2023-12:56:49] [V] [TRT] Conv_44 + Relu_45 Set Tactic Name: ampere_h1688cudnn_256x64_sliced1x2_ldg8_relu_exp_small_nhwc_tn_v1 Tactic: 5398999388616959893
[03/24/2023-12:56:49] [V] [TRT] Tactic: 5398999388616959893 Time: 0.057856
[03/24/2023-12:56:49] [V] [TRT] Conv_44 + Relu_45 Set Tactic Name: sm75_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x256x32_stage1_warpsize2x4x1_g1_tensor16x8x8_t1r3s3 Tactic: 5506334059535811602
[03/24/2023-12:56:49] [V] [TRT] Tactic: 5506334059535811602 Time: 0.045824
[03/24/2023-12:56:49] [V] [TRT] Conv_44 + Relu_45 Set Tactic Name: ampere_h16816cudnn_64x128_sliced1x2_ldg8_relu_exp_stages_64x3_large_nhwc_tn_v1 Tactic: 5746691132547383910
[03/24/2023-12:56:49] [V] [TRT] Tactic: 5746691132547383910 Time: 0.04224
[03/24/2023-12:56:49] [V] [TRT] Conv_44 + Relu_45 Set Tactic Name: ampere_h16816cudnn_256x64_ldg8_relu_exp_large_nhwc_tn_v1 Tactic: 5770170567977052602
[03/24/2023-12:56:49] [V] [TRT] Tactic: 5770170567977052602 Time: 0.050944
[03/24/2023-12:56:49] [V] [TRT] Conv_44 + Relu_45 Set Tactic Name: sm75_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x32x64_stage1_warpsize2x1x2_g1_tensor16x8x8_t1r3s3 Tactic: 5932046018238429951
[03/24/2023-12:56:49] [V] [TRT] Tactic: 5932046018238429951 Time: 0.060416
[03/24/2023-12:56:49] [V] [TRT] Conv_44 + Relu_45 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x64x32_stage3_warpsize4x1x1_g1_tensor16x8x16_t1r3s3 Tactic: 5953552212833506549
[03/24/2023-12:56:49] [V] [TRT] Tactic: 5953552212833506549 Time: 0.041216
[03/24/2023-12:56:49] [V] [TRT] Conv_44 + Relu_45 Set Tactic Name: ampere_h16816cudnn_64x128_ldg8_relu_exp_stages_64x3_small_nhwc_tn_v1 Tactic: 6034364043891107501
[03/24/2023-12:56:49] [V] [TRT] Tactic: 6034364043891107501 Time: 0.041728
[03/24/2023-12:56:49] [V] [TRT] Conv_44 + Relu_45 Set Tactic Name: ampere_h16816cudnn_64x64_ldg8_relu_exp_stages_64x5_large_nhwc_tn_v1 Tactic: 6074229447555668232
[03/24/2023-12:56:49] [V] [TRT] Tactic: 6074229447555668232 Time: 0.056576
[03/24/2023-12:56:49] [V] [TRT] Conv_44 + Relu_45 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x64x64_stage3_warpsize2x2x1_g1_tensor16x8x16 Tactic: 6154447660803990543
[03/24/2023-12:56:49] [V] [TRT] Tactic: 6154447660803990543 Time: 0.045056
[03/24/2023-12:56:49] [V] [TRT] Conv_44 + Relu_45 Set Tactic Name: sm75_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x32x64_stage1_warpsize2x1x2_g1_tensor16x8x8 Tactic: 6195603576432354734
[03/24/2023-12:56:49] [V] [TRT] Tactic: 6195603576432354734 Time: 0.062592
[03/24/2023-12:56:49] [V] [TRT] Conv_44 + Relu_45 Set Tactic Name: sm75_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x32x32_stage1_warpsize4x1x1_g1_tensor16x8x8_t1r3s3 Tactic: 6252808259936499253
[03/24/2023-12:56:49] [V] [TRT] Tactic: 6252808259936499253 Time: 0.064896
[03/24/2023-12:56:49] [V] [TRT] Conv_44 + Relu_45 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x128x64_stage3_warpsize2x2x1_g1_tensor16x8x16 Tactic: 6325769668000961702
[03/24/2023-12:56:49] [V] [TRT] Tactic: 6325769668000961702 Time: 0.045184
[03/24/2023-12:56:49] [V] [TRT] Conv_44 + Relu_45 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x32x64_stage5_warpsize2x2x1_g1_tensor16x8x16 Tactic: 6350273239113254096
[03/24/2023-12:56:49] [V] [TRT] Tactic: 6350273239113254096 Time: 0.066944
[03/24/2023-12:56:49] [V] [TRT] Conv_44 + Relu_45 Set Tactic Name: ampere_h16816cudnn_128x128_ldg8_relu_exp_stages_64x3_small_nhwc_tn_v1 Tactic: 6377497238381488891
[03/24/2023-12:56:49] [V] [TRT] Tactic: 6377497238381488891 Time: 0.0448
[03/24/2023-12:56:49] [V] [TRT] Conv_44 + Relu_45 Set Tactic Name: sm75_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x64x64_stage1_warpsize2x2x1_g1_tensor16x8x8 Tactic: 6408235920257988861
[03/24/2023-12:56:49] [V] [TRT] Tactic: 6408235920257988861 Time: 0.049792
[03/24/2023-12:56:49] [V] [TRT] Conv_44 + Relu_45 Set Tactic Name: ampere_h16816cudnn_128x64_ldg8_relu_exp_stages_64x3_large_nhwc_tn_v1 Tactic: 6446388116965632819
[03/24/2023-12:56:49] [V] [TRT] Tactic: 6446388116965632819 Time: 0.042624
[03/24/2023-12:56:49] [V] [TRT] Conv_44 + Relu_45 Set Tactic Name: ampere_h16816cudnn_128x64_sliced1x2_ldg8_relu_exp_stages_64x4_medium_nhwc_tn_v1 Tactic: 6468794451065529747
[03/24/2023-12:56:49] [V] [TRT] Tactic: 6468794451065529747 Time: 0.043776
[03/24/2023-12:56:49] [V] [TRT] Conv_44 + Relu_45 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x128x64_stage3_warpsize4x2x1_g1_tensor16x8x16 Tactic: 6509152032538119080
[03/24/2023-12:56:49] [V] [TRT] Tactic: 6509152032538119080 Time: 0.04096
[03/24/2023-12:56:49] [V] [TRT] Conv_44 + Relu_45 Set Tactic Name: ampere_h1688cudnn_256x128_ldg8_relu_exp_large_nhwc_tn_v1 Tactic: 6642277870194067185
[03/24/2023-12:56:49] [V] [TRT] Tactic: 6642277870194067185 Time: 0.04992
[03/24/2023-12:56:49] [V] [TRT] Conv_44 + Relu_45 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x256x64_stage3_warpsize1x4x1_g1_tensor16x8x16 Tactic: 6703181542003057635
[03/24/2023-12:56:49] [V] [TRT] Tactic: 6703181542003057635 Time: 0.047104
[03/24/2023-12:56:49] [V] [TRT] Conv_44 + Relu_45 Set Tactic Name: ampere_h16816cudnn_64x64_ldg8_relu_exp_stages_64x5_medium_nhwc_tn_v1 Tactic: 6859477213531075460
[03/24/2023-12:56:49] [V] [TRT] Tactic: 6859477213531075460 Time: 0.056576
[03/24/2023-12:56:49] [V] [TRT] Conv_44 + Relu_45 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x128x32_stage4_warpsize2x2x1_g1_tensor16x8x16_t1r3s3 Tactic: 6972489290272968208
[03/24/2023-12:56:49] [V] [TRT] Tactic: 6972489290272968208 Time: 0.040832
[03/24/2023-12:56:49] [V] [TRT] Conv_44 + Relu_45 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x128x32_stage3_warpsize4x2x1_g1_tensor16x8x16 Tactic: 6979044990896381511
[03/24/2023-12:56:49] [V] [TRT] Tactic: 6979044990896381511 Time: 0.039808
[03/24/2023-12:56:49] [V] [TRT] Conv_44 + Relu_45 Set Tactic Name: ampere_h1688cudnn_256x64_ldg8_relu_exp_medium_nhwc_tn_v1 Tactic: 7216571380637776659
[03/24/2023-12:56:49] [V] [TRT] Tactic: 7216571380637776659 Time: 0.057216
[03/24/2023-12:56:49] [V] [TRT] Conv_44 + Relu_45 Set Tactic Name: ampere_h16816cudnn_128x64_ldg8_relu_exp_stages_64x3_medium_nhwc_tn_v1 Tactic: 7609923741161019135
[03/24/2023-12:56:49] [V] [TRT] Tactic: 7609923741161019135 Time: 0.04608
[03/24/2023-12:56:49] [V] [TRT] Conv_44 + Relu_45 Set Tactic Name: sm75_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x64x32_stage1_warpsize2x2x1_g1_tensor16x8x8 Tactic: 7612687199567064086
[03/24/2023-12:56:49] [V] [TRT] Tactic: 7612687199567064086 Time: 0.054656
[03/24/2023-12:56:49] [V] [TRT] Conv_44 + Relu_45 Set Tactic Name: ampere_h16816cudnn_64x64_ldg8_relu_exp_stages_64x6_large_nhwc_tn_v1 Tactic: 7705739241028240201
[03/24/2023-12:56:49] [V] [TRT] Tactic: 7705739241028240201 Time: 0.054656
[03/24/2023-12:56:49] [V] [TRT] Conv_44 + Relu_45 Set Tactic Name: sm75_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x128x32_stage1_warpsize2x2x1_g1_tensor16x8x8 Tactic: 7729555994715864793
[03/24/2023-12:56:49] [V] [TRT] Tactic: 7729555994715864793 Time: 0.05312
[03/24/2023-12:56:49] [V] [TRT] Conv_44 + Relu_45 Set Tactic Name: sm75_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x64x64_stage1_warpsize2x2x1_g1_tensor16x8x8_t1r3s3 Tactic: 7849296535223586261
[03/24/2023-12:56:49] [V] [TRT] Tactic: 7849296535223586261 Time: 0.049024
[03/24/2023-12:56:49] [V] [TRT] Conv_44 + Relu_45 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x256x32_stage3_warpsize2x4x1_g1_tensor16x8x16 Tactic: 8072087735545283117
[03/24/2023-12:56:49] [V] [TRT] Tactic: 8072087735545283117 Time: 0.039936
[03/24/2023-12:56:49] [V] [TRT] Conv_44 + Relu_45 Set Tactic Name: ampere_h16816cudnn_64x64_sliced1x2_ldg8_relu_exp_stages_64x5_medium_nhwc_tn_v1 Tactic: 8101703987960976805
[03/24/2023-12:56:49] [V] [TRT] Tactic: 8101703987960976805 Time: 0.053504
[03/24/2023-12:56:49] [V] [TRT] Conv_44 + Relu_45 Set Tactic Name: ampere_h16816cudnn_128x64_sliced1x2_ldg8_relu_exp_stages_64x4_small_nhwc_tn_v1 Tactic: 8170606396342855895
[03/24/2023-12:56:49] [V] [TRT] Tactic: 8170606396342855895 Time: 0.042752
[03/24/2023-12:56:49] [V] [TRT] Conv_44 + Relu_45 Set Tactic Name: sm75_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x32x64_stage1_warpsize2x1x2_g1_tensor16x8x8 Tactic: 8455608235315878803
[03/24/2023-12:56:49] [V] [TRT] Tactic: 8455608235315878803 Time: 0.065536
[03/24/2023-12:56:49] [V] [TRT] Conv_44 + Relu_45 Set Tactic Name: sm75_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x64x64_stage1_warpsize2x2x1_g1_tensor16x8x8 Tactic: 8668812313058150080
[03/24/2023-12:56:49] [V] [TRT] Tactic: 8668812313058150080 Time: 0.051968
[03/24/2023-12:56:49] [V] [TRT] Conv_44 + Relu_45 Set Tactic Name: ampere_h1688cudnn_256x64_ldg8_relu_exp_small_nhwc_tn_v1 Tactic: 8839784824303350101
[03/24/2023-12:56:49] [V] [TRT] Tactic: 8839784824303350101 Time: 0.054016
[03/24/2023-12:56:49] [V] [TRT] Conv_44 + Relu_45 Set Tactic Name: ampere_h16816cudnn_64x64_sliced1x2_ldg8_relu_exp_stages_64x5_large_nhwc_tn_v1 Tactic: -9217371357561775773
[03/24/2023-12:56:49] [V] [TRT] Tactic: -9217371357561775773 Time: 0.05376
[03/24/2023-12:56:49] [V] [TRT] Conv_44 + Relu_45 Set Tactic Name: ampere_h16816cudnn_256x64_sliced1x2_ldg8_relu_exp_medium_nhwc_tn_v1 Tactic: -9009272790678027912
[03/24/2023-12:56:49] [V] [TRT] Tactic: -9009272790678027912 Time: 0.061824
[03/24/2023-12:56:49] [V] [TRT] Conv_44 + Relu_45 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x32x32_stage4_warpsize4x1x1_g1_tensor16x8x16 Tactic: -8985224497679592364
[03/24/2023-12:56:49] [V] [TRT] Tactic: -8985224497679592364 Time: 0.055168
[03/24/2023-12:56:49] [V] [TRT] Conv_44 + Relu_45 Set Tactic Name: ampere_h16816cudnn_128x64_sliced1x2_ldg8_relu_exp_stages_64x3_large_nhwc_tn_v1 Tactic: -8949544755481315679
[03/24/2023-12:56:49] [V] [TRT] Tactic: -8949544755481315679 Time: 0.042752
[03/24/2023-12:56:49] [V] [TRT] Conv_44 + Relu_45 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x64x64_stage3_warpsize4x1x1_g1_tensor16x8x16_t1r3s3 Tactic: -8867999442759527766
[03/24/2023-12:56:49] [V] [TRT] Tactic: -8867999442759527766 Time: 0.048
[03/24/2023-12:56:49] [V] [TRT] Conv_44 + Relu_45 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x128x64_stage3_warpsize2x2x1_g1_tensor16x8x16 Tactic: -8759929675070720385
[03/24/2023-12:56:49] [V] [TRT] Tactic: -8759929675070720385 Time: 0.044032
[03/24/2023-12:56:49] [V] [TRT] Conv_44 + Relu_45 Set Tactic Name: ampere_h16816cudnn_64x64_ldg8_relu_exp_stages_64x6_medium_nhwc_tn_v1 Tactic: -8604374562669615024
[03/24/2023-12:56:49] [V] [TRT] Tactic: -8604374562669615024 Time: 0.05312
[03/24/2023-12:56:49] [V] [TRT] Conv_44 + Relu_45 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x128x64_stage3_warpsize4x2x1_g1_tensor16x8x16 Tactic: -8362347876645295759
[03/24/2023-12:56:49] [V] [TRT] Tactic: -8362347876645295759 Time: 0.040576
[03/24/2023-12:56:49] [V] [TRT] Conv_44 + Relu_45 Set Tactic Name: sm75_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x128x32_stage1_warpsize4x2x1_g1_tensor16x8x8 Tactic: -8254009616492665198
[03/24/2023-12:56:49] [V] [TRT] Tactic: -8254009616492665198 Time: 0.046208
[03/24/2023-12:56:49] [V] [TRT] Conv_44 + Relu_45 Set Tactic Name: ampere_h16816cudnn_256x128_ldg8_relu_exp_stages_64x3_large_nhwc_tn_v1 Tactic: -7757610000269494813
[03/24/2023-12:56:49] [V] [TRT] Tactic: -7757610000269494813 Time: 0.041856
[03/24/2023-12:56:49] [V] [TRT] Conv_44 + Relu_45 Set Tactic Name: sm75_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x128x32_stage1_warpsize4x2x1_g1_tensor16x8x8 Tactic: -7615325597099025933
[03/24/2023-12:56:49] [V] [TRT] Tactic: -7615325597099025933 Time: 0.04736
[03/24/2023-12:56:49] [V] [TRT] Conv_44 + Relu_45 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x64x64_stage3_warpsize4x1x1_g1_tensor16x8x16 Tactic: -6917689122519989488
[03/24/2023-12:56:49] [V] [TRT] Tactic: -6917689122519989488 Time: 0.048512
[03/24/2023-12:56:49] [V] [TRT] Conv_44 + Relu_45 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x32x64_stage5_warpsize2x2x1_g1_tensor16x8x16_t1r3s3 Tactic: -6902925267326201166
[03/24/2023-12:56:49] [V] [TRT] Tactic: -6902925267326201166 Time: 0.065152
[03/24/2023-12:56:49] [V] [TRT] Conv_44 + Relu_45 Set Tactic Name: ampere_h16816cudnn_64x128_ldg8_relu_exp_stages_64x4_large_nhwc_tn_v1 Tactic: -6840588038605932325
[03/24/2023-12:56:49] [V] [TRT] Tactic: -6840588038605932325 Time: 0.043392
[03/24/2023-12:56:49] [V] [TRT] Conv_44 + Relu_45 Set Tactic Name: sm75_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x32x32_stage1_warpsize4x1x1_g1_tensor16x8x8 Tactic: -6828337260021572283
[03/24/2023-12:56:49] [V] [TRT] Tactic: -6828337260021572283 Time: 0.068096
[03/24/2023-12:56:49] [V] [TRT] Conv_44 + Relu_45 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x256x32_stage3_warpsize2x4x1_g1_tensor16x8x16 Tactic: -6799856376604253964
[03/24/2023-12:56:49] [V] [TRT] Tactic: -6799856376604253964 Time: 0.040192
[03/24/2023-12:56:49] [V] [TRT] Conv_44 + Relu_45 Set Tactic Name: sm75_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x32x32_stage1_warpsize4x1x1_g1_tensor16x8x8 Tactic: -6711815420995272523
[03/24/2023-12:56:49] [V] [TRT] Tactic: -6711815420995272523 Time: 0.070656
[03/24/2023-12:56:49] [V] [TRT] Conv_44 + Relu_45 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x32x32_stage4_warpsize4x1x1_g1_tensor16x8x16_t1r3s3 Tactic: -6625722781282978136
[03/24/2023-12:56:49] [V] [TRT] Tactic: -6625722781282978136 Time: 0.06336
[03/24/2023-12:56:49] [V] [TRT] Conv_44 + Relu_45 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x64x32_stage3_warpsize4x1x1_g1_tensor16x8x16 Tactic: -6525498856028268801
[03/24/2023-12:56:49] [V] [TRT] Tactic: -6525498856028268801 Time: 0.0448
[03/24/2023-12:56:49] [V] [TRT] Conv_44 + Relu_45 Set Tactic Name: sm75_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x256x64_stage1_warpsize1x4x2_g1_tensor16x8x8 Tactic: -6489479581011009593
[03/24/2023-12:56:49] [V] [TRT] Tactic: -6489479581011009593 Time: 0.055552
[03/24/2023-12:56:49] [V] [TRT] Conv_44 + Relu_45 Set Tactic Name: ampere_h16816cudnn_64x64_sliced1x2_ldg8_relu_exp_stages_64x6_medium_nhwc_tn_v1 Tactic: -6356316196810535311
[03/24/2023-12:56:49] [V] [TRT] Tactic: -6356316196810535311 Time: 0.05312
[03/24/2023-12:56:49] [V] [TRT] Conv_44 + Relu_45 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x32x32_stage4_warpsize4x1x1_g1_tensor16x8x16 Tactic: -6324345858751792783
[03/24/2023-12:56:49] [V] [TRT] Tactic: -6324345858751792783 Time: 0.064128
[03/24/2023-12:56:49] [V] [TRT] Conv_44 + Relu_45 Set Tactic Name: sm75_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x256x64_stage1_warpsize1x4x2_g1_tensor16x8x8_t1r3s3 Tactic: -6320761427625651496
[03/24/2023-12:56:49] [V] [TRT] Tactic: -6320761427625651496 Time: 0.0544
[03/24/2023-12:56:49] [V] [TRT] Conv_44 + Relu_45 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x256x32_stage3_warpsize2x4x1_g1_tensor16x8x16_t1r3s3 Tactic: -6262400699544994312
[03/24/2023-12:56:49] [V] [TRT] Tactic: -6262400699544994312 Time: 0.03968
[03/24/2023-12:56:49] [V] [TRT] Conv_44 + Relu_45 Set Tactic Name: ampere_h1688cudnn_128x128_ldg8_relu_exp_large_nhwc_tn_v1 Tactic: -6257787336162086472
[03/24/2023-12:56:49] [V] [TRT] Tactic: -6257787336162086472 Time: 0.049536
[03/24/2023-12:56:49] [V] [TRT] Conv_44 + Relu_45 Set Tactic Name: sm75_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x128x64_stage1_warpsize2x2x1_g1_tensor16x8x8 Tactic: -6080892721161662420
[03/24/2023-12:56:49] [V] [TRT] Tactic: -6080892721161662420 Time: 0.047872
[03/24/2023-12:56:49] [V] [TRT] Conv_44 + Relu_45 Set Tactic Name: ampere_h16816cudnn_128x64_ldg8_relu_exp_stages_64x4_small_nhwc_tn_v1 Tactic: -6063766379489217211
[03/24/2023-12:56:49] [V] [TRT] Tactic: -6063766379489217211 Time: 0.043776
[03/24/2023-12:56:49] [V] [TRT] Conv_44 + Relu_45 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x128x32_stage5_warpsize2x2x1_g1_tensor16x8x16 Tactic: -5777580938094193096
[03/24/2023-12:56:49] [V] [TRT] Tactic: -5777580938094193096 Time: 0.04096
[03/24/2023-12:56:49] [V] [TRT] Conv_44 + Relu_45 Set Tactic Name: sm75_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x128x64_stage1_warpsize2x2x1_g1_tensor16x8x8 Tactic: -5710735840878760115
[03/24/2023-12:56:49] [V] [TRT] Tactic: -5710735840878760115 Time: 0.049024
[03/24/2023-12:56:49] [V] [TRT] Conv_44 + Relu_45 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x128x32_stage3_warpsize4x2x1_g1_tensor16x8x16 Tactic: -5657273398217409378
[03/24/2023-12:56:49] [V] [TRT] Tactic: -5657273398217409378 Time: 0.04096
[03/24/2023-12:56:49] [V] [TRT] Conv_44 + Relu_45 Set Tactic Name: sm75_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x128x32_stage1_warpsize2x2x1_g1_tensor16x8x8_t1r3s3 Tactic: -5546257196173962281
[03/24/2023-12:56:49] [V] [TRT] Tactic: -5546257196173962281 Time: 0.052096
[03/24/2023-12:56:49] [V] [TRT] Conv_44 + Relu_45 Set Tactic Name: ampere_h16816cudnn_128x128_ldg8_relu_exp_small_nhwc_tn_v1 Tactic: -5530886555766748586
[03/24/2023-12:56:49] [V] [TRT] Tactic: -5530886555766748586 Time: 0.043904
[03/24/2023-12:56:49] [V] [TRT] Conv_44 + Relu_45 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x64x32_stage5_warpsize2x2x1_g1_tensor16x8x16_t1r3s3 Tactic: -5422685219138380548
[03/24/2023-12:56:49] [V] [TRT] Tactic: -5422685219138380548 Time: 0.047104
[03/24/2023-12:56:49] [V] [TRT] Conv_44 + Relu_45 Set Tactic Name: ampere_h16816cudnn_256x64_ldg8_relu_exp_stages_64x3_small_nhwc_tn_v1 Tactic: -5261787675443473128
[03/24/2023-12:56:49] [V] [TRT] Tactic: -5261787675443473128 Time: 0.04608
[03/24/2023-12:56:49] [V] [TRT] Conv_44 + Relu_45 Set Tactic Name: sm75_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x64x32_stage1_warpsize4x1x1_g1_tensor16x8x8 Tactic: -5198219374380660379
[03/24/2023-12:56:50] [V] [TRT] Tactic: -5198219374380660379 Time: 0.054272
[03/24/2023-12:56:50] [V] [TRT] Conv_44 + Relu_45 Set Tactic Name: ampere_h16816cudnn_64x128_sliced1x2_ldg8_relu_exp_stages_64x3_medium_nhwc_tn_v1 Tactic: -5161596964442251102
[03/24/2023-12:56:50] [V] [TRT] Tactic: -5161596964442251102 Time: 0.041856
[03/24/2023-12:56:50] [V] [TRT] Conv_44 + Relu_45 Set Tactic Name: ampere_h16816cudnn_64x128_ldg8_relu_exp_stages_64x3_medium_nhwc_tn_v1 Tactic: -5127240325355316006
[03/24/2023-12:56:50] [V] [TRT] Tactic: -5127240325355316006 Time: 0.04224
[03/24/2023-12:56:50] [V] [TRT] Conv_44 + Relu_45 Set Tactic Name: ampere_h16816cudnn_256x128_ldg8_relu_exp_stages_64x3_medium_nhwc_tn_v1 Tactic: -5109582882231362997
[03/24/2023-12:56:50] [V] [TRT] Tactic: -5109582882231362997 Time: 0.041216
[03/24/2023-12:56:50] [V] [TRT] Conv_44 + Relu_45 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x64x32_stage5_warpsize2x2x1_g1_tensor16x8x16 Tactic: -4825567853927730435
[03/24/2023-12:56:50] [V] [TRT] Tactic: -4825567853927730435 Time: 0.049664
[03/24/2023-12:56:50] [V] [TRT] Conv_44 + Relu_45 Set Tactic Name: ampere_h16816cudnn_64x128_sliced1x2_ldg8_relu_exp_stages_64x4_small_nhwc_tn_v1 Tactic: -4796511246675321840
[03/24/2023-12:56:50] [V] [TRT] Tactic: -4796511246675321840 Time: 0.04416
[03/24/2023-12:56:50] [V] [TRT] Conv_44 + Relu_45 Set Tactic Name: ampere_h16816cudnn_64x64_sliced1x2_ldg8_relu_exp_stages_64x6_large_nhwc_tn_v1 Tactic: -4706569565442112734
[03/24/2023-12:56:50] [V] [TRT] Tactic: -4706569565442112734 Time: 0.054272
[03/24/2023-12:56:50] [V] [TRT] Conv_44 + Relu_45 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x128x64_stage3_warpsize2x2x1_g1_tensor16x8x16_t1r3s3 Tactic: -4566599693570369588
[03/24/2023-12:56:50] [V] [TRT] Tactic: -4566599693570369588 Time: 0.045312
[03/24/2023-12:56:50] [V] [TRT] Conv_44 + Relu_45 Set Tactic Name: ampere_h16816cudnn_128x128_ldg8_relu_exp_stages_64x3_large_nhwc_tn_v1 Tactic: -4409144516525410768
[03/24/2023-12:56:50] [V] [TRT] Tactic: -4409144516525410768 Time: 0.044288
[03/24/2023-12:56:50] [V] [TRT] Conv_44 + Relu_45 Set Tactic Name: ampere_h16816cudnn_128x64_ldg8_relu_exp_stages_64x3_small_nhwc_tn_v1 Tactic: -4379519430184503304
[03/24/2023-12:56:50] [V] [TRT] Tactic: -4379519430184503304 Time: 0.04224
[03/24/2023-12:56:50] [V] [TRT] Conv_44 + Relu_45 Set Tactic Name: ampere_h1688cudnn_256x128_ldg8_relu_exp_small_nhwc_tn_v1 Tactic: -4152066959007262150
[03/24/2023-12:56:50] [V] [TRT] Tactic: -4152066959007262150 Time: 0.046208
[03/24/2023-12:56:50] [V] [TRT] Conv_44 + Relu_45 Set Tactic Name: ampere_h16816cudnn_64x128_ldg8_relu_exp_stages_64x4_medium_nhwc_tn_v1 Tactic: -4021926646879732549
[03/24/2023-12:56:50] [V] [TRT] Tactic: -4021926646879732549 Time: 0.04288
[03/24/2023-12:56:50] [V] [TRT] Conv_44 + Relu_45 Set Tactic Name: ampere_h16816cudnn_64x128_sliced1x2_ldg8_relu_exp_stages_64x4_medium_nhwc_tn_v1 Tactic: -3987638434926559037
[03/24/2023-12:56:50] [V] [TRT] Tactic: -3987638434926559037 Time: 0.044288
[03/24/2023-12:56:50] [V] [TRT] Conv_44 + Relu_45 Set Tactic Name: ampere_h1688cudnn_256x64_sliced1x2_ldg8_relu_exp_medium_nhwc_tn_v1 Tactic: -3905653247016903130
[03/24/2023-12:56:50] [V] [TRT] Tactic: -3905653247016903130 Time: 0.062592
[03/24/2023-12:56:50] [V] [TRT] Conv_44 + Relu_45 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x64x32_stage5_warpsize2x2x1_g1_tensor16x8x16 Tactic: -3903974568488493144
[03/24/2023-12:56:50] [V] [TRT] Tactic: -3903974568488493144 Time: 0.043008
[03/24/2023-12:56:50] [V] [TRT] Conv_44 + Relu_45 Set Tactic Name: ampere_h16816cudnn_64x128_ldg8_relu_exp_stages_64x3_large_nhwc_tn_v1 Tactic: -3895429239811098010
[03/24/2023-12:56:50] [V] [TRT] Tactic: -3895429239811098010 Time: 0.042112
[03/24/2023-12:56:50] [V] [TRT] Conv_44 + Relu_45 Set Tactic Name: ampere_h16816cudnn_256x64_ldg8_relu_exp_small_nhwc_tn_v1 Tactic: -3864869056275745423
[03/24/2023-12:56:50] [V] [TRT] Tactic: -3864869056275745423 Time: 0.049024
[03/24/2023-12:56:50] [V] [TRT] Conv_44 + Relu_45 Set Tactic Name: sm75_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x32x32_stage1_warpsize4x1x1_g1_tensor16x8x8_t1r3s3 Tactic: -3784342055748695733
[03/24/2023-12:56:50] [V] [TRT] Tactic: -3784342055748695733 Time: 0.062976
[03/24/2023-12:56:50] [V] [TRT] Conv_44 + Relu_45 Set Tactic Name: ampere_h16816cudnn_64x64_ldg8_relu_exp_stages_64x5_small_nhwc_tn_v1 Tactic: -3601464762214218301
[03/24/2023-12:56:50] [V] [TRT] Tactic: -3601464762214218301 Time: 0.05568
[03/24/2023-12:56:50] [V] [TRT] Conv_44 + Relu_45 Set Tactic Name: sm75_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x64x32_stage1_warpsize2x2x1_g1_tensor16x8x8 Tactic: -3425274793298557239
[03/24/2023-12:56:50] [V] [TRT] Tactic: -3425274793298557239 Time: 0.05248
[03/24/2023-12:56:50] [V] [TRT] Conv_44 + Relu_45 Set Tactic Name: ampere_h1688cudnn_256x64_sliced1x2_ldg8_relu_exp_large_nhwc_tn_v1 Tactic: -3412636942650049698
[03/24/2023-12:56:50] [V] [TRT] Tactic: -3412636942650049698 Time: 0.063488
[03/24/2023-12:56:50] [V] [TRT] Conv_44 + Relu_45 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x64x32_stage3_warpsize4x1x1_g1_tensor16x8x16 Tactic: -3338665856053412950
[03/24/2023-12:56:50] [V] [TRT] Tactic: -3338665856053412950 Time: 0.0416
[03/24/2023-12:56:50] [V] [TRT] Conv_44 + Relu_45 Set Tactic Name: sm75_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x128x32_stage1_warpsize2x2x1_g1_tensor16x8x8 Tactic: -3271955096576257018
[03/24/2023-12:56:50] [V] [TRT] Tactic: -3271955096576257018 Time: 0.052352
[03/24/2023-12:56:50] [V] [TRT] Conv_44 + Relu_45 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x128x64_stage3_warpsize4x2x1_g1_tensor16x8x16_t1r3s3 Tactic: -3243541398692466074
[03/24/2023-12:56:50] [V] [TRT] Tactic: -3243541398692466074 Time: 0.04096
[03/24/2023-12:56:50] [V] [TRT] Conv_44 + Relu_45 Set Tactic Name: ampere_h16816cudnn_64x128_sliced1x2_ldg8_relu_exp_stages_64x3_small_nhwc_tn_v1 Tactic: -3058330359340425555
[03/24/2023-12:56:50] [V] [TRT] Tactic: -3058330359340425555 Time: 0.041728
[03/24/2023-12:56:50] [V] [TRT] Conv_44 + Relu_45 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x256x64_stage3_warpsize1x4x1_g1_tensor16x8x16_t1r3s3 Tactic: -2899647483672319239
[03/24/2023-12:56:50] [V] [TRT] Tactic: -2899647483672319239 Time: 0.047232
[03/24/2023-12:56:50] [V] [TRT] Conv_44 + Relu_45 Set Tactic Name: ampere_h16816cudnn_256x64_sliced1x2_ldg8_relu_exp_large_nhwc_tn_v1 Tactic: -2816084650627734155
[03/24/2023-12:56:50] [V] [TRT] Tactic: -2816084650627734155 Time: 0.062592
[03/24/2023-12:56:50] [V] [TRT] Conv_44 + Relu_45 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x128x32_stage5_warpsize2x2x1_g1_tensor16x8x16 Tactic: -2662892962457732243
[03/24/2023-12:56:50] [V] [TRT] Tactic: -2662892962457732243 Time: 0.041344
[03/24/2023-12:56:50] [V] [TRT] Conv_44 + Relu_45 Set Tactic Name: ampere_h16816cudnn_256x128_ldg8_relu_exp_large_nhwc_tn_v1 Tactic: -2559894581585337900
[03/24/2023-12:56:50] [V] [TRT] Tactic: -2559894581585337900 Time: 0.041856
[03/24/2023-12:56:50] [V] [TRT] Conv_44 + Relu_45 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x32x32_stage4_warpsize4x1x1_g1_tensor16x8x16 Tactic: -2530740716768816092
[03/24/2023-12:56:50] [V] [TRT] Tactic: -2530740716768816092 Time: 0.053248
[03/24/2023-12:56:50] [V] [TRT] Conv_44 + Relu_45 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x128x32_stage4_warpsize2x2x1_g1_tensor16x8x16 Tactic: -2332828394978346992
[03/24/2023-12:56:50] [V] [TRT] Tactic: -2332828394978346992 Time: 0.041856
[03/24/2023-12:56:50] [V] [TRT] Conv_44 + Relu_45 Set Tactic Name: ampere_h1688cudnn_256x64_ldg8_relu_exp_large_nhwc_tn_v1 Tactic: -2241736083352441442
[03/24/2023-12:56:50] [V] [TRT] Tactic: -2241736083352441442 Time: 0.056704
[03/24/2023-12:56:50] [V] [TRT] Conv_44 + Relu_45 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x32x64_stage5_warpsize2x2x1_g1_tensor16x8x16 Tactic: -2161909437867201546
[03/24/2023-12:56:50] [V] [TRT] Tactic: -2161909437867201546 Time: 0.065664
[03/24/2023-12:56:50] [V] [TRT] Conv_44 + Relu_45 Set Tactic Name: ampere_h16816cudnn_256x64_ldg8_relu_exp_medium_nhwc_tn_v1 Tactic: -1985778916402815946
[03/24/2023-12:56:50] [V] [TRT] Tactic: -1985778916402815946 Time: 0.049792
[03/24/2023-12:56:50] [V] [TRT] Conv_44 + Relu_45 Set Tactic Name: sm75_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x256x32_stage1_warpsize2x4x1_g1_tensor16x8x8 Tactic: -1708101578041178688
[03/24/2023-12:56:50] [V] [TRT] Tactic: -1708101578041178688 Time: 0.046976
[03/24/2023-12:56:50] [V] [TRT] Conv_44 + Relu_45 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x64x64_stage3_warpsize4x1x1_g1_tensor16x8x16 Tactic: -1502788097503482299
[03/24/2023-12:56:50] [V] [TRT] Tactic: -1502788097503482299 Time: 0.049152
[03/24/2023-12:56:50] [V] [TRT] Conv_44 + Relu_45 Set Tactic Name: ampere_h16816cudnn_128x64_sliced1x2_ldg8_relu_exp_stages_64x4_large_nhwc_tn_v1 Tactic: -1500496213132463076
[03/24/2023-12:56:50] [V] [TRT] Tactic: -1500496213132463076 Time: 0.045056
[03/24/2023-12:56:50] [V] [TRT] Conv_44 + Relu_45 Set Tactic Name: ampere_h16816cudnn_64x64_ldg8_relu_exp_stages_64x6_small_nhwc_tn_v1 Tactic: -1099247066487349374
[03/24/2023-12:56:50] [V] [TRT] Tactic: -1099247066487349374 Time: 0.050688
[03/24/2023-12:56:50] [V] [TRT] Conv_44 + Relu_45 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x64x64_stage4_warpsize2x2x1_g1_tensor16x8x16 Tactic: -910286698936744682
[03/24/2023-12:56:50] [V] [TRT] Tactic: -910286698936744682 Time: 0.051328
[03/24/2023-12:56:50] [V] [TRT] Conv_44 + Relu_45 Set Tactic Name: sm75_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x256x32_stage1_warpsize2x4x1_g1_tensor16x8x8 Tactic: -907287437357565279
[03/24/2023-12:56:50] [V] [TRT] Tactic: -907287437357565279 Time: 0.04608
[03/24/2023-12:56:50] [V] [TRT] Conv_44 + Relu_45 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x32x32_stage4_warpsize4x1x1_g1_tensor16x8x16 Tactic: -606726295133751039
[03/24/2023-12:56:50] [V] [TRT] Tactic: -606726295133751039 Time: 0.054528
[03/24/2023-12:56:50] [V] [TRT] Fastest Tactic: 328038211831149625 Time: 0.03968
[03/24/2023-12:56:50] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: 328038211831149625
[03/24/2023-12:56:50] [V] [TRT] *************** Autotuning format combination: Half(259200,1:16,1440,8) -> Half(129600,1:16,1440,16) ***************
[03/24/2023-12:56:50] [V] [TRT] --------------- Timing Runner: Conv_44 + Relu_45 (CudnnConvolution)
[03/24/2023-12:56:50] [V] [TRT] CudnnConvolution has no valid tactics for this config, skipping
[03/24/2023-12:56:50] [V] [TRT] --------------- Timing Runner: Conv_44 + Relu_45 (CaskConvolution)
[03/24/2023-12:56:50] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[03/24/2023-12:56:50] [V] [TRT] =============== Computing costs for 
[03/24/2023-12:56:50] [V] [TRT] *************** Autotuning format combination: Float(2073600,8100,90,1) -> Float(2073600,8100,90,1) ***************
[03/24/2023-12:56:50] [V] [TRT] --------------- Timing Runner: Conv_46 + Relu_47 (CudaDepthwiseConvolution)
[03/24/2023-12:56:50] [V] [TRT] CudaDepthwiseConvolution has no valid tactics for this config, skipping
[03/24/2023-12:56:50] [V] [TRT] --------------- Timing Runner: Conv_46 + Relu_47 (FusedConvActConvolution)
[03/24/2023-12:56:50] [V] [TRT] Tactic: 524287 Time: 0.66752
[03/24/2023-12:56:50] [V] [TRT] Tactic: 720895 Time: 0.675712
[03/24/2023-12:56:50] [V] [TRT] Tactic: 983039 Time: 0.604416
[03/24/2023-12:56:50] [V] [TRT] Tactic: 1048575 Time: 0.628352
[03/24/2023-12:56:50] [V] [TRT] Tactic: 1703935 Time: 0.609024
[03/24/2023-12:56:50] [V] [TRT] Tactic: 1769471 Time: 0.616832
[03/24/2023-12:56:50] [V] [TRT] Tactic: 1966079 Time: 0.733568
[03/24/2023-12:56:50] [V] [TRT] Tactic: 2031615 Time: 0.602368
[03/24/2023-12:56:50] [V] [TRT] Tactic: 2228223 Time: 0.633088
[03/24/2023-12:56:50] [V] [TRT] Tactic: 2424831 Time: 0.66048
[03/24/2023-12:56:50] [V] [TRT] Tactic: 2621439 Time: 0.609536
[03/24/2023-12:56:50] [V] [TRT] Tactic: 2752511 Time: 0.656768
[03/24/2023-12:56:51] [V] [TRT] Tactic: 2818047 Time: 0.644096
[03/24/2023-12:56:51] [V] [TRT] Tactic: 2883583 Time: 0.64512
[03/24/2023-12:56:51] [V] [TRT] Tactic: 3014655 Time: 0.630784
[03/24/2023-12:56:51] [V] [TRT] Tactic: 3145727 Time: 0.582016
[03/24/2023-12:56:51] [V] [TRT] Tactic: 3473407 Time: 0.637056
[03/24/2023-12:56:51] [V] [TRT] Tactic: 3604479 Time: 0.62464
[03/24/2023-12:56:51] [V] [TRT] Tactic: 3735551 Time: 0.621824
[03/24/2023-12:56:51] [V] [TRT] Tactic: 4390911 Time: 0.802304
[03/24/2023-12:56:51] [V] [TRT] Tactic: 5046271 Time: 0.644864
[03/24/2023-12:56:51] [V] [TRT] Tactic: 5963775 Time: 0.66304
[03/24/2023-12:56:51] [V] [TRT] Tactic: 6160383 Time: 0.65856
[03/24/2023-12:56:51] [V] [TRT] Tactic: 6488063 Time: 0.648832
[03/24/2023-12:56:51] [V] [TRT] Tactic: 6881279 Time: 0.651648
[03/24/2023-12:56:51] [V] [TRT] Tactic: 7274495 Time: 0.593408
[03/24/2023-12:56:51] [V] [TRT] Tactic: 7864319 Time: 0.606208
[03/24/2023-12:56:51] [V] [TRT] Tactic: 7995391 Time: 0.702592
[03/24/2023-12:56:51] [V] [TRT] Tactic: 8585215 Time: 0.69248
[03/24/2023-12:56:51] [V] [TRT] Tactic: 8847359 Time: 0.596224
[03/24/2023-12:56:52] [V] [TRT] Tactic: 8978431 Time: 0.666496
[03/24/2023-12:56:52] [V] [TRT] Tactic: 9043967 Time: 0.595968
[03/24/2023-12:56:52] [V] [TRT] Tactic: 9175039 Time: 0.62464
[03/24/2023-12:56:52] [V] [TRT] Tactic: 9502719 Time: 0.800512
[03/24/2023-12:56:52] [V] [TRT] Tactic: 9830399 Time: 0.639872
[03/24/2023-12:56:52] [V] [TRT] Tactic: 9961471 Time: 0.655488
[03/24/2023-12:56:52] [V] [TRT] Tactic: 10027007 Time: 0.600064
[03/24/2023-12:56:52] [V] [TRT] Tactic: 10092543 Time: 0.802944
[03/24/2023-12:56:52] [V] [TRT] Tactic: 10289151 Time: 0.732416
[03/24/2023-12:56:52] [V] [TRT] Tactic: 10485759 Time: 0.586752
[03/24/2023-12:56:52] [V] [TRT] Tactic: 10682367 Time: 0.608256
[03/24/2023-12:56:52] [V] [TRT] Tactic: 10813439 Time: 0.636032
[03/24/2023-12:56:52] [V] [TRT] Fastest Tactic: 3145727 Time: 0.582016
[03/24/2023-12:56:52] [V] [TRT] --------------- Timing Runner: Conv_46 + Relu_47 (CudnnConvolution)
[03/24/2023-12:56:52] [V] [TRT] Tactic: 0 Time: 0.915712
[03/24/2023-12:56:52] [V] [TRT] Tactic: 1 Time: 0.180352
[03/24/2023-12:56:52] [V] [TRT] Tactic: 2 Time: 1.0039
[03/24/2023-12:56:52] [V] [TRT] Tactic: 4 skipped. Scratch requested: 8760590336, available: 4294967296
[03/24/2023-12:56:52] [V] [TRT] Tactic: 5 Time: 2.28019
[03/24/2023-12:56:52] [V] [TRT] Tactic: 6 Time: 0.361344
[03/24/2023-12:56:52] [V] [TRT] Tactic: 56 Time: 0.915584
[03/24/2023-12:56:52] [V] [TRT] Tactic: 57 Time: 0.180096
[03/24/2023-12:56:52] [V] [TRT] Tactic: 58 Time: 1.00429
[03/24/2023-12:56:52] [V] [TRT] Tactic: 60 skipped. Scratch requested: 8760590336, available: 4294967296
[03/24/2023-12:56:52] [V] [TRT] Tactic: 61 Time: 2.27917
[03/24/2023-12:56:52] [V] [TRT] Tactic: 62 Time: 0.361728
[03/24/2023-12:56:52] [V] [TRT] Tactic: 112 Time: 0.915712
[03/24/2023-12:56:52] [V] [TRT] Tactic: 113 Time: 0.723712
[03/24/2023-12:56:52] [V] [TRT] Tactic: 114 Time: 1.00403
[03/24/2023-12:56:52] [V] [TRT] Tactic: 116 skipped. Scratch requested: 8760590336, available: 4294967296
[03/24/2023-12:56:52] [V] [TRT] Tactic: 117 Time: 2.27661
[03/24/2023-12:56:52] [V] [TRT] Tactic: 118 Time: 0.361472
[03/24/2023-12:56:52] [V] [TRT] Fastest Tactic: 57 Time: 0.180096
[03/24/2023-12:56:52] [V] [TRT] Setting workspace to 8760590336enables more tactics for profiling
[03/24/2023-12:56:52] [V] [TRT] --------------- Timing Runner: Conv_46 + Relu_47 (CaskConvolution)
[03/24/2023-12:56:52] [V] [TRT] Conv_46 + Relu_47 Set Tactic Name: ampere_scudnn_128x64_relu_small_nn_v1 Tactic: 4549827808004681195
[03/24/2023-12:56:53] [V] [TRT] Tactic: 4549827808004681195 Time: 0.690176
[03/24/2023-12:56:53] [V] [TRT] Conv_46 + Relu_47 Set Tactic Name: ampere_scudnn_128x128_relu_small_nn_v1 Tactic: 5779835512569528575
[03/24/2023-12:56:53] [V] [TRT] Tactic: 5779835512569528575 Time: 0.870272
[03/24/2023-12:56:53] [V] [TRT] Conv_46 + Relu_47 Set Tactic Name: ampere_scudnn_128x128_relu_xregs_large_nn_v1 Tactic: 6053873026024413720
[03/24/2023-12:56:53] [V] [TRT] Tactic: 6053873026024413720 Time: 0.898944
[03/24/2023-12:56:53] [V] [TRT] Conv_46 + Relu_47 Set Tactic Name: ampere_scudnn_128x64_relu_xregs_large_nn_v1 Tactic: 6767548733843469815
[03/24/2023-12:56:53] [V] [TRT] Tactic: 6767548733843469815 Time: 0.68928
[03/24/2023-12:56:53] [V] [TRT] Conv_46 + Relu_47 Set Tactic Name: ampere_scudnn_128x32_relu_small_nn_v1 Tactic: -6313876406580483184
[03/24/2023-12:56:53] [V] [TRT] Tactic: -6313876406580483184 Time: 0.762368
[03/24/2023-12:56:53] [V] [TRT] Conv_46 + Relu_47 Set Tactic Name: ampere_scudnn_128x128_relu_medium_nn_v1 Tactic: -1123676555321336786
[03/24/2023-12:56:53] [V] [TRT] Tactic: -1123676555321336786 Time: 0.871936
[03/24/2023-12:56:53] [V] [TRT] Conv_46 + Relu_47 Set Tactic Name: ampere_scudnn_128x64_relu_medium_nn_v1 Tactic: -701551393537224327
[03/24/2023-12:56:53] [V] [TRT] Tactic: -701551393537224327 Time: 0.710272
[03/24/2023-12:56:53] [V] [TRT] Fastest Tactic: 6767548733843469815 Time: 0.68928
[03/24/2023-12:56:53] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CudnnConvolution Tactic: 57
[03/24/2023-12:56:53] [V] [TRT] *************** Autotuning format combination: Float(2073600,1,23040,256) -> Float(2073600,1,23040,256) ***************
[03/24/2023-12:56:53] [V] [TRT] --------------- Timing Runner: Conv_46 + Relu_47 (CudnnConvolution)
[03/24/2023-12:56:53] [V] [TRT] CudnnConvolution has no valid tactics for this config, skipping
[03/24/2023-12:56:53] [V] [TRT] --------------- Timing Runner: Conv_46 + Relu_47 (CaskConvolution)
[03/24/2023-12:56:53] [V] [TRT] Conv_46 + Relu_47 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize64x128x8_stage3_warpsize1x4x1_g1_ffma_t1r3s3 Tactic: 2086609538387166260
[03/24/2023-12:56:53] [V] [TRT] Tactic: 2086609538387166260 Time: 0.655872
[03/24/2023-12:56:53] [V] [TRT] Conv_46 + Relu_47 Set Tactic Name: ampere_scudnn_128x64_sliced1x2_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: 2860655430572478466
[03/24/2023-12:56:53] [V] [TRT] Tactic: 2860655430572478466 Time: 0.667392
[03/24/2023-12:56:53] [V] [TRT] Conv_46 + Relu_47 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize64x128x8_stage3_warpsize1x4x1_g1_ffma Tactic: 3239733199291090177
[03/24/2023-12:56:53] [V] [TRT] Tactic: 3239733199291090177 Time: 0.653824
[03/24/2023-12:56:53] [V] [TRT] Conv_46 + Relu_47 Set Tactic Name: ampere_scudnn_128x32_sliced1x4_ldg4_relu_exp_medium_nhwc_tn_v1 Tactic: 4474630279712975759
[03/24/2023-12:56:53] [V] [TRT] Tactic: 4474630279712975759 Time: 0.564224
[03/24/2023-12:56:53] [V] [TRT] Conv_46 + Relu_47 Set Tactic Name: ampere_scudnn_128x32_sliced1x4_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: 4479823862704990365
[03/24/2023-12:56:53] [V] [TRT] Tactic: 4479823862704990365 Time: 0.561664
[03/24/2023-12:56:53] [V] [TRT] Conv_46 + Relu_47 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize64x256x8_stage3_warpsize1x4x1_g1_ffma Tactic: 4517590677127196184
[03/24/2023-12:56:53] [V] [TRT] Tactic: 4517590677127196184 Time: 0.898688
[03/24/2023-12:56:53] [V] [TRT] Conv_46 + Relu_47 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize128x128x8_stage3_warpsize2x4x1_g1_ffma_t1r3s3 Tactic: 4634080872644479428
[03/24/2023-12:56:53] [V] [TRT] Tactic: 4634080872644479428 Time: 0.86784
[03/24/2023-12:56:53] [V] [TRT] Conv_46 + Relu_47 Set Tactic Name: ampere_scudnn_128x64_sliced1x2_ldg4_relu_exp_medium_nhwc_tn_v1 Tactic: 4696204239951173149
[03/24/2023-12:56:53] [V] [TRT] Tactic: 4696204239951173149 Time: 0.667776
[03/24/2023-12:56:53] [V] [TRT] Conv_46 + Relu_47 Set Tactic Name: ampere_scudnn_128x128_relu_exp_small_nhwc_tn_v1 Tactic: 5778138195697110003
[03/24/2023-12:56:53] [V] [TRT] Tactic: 5778138195697110003 Time: 0.8672
[03/24/2023-12:56:53] [V] [TRT] Conv_46 + Relu_47 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize256x128x8_stage3_warpsize2x4x1_g1_ffma Tactic: 6310198979346901507
[03/24/2023-12:56:53] [V] [TRT] Tactic: 6310198979346901507 Time: 0.909312
[03/24/2023-12:56:53] [V] [TRT] Conv_46 + Relu_47 Set Tactic Name: ampere_scudnn_128x128_ldg4_relu_exp_large_nhwc_tn_v1 Tactic: 7155825427510256858
[03/24/2023-12:56:53] [V] [TRT] Tactic: 7155825427510256858 Time: 0.875904
[03/24/2023-12:56:53] [V] [TRT] Conv_46 + Relu_47 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize128x64x8_stage3_warpsize1x4x1_g1_ffma Tactic: 7222247112373541608
[03/24/2023-12:56:53] [V] [TRT] Tactic: 7222247112373541608 Time: 0.909312
[03/24/2023-12:56:53] [V] [TRT] Conv_46 + Relu_47 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize128x128x8_stage3_warpsize2x4x1_g1_ffma Tactic: 7472640475524677095
[03/24/2023-12:56:53] [V] [TRT] Tactic: 7472640475524677095 Time: 0.884992
[03/24/2023-12:56:53] [V] [TRT] Conv_46 + Relu_47 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize128x256x8_stage3_warpsize2x4x1_g1_ffma Tactic: 8498373915030836990
[03/24/2023-12:56:53] [V] [TRT] Tactic: 8498373915030836990 Time: 0.881408
[03/24/2023-12:56:53] [V] [TRT] Conv_46 + Relu_47 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize256x64x8_stage3_warpsize1x4x1_g1_ffma Tactic: 8869697132622550639
[03/24/2023-12:56:53] [V] [TRT] Tactic: 8869697132622550639 Time: 1.01504
[03/24/2023-12:56:53] [V] [TRT] Conv_46 + Relu_47 Set Tactic Name: ampere_scudnn_128x128_ldg4_relu_exp_medium_nhwc_tn_v1 Tactic: 8918020581761223752
[03/24/2023-12:56:53] [V] [TRT] Tactic: 8918020581761223752 Time: 0.86656
[03/24/2023-12:56:53] [V] [TRT] Conv_46 + Relu_47 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize256x128x8_stage3_warpsize2x4x1_g1_ffma_t1r3s3 Tactic: -8937725997228636978
[03/24/2023-12:56:53] [V] [TRT] Tactic: -8937725997228636978 Time: 0.872832
[03/24/2023-12:56:53] [V] [TRT] Conv_46 + Relu_47 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize128x256x8_stage3_warpsize2x4x1_g1_ffma_t1r3s3 Tactic: -8833858409138163072
[03/24/2023-12:56:53] [V] [TRT] Tactic: -8833858409138163072 Time: 0.87168
[03/24/2023-12:56:53] [V] [TRT] Conv_46 + Relu_47 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize64x64x8_stage3_warpsize1x4x1_g1_ffma_t1r3s3 Tactic: -7989138351613022500
[03/24/2023-12:56:53] [V] [TRT] Tactic: -7989138351613022500 Time: 0.553984
[03/24/2023-12:56:53] [V] [TRT] Conv_46 + Relu_47 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize256x128x8_stage3_warpsize2x4x1_g1_ffma Tactic: -7872883691240863058
[03/24/2023-12:56:53] [V] [TRT] Tactic: -7872883691240863058 Time: 0.9024
[03/24/2023-12:56:53] [V] [TRT] Conv_46 + Relu_47 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize128x128x8_stage3_warpsize2x4x1_g1_ffma Tactic: -6729618519651721910
[03/24/2023-12:56:53] [V] [TRT] Tactic: -6729618519651721910 Time: 0.874496
[03/24/2023-12:56:53] [V] [TRT] Conv_46 + Relu_47 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize256x64x8_stage3_warpsize1x4x1_g1_ffma Tactic: -5893833996418445881
[03/24/2023-12:56:53] [V] [TRT] Tactic: -5893833996418445881 Time: 0.983296
[03/24/2023-12:56:53] [V] [TRT] Conv_46 + Relu_47 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize128x256x8_stage3_warpsize2x4x1_g1_ffma Tactic: -5701562095007058349
[03/24/2023-12:56:53] [V] [TRT] Tactic: -5701562095007058349 Time: 0.870016
[03/24/2023-12:56:53] [V] [TRT] Conv_46 + Relu_47 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize128x64x8_stage3_warpsize1x4x1_g1_ffma Tactic: -5685503422376017600
[03/24/2023-12:56:53] [V] [TRT] Tactic: -5685503422376017600 Time: 0.880512
[03/24/2023-12:56:53] [V] [TRT] Conv_46 + Relu_47 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize64x64x8_stage3_warpsize1x4x1_g1_ffma Tactic: -5521125187060117489
[03/24/2023-12:56:53] [V] [TRT] Tactic: -5521125187060117489 Time: 0.601472
[03/24/2023-12:56:53] [V] [TRT] Conv_46 + Relu_47 Set Tactic Name: ampere_scudnn_128x64_sliced1x2_ldg4_relu_exp_large_nhwc_tn_v1 Tactic: -4756382386362004279
[03/24/2023-12:56:53] [V] [TRT] Tactic: -4756382386362004279 Time: 0.658432
[03/24/2023-12:56:53] [V] [TRT] Conv_46 + Relu_47 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize64x64x8_stage3_warpsize1x4x1_g1_ffma Tactic: -4615000974950361663
[03/24/2023-12:56:53] [V] [TRT] Tactic: -4615000974950361663 Time: 0.57344
[03/24/2023-12:56:53] [V] [TRT] Conv_46 + Relu_47 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize256x64x8_stage3_warpsize1x4x1_g1_ffma_t1r3s3 Tactic: -4314913710375142296
[03/24/2023-12:56:53] [V] [TRT] Tactic: -4314913710375142296 Time: 0.955008
[03/24/2023-12:56:53] [V] [TRT] Conv_46 + Relu_47 Set Tactic Name: ampere_scudnn_128x128_relu_exp_large_nhwc_tn_v1 Tactic: -3855385237722507464
[03/24/2023-12:56:53] [V] [TRT] Tactic: -3855385237722507464 Time: 0.874496
[03/24/2023-12:56:53] [V] [TRT] Conv_46 + Relu_47 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize128x64x8_stage3_warpsize1x4x1_g1_ffma_t1r3s3 Tactic: -3697587361057948972
[03/24/2023-12:56:53] [V] [TRT] Tactic: -3697587361057948972 Time: 0.882816
[03/24/2023-12:56:53] [V] [TRT] Conv_46 + Relu_47 Set Tactic Name: ampere_scudnn_128x128_relu_exp_medium_nhwc_tn_v1 Tactic: -2809379259463049391
[03/24/2023-12:56:53] [V] [TRT] Tactic: -2809379259463049391 Time: 0.869632
[03/24/2023-12:56:53] [V] [TRT] Conv_46 + Relu_47 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize64x256x8_stage3_warpsize1x4x1_g1_ffma_t1r3s3 Tactic: -2747929399988666512
[03/24/2023-12:56:53] [V] [TRT] Tactic: -2747929399988666512 Time: 0.875264
[03/24/2023-12:56:53] [V] [TRT] Conv_46 + Relu_47 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize64x256x8_stage3_warpsize1x4x1_g1_ffma Tactic: -1472061967969061456
[03/24/2023-12:56:53] [V] [TRT] Tactic: -1472061967969061456 Time: 0.889472
[03/24/2023-12:56:53] [V] [TRT] Conv_46 + Relu_47 Set Tactic Name: ampere_scudnn_128x128_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: -504296718212024303
[03/24/2023-12:56:53] [V] [TRT] Tactic: -504296718212024303 Time: 0.86464
[03/24/2023-12:56:53] [V] [TRT] Conv_46 + Relu_47 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize64x128x8_stage3_warpsize1x4x1_g1_ffma Tactic: -444093195553988951
[03/24/2023-12:56:53] [V] [TRT] Tactic: -444093195553988951 Time: 0.684416
[03/24/2023-12:56:53] [V] [TRT] Fastest Tactic: -7989138351613022500 Time: 0.553984
[03/24/2023-12:56:53] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: -7989138351613022500
[03/24/2023-12:56:53] [V] [TRT] *************** Autotuning format combination: Float(518400,1:4,5760,64) -> Float(518400,1:4,5760,64) ***************
[03/24/2023-12:56:53] [V] [TRT] --------------- Timing Runner: Conv_46 + Relu_47 (CudnnConvolution)
[03/24/2023-12:56:53] [V] [TRT] CudnnConvolution has no valid tactics for this config, skipping
[03/24/2023-12:56:53] [V] [TRT] --------------- Timing Runner: Conv_46 + Relu_47 (CaskConvolution)
[03/24/2023-12:56:53] [V] [TRT] Conv_46 + Relu_47 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize64x128x32_stage5_warpsize2x2x1_g1_tensor16x8x8 Tactic: 1237784342446422381
[03/24/2023-12:56:53] [V] [TRT] Tactic: 1237784342446422381 Time: 0.149632
[03/24/2023-12:56:53] [V] [TRT] Conv_46 + Relu_47 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x64x32_stage5_warpsize2x2x1_g1_tensor16x8x8 Tactic: 1426562292875733922
[03/24/2023-12:56:53] [V] [TRT] Tactic: 1426562292875733922 Time: 0.158464
[03/24/2023-12:56:53] [V] [TRT] Conv_46 + Relu_47 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize64x128x8_stage3_warpsize1x4x1_g1_ffma_t1r3s3 Tactic: 2086609538387166260
[03/24/2023-12:56:53] [V] [TRT] Tactic: 2086609538387166260 Time: 0.654976
[03/24/2023-12:56:53] [V] [TRT] Conv_46 + Relu_47 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize256x128x32_stage3_warpsize4x2x1_g1_tensor16x8x8_t1r3s3 Tactic: 2388153022056233219
[03/24/2023-12:56:53] [V] [TRT] Tactic: 2388153022056233219 Time: 0.13184
[03/24/2023-12:56:53] [V] [TRT] Conv_46 + Relu_47 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x128x32_stage4_warpsize2x2x1_g1_tensor16x8x8 Tactic: 2716437853123234317
[03/24/2023-12:56:53] [V] [TRT] Tactic: 2716437853123234317 Time: 0.138624
[03/24/2023-12:56:53] [V] [TRT] Conv_46 + Relu_47 Set Tactic Name: ampere_scudnn_128x64_sliced1x2_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: 2860655430572478466
[03/24/2023-12:56:53] [V] [TRT] Tactic: 2860655430572478466 Time: 0.667008
[03/24/2023-12:56:53] [V] [TRT] Conv_46 + Relu_47 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize64x128x8_stage3_warpsize1x4x1_g1_ffma Tactic: 3239733199291090177
[03/24/2023-12:56:53] [V] [TRT] Tactic: 3239733199291090177 Time: 0.653184
[03/24/2023-12:56:53] [V] [TRT] Conv_46 + Relu_47 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize64x64x64_stage4_warpsize2x2x1_g1_tensor16x8x8_t1r3s3 Tactic: 3278852197192504305
[03/24/2023-12:56:53] [V] [TRT] Tactic: 3278852197192504305 Time: 0.148352
[03/24/2023-12:56:53] [V] [TRT] Conv_46 + Relu_47 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize256x128x32_stage3_warpsize4x2x1_g1_tensor16x8x8 Tactic: 3904690393614050557
[03/24/2023-12:56:53] [V] [TRT] Tactic: 3904690393614050557 Time: 0.1696
[03/24/2023-12:56:53] [V] [TRT] Conv_46 + Relu_47 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize64x64x64_stage4_warpsize2x2x1_g1_tensor16x8x8 Tactic: 4061115162338989075
[03/24/2023-12:56:53] [V] [TRT] Tactic: 4061115162338989075 Time: 0.16384
[03/24/2023-12:56:53] [V] [TRT] Conv_46 + Relu_47 Set Tactic Name: ampere_scudnn_128x32_sliced1x4_ldg4_relu_exp_medium_nhwc_tn_v1 Tactic: 4474630279712975759
[03/24/2023-12:56:53] [V] [TRT] Tactic: 4474630279712975759 Time: 0.564096
[03/24/2023-12:56:53] [V] [TRT] Conv_46 + Relu_47 Set Tactic Name: ampere_scudnn_128x32_sliced1x4_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: 4479823862704990365
[03/24/2023-12:56:54] [V] [TRT] Tactic: 4479823862704990365 Time: 0.561152
[03/24/2023-12:56:54] [V] [TRT] Conv_46 + Relu_47 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize64x256x8_stage3_warpsize1x4x1_g1_ffma Tactic: 4517590677127196184
[03/24/2023-12:56:54] [V] [TRT] Tactic: 4517590677127196184 Time: 0.89792
[03/24/2023-12:56:54] [V] [TRT] Conv_46 + Relu_47 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize128x128x8_stage3_warpsize2x4x1_g1_ffma_t1r3s3 Tactic: 4634080872644479428
[03/24/2023-12:56:54] [V] [TRT] Tactic: 4634080872644479428 Time: 0.8672
[03/24/2023-12:56:54] [V] [TRT] Conv_46 + Relu_47 Set Tactic Name: ampere_scudnn_128x64_sliced1x2_ldg4_relu_exp_medium_nhwc_tn_v1 Tactic: 4696204239951173149
[03/24/2023-12:56:54] [V] [TRT] Tactic: 4696204239951173149 Time: 0.667776
[03/24/2023-12:56:54] [V] [TRT] Conv_46 + Relu_47 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x256x32_stage3_warpsize2x4x1_g1_tensor16x8x8 Tactic: 5200329514761435342
[03/24/2023-12:56:54] [V] [TRT] Tactic: 5200329514761435342 Time: 0.127744
[03/24/2023-12:56:54] [V] [TRT] Conv_46 + Relu_47 Set Tactic Name: ampere_scudnn_128x128_relu_exp_small_nhwc_tn_v1 Tactic: 5778138195697110003
[03/24/2023-12:56:54] [V] [TRT] Tactic: 5778138195697110003 Time: 0.86656
[03/24/2023-12:56:54] [V] [TRT] Conv_46 + Relu_47 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize256x128x8_stage3_warpsize2x4x1_g1_ffma Tactic: 6310198979346901507
[03/24/2023-12:56:54] [V] [TRT] Tactic: 6310198979346901507 Time: 0.909184
[03/24/2023-12:56:54] [V] [TRT] Conv_46 + Relu_47 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x256x32_stage3_warpsize2x4x1_g1_tensor16x8x8_t1r3s3 Tactic: 7011693366046809027
[03/24/2023-12:56:54] [V] [TRT] Tactic: 7011693366046809027 Time: 0.125056
[03/24/2023-12:56:54] [V] [TRT] Conv_46 + Relu_47 Set Tactic Name: ampere_scudnn_128x128_ldg4_relu_exp_large_nhwc_tn_v1 Tactic: 7155825427510256858
[03/24/2023-12:56:54] [V] [TRT] Tactic: 7155825427510256858 Time: 0.875648
[03/24/2023-12:56:54] [V] [TRT] Conv_46 + Relu_47 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize128x64x8_stage3_warpsize1x4x1_g1_ffma Tactic: 7222247112373541608
[03/24/2023-12:56:54] [V] [TRT] Tactic: 7222247112373541608 Time: 0.909056
[03/24/2023-12:56:54] [V] [TRT] Conv_46 + Relu_47 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x128x16_stage4_warpsize2x2x1_g1_tensor16x8x8 Tactic: 7342025736444949634
[03/24/2023-12:56:54] [V] [TRT] Tactic: 7342025736444949634 Time: 0.155392
[03/24/2023-12:56:54] [V] [TRT] Conv_46 + Relu_47 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize64x128x32_stage5_warpsize2x2x1_g1_tensor16x8x8 Tactic: 7347365539922924600
[03/24/2023-12:56:54] [V] [TRT] Tactic: 7347365539922924600 Time: 0.132224
[03/24/2023-12:56:54] [V] [TRT] Conv_46 + Relu_47 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x64x32_stage5_warpsize2x2x1_g1_tensor16x8x8 Tactic: 7428197830878119671
[03/24/2023-12:56:54] [V] [TRT] Tactic: 7428197830878119671 Time: 0.141056
[03/24/2023-12:56:54] [V] [TRT] Conv_46 + Relu_47 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize64x32x64_stage5_warpsize2x2x1_g1_tensor16x8x8_t1r3s3 Tactic: 7465323447915168822
[03/24/2023-12:56:54] [V] [TRT] Tactic: 7465323447915168822 Time: 0.218752
[03/24/2023-12:56:54] [V] [TRT] Conv_46 + Relu_47 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize128x128x8_stage3_warpsize2x4x1_g1_ffma Tactic: 7472640475524677095
[03/24/2023-12:56:54] [V] [TRT] Tactic: 7472640475524677095 Time: 0.884864
[03/24/2023-12:56:54] [V] [TRT] Conv_46 + Relu_47 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize64x32x64_stage5_warpsize2x2x1_g1_tensor16x8x8 Tactic: 7938223790021272801
[03/24/2023-12:56:54] [V] [TRT] Tactic: 7938223790021272801 Time: 0.226304
[03/24/2023-12:56:54] [V] [TRT] Conv_46 + Relu_47 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize128x256x8_stage3_warpsize2x4x1_g1_ffma Tactic: 8498373915030836990
[03/24/2023-12:56:54] [V] [TRT] Tactic: 8498373915030836990 Time: 0.88128
[03/24/2023-12:56:54] [V] [TRT] Conv_46 + Relu_47 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x64x32_stage5_warpsize2x2x1_g1_tensor16x8x8_t1r3s3 Tactic: 8836645772682419994
[03/24/2023-12:56:54] [V] [TRT] Tactic: 8836645772682419994 Time: 0.135808
[03/24/2023-12:56:54] [V] [TRT] Conv_46 + Relu_47 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize256x64x8_stage3_warpsize1x4x1_g1_ffma Tactic: 8869697132622550639
[03/24/2023-12:56:54] [V] [TRT] Tactic: 8869697132622550639 Time: 1.01581
[03/24/2023-12:56:54] [V] [TRT] Conv_46 + Relu_47 Set Tactic Name: ampere_scudnn_128x128_ldg4_relu_exp_medium_nhwc_tn_v1 Tactic: 8918020581761223752
[03/24/2023-12:56:54] [V] [TRT] Tactic: 8918020581761223752 Time: 0.866944
[03/24/2023-12:56:54] [V] [TRT] Conv_46 + Relu_47 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize64x64x64_stage4_warpsize2x2x1_g1_tensor16x8x8 Tactic: -9114138070928278731
[03/24/2023-12:56:54] [V] [TRT] Tactic: -9114138070928278731 Time: 0.153984
[03/24/2023-12:56:54] [V] [TRT] Conv_46 + Relu_47 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize256x128x8_stage3_warpsize2x4x1_g1_ffma_t1r3s3 Tactic: -8937725997228636978
[03/24/2023-12:56:54] [V] [TRT] Tactic: -8937725997228636978 Time: 0.872448
[03/24/2023-12:56:54] [V] [TRT] Conv_46 + Relu_47 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize128x256x8_stage3_warpsize2x4x1_g1_ffma_t1r3s3 Tactic: -8833858409138163072
[03/24/2023-12:56:54] [V] [TRT] Tactic: -8833858409138163072 Time: 0.871168
[03/24/2023-12:56:54] [V] [TRT] Conv_46 + Relu_47 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize64x64x8_stage3_warpsize1x4x1_g1_ffma_t1r3s3 Tactic: -7989138351613022500
[03/24/2023-12:56:54] [V] [TRT] Tactic: -7989138351613022500 Time: 0.55424
[03/24/2023-12:56:54] [V] [TRT] Conv_46 + Relu_47 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize256x128x8_stage3_warpsize2x4x1_g1_ffma Tactic: -7872883691240863058
[03/24/2023-12:56:54] [V] [TRT] Tactic: -7872883691240863058 Time: 0.902528
[03/24/2023-12:56:54] [V] [TRT] Conv_46 + Relu_47 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x256x32_stage3_warpsize2x4x1_g1_tensor16x8x8 Tactic: -7382359095196034537
[03/24/2023-12:56:54] [V] [TRT] Tactic: -7382359095196034537 Time: 0.12928
[03/24/2023-12:56:54] [V] [TRT] Conv_46 + Relu_47 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x128x16_stage4_warpsize2x2x1_g1_tensor16x8x8_t1r3s3 Tactic: -7377458734869418330
[03/24/2023-12:56:54] [V] [TRT] Tactic: -7377458734869418330 Time: 0.147456
[03/24/2023-12:56:54] [V] [TRT] Conv_46 + Relu_47 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize128x128x8_stage3_warpsize2x4x1_g1_ffma Tactic: -6729618519651721910
[03/24/2023-12:56:54] [V] [TRT] Tactic: -6729618519651721910 Time: 0.874496
[03/24/2023-12:56:54] [V] [TRT] Conv_46 + Relu_47 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize256x64x32_stage3_warpsize4x2x1_g1_tensor16x8x8_t1r3s3 Tactic: -6223854811627385844
[03/24/2023-12:56:54] [V] [TRT] Tactic: -6223854811627385844 Time: 0.147456
[03/24/2023-12:56:54] [V] [TRT] Conv_46 + Relu_47 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize256x64x8_stage3_warpsize1x4x1_g1_ffma Tactic: -5893833996418445881
[03/24/2023-12:56:54] [V] [TRT] Tactic: -5893833996418445881 Time: 0.983168
[03/24/2023-12:56:54] [V] [TRT] Conv_46 + Relu_47 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize128x256x8_stage3_warpsize2x4x1_g1_ffma Tactic: -5701562095007058349
[03/24/2023-12:56:54] [V] [TRT] Tactic: -5701562095007058349 Time: 0.86976
[03/24/2023-12:56:54] [V] [TRT] Conv_46 + Relu_47 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize128x64x8_stage3_warpsize1x4x1_g1_ffma Tactic: -5685503422376017600
[03/24/2023-12:56:54] [V] [TRT] Tactic: -5685503422376017600 Time: 0.880512
[03/24/2023-12:56:54] [V] [TRT] Conv_46 + Relu_47 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize64x64x8_stage3_warpsize1x4x1_g1_ffma Tactic: -5521125187060117489
[03/24/2023-12:56:54] [V] [TRT] Tactic: -5521125187060117489 Time: 0.601728
[03/24/2023-12:56:54] [V] [TRT] Conv_46 + Relu_47 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x128x16_stage4_warpsize2x2x1_g1_tensor16x8x8 Tactic: -5457304872213719461
[03/24/2023-12:56:54] [V] [TRT] Tactic: -5457304872213719461 Time: 0.149888
[03/24/2023-12:56:54] [V] [TRT] Conv_46 + Relu_47 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x64x64_stage3_warpsize2x2x1_g1_tensor16x8x8 Tactic: -5441054706931585554
[03/24/2023-12:56:54] [V] [TRT] Tactic: -5441054706931585554 Time: 0.150656
[03/24/2023-12:56:54] [V] [TRT] Conv_46 + Relu_47 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize256x64x32_stage3_warpsize4x2x1_g1_tensor16x8x8 Tactic: -5043603702497465467
[03/24/2023-12:56:54] [V] [TRT] Tactic: -5043603702497465467 Time: 0.18624
[03/24/2023-12:56:54] [V] [TRT] Conv_46 + Relu_47 Set Tactic Name: ampere_scudnn_128x64_sliced1x2_ldg4_relu_exp_large_nhwc_tn_v1 Tactic: -4756382386362004279
[03/24/2023-12:56:54] [V] [TRT] Tactic: -4756382386362004279 Time: 0.658688
[03/24/2023-12:56:54] [V] [TRT] Conv_46 + Relu_47 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize64x64x8_stage3_warpsize1x4x1_g1_ffma Tactic: -4615000974950361663
[03/24/2023-12:56:54] [V] [TRT] Tactic: -4615000974950361663 Time: 0.57344
[03/24/2023-12:56:54] [V] [TRT] Conv_46 + Relu_47 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x64x64_stage3_warpsize2x2x1_g1_tensor16x8x8 Tactic: -4564655677311401797
[03/24/2023-12:56:54] [V] [TRT] Tactic: -4564655677311401797 Time: 0.14784
[03/24/2023-12:56:54] [V] [TRT] Conv_46 + Relu_47 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize256x64x8_stage3_warpsize1x4x1_g1_ffma_t1r3s3 Tactic: -4314913710375142296
[03/24/2023-12:56:54] [V] [TRT] Tactic: -4314913710375142296 Time: 0.956032
[03/24/2023-12:56:54] [V] [TRT] Conv_46 + Relu_47 Set Tactic Name: ampere_scudnn_128x128_relu_exp_large_nhwc_tn_v1 Tactic: -3855385237722507464
[03/24/2023-12:56:54] [V] [TRT] Tactic: -3855385237722507464 Time: 0.874624
[03/24/2023-12:56:54] [V] [TRT] Conv_46 + Relu_47 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize128x64x8_stage3_warpsize1x4x1_g1_ffma_t1r3s3 Tactic: -3697587361057948972
[03/24/2023-12:56:54] [V] [TRT] Tactic: -3697587361057948972 Time: 0.882688
[03/24/2023-12:56:54] [V] [TRT] Conv_46 + Relu_47 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize256x64x32_stage3_warpsize4x2x1_g1_tensor16x8x8 Tactic: -3540975627865078064
[03/24/2023-12:56:54] [V] [TRT] Tactic: -3540975627865078064 Time: 0.158464
[03/24/2023-12:56:54] [V] [TRT] Conv_46 + Relu_47 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize64x128x32_stage5_warpsize2x2x1_g1_tensor16x8x8_t1r3s3 Tactic: -3151804561246216835
[03/24/2023-12:56:54] [V] [TRT] Tactic: -3151804561246216835 Time: 0.132992
[03/24/2023-12:56:54] [V] [TRT] Conv_46 + Relu_47 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize64x32x64_stage5_warpsize2x2x1_g1_tensor16x8x8 Tactic: -2885165284206163001
[03/24/2023-12:56:54] [V] [TRT] Tactic: -2885165284206163001 Time: 0.249856
[03/24/2023-12:56:54] [V] [TRT] Conv_46 + Relu_47 Set Tactic Name: ampere_scudnn_128x128_relu_exp_medium_nhwc_tn_v1 Tactic: -2809379259463049391
[03/24/2023-12:56:54] [V] [TRT] Tactic: -2809379259463049391 Time: 0.870272
[03/24/2023-12:56:54] [V] [TRT] Conv_46 + Relu_47 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x128x32_stage4_warpsize2x2x1_g1_tensor16x8x8_t1r3s3 Tactic: -2801041895330778813
[03/24/2023-12:56:54] [V] [TRT] Tactic: -2801041895330778813 Time: 0.153088
[03/24/2023-12:56:54] [V] [TRT] Conv_46 + Relu_47 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize64x256x8_stage3_warpsize1x4x1_g1_ffma_t1r3s3 Tactic: -2747929399988666512
[03/24/2023-12:56:54] [V] [TRT] Tactic: -2747929399988666512 Time: 0.87488
[03/24/2023-12:56:54] [V] [TRT] Conv_46 + Relu_47 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize256x128x32_stage3_warpsize4x2x1_g1_tensor16x8x8 Tactic: -1758690179295738332
[03/24/2023-12:56:54] [V] [TRT] Tactic: -1758690179295738332 Time: 0.139392
[03/24/2023-12:56:54] [V] [TRT] Conv_46 + Relu_47 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x64x64_stage3_warpsize2x2x1_g1_tensor16x8x8_t1r3s3 Tactic: -1484546572846226796
[03/24/2023-12:56:54] [V] [TRT] Tactic: -1484546572846226796 Time: 0.13888
[03/24/2023-12:56:54] [V] [TRT] Conv_46 + Relu_47 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize64x256x8_stage3_warpsize1x4x1_g1_ffma Tactic: -1472061967969061456
[03/24/2023-12:56:54] [V] [TRT] Tactic: -1472061967969061456 Time: 0.890112
[03/24/2023-12:56:54] [V] [TRT] Conv_46 + Relu_47 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x128x32_stage4_warpsize2x2x1_g1_tensor16x8x8 Tactic: -858667497925695276
[03/24/2023-12:56:54] [V] [TRT] Tactic: -858667497925695276 Time: 0.231936
[03/24/2023-12:56:54] [V] [TRT] Conv_46 + Relu_47 Set Tactic Name: ampere_scudnn_128x128_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: -504296718212024303
[03/24/2023-12:56:54] [V] [TRT] Tactic: -504296718212024303 Time: 0.866816
[03/24/2023-12:56:54] [V] [TRT] Conv_46 + Relu_47 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize64x128x8_stage3_warpsize1x4x1_g1_ffma Tactic: -444093195553988951
[03/24/2023-12:56:54] [V] [TRT] Tactic: -444093195553988951 Time: 0.684928
[03/24/2023-12:56:54] [V] [TRT] Fastest Tactic: 7011693366046809027 Time: 0.125056
[03/24/2023-12:56:54] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: 7011693366046809027
[03/24/2023-12:56:54] [V] [TRT] *************** Autotuning format combination: Half(2073600,8100,90,1) -> Half(2073600,8100,90,1) ***************
[03/24/2023-12:56:54] [V] [TRT] --------------- Timing Runner: Conv_46 + Relu_47 (CudnnConvolution)
[03/24/2023-12:56:54] [V] [TRT] Tactic: 0 Time: 0.940672
[03/24/2023-12:56:54] [V] [TRT] Tactic: 1 Time: 0.842752
[03/24/2023-12:56:54] [V] [TRT] Tactic: 2 Time: 0.995328
[03/24/2023-12:56:54] [V] [TRT] Tactic: 4 skipped. Scratch requested: 8760590336, available: 4294967296
[03/24/2023-12:56:54] [V] [TRT] Tactic: 5 Time: 2.25882
[03/24/2023-12:56:54] [V] [TRT] Tactic: 6 Time: 0.38912
[03/24/2023-12:56:54] [V] [TRT] Tactic: 56 Time: 0.941568
[03/24/2023-12:56:54] [V] [TRT] Tactic: 58 Time: 0.995968
[03/24/2023-12:56:54] [V] [TRT] Tactic: 60 skipped. Scratch requested: 8760590336, available: 4294967296
[03/24/2023-12:56:55] [V] [TRT] Tactic: 61 Time: 2.25562
[03/24/2023-12:56:55] [V] [TRT] Tactic: 62 Time: 0.389248
[03/24/2023-12:56:55] [V] [TRT] Fastest Tactic: 6 Time: 0.38912
[03/24/2023-12:56:55] [V] [TRT] Setting workspace to 8760590336enables more tactics for profiling
[03/24/2023-12:56:55] [V] [TRT] --------------- Timing Runner: Conv_46 + Relu_47 (CaskConvolution)
[03/24/2023-12:56:55] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[03/24/2023-12:56:55] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CudnnConvolution Tactic: 6
[03/24/2023-12:56:55] [V] [TRT] *************** Autotuning format combination: Half(1036800,8100:2,90,1) -> Half(1036800,8100:2,90,1) ***************
[03/24/2023-12:56:55] [V] [TRT] --------------- Timing Runner: Conv_46 + Relu_47 (FusedConvActConvolution)
[03/24/2023-12:56:55] [V] [TRT] Tactic: 524287 Time: 0.284672
[03/24/2023-12:56:55] [V] [TRT] Tactic: 720895 Time: 0.249984
[03/24/2023-12:56:55] [V] [TRT] Tactic: 983039 Time: 0.243328
[03/24/2023-12:56:55] [V] [TRT] Tactic: 1048575 Time: 0.260992
[03/24/2023-12:56:55] [V] [TRT] Tactic: 1703935 Time: 0.252928
[03/24/2023-12:56:55] [V] [TRT] Tactic: 1769471 Time: 0.257664
[03/24/2023-12:56:55] [V] [TRT] Tactic: 1966079 Time: 0.274432
[03/24/2023-12:56:55] [V] [TRT] Tactic: 2031615 Time: 0.224768
[03/24/2023-12:56:55] [V] [TRT] Tactic: 2228223 Time: 0.277504
[03/24/2023-12:56:55] [V] [TRT] Tactic: 2424831 Time: 0.305408
[03/24/2023-12:56:55] [V] [TRT] Tactic: 2621439 Time: 0.2592
[03/24/2023-12:56:55] [V] [TRT] Tactic: 2752511 Time: 0.248448
[03/24/2023-12:56:55] [V] [TRT] Tactic: 2818047 Time: 0.313728
[03/24/2023-12:56:55] [V] [TRT] Tactic: 2883583 Time: 0.25408
[03/24/2023-12:56:55] [V] [TRT] Tactic: 3014655 Time: 0.25472
[03/24/2023-12:56:55] [V] [TRT] Tactic: 3145727 Time: 0.223488
[03/24/2023-12:56:55] [V] [TRT] Tactic: 3473407 Time: 0.288128
[03/24/2023-12:56:55] [V] [TRT] Tactic: 3604479 Time: 0.261248
[03/24/2023-12:56:55] [V] [TRT] Tactic: 3735551 Time: 0.257152
[03/24/2023-12:56:55] [V] [TRT] Tactic: 4390911 Time: 0.293248
[03/24/2023-12:56:55] [V] [TRT] Tactic: 5046271 Time: 0.267264
[03/24/2023-12:56:55] [V] [TRT] Tactic: 5963775 Time: 0.245888
[03/24/2023-12:56:55] [V] [TRT] Tactic: 6160383 Time: 0.279168
[03/24/2023-12:56:55] [V] [TRT] Tactic: 6488063 Time: 0.275584
[03/24/2023-12:56:55] [V] [TRT] Tactic: 6881279 Time: 0.256768
[03/24/2023-12:56:55] [V] [TRT] Tactic: 7274495 Time: 0.254592
[03/24/2023-12:56:55] [V] [TRT] Tactic: 7864319 Time: 0.25472
[03/24/2023-12:56:55] [V] [TRT] Tactic: 7995391 Time: 0.280832
[03/24/2023-12:56:55] [V] [TRT] Tactic: 8585215 Time: 0.286848
[03/24/2023-12:56:55] [V] [TRT] Tactic: 8847359 Time: 0.250752
[03/24/2023-12:56:55] [V] [TRT] Tactic: 8978431 Time: 0.254336
[03/24/2023-12:56:55] [V] [TRT] Tactic: 9043967 Time: 0.243584
[03/24/2023-12:56:55] [V] [TRT] Tactic: 9175039 Time: 0.261376
[03/24/2023-12:56:55] [V] [TRT] Tactic: 9502719 Time: 0.291456
[03/24/2023-12:56:55] [V] [TRT] Tactic: 9830399 Time: 0.263168
[03/24/2023-12:56:55] [V] [TRT] Tactic: 9961471 Time: 0.311296
[03/24/2023-12:56:55] [V] [TRT] Tactic: 10027007 Time: 0.243328
[03/24/2023-12:56:55] [V] [TRT] Tactic: 10092543 Time: 0.293248
[03/24/2023-12:56:56] [V] [TRT] Tactic: 10289151 Time: 0.274048
[03/24/2023-12:56:56] [V] [TRT] Tactic: 10485759 Time: 0.240384
[03/24/2023-12:56:56] [V] [TRT] Tactic: 10682367 Time: 0.264576
[03/24/2023-12:56:56] [V] [TRT] Tactic: 10813439 Time: 0.2688
[03/24/2023-12:56:56] [V] [TRT] Fastest Tactic: 3145727 Time: 0.223488
[03/24/2023-12:56:56] [V] [TRT] --------------- Timing Runner: Conv_46 + Relu_47 (CudnnConvolution)
[03/24/2023-12:56:56] [V] [TRT] CudnnConvolution has no valid tactics for this config, skipping
[03/24/2023-12:56:56] [V] [TRT] --------------- Timing Runner: Conv_46 + Relu_47 (CaskConvolution)
[03/24/2023-12:56:56] [V] [TRT] Conv_46 + Relu_47 Set Tactic Name: ampere_fp16x2_hcudnn_fp16x2_128x32_relu_medium_nn_v1 Tactic: 2195670545862694453
[03/24/2023-12:56:56] [V] [TRT] Tactic: 2195670545862694453 Time: 0.38016
[03/24/2023-12:56:56] [V] [TRT] Conv_46 + Relu_47 Set Tactic Name: ampere_fp16x2_hcudnn_fp16x2_128x64_relu_large_nn_v1 Tactic: 3419182076704469245
[03/24/2023-12:56:56] [V] [TRT] Tactic: 3419182076704469245 Time: 0.36992
[03/24/2023-12:56:56] [V] [TRT] Conv_46 + Relu_47 Set Tactic Name: ampere_fp16x2_hcudnn_fp16x2_128x128_relu_medium_nn_v1 Tactic: 3891805945559659536
[03/24/2023-12:56:56] [V] [TRT] Tactic: 3891805945559659536 Time: 0.449792
[03/24/2023-12:56:56] [V] [TRT] Conv_46 + Relu_47 Set Tactic Name: ampere_fp16x2_hcudnn_fp16x2_128x64_relu_medium_nn_v1 Tactic: 5548126322150286555
[03/24/2023-12:56:56] [V] [TRT] Tactic: 5548126322150286555 Time: 0.365312
[03/24/2023-12:56:56] [V] [TRT] Conv_46 + Relu_47 Set Tactic Name: ampere_fp16x2_hcudnn_fp16x2_128x64_relu_small_nn_v1 Tactic: 6057304366605292508
[03/24/2023-12:56:56] [V] [TRT] Tactic: 6057304366605292508 Time: 0.353152
[03/24/2023-12:56:56] [V] [TRT] Conv_46 + Relu_47 Set Tactic Name: ampere_fp16x2_hcudnn_fp16x2_128x128_relu_large_nn_v1 Tactic: -7928611605886347652
[03/24/2023-12:56:56] [V] [TRT] Tactic: -7928611605886347652 Time: 0.463872
[03/24/2023-12:56:56] [V] [TRT] Conv_46 + Relu_47 Set Tactic Name: ampere_fp16x2_hcudnn_fp16x2_128x32_relu_large_nn_v1 Tactic: -5172391392092686714
[03/24/2023-12:56:56] [V] [TRT] Tactic: -5172391392092686714 Time: 0.384512
[03/24/2023-12:56:56] [V] [TRT] Conv_46 + Relu_47 Set Tactic Name: ampere_fp16x2_hcudnn_fp16x2_128x32_relu_small_nn_v1 Tactic: -4374269919094467161
[03/24/2023-12:56:56] [V] [TRT] Tactic: -4374269919094467161 Time: 0.369664
[03/24/2023-12:56:56] [V] [TRT] Conv_46 + Relu_47 Set Tactic Name: ampere_fp16x2_hcudnn_winograd_fp16x2_128x128_ldg1_ldg4_relu_tile148t_nt_v1 Tactic: -4083394051665370953
[03/24/2023-12:56:56] [V] [TRT] Tactic: -4083394051665370953 Time: 0.173824
[03/24/2023-12:56:56] [V] [TRT] Conv_46 + Relu_47 Set Tactic Name: ampere_fp16x2_hcudnn_fp16x2_128x128_relu_small_nn_v1 Tactic: -1546027692247304867
[03/24/2023-12:56:56] [V] [TRT] Tactic: -1546027692247304867 Time: 0.452352
[03/24/2023-12:56:56] [V] [TRT] Fastest Tactic: -4083394051665370953 Time: 0.173824
[03/24/2023-12:56:56] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: -4083394051665370953
[03/24/2023-12:56:56] [V] [TRT] *************** Autotuning format combination: Half(259200,1:8,2880,32) -> Float(2073600,8100,90,1) ***************
[03/24/2023-12:56:56] [V] [TRT] --------------- Timing Runner: Conv_46 + Relu_47 (CudnnConvolution)
[03/24/2023-12:56:56] [V] [TRT] CudnnConvolution has no valid tactics for this config, skipping
[03/24/2023-12:56:56] [V] [TRT] --------------- Timing Runner: Conv_46 + Relu_47 (CaskConvolution)
[03/24/2023-12:56:56] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[03/24/2023-12:56:56] [V] [TRT] *************** Autotuning format combination: Half(259200,1:8,2880,32) -> Half(259200,1:8,2880,32) ***************
[03/24/2023-12:56:56] [V] [TRT] --------------- Timing Runner: Conv_46 + Relu_47 (CudaDepthwiseConvolution)
[03/24/2023-12:56:56] [V] [TRT] CudaDepthwiseConvolution has no valid tactics for this config, skipping
[03/24/2023-12:56:56] [V] [TRT] --------------- Timing Runner: Conv_46 + Relu_47 (CudnnConvolution)
[03/24/2023-12:56:56] [V] [TRT] Tactic: 0 Time: 1.0665
[03/24/2023-12:56:56] [V] [TRT] Tactic: 1 Time: 1.61318
[03/24/2023-12:56:56] [V] [TRT] Tactic: 2 Time: 1.13702
[03/24/2023-12:56:56] [V] [TRT] Tactic: 6 Time: 0.386304
[03/24/2023-12:56:56] [V] [TRT] Tactic: 56 Time: 1.06701
[03/24/2023-12:56:56] [V] [TRT] Tactic: 58 Time: 1.13613
[03/24/2023-12:56:56] [V] [TRT] Tactic: 62 Time: 0.386048
[03/24/2023-12:56:56] [V] [TRT] Fastest Tactic: 62 Time: 0.386048
[03/24/2023-12:56:56] [V] [TRT] --------------- Timing Runner: Conv_46 + Relu_47 (CaskConvolution)
[03/24/2023-12:56:56] [V] [TRT] Conv_46 + Relu_47 Set Tactic Name: ampere_h16816cudnn_256x128_ldg8_relu_exp_medium_nhwc_tn_v1 Tactic: 254850674756030979
[03/24/2023-12:56:56] [V] [TRT] Tactic: 254850674756030979 Time: 0.06976
[03/24/2023-12:56:56] [V] [TRT] Conv_46 + Relu_47 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x128x32_stage3_warpsize4x2x1_g1_tensor16x8x16_t1r3s3 Tactic: 328038211831149625
[03/24/2023-12:56:56] [V] [TRT] Tactic: 328038211831149625 Time: 0.067584
[03/24/2023-12:56:56] [V] [TRT] Conv_46 + Relu_47 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x64x64_stage3_warpsize2x2x1_g1_tensor16x8x16_t1r3s3 Tactic: 411553864378931917
[03/24/2023-12:56:56] [V] [TRT] Tactic: 411553864378931917 Time: 0.078208
[03/24/2023-12:56:56] [V] [TRT] Conv_46 + Relu_47 Set Tactic Name: sm75_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x128x32_stage1_warpsize4x2x1_g1_tensor16x8x8_t1r3s3 Tactic: 864841579020773074
[03/24/2023-12:56:56] [V] [TRT] Tactic: 864841579020773074 Time: 0.082432
[03/24/2023-12:56:56] [V] [TRT] Conv_46 + Relu_47 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x128x32_stage4_warpsize2x2x1_g1_tensor16x8x16 Tactic: 1011057357468998345
[03/24/2023-12:56:56] [V] [TRT] Tactic: 1011057357468998345 Time: 0.0736
[03/24/2023-12:56:56] [V] [TRT] Conv_46 + Relu_47 Set Tactic Name: sm75_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x64x32_stage1_warpsize4x1x1_g1_tensor16x8x8 Tactic: 1013168150133367738
[03/24/2023-12:56:56] [V] [TRT] Tactic: 1013168150133367738 Time: 0.102272
[03/24/2023-12:56:56] [V] [TRT] Conv_46 + Relu_47 Set Tactic Name: ampere_h16816cudnn_256x128_ldg8_relu_exp_stages_64x3_small_nhwc_tn_v1 Tactic: 1016009564074305832
[03/24/2023-12:56:56] [V] [TRT] Tactic: 1016009564074305832 Time: 0.067712
[03/24/2023-12:56:56] [V] [TRT] Conv_46 + Relu_47 Set Tactic Name: sm75_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x128x32_stage1_warpsize2x2x1_g1_tensor16x8x8 Tactic: 1067227531433278814
[03/24/2023-12:56:56] [V] [TRT] Tactic: 1067227531433278814 Time: 0.088576
[03/24/2023-12:56:56] [V] [TRT] Conv_46 + Relu_47 Set Tactic Name: ampere_h1688cudnn_128x128_ldg8_relu_exp_medium_nhwc_tn_v1 Tactic: 1156328698016730421
[03/24/2023-12:56:56] [V] [TRT] Tactic: 1156328698016730421 Time: 0.086016
[03/24/2023-12:56:56] [V] [TRT] Conv_46 + Relu_47 Set Tactic Name: sm75_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x128x32_stage1_warpsize2x2x1_g1_tensor16x8x8 Tactic: 1579845938601132607
[03/24/2023-12:56:56] [V] [TRT] Tactic: 1579845938601132607 Time: 0.085504
[03/24/2023-12:56:56] [V] [TRT] Conv_46 + Relu_47 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x128x32_stage5_warpsize2x2x1_g1_tensor16x8x16_t1r3s3 Tactic: 1723736032573714698
[03/24/2023-12:56:56] [V] [TRT] Tactic: 1723736032573714698 Time: 0.080128
[03/24/2023-12:56:56] [V] [TRT] Conv_46 + Relu_47 Set Tactic Name: sm75_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x32x32_stage1_warpsize4x1x1_g1_tensor16x8x8 Tactic: 1796821236841789338
[03/24/2023-12:56:56] [V] [TRT] Tactic: 1796821236841789338 Time: 0.11968
[03/24/2023-12:56:56] [V] [TRT] Conv_46 + Relu_47 Set Tactic Name: ampere_h16816cudnn_128x64_ldg8_relu_exp_stages_64x4_medium_nhwc_tn_v1 Tactic: 1832046141070096030
[03/24/2023-12:56:56] [V] [TRT] Tactic: 1832046141070096030 Time: 0.070784
[03/24/2023-12:56:56] [V] [TRT] Conv_46 + Relu_47 Set Tactic Name: ampere_h16816cudnn_128x64_sliced1x2_ldg8_relu_exp_stages_64x3_small_nhwc_tn_v1 Tactic: 1838082074606840426
[03/24/2023-12:56:56] [V] [TRT] Tactic: 1838082074606840426 Time: 0.064128
[03/24/2023-12:56:56] [V] [TRT] Conv_46 + Relu_47 Set Tactic Name: ampere_h16816cudnn_64x64_sliced1x2_ldg8_relu_exp_stages_64x5_small_nhwc_tn_v1 Tactic: 1899296423087490472
[03/24/2023-12:56:56] [V] [TRT] Tactic: 1899296423087490472 Time: 0.082688
[03/24/2023-12:56:56] [V] [TRT] Conv_46 + Relu_47 Set Tactic Name: sm75_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x32x32_stage1_warpsize4x1x1_g1_tensor16x8x8 Tactic: 1948263663414159978
[03/24/2023-12:56:56] [V] [TRT] Tactic: 1948263663414159978 Time: 0.11648
[03/24/2023-12:56:56] [V] [TRT] Conv_46 + Relu_47 Set Tactic Name: sm75_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x256x64_stage1_warpsize1x4x2_g1_tensor16x8x8 Tactic: 2027733232253711640
[03/24/2023-12:56:56] [V] [TRT] Tactic: 2027733232253711640 Time: 0.093952
[03/24/2023-12:56:56] [V] [TRT] Conv_46 + Relu_47 Set Tactic Name: sm75_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x64x32_stage1_warpsize2x2x1_g1_tensor16x8x8_t1r3s3 Tactic: 2154731107061273008
[03/24/2023-12:56:56] [V] [TRT] Tactic: 2154731107061273008 Time: 0.091648
[03/24/2023-12:56:56] [V] [TRT] Conv_46 + Relu_47 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x64x64_stage3_warpsize2x2x1_g1_tensor16x8x16 Tactic: 2428167804343994714
[03/24/2023-12:56:56] [V] [TRT] Tactic: 2428167804343994714 Time: 0.07104
[03/24/2023-12:56:56] [V] [TRT] Conv_46 + Relu_47 Set Tactic Name: ampere_h16816cudnn_128x128_ldg8_relu_exp_medium_nhwc_tn_v1 Tactic: 2541579301352125276
[03/24/2023-12:56:56] [V] [TRT] Tactic: 2541579301352125276 Time: 0.072704
[03/24/2023-12:56:56] [V] [TRT] Conv_46 + Relu_47 Set Tactic Name: ampere_h16816cudnn_64x64_sliced1x2_ldg8_relu_exp_stages_64x6_small_nhwc_tn_v1 Tactic: 2657157263811141609
[03/24/2023-12:56:56] [V] [TRT] Tactic: 2657157263811141609 Time: 0.072704
[03/24/2023-12:56:56] [V] [TRT] Conv_46 + Relu_47 Set Tactic Name: ampere_h16816cudnn_64x128_sliced1x2_ldg8_relu_exp_stages_64x4_large_nhwc_tn_v1 Tactic: 2819719497590964443
[03/24/2023-12:56:56] [V] [TRT] Tactic: 2819719497590964443 Time: 0.06848
[03/24/2023-12:56:56] [V] [TRT] Conv_46 + Relu_47 Set Tactic Name: ampere_h16816cudnn_128x64_sliced1x2_ldg8_relu_exp_stages_64x3_medium_nhwc_tn_v1 Tactic: 2968605903460894194
[03/24/2023-12:56:56] [V] [TRT] Tactic: 2968605903460894194 Time: 0.065024
[03/24/2023-12:56:56] [V] [TRT] Conv_46 + Relu_47 Set Tactic Name: ampere_h16816cudnn_128x128_ldg8_relu_exp_large_nhwc_tn_v1 Tactic: 2986078304285316765
[03/24/2023-12:56:56] [V] [TRT] Tactic: 2986078304285316765 Time: 0.073728
[03/24/2023-12:56:56] [V] [TRT] Conv_46 + Relu_47 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x256x64_stage3_warpsize1x4x1_g1_tensor16x8x16 Tactic: 3016308193087082166
[03/24/2023-12:56:56] [V] [TRT] Tactic: 3016308193087082166 Time: 0.07744
[03/24/2023-12:56:56] [V] [TRT] Conv_46 + Relu_47 Set Tactic Name: ampere_h16816cudnn_256x64_ldg8_relu_exp_stages_64x3_large_nhwc_tn_v1 Tactic: 3221382575080507859
[03/24/2023-12:56:56] [V] [TRT] Tactic: 3221382575080507859 Time: 0.073088
[03/24/2023-12:56:56] [V] [TRT] Conv_46 + Relu_47 Set Tactic Name: ampere_h16816cudnn_128x128_ldg8_relu_exp_stages_64x3_medium_nhwc_tn_v1 Tactic: 3362537467505018070
[03/24/2023-12:56:56] [V] [TRT] Tactic: 3362537467505018070 Time: 0.072576
[03/24/2023-12:56:56] [V] [TRT] Conv_46 + Relu_47 Set Tactic Name: sm75_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x64x32_stage1_warpsize4x1x1_g1_tensor16x8x8_t1r3s3 Tactic: 3464689803495983377
[03/24/2023-12:56:56] [V] [TRT] Tactic: 3464689803495983377 Time: 0.096
[03/24/2023-12:56:56] [V] [TRT] Conv_46 + Relu_47 Set Tactic Name: ampere_h1688cudnn_256x128_ldg8_relu_exp_medium_nhwc_tn_v1 Tactic: 3513075359009385578
[03/24/2023-12:56:56] [V] [TRT] Tactic: 3513075359009385578 Time: 0.086016
[03/24/2023-12:56:56] [V] [TRT] Conv_46 + Relu_47 Set Tactic Name: ampere_h16816cudnn_128x64_ldg8_relu_exp_stages_64x4_large_nhwc_tn_v1 Tactic: 3573559043797674382
[03/24/2023-12:56:56] [V] [TRT] Tactic: 3573559043797674382 Time: 0.072448
[03/24/2023-12:56:56] [V] [TRT] Conv_46 + Relu_47 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x64x64_stage4_warpsize2x2x1_g1_tensor16x8x16_t1r3s3 Tactic: 3591970081995419777
[03/24/2023-12:56:56] [V] [TRT] Tactic: 3591970081995419777 Time: 0.084608
[03/24/2023-12:56:56] [V] [TRT] Conv_46 + Relu_47 Set Tactic Name: sm75_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x128x32_stage1_warpsize2x2x1_g1_tensor16x8x8_t1r3s3 Tactic: 3636831327753843771
[03/24/2023-12:56:56] [V] [TRT] Tactic: 3636831327753843771 Time: 0.084864
[03/24/2023-12:56:56] [V] [TRT] Conv_46 + Relu_47 Set Tactic Name: ampere_h1688cudnn_128x128_ldg8_relu_exp_small_nhwc_tn_v1 Tactic: 3704534001553878387
[03/24/2023-12:56:56] [V] [TRT] Tactic: 3704534001553878387 Time: 0.08192
[03/24/2023-12:56:56] [V] [TRT] Conv_46 + Relu_47 Set Tactic Name: ampere_h16816cudnn_64x128_ldg8_relu_exp_stages_64x4_small_nhwc_tn_v1 Tactic: 4278315135102886928
[03/24/2023-12:56:56] [V] [TRT] Tactic: 4278315135102886928 Time: 0.0672
[03/24/2023-12:56:56] [V] [TRT] Conv_46 + Relu_47 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x32x32_stage4_warpsize4x1x1_g1_tensor16x8x16_t1r3s3 Tactic: 4503233883285355107
[03/24/2023-12:56:56] [V] [TRT] Tactic: 4503233883285355107 Time: 0.096384
[03/24/2023-12:56:56] [V] [TRT] Conv_46 + Relu_47 Set Tactic Name: ampere_h16816cudnn_256x64_ldg8_relu_exp_stages_64x3_medium_nhwc_tn_v1 Tactic: 4540505769798915372
[03/24/2023-12:56:56] [V] [TRT] Tactic: 4540505769798915372 Time: 0.07296
[03/24/2023-12:56:56] [V] [TRT] Conv_46 + Relu_47 Set Tactic Name: ampere_h16816cudnn_256x64_sliced1x2_ldg8_relu_exp_small_nhwc_tn_v1 Tactic: 4802447371470387646
[03/24/2023-12:56:56] [V] [TRT] Tactic: 4802447371470387646 Time: 0.085376
[03/24/2023-12:56:56] [V] [TRT] Conv_46 + Relu_47 Set Tactic Name: ampere_h16816cudnn_256x128_ldg8_relu_exp_small_nhwc_tn_v1 Tactic: 5059676457552313631
[03/24/2023-12:56:56] [V] [TRT] Tactic: 5059676457552313631 Time: 0.06848
[03/24/2023-12:56:56] [V] [TRT] Conv_46 + Relu_47 Set Tactic Name: sm75_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x128x64_stage1_warpsize2x2x1_g1_tensor16x8x8_t1r3s3 Tactic: 5263029549013613567
[03/24/2023-12:56:56] [V] [TRT] Tactic: 5263029549013613567 Time: 0.079872
[03/24/2023-12:56:56] [V] [TRT] Conv_46 + Relu_47 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x64x64_stage4_warpsize2x2x1_g1_tensor16x8x16 Tactic: 5368829646735632944
[03/24/2023-12:56:56] [V] [TRT] Tactic: 5368829646735632944 Time: 0.084608
[03/24/2023-12:56:56] [V] [TRT] Conv_46 + Relu_47 Set Tactic Name: ampere_h1688cudnn_256x64_sliced1x2_ldg8_relu_exp_small_nhwc_tn_v1 Tactic: 5398999388616959893
[03/24/2023-12:56:56] [V] [TRT] Tactic: 5398999388616959893 Time: 0.093184
[03/24/2023-12:56:56] [V] [TRT] Conv_46 + Relu_47 Set Tactic Name: sm75_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x256x32_stage1_warpsize2x4x1_g1_tensor16x8x8_t1r3s3 Tactic: 5506334059535811602
[03/24/2023-12:56:56] [V] [TRT] Tactic: 5506334059535811602 Time: 0.078976
[03/24/2023-12:56:56] [V] [TRT] Conv_46 + Relu_47 Set Tactic Name: ampere_h16816cudnn_64x128_sliced1x2_ldg8_relu_exp_stages_64x3_large_nhwc_tn_v1 Tactic: 5746691132547383910
[03/24/2023-12:56:56] [V] [TRT] Tactic: 5746691132547383910 Time: 0.067072
[03/24/2023-12:56:56] [V] [TRT] Conv_46 + Relu_47 Set Tactic Name: ampere_h16816cudnn_256x64_ldg8_relu_exp_large_nhwc_tn_v1 Tactic: 5770170567977052602
[03/24/2023-12:56:56] [V] [TRT] Tactic: 5770170567977052602 Time: 0.087296
[03/24/2023-12:56:56] [V] [TRT] Conv_46 + Relu_47 Set Tactic Name: sm75_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x32x64_stage1_warpsize2x1x2_g1_tensor16x8x8_t1r3s3 Tactic: 5932046018238429951
[03/24/2023-12:56:56] [V] [TRT] Tactic: 5932046018238429951 Time: 0.10432
[03/24/2023-12:56:56] [V] [TRT] Conv_46 + Relu_47 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x64x32_stage3_warpsize4x1x1_g1_tensor16x8x16_t1r3s3 Tactic: 5953552212833506549
[03/24/2023-12:56:56] [V] [TRT] Tactic: 5953552212833506549 Time: 0.068352
[03/24/2023-12:56:56] [V] [TRT] Conv_46 + Relu_47 Set Tactic Name: ampere_h16816cudnn_64x128_ldg8_relu_exp_stages_64x3_small_nhwc_tn_v1 Tactic: 6034364043891107501
[03/24/2023-12:56:56] [V] [TRT] Tactic: 6034364043891107501 Time: 0.068864
[03/24/2023-12:56:56] [V] [TRT] Conv_46 + Relu_47 Set Tactic Name: ampere_h16816cudnn_64x64_ldg8_relu_exp_stages_64x5_large_nhwc_tn_v1 Tactic: 6074229447555668232
[03/24/2023-12:56:56] [V] [TRT] Tactic: 6074229447555668232 Time: 0.091136
[03/24/2023-12:56:56] [V] [TRT] Conv_46 + Relu_47 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x64x64_stage3_warpsize2x2x1_g1_tensor16x8x16 Tactic: 6154447660803990543
[03/24/2023-12:56:56] [V] [TRT] Tactic: 6154447660803990543 Time: 0.073088
[03/24/2023-12:56:56] [V] [TRT] Conv_46 + Relu_47 Set Tactic Name: sm75_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x32x64_stage1_warpsize2x1x2_g1_tensor16x8x8 Tactic: 6195603576432354734
[03/24/2023-12:56:56] [V] [TRT] Tactic: 6195603576432354734 Time: 0.1056
[03/24/2023-12:56:56] [V] [TRT] Conv_46 + Relu_47 Set Tactic Name: sm75_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x32x32_stage1_warpsize4x1x1_g1_tensor16x8x8_t1r3s3 Tactic: 6252808259936499253
[03/24/2023-12:56:56] [V] [TRT] Tactic: 6252808259936499253 Time: 0.11584
[03/24/2023-12:56:56] [V] [TRT] Conv_46 + Relu_47 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x128x64_stage3_warpsize2x2x1_g1_tensor16x8x16 Tactic: 6325769668000961702
[03/24/2023-12:56:56] [V] [TRT] Tactic: 6325769668000961702 Time: 0.072448
[03/24/2023-12:56:56] [V] [TRT] Conv_46 + Relu_47 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x32x64_stage5_warpsize2x2x1_g1_tensor16x8x16 Tactic: 6350273239113254096
[03/24/2023-12:56:56] [V] [TRT] Tactic: 6350273239113254096 Time: 0.112768
[03/24/2023-12:56:56] [V] [TRT] Conv_46 + Relu_47 Set Tactic Name: ampere_h16816cudnn_128x128_ldg8_relu_exp_stages_64x3_small_nhwc_tn_v1 Tactic: 6377497238381488891
[03/24/2023-12:56:56] [V] [TRT] Tactic: 6377497238381488891 Time: 0.072832
[03/24/2023-12:56:56] [V] [TRT] Conv_46 + Relu_47 Set Tactic Name: sm75_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x64x64_stage1_warpsize2x2x1_g1_tensor16x8x8 Tactic: 6408235920257988861
[03/24/2023-12:56:56] [V] [TRT] Tactic: 6408235920257988861 Time: 0.086016
[03/24/2023-12:56:56] [V] [TRT] Conv_46 + Relu_47 Set Tactic Name: ampere_h16816cudnn_128x64_ldg8_relu_exp_stages_64x3_large_nhwc_tn_v1 Tactic: 6446388116965632819
[03/24/2023-12:56:56] [V] [TRT] Tactic: 6446388116965632819 Time: 0.069248
[03/24/2023-12:56:56] [V] [TRT] Conv_46 + Relu_47 Set Tactic Name: ampere_h16816cudnn_128x64_sliced1x2_ldg8_relu_exp_stages_64x4_medium_nhwc_tn_v1 Tactic: 6468794451065529747
[03/24/2023-12:56:56] [V] [TRT] Tactic: 6468794451065529747 Time: 0.067328
[03/24/2023-12:56:56] [V] [TRT] Conv_46 + Relu_47 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x128x64_stage3_warpsize4x2x1_g1_tensor16x8x16 Tactic: 6509152032538119080
[03/24/2023-12:56:56] [V] [TRT] Tactic: 6509152032538119080 Time: 0.06784
[03/24/2023-12:56:56] [V] [TRT] Conv_46 + Relu_47 Set Tactic Name: ampere_h1688cudnn_256x128_ldg8_relu_exp_large_nhwc_tn_v1 Tactic: 6642277870194067185
[03/24/2023-12:56:56] [V] [TRT] Tactic: 6642277870194067185 Time: 0.086784
[03/24/2023-12:56:56] [V] [TRT] Conv_46 + Relu_47 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x256x64_stage3_warpsize1x4x1_g1_tensor16x8x16 Tactic: 6703181542003057635
[03/24/2023-12:56:56] [V] [TRT] Tactic: 6703181542003057635 Time: 0.0768
[03/24/2023-12:56:56] [V] [TRT] Conv_46 + Relu_47 Set Tactic Name: ampere_h16816cudnn_64x64_ldg8_relu_exp_stages_64x5_medium_nhwc_tn_v1 Tactic: 6859477213531075460
[03/24/2023-12:56:56] [V] [TRT] Tactic: 6859477213531075460 Time: 0.090752
[03/24/2023-12:56:56] [V] [TRT] Conv_46 + Relu_47 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x128x32_stage4_warpsize2x2x1_g1_tensor16x8x16_t1r3s3 Tactic: 6972489290272968208
[03/24/2023-12:56:56] [V] [TRT] Tactic: 6972489290272968208 Time: 0.067584
[03/24/2023-12:56:56] [V] [TRT] Conv_46 + Relu_47 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x128x32_stage3_warpsize4x2x1_g1_tensor16x8x16 Tactic: 6979044990896381511
[03/24/2023-12:56:56] [V] [TRT] Tactic: 6979044990896381511 Time: 0.06656
[03/24/2023-12:56:56] [V] [TRT] Conv_46 + Relu_47 Set Tactic Name: ampere_h1688cudnn_256x64_ldg8_relu_exp_medium_nhwc_tn_v1 Tactic: 7216571380637776659
[03/24/2023-12:56:56] [V] [TRT] Tactic: 7216571380637776659 Time: 0.107648
[03/24/2023-12:56:56] [V] [TRT] Conv_46 + Relu_47 Set Tactic Name: ampere_h16816cudnn_128x64_ldg8_relu_exp_stages_64x3_medium_nhwc_tn_v1 Tactic: 7609923741161019135
[03/24/2023-12:56:56] [V] [TRT] Tactic: 7609923741161019135 Time: 0.069376
[03/24/2023-12:56:56] [V] [TRT] Conv_46 + Relu_47 Set Tactic Name: sm75_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x64x32_stage1_warpsize2x2x1_g1_tensor16x8x8 Tactic: 7612687199567064086
[03/24/2023-12:56:56] [V] [TRT] Tactic: 7612687199567064086 Time: 0.09728
[03/24/2023-12:56:56] [V] [TRT] Conv_46 + Relu_47 Set Tactic Name: ampere_h16816cudnn_64x64_ldg8_relu_exp_stages_64x6_large_nhwc_tn_v1 Tactic: 7705739241028240201
[03/24/2023-12:56:56] [V] [TRT] Tactic: 7705739241028240201 Time: 0.086272
[03/24/2023-12:56:56] [V] [TRT] Conv_46 + Relu_47 Set Tactic Name: sm75_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x128x32_stage1_warpsize2x2x1_g1_tensor16x8x8 Tactic: 7729555994715864793
[03/24/2023-12:56:56] [V] [TRT] Tactic: 7729555994715864793 Time: 0.094848
[03/24/2023-12:56:56] [V] [TRT] Conv_46 + Relu_47 Set Tactic Name: sm75_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x64x64_stage1_warpsize2x2x1_g1_tensor16x8x8_t1r3s3 Tactic: 7849296535223586261
[03/24/2023-12:56:56] [V] [TRT] Tactic: 7849296535223586261 Time: 0.085248
[03/24/2023-12:56:56] [V] [TRT] Conv_46 + Relu_47 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x256x32_stage3_warpsize2x4x1_g1_tensor16x8x16 Tactic: 8072087735545283117
[03/24/2023-12:56:56] [V] [TRT] Tactic: 8072087735545283117 Time: 0.067584
[03/24/2023-12:56:56] [V] [TRT] Conv_46 + Relu_47 Set Tactic Name: ampere_h16816cudnn_64x64_sliced1x2_ldg8_relu_exp_stages_64x5_medium_nhwc_tn_v1 Tactic: 8101703987960976805
[03/24/2023-12:56:56] [V] [TRT] Tactic: 8101703987960976805 Time: 0.077312
[03/24/2023-12:56:56] [V] [TRT] Conv_46 + Relu_47 Set Tactic Name: ampere_h16816cudnn_128x64_sliced1x2_ldg8_relu_exp_stages_64x4_small_nhwc_tn_v1 Tactic: 8170606396342855895
[03/24/2023-12:56:56] [V] [TRT] Tactic: 8170606396342855895 Time: 0.064384
[03/24/2023-12:56:56] [V] [TRT] Conv_46 + Relu_47 Set Tactic Name: sm75_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x32x64_stage1_warpsize2x1x2_g1_tensor16x8x8 Tactic: 8455608235315878803
[03/24/2023-12:56:56] [V] [TRT] Tactic: 8455608235315878803 Time: 0.114432
[03/24/2023-12:56:56] [V] [TRT] Conv_46 + Relu_47 Set Tactic Name: sm75_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x64x64_stage1_warpsize2x2x1_g1_tensor16x8x8 Tactic: 8668812313058150080
[03/24/2023-12:56:56] [V] [TRT] Tactic: 8668812313058150080 Time: 0.09088
[03/24/2023-12:56:56] [V] [TRT] Conv_46 + Relu_47 Set Tactic Name: ampere_h1688cudnn_256x64_ldg8_relu_exp_small_nhwc_tn_v1 Tactic: 8839784824303350101
[03/24/2023-12:56:56] [V] [TRT] Tactic: 8839784824303350101 Time: 0.098432
[03/24/2023-12:56:56] [V] [TRT] Conv_46 + Relu_47 Set Tactic Name: ampere_h16816cudnn_64x64_sliced1x2_ldg8_relu_exp_stages_64x5_large_nhwc_tn_v1 Tactic: -9217371357561775773
[03/24/2023-12:56:56] [V] [TRT] Tactic: -9217371357561775773 Time: 0.07616
[03/24/2023-12:56:56] [V] [TRT] Conv_46 + Relu_47 Set Tactic Name: ampere_h16816cudnn_256x64_sliced1x2_ldg8_relu_exp_medium_nhwc_tn_v1 Tactic: -9009272790678027912
[03/24/2023-12:56:56] [V] [TRT] Tactic: -9009272790678027912 Time: 0.096384
[03/24/2023-12:56:56] [V] [TRT] Conv_46 + Relu_47 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x32x32_stage4_warpsize4x1x1_g1_tensor16x8x16 Tactic: -8985224497679592364
[03/24/2023-12:56:56] [V] [TRT] Tactic: -8985224497679592364 Time: 0.093824
[03/24/2023-12:56:56] [V] [TRT] Conv_46 + Relu_47 Set Tactic Name: ampere_h16816cudnn_128x64_sliced1x2_ldg8_relu_exp_stages_64x3_large_nhwc_tn_v1 Tactic: -8949544755481315679
[03/24/2023-12:56:56] [V] [TRT] Tactic: -8949544755481315679 Time: 0.065792
[03/24/2023-12:56:56] [V] [TRT] Conv_46 + Relu_47 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x64x64_stage3_warpsize4x1x1_g1_tensor16x8x16_t1r3s3 Tactic: -8867999442759527766
[03/24/2023-12:56:57] [V] [TRT] Tactic: -8867999442759527766 Time: 0.07744
[03/24/2023-12:56:57] [V] [TRT] Conv_46 + Relu_47 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x128x64_stage3_warpsize2x2x1_g1_tensor16x8x16 Tactic: -8759929675070720385
[03/24/2023-12:56:57] [V] [TRT] Tactic: -8759929675070720385 Time: 0.07168
[03/24/2023-12:56:57] [V] [TRT] Conv_46 + Relu_47 Set Tactic Name: ampere_h16816cudnn_64x64_ldg8_relu_exp_stages_64x6_medium_nhwc_tn_v1 Tactic: -8604374562669615024
[03/24/2023-12:56:57] [V] [TRT] Tactic: -8604374562669615024 Time: 0.084096
[03/24/2023-12:56:57] [V] [TRT] Conv_46 + Relu_47 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x128x64_stage3_warpsize4x2x1_g1_tensor16x8x16 Tactic: -8362347876645295759
[03/24/2023-12:56:57] [V] [TRT] Tactic: -8362347876645295759 Time: 0.067584
[03/24/2023-12:56:57] [V] [TRT] Conv_46 + Relu_47 Set Tactic Name: sm75_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x128x32_stage1_warpsize4x2x1_g1_tensor16x8x8 Tactic: -8254009616492665198
[03/24/2023-12:56:57] [V] [TRT] Tactic: -8254009616492665198 Time: 0.079872
[03/24/2023-12:56:57] [V] [TRT] Conv_46 + Relu_47 Set Tactic Name: ampere_h16816cudnn_256x128_ldg8_relu_exp_stages_64x3_large_nhwc_tn_v1 Tactic: -7757610000269494813
[03/24/2023-12:56:57] [V] [TRT] Tactic: -7757610000269494813 Time: 0.06848
[03/24/2023-12:56:57] [V] [TRT] Conv_46 + Relu_47 Set Tactic Name: sm75_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x128x32_stage1_warpsize4x2x1_g1_tensor16x8x8 Tactic: -7615325597099025933
[03/24/2023-12:56:57] [V] [TRT] Tactic: -7615325597099025933 Time: 0.083712
[03/24/2023-12:56:57] [V] [TRT] Conv_46 + Relu_47 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x64x64_stage3_warpsize4x1x1_g1_tensor16x8x16 Tactic: -6917689122519989488
[03/24/2023-12:56:57] [V] [TRT] Tactic: -6917689122519989488 Time: 0.08064
[03/24/2023-12:56:57] [V] [TRT] Conv_46 + Relu_47 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x32x64_stage5_warpsize2x2x1_g1_tensor16x8x16_t1r3s3 Tactic: -6902925267326201166
[03/24/2023-12:56:57] [V] [TRT] Tactic: -6902925267326201166 Time: 0.111232
[03/24/2023-12:56:57] [V] [TRT] Conv_46 + Relu_47 Set Tactic Name: ampere_h16816cudnn_64x128_ldg8_relu_exp_stages_64x4_large_nhwc_tn_v1 Tactic: -6840588038605932325
[03/24/2023-12:56:57] [V] [TRT] Tactic: -6840588038605932325 Time: 0.067584
[03/24/2023-12:56:57] [V] [TRT] Conv_46 + Relu_47 Set Tactic Name: sm75_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x32x32_stage1_warpsize4x1x1_g1_tensor16x8x8 Tactic: -6828337260021572283
[03/24/2023-12:56:57] [V] [TRT] Tactic: -6828337260021572283 Time: 0.123008
[03/24/2023-12:56:57] [V] [TRT] Conv_46 + Relu_47 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x256x32_stage3_warpsize2x4x1_g1_tensor16x8x16 Tactic: -6799856376604253964
[03/24/2023-12:56:57] [V] [TRT] Tactic: -6799856376604253964 Time: 0.067584
[03/24/2023-12:56:57] [V] [TRT] Conv_46 + Relu_47 Set Tactic Name: sm75_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x32x32_stage1_warpsize4x1x1_g1_tensor16x8x8 Tactic: -6711815420995272523
[03/24/2023-12:56:57] [V] [TRT] Tactic: -6711815420995272523 Time: 0.12736
[03/24/2023-12:56:57] [V] [TRT] Conv_46 + Relu_47 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x32x32_stage4_warpsize4x1x1_g1_tensor16x8x16_t1r3s3 Tactic: -6625722781282978136
[03/24/2023-12:56:57] [V] [TRT] Tactic: -6625722781282978136 Time: 0.114048
[03/24/2023-12:56:57] [V] [TRT] Conv_46 + Relu_47 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x64x32_stage3_warpsize4x1x1_g1_tensor16x8x16 Tactic: -6525498856028268801
[03/24/2023-12:56:57] [V] [TRT] Tactic: -6525498856028268801 Time: 0.076032
[03/24/2023-12:56:57] [V] [TRT] Conv_46 + Relu_47 Set Tactic Name: sm75_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x256x64_stage1_warpsize1x4x2_g1_tensor16x8x8 Tactic: -6489479581011009593
[03/24/2023-12:56:57] [V] [TRT] Tactic: -6489479581011009593 Time: 0.092544
[03/24/2023-12:56:57] [V] [TRT] Conv_46 + Relu_47 Set Tactic Name: ampere_h16816cudnn_64x64_sliced1x2_ldg8_relu_exp_stages_64x6_medium_nhwc_tn_v1 Tactic: -6356316196810535311
[03/24/2023-12:56:57] [V] [TRT] Tactic: -6356316196810535311 Time: 0.079872
[03/24/2023-12:56:57] [V] [TRT] Conv_46 + Relu_47 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x32x32_stage4_warpsize4x1x1_g1_tensor16x8x16 Tactic: -6324345858751792783
[03/24/2023-12:56:57] [V] [TRT] Tactic: -6324345858751792783 Time: 0.114432
[03/24/2023-12:56:57] [V] [TRT] Conv_46 + Relu_47 Set Tactic Name: sm75_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x256x64_stage1_warpsize1x4x2_g1_tensor16x8x8_t1r3s3 Tactic: -6320761427625651496
[03/24/2023-12:56:57] [V] [TRT] Tactic: -6320761427625651496 Time: 0.091904
[03/24/2023-12:56:57] [V] [TRT] Conv_46 + Relu_47 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x256x32_stage3_warpsize2x4x1_g1_tensor16x8x16_t1r3s3 Tactic: -6262400699544994312
[03/24/2023-12:56:57] [V] [TRT] Tactic: -6262400699544994312 Time: 0.06656
[03/24/2023-12:56:57] [V] [TRT] Conv_46 + Relu_47 Set Tactic Name: ampere_h1688cudnn_128x128_ldg8_relu_exp_large_nhwc_tn_v1 Tactic: -6257787336162086472
[03/24/2023-12:56:57] [V] [TRT] Tactic: -6257787336162086472 Time: 0.086656
[03/24/2023-12:56:57] [V] [TRT] Conv_46 + Relu_47 Set Tactic Name: sm75_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x128x64_stage1_warpsize2x2x1_g1_tensor16x8x8 Tactic: -6080892721161662420
[03/24/2023-12:56:57] [V] [TRT] Tactic: -6080892721161662420 Time: 0.08064
[03/24/2023-12:56:57] [V] [TRT] Conv_46 + Relu_47 Set Tactic Name: ampere_h16816cudnn_128x64_ldg8_relu_exp_stages_64x4_small_nhwc_tn_v1 Tactic: -6063766379489217211
[03/24/2023-12:56:57] [V] [TRT] Tactic: -6063766379489217211 Time: 0.069632
[03/24/2023-12:56:57] [V] [TRT] Conv_46 + Relu_47 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x128x32_stage5_warpsize2x2x1_g1_tensor16x8x16 Tactic: -5777580938094193096
[03/24/2023-12:56:57] [V] [TRT] Tactic: -5777580938094193096 Time: 0.068224
[03/24/2023-12:56:57] [V] [TRT] Conv_46 + Relu_47 Set Tactic Name: sm75_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x128x64_stage1_warpsize2x2x1_g1_tensor16x8x8 Tactic: -5710735840878760115
[03/24/2023-12:56:57] [V] [TRT] Tactic: -5710735840878760115 Time: 0.084608
[03/24/2023-12:56:57] [V] [TRT] Conv_46 + Relu_47 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x128x32_stage3_warpsize4x2x1_g1_tensor16x8x16 Tactic: -5657273398217409378
[03/24/2023-12:56:57] [V] [TRT] Tactic: -5657273398217409378 Time: 0.06848
[03/24/2023-12:56:57] [V] [TRT] Conv_46 + Relu_47 Set Tactic Name: sm75_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x128x32_stage1_warpsize2x2x1_g1_tensor16x8x8_t1r3s3 Tactic: -5546257196173962281
[03/24/2023-12:56:57] [V] [TRT] Tactic: -5546257196173962281 Time: 0.092288
[03/24/2023-12:56:57] [V] [TRT] Conv_46 + Relu_47 Set Tactic Name: ampere_h16816cudnn_128x128_ldg8_relu_exp_small_nhwc_tn_v1 Tactic: -5530886555766748586
[03/24/2023-12:56:57] [V] [TRT] Tactic: -5530886555766748586 Time: 0.071936
[03/24/2023-12:56:57] [V] [TRT] Conv_46 + Relu_47 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x64x32_stage5_warpsize2x2x1_g1_tensor16x8x16_t1r3s3 Tactic: -5422685219138380548
[03/24/2023-12:56:57] [V] [TRT] Tactic: -5422685219138380548 Time: 0.079104
[03/24/2023-12:56:57] [V] [TRT] Conv_46 + Relu_47 Set Tactic Name: ampere_h16816cudnn_256x64_ldg8_relu_exp_stages_64x3_small_nhwc_tn_v1 Tactic: -5261787675443473128
[03/24/2023-12:56:57] [V] [TRT] Tactic: -5261787675443473128 Time: 0.072704
[03/24/2023-12:56:57] [V] [TRT] Conv_46 + Relu_47 Set Tactic Name: sm75_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x64x32_stage1_warpsize4x1x1_g1_tensor16x8x8 Tactic: -5198219374380660379
[03/24/2023-12:56:57] [V] [TRT] Tactic: -5198219374380660379 Time: 0.095872
[03/24/2023-12:56:57] [V] [TRT] Conv_46 + Relu_47 Set Tactic Name: ampere_h16816cudnn_64x128_sliced1x2_ldg8_relu_exp_stages_64x3_medium_nhwc_tn_v1 Tactic: -5161596964442251102
[03/24/2023-12:56:57] [V] [TRT] Tactic: -5161596964442251102 Time: 0.066432
[03/24/2023-12:56:57] [V] [TRT] Conv_46 + Relu_47 Set Tactic Name: ampere_h16816cudnn_64x128_ldg8_relu_exp_stages_64x3_medium_nhwc_tn_v1 Tactic: -5127240325355316006
[03/24/2023-12:56:57] [V] [TRT] Tactic: -5127240325355316006 Time: 0.06848
[03/24/2023-12:56:57] [V] [TRT] Conv_46 + Relu_47 Set Tactic Name: ampere_h16816cudnn_256x128_ldg8_relu_exp_stages_64x3_medium_nhwc_tn_v1 Tactic: -5109582882231362997
[03/24/2023-12:56:57] [V] [TRT] Tactic: -5109582882231362997 Time: 0.068352
[03/24/2023-12:56:57] [V] [TRT] Conv_46 + Relu_47 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x64x32_stage5_warpsize2x2x1_g1_tensor16x8x16 Tactic: -4825567853927730435
[03/24/2023-12:56:57] [V] [TRT] Tactic: -4825567853927730435 Time: 0.0832
[03/24/2023-12:56:57] [V] [TRT] Conv_46 + Relu_47 Set Tactic Name: ampere_h16816cudnn_64x128_sliced1x2_ldg8_relu_exp_stages_64x4_small_nhwc_tn_v1 Tactic: -4796511246675321840
[03/24/2023-12:56:57] [V] [TRT] Tactic: -4796511246675321840 Time: 0.065536
[03/24/2023-12:56:57] [V] [TRT] Conv_46 + Relu_47 Set Tactic Name: ampere_h16816cudnn_64x64_sliced1x2_ldg8_relu_exp_stages_64x6_large_nhwc_tn_v1 Tactic: -4706569565442112734
[03/24/2023-12:56:57] [V] [TRT] Tactic: -4706569565442112734 Time: 0.078848
[03/24/2023-12:56:57] [V] [TRT] Conv_46 + Relu_47 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x128x64_stage3_warpsize2x2x1_g1_tensor16x8x16_t1r3s3 Tactic: -4566599693570369588
[03/24/2023-12:56:57] [V] [TRT] Tactic: -4566599693570369588 Time: 0.072448
[03/24/2023-12:56:57] [V] [TRT] Conv_46 + Relu_47 Set Tactic Name: ampere_h16816cudnn_128x128_ldg8_relu_exp_stages_64x3_large_nhwc_tn_v1 Tactic: -4409144516525410768
[03/24/2023-12:56:57] [V] [TRT] Tactic: -4409144516525410768 Time: 0.07232
[03/24/2023-12:56:57] [V] [TRT] Conv_46 + Relu_47 Set Tactic Name: ampere_h16816cudnn_128x64_ldg8_relu_exp_stages_64x3_small_nhwc_tn_v1 Tactic: -4379519430184503304
[03/24/2023-12:56:57] [V] [TRT] Tactic: -4379519430184503304 Time: 0.068096
[03/24/2023-12:56:57] [V] [TRT] Conv_46 + Relu_47 Set Tactic Name: ampere_h1688cudnn_256x128_ldg8_relu_exp_small_nhwc_tn_v1 Tactic: -4152066959007262150
[03/24/2023-12:56:57] [V] [TRT] Tactic: -4152066959007262150 Time: 0.07872
[03/24/2023-12:56:57] [V] [TRT] Conv_46 + Relu_47 Set Tactic Name: ampere_h16816cudnn_64x128_ldg8_relu_exp_stages_64x4_medium_nhwc_tn_v1 Tactic: -4021926646879732549
[03/24/2023-12:56:57] [V] [TRT] Tactic: -4021926646879732549 Time: 0.066816
[03/24/2023-12:56:57] [V] [TRT] Conv_46 + Relu_47 Set Tactic Name: ampere_h16816cudnn_64x128_sliced1x2_ldg8_relu_exp_stages_64x4_medium_nhwc_tn_v1 Tactic: -3987638434926559037
[03/24/2023-12:56:57] [V] [TRT] Tactic: -3987638434926559037 Time: 0.064896
[03/24/2023-12:56:57] [V] [TRT] Conv_46 + Relu_47 Set Tactic Name: ampere_h1688cudnn_256x64_sliced1x2_ldg8_relu_exp_medium_nhwc_tn_v1 Tactic: -3905653247016903130
[03/24/2023-12:56:57] [V] [TRT] Tactic: -3905653247016903130 Time: 0.103296
[03/24/2023-12:56:57] [V] [TRT] Conv_46 + Relu_47 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x64x32_stage5_warpsize2x2x1_g1_tensor16x8x16 Tactic: -3903974568488493144
[03/24/2023-12:56:57] [V] [TRT] Tactic: -3903974568488493144 Time: 0.07168
[03/24/2023-12:56:57] [V] [TRT] Conv_46 + Relu_47 Set Tactic Name: ampere_h16816cudnn_64x128_ldg8_relu_exp_stages_64x3_large_nhwc_tn_v1 Tactic: -3895429239811098010
[03/24/2023-12:56:57] [V] [TRT] Tactic: -3895429239811098010 Time: 0.068992
[03/24/2023-12:56:57] [V] [TRT] Conv_46 + Relu_47 Set Tactic Name: ampere_h16816cudnn_256x64_ldg8_relu_exp_small_nhwc_tn_v1 Tactic: -3864869056275745423
[03/24/2023-12:56:57] [V] [TRT] Tactic: -3864869056275745423 Time: 0.083072
[03/24/2023-12:56:57] [V] [TRT] Conv_46 + Relu_47 Set Tactic Name: sm75_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x32x32_stage1_warpsize4x1x1_g1_tensor16x8x8_t1r3s3 Tactic: -3784342055748695733
[03/24/2023-12:56:57] [V] [TRT] Tactic: -3784342055748695733 Time: 0.112896
[03/24/2023-12:56:57] [V] [TRT] Conv_46 + Relu_47 Set Tactic Name: ampere_h16816cudnn_64x64_ldg8_relu_exp_stages_64x5_small_nhwc_tn_v1 Tactic: -3601464762214218301
[03/24/2023-12:56:57] [V] [TRT] Tactic: -3601464762214218301 Time: 0.090752
[03/24/2023-12:56:57] [V] [TRT] Conv_46 + Relu_47 Set Tactic Name: sm75_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x64x32_stage1_warpsize2x2x1_g1_tensor16x8x8 Tactic: -3425274793298557239
[03/24/2023-12:56:57] [V] [TRT] Tactic: -3425274793298557239 Time: 0.092032
[03/24/2023-12:56:57] [V] [TRT] Conv_46 + Relu_47 Set Tactic Name: ampere_h1688cudnn_256x64_sliced1x2_ldg8_relu_exp_large_nhwc_tn_v1 Tactic: -3412636942650049698
[03/24/2023-12:56:57] [V] [TRT] Tactic: -3412636942650049698 Time: 0.10432
[03/24/2023-12:56:57] [V] [TRT] Conv_46 + Relu_47 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x64x32_stage3_warpsize4x1x1_g1_tensor16x8x16 Tactic: -3338665856053412950
[03/24/2023-12:56:57] [V] [TRT] Tactic: -3338665856053412950 Time: 0.068608
[03/24/2023-12:56:57] [V] [TRT] Conv_46 + Relu_47 Set Tactic Name: sm75_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x128x32_stage1_warpsize2x2x1_g1_tensor16x8x8 Tactic: -3271955096576257018
[03/24/2023-12:56:57] [V] [TRT] Tactic: -3271955096576257018 Time: 0.093056
[03/24/2023-12:56:57] [V] [TRT] Conv_46 + Relu_47 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x128x64_stage3_warpsize4x2x1_g1_tensor16x8x16_t1r3s3 Tactic: -3243541398692466074
[03/24/2023-12:56:57] [V] [TRT] Tactic: -3243541398692466074 Time: 0.067584
[03/24/2023-12:56:57] [V] [TRT] Conv_46 + Relu_47 Set Tactic Name: ampere_h16816cudnn_64x128_sliced1x2_ldg8_relu_exp_stages_64x3_small_nhwc_tn_v1 Tactic: -3058330359340425555
[03/24/2023-12:56:57] [V] [TRT] Tactic: -3058330359340425555 Time: 0.066688
[03/24/2023-12:56:57] [V] [TRT] Conv_46 + Relu_47 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x256x64_stage3_warpsize1x4x1_g1_tensor16x8x16_t1r3s3 Tactic: -2899647483672319239
[03/24/2023-12:56:57] [V] [TRT] Tactic: -2899647483672319239 Time: 0.07616
[03/24/2023-12:56:57] [V] [TRT] Conv_46 + Relu_47 Set Tactic Name: ampere_h16816cudnn_256x64_sliced1x2_ldg8_relu_exp_large_nhwc_tn_v1 Tactic: -2816084650627734155
[03/24/2023-12:56:57] [V] [TRT] Tactic: -2816084650627734155 Time: 0.09792
[03/24/2023-12:56:57] [V] [TRT] Conv_46 + Relu_47 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x128x32_stage5_warpsize2x2x1_g1_tensor16x8x16 Tactic: -2662892962457732243
[03/24/2023-12:56:57] [V] [TRT] Tactic: -2662892962457732243 Time: 0.06656
[03/24/2023-12:56:57] [V] [TRT] Conv_46 + Relu_47 Set Tactic Name: ampere_h16816cudnn_256x128_ldg8_relu_exp_large_nhwc_tn_v1 Tactic: -2559894581585337900
[03/24/2023-12:56:57] [V] [TRT] Tactic: -2559894581585337900 Time: 0.069632
[03/24/2023-12:56:57] [V] [TRT] Conv_46 + Relu_47 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x32x32_stage4_warpsize4x1x1_g1_tensor16x8x16 Tactic: -2530740716768816092
[03/24/2023-12:56:57] [V] [TRT] Tactic: -2530740716768816092 Time: 0.092928
[03/24/2023-12:56:57] [V] [TRT] Conv_46 + Relu_47 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x128x32_stage4_warpsize2x2x1_g1_tensor16x8x16 Tactic: -2332828394978346992
[03/24/2023-12:56:57] [V] [TRT] Tactic: -2332828394978346992 Time: 0.068992
[03/24/2023-12:56:57] [V] [TRT] Conv_46 + Relu_47 Set Tactic Name: ampere_h1688cudnn_256x64_ldg8_relu_exp_large_nhwc_tn_v1 Tactic: -2241736083352441442
[03/24/2023-12:56:57] [V] [TRT] Tactic: -2241736083352441442 Time: 0.106752
[03/24/2023-12:56:57] [V] [TRT] Conv_46 + Relu_47 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x32x64_stage5_warpsize2x2x1_g1_tensor16x8x16 Tactic: -2161909437867201546
[03/24/2023-12:56:57] [V] [TRT] Tactic: -2161909437867201546 Time: 0.11136
[03/24/2023-12:56:57] [V] [TRT] Conv_46 + Relu_47 Set Tactic Name: ampere_h16816cudnn_256x64_ldg8_relu_exp_medium_nhwc_tn_v1 Tactic: -1985778916402815946
[03/24/2023-12:56:57] [V] [TRT] Tactic: -1985778916402815946 Time: 0.084992
[03/24/2023-12:56:57] [V] [TRT] Conv_46 + Relu_47 Set Tactic Name: sm75_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x256x32_stage1_warpsize2x4x1_g1_tensor16x8x8 Tactic: -1708101578041178688
[03/24/2023-12:56:57] [V] [TRT] Tactic: -1708101578041178688 Time: 0.081792
[03/24/2023-12:56:57] [V] [TRT] Conv_46 + Relu_47 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x64x64_stage3_warpsize4x1x1_g1_tensor16x8x16 Tactic: -1502788097503482299
[03/24/2023-12:56:57] [V] [TRT] Tactic: -1502788097503482299 Time: 0.077952
[03/24/2023-12:56:57] [V] [TRT] Conv_46 + Relu_47 Set Tactic Name: ampere_h16816cudnn_128x64_sliced1x2_ldg8_relu_exp_stages_64x4_large_nhwc_tn_v1 Tactic: -1500496213132463076
[03/24/2023-12:56:57] [V] [TRT] Tactic: -1500496213132463076 Time: 0.0704
[03/24/2023-12:56:57] [V] [TRT] Conv_46 + Relu_47 Set Tactic Name: ampere_h16816cudnn_64x64_ldg8_relu_exp_stages_64x6_small_nhwc_tn_v1 Tactic: -1099247066487349374
[03/24/2023-12:56:57] [V] [TRT] Tactic: -1099247066487349374 Time: 0.077824
[03/24/2023-12:56:57] [V] [TRT] Conv_46 + Relu_47 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x64x64_stage4_warpsize2x2x1_g1_tensor16x8x16 Tactic: -910286698936744682
[03/24/2023-12:56:57] [V] [TRT] Tactic: -910286698936744682 Time: 0.085888
[03/24/2023-12:56:57] [V] [TRT] Conv_46 + Relu_47 Set Tactic Name: sm75_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x256x32_stage1_warpsize2x4x1_g1_tensor16x8x8 Tactic: -907287437357565279
[03/24/2023-12:56:57] [V] [TRT] Tactic: -907287437357565279 Time: 0.08
[03/24/2023-12:56:57] [V] [TRT] Conv_46 + Relu_47 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x32x32_stage4_warpsize4x1x1_g1_tensor16x8x16 Tactic: -606726295133751039
[03/24/2023-12:56:57] [V] [TRT] Tactic: -606726295133751039 Time: 0.09216
[03/24/2023-12:56:57] [V] [TRT] Fastest Tactic: 1838082074606840426 Time: 0.064128
[03/24/2023-12:56:57] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: 1838082074606840426
[03/24/2023-12:56:57] [V] [TRT] *************** Autotuning format combination: Half(129600,1:16,1440,16) -> Half(129600,1:16,1440,16) ***************
[03/24/2023-12:56:57] [V] [TRT] --------------- Timing Runner: Conv_46 + Relu_47 (CudnnConvolution)
[03/24/2023-12:56:57] [V] [TRT] CudnnConvolution has no valid tactics for this config, skipping
[03/24/2023-12:56:57] [V] [TRT] --------------- Timing Runner: Conv_46 + Relu_47 (CaskConvolution)
[03/24/2023-12:56:57] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[03/24/2023-12:56:57] [V] [TRT] =============== Computing costs for 
[03/24/2023-12:56:57] [V] [TRT] *************** Autotuning format combination: Float(2073600,8100,90,1) -> Float(2073600,8100,90,1) ***************
[03/24/2023-12:56:57] [V] [TRT] *************** Autotuning format combination: Float(2073600,1,23040,256) -> Float(2073600,1,23040,256) ***************
[03/24/2023-12:56:57] [V] [TRT] *************** Autotuning format combination: Float(518400,1:4,5760,64) -> Float(518400,1:4,5760,64) ***************
[03/24/2023-12:56:57] [V] [TRT] *************** Autotuning format combination: Half(2073600,8100,90,1) -> Half(2073600,8100,90,1) ***************
[03/24/2023-12:56:57] [V] [TRT] *************** Autotuning format combination: Half(1036800,8100:2,90,1) -> Half(1036800,8100:2,90,1) ***************
[03/24/2023-12:56:57] [V] [TRT] *************** Autotuning format combination: Half(259200,1:8,2880,32) -> Float(2073600,8100,90,1) ***************
[03/24/2023-12:56:57] [V] [TRT] *************** Autotuning format combination: Half(259200,1:8,2880,32) -> Half(259200,1:8,2880,32) ***************
[03/24/2023-12:56:57] [V] [TRT] *************** Autotuning format combination: Half(129600,1:16,1440,16) -> Half(129600,1:16,1440,16) ***************
[03/24/2023-12:56:57] [V] [TRT] =============== Computing costs for 
[03/24/2023-12:56:57] [V] [TRT] *************** Autotuning format combination: Float(2073600,8100,90,1) -> Float(2073600,8100,90,1) ***************
[03/24/2023-12:56:57] [V] [TRT] *************** Autotuning format combination: Float(2073600,1,23040,256) -> Float(2073600,1,23040,256) ***************
[03/24/2023-12:56:57] [V] [TRT] *************** Autotuning format combination: Float(518400,1:4,5760,64) -> Float(518400,1:4,5760,64) ***************
[03/24/2023-12:56:57] [V] [TRT] *************** Autotuning format combination: Half(2073600,8100,90,1) -> Half(2073600,8100,90,1) ***************
[03/24/2023-12:56:57] [V] [TRT] *************** Autotuning format combination: Half(1036800,8100:2,90,1) -> Half(1036800,8100:2,90,1) ***************
[03/24/2023-12:56:57] [V] [TRT] *************** Autotuning format combination: Half(259200,1:8,2880,32) -> Float(2073600,8100,90,1) ***************
[03/24/2023-12:56:57] [V] [TRT] *************** Autotuning format combination: Half(259200,1:8,2880,32) -> Half(259200,1:8,2880,32) ***************
[03/24/2023-12:56:57] [V] [TRT] *************** Autotuning format combination: Half(129600,1:16,1440,16) -> Half(129600,1:16,1440,16) ***************
[03/24/2023-12:56:57] [V] [TRT] =============== Computing costs for 
[03/24/2023-12:56:57] [V] [TRT] *************** Autotuning format combination: Float(2073600,8100,90,1) -> Float(2073600,8100,90,1) ***************
[03/24/2023-12:56:57] [V] [TRT] *************** Autotuning format combination: Float(2073600,1,23040,256) -> Float(2073600,1,23040,256) ***************
[03/24/2023-12:56:57] [V] [TRT] *************** Autotuning format combination: Float(518400,1:4,5760,64) -> Float(518400,1:4,5760,64) ***************
[03/24/2023-12:56:57] [V] [TRT] *************** Autotuning format combination: Half(2073600,8100,90,1) -> Half(2073600,8100,90,1) ***************
[03/24/2023-12:56:57] [V] [TRT] *************** Autotuning format combination: Half(1036800,8100:2,90,1) -> Half(1036800,8100:2,90,1) ***************
[03/24/2023-12:56:57] [V] [TRT] *************** Autotuning format combination: Half(259200,1:8,2880,32) -> Float(2073600,8100,90,1) ***************
[03/24/2023-12:56:57] [V] [TRT] *************** Autotuning format combination: Half(259200,1:8,2880,32) -> Half(259200,1:8,2880,32) ***************
[03/24/2023-12:56:57] [V] [TRT] *************** Autotuning format combination: Half(129600,1:16,1440,16) -> Half(129600,1:16,1440,16) ***************
[03/24/2023-12:56:57] [V] [TRT] =============== Computing costs for 
[03/24/2023-12:56:57] [V] [TRT] *************** Autotuning format combination: Float(2073600,8100,90,1) -> Float(2073600,8100,90,1) ***************
[03/24/2023-12:56:57] [V] [TRT] *************** Autotuning format combination: Float(2073600,1,23040,256) -> Float(2073600,1,23040,256) ***************
[03/24/2023-12:56:57] [V] [TRT] *************** Autotuning format combination: Float(518400,1:4,5760,64) -> Float(518400,1:4,5760,64) ***************
[03/24/2023-12:56:57] [V] [TRT] *************** Autotuning format combination: Half(2073600,8100,90,1) -> Half(2073600,8100,90,1) ***************
[03/24/2023-12:56:57] [V] [TRT] *************** Autotuning format combination: Half(1036800,8100:2,90,1) -> Half(1036800,8100:2,90,1) ***************
[03/24/2023-12:56:57] [V] [TRT] *************** Autotuning format combination: Half(259200,1:8,2880,32) -> Float(2073600,8100,90,1) ***************
[03/24/2023-12:56:57] [V] [TRT] *************** Autotuning format combination: Half(259200,1:8,2880,32) -> Half(259200,1:8,2880,32) ***************
[03/24/2023-12:56:57] [V] [TRT] *************** Autotuning format combination: Half(129600,1:16,1440,16) -> Half(129600,1:16,1440,16) ***************
[03/24/2023-12:56:57] [V] [TRT] =============== Computing costs for 
[03/24/2023-12:56:57] [V] [TRT] *************** Autotuning format combination: Float(2073600,8100,90,1) -> Float(8294400,32400,180,1) ***************
[03/24/2023-12:56:57] [V] [TRT] --------------- Timing Runner: ConvTranspose_56 + BatchNormalization_57 + Relu_58 (CudnnDeconvolution)
[03/24/2023-12:56:57] [V] [TRT] Tactic: 0 Time: 0.469376
[03/24/2023-12:56:57] [V] [TRT] Tactic: 1 Time: 0.25216
[03/24/2023-12:56:57] [V] [TRT] Tactic: 3 Time: 8.28288
[03/24/2023-12:56:57] [V] [TRT] Fastest Tactic: 1 Time: 0.25216
[03/24/2023-12:56:57] [V] [TRT] --------------- Timing Runner: ConvTranspose_56 + BatchNormalization_57 + Relu_58 (GemmDeconvolution)
[03/24/2023-12:56:57] [V] [TRT] Tactic: 0 Time: 0.337536
[03/24/2023-12:56:57] [V] [TRT] Fastest Tactic: 0 Time: 0.337536
[03/24/2023-12:56:57] [V] [TRT] --------------- Timing Runner: ConvTranspose_56 + BatchNormalization_57 + Relu_58 (CaskDeconvolution)
[03/24/2023-12:56:57] [V] [TRT] CaskDeconvolution has no valid tactics for this config, skipping
[03/24/2023-12:56:57] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CudnnDeconvolution Tactic: 1
[03/24/2023-12:56:57] [V] [TRT] *************** Autotuning format combination: Float(2073600,1,23040,256) -> Float(8294400,1,46080,256) ***************
[03/24/2023-12:56:57] [V] [TRT] --------------- Timing Runner: ConvTranspose_56 + BatchNormalization_57 + Relu_58 (CudnnDeconvolution)
[03/24/2023-12:56:57] [V] [TRT] CudnnDeconvolution has no valid tactics for this config, skipping
[03/24/2023-12:56:57] [V] [TRT] --------------- Timing Runner: ConvTranspose_56 + BatchNormalization_57 + Relu_58 (GemmDeconvolution)
[03/24/2023-12:56:57] [V] [TRT] GemmDeconvolution has no valid tactics for this config, skipping
[03/24/2023-12:56:57] [V] [TRT] --------------- Timing Runner: ConvTranspose_56 + BatchNormalization_57 + Relu_58 (CaskDeconvolution)
[03/24/2023-12:56:57] [V] [TRT] CaskDeconvolution has no valid tactics for this config, skipping
[03/24/2023-12:56:57] [V] [TRT] *************** Autotuning format combination: Float(518400,1:4,5760,64) -> Float(2073600,1:4,11520,64) ***************
[03/24/2023-12:56:57] [V] [TRT] --------------- Timing Runner: ConvTranspose_56 + BatchNormalization_57 + Relu_58 (CudnnDeconvolution)
[03/24/2023-12:56:57] [V] [TRT] CudnnDeconvolution has no valid tactics for this config, skipping
[03/24/2023-12:56:57] [V] [TRT] --------------- Timing Runner: ConvTranspose_56 + BatchNormalization_57 + Relu_58 (GemmDeconvolution)
[03/24/2023-12:56:57] [V] [TRT] GemmDeconvolution has no valid tactics for this config, skipping
[03/24/2023-12:56:57] [V] [TRT] --------------- Timing Runner: ConvTranspose_56 + BatchNormalization_57 + Relu_58 (CaskDeconvolution)
[03/24/2023-12:56:57] [V] [TRT] CaskDeconvolution has no valid tactics for this config, skipping
[03/24/2023-12:56:57] [V] [TRT] *************** Autotuning format combination: Half(2073600,8100,90,1) -> Half(8294400,32400,180,1) ***************
[03/24/2023-12:56:57] [V] [TRT] --------------- Timing Runner: ConvTranspose_56 + BatchNormalization_57 + Relu_58 (CudnnDeconvolution)
[03/24/2023-12:56:57] [V] [TRT] Tactic: 0 Time: 0.644992
[03/24/2023-12:56:58] [V] [TRT] Tactic: 1 Time: 1.60589
[03/24/2023-12:56:58] [V] [TRT] Tactic: 3 Time: 8.23962
[03/24/2023-12:56:58] [V] [TRT] Fastest Tactic: 0 Time: 0.644992
[03/24/2023-12:56:58] [V] [TRT] --------------- Timing Runner: ConvTranspose_56 + BatchNormalization_57 + Relu_58 (GemmDeconvolution)
[03/24/2023-12:56:58] [V] [TRT] Tactic: 0 Time: 0.105856
[03/24/2023-12:56:58] [V] [TRT] Fastest Tactic: 0 Time: 0.105856
[03/24/2023-12:56:58] [V] [TRT] --------------- Timing Runner: ConvTranspose_56 + BatchNormalization_57 + Relu_58 (CaskDeconvolution)
[03/24/2023-12:56:58] [V] [TRT] CaskDeconvolution has no valid tactics for this config, skipping
[03/24/2023-12:56:58] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: GemmDeconvolution Tactic: 0
[03/24/2023-12:56:58] [V] [TRT] *************** Autotuning format combination: Half(1036800,8100:2,90,1) -> Half(4147200,32400:2,180,1) ***************
[03/24/2023-12:56:58] [V] [TRT] --------------- Timing Runner: ConvTranspose_56 + BatchNormalization_57 + Relu_58 (CudnnDeconvolution)
[03/24/2023-12:56:58] [V] [TRT] CudnnDeconvolution has no valid tactics for this config, skipping
[03/24/2023-12:56:58] [V] [TRT] --------------- Timing Runner: ConvTranspose_56 + BatchNormalization_57 + Relu_58 (GemmDeconvolution)
[03/24/2023-12:56:58] [V] [TRT] Tactic: 0 Time: 0.188416
[03/24/2023-12:56:58] [V] [TRT] Fastest Tactic: 0 Time: 0.188416
[03/24/2023-12:56:58] [V] [TRT] --------------- Timing Runner: ConvTranspose_56 + BatchNormalization_57 + Relu_58 (CaskDeconvolution)
[03/24/2023-12:56:58] [V] [TRT] CaskDeconvolution has no valid tactics for this config, skipping
[03/24/2023-12:56:58] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: GemmDeconvolution Tactic: 0
[03/24/2023-12:56:58] [V] [TRT] *************** Autotuning format combination: Half(259200,1:8,2880,32) -> Half(1036800,1:8,5760,32) ***************
[03/24/2023-12:56:58] [V] [TRT] --------------- Timing Runner: ConvTranspose_56 + BatchNormalization_57 + Relu_58 (CudnnDeconvolution)
[03/24/2023-12:56:58] [V] [TRT] CudnnDeconvolution has no valid tactics for this config, skipping
[03/24/2023-12:56:58] [V] [TRT] --------------- Timing Runner: ConvTranspose_56 + BatchNormalization_57 + Relu_58 (GemmDeconvolution)
[03/24/2023-12:56:58] [V] [TRT] Tactic: 0 Time: 0.06464
[03/24/2023-12:56:58] [V] [TRT] Fastest Tactic: 0 Time: 0.06464
[03/24/2023-12:56:58] [V] [TRT] --------------- Timing Runner: ConvTranspose_56 + BatchNormalization_57 + Relu_58 (CaskDeconvolution)
[03/24/2023-12:56:58] [V] [TRT] CaskDeconvolution has no valid tactics for this config, skipping
[03/24/2023-12:56:58] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: GemmDeconvolution Tactic: 0
[03/24/2023-12:56:58] [V] [TRT] *************** Autotuning format combination: Half(129600,1:16,1440,16) -> Half(518400,1:16,2880,16) ***************
[03/24/2023-12:56:58] [V] [TRT] --------------- Timing Runner: ConvTranspose_56 + BatchNormalization_57 + Relu_58 (CudnnDeconvolution)
[03/24/2023-12:56:58] [V] [TRT] CudnnDeconvolution has no valid tactics for this config, skipping
[03/24/2023-12:56:58] [V] [TRT] --------------- Timing Runner: ConvTranspose_56 + BatchNormalization_57 + Relu_58 (GemmDeconvolution)
[03/24/2023-12:56:58] [V] [TRT] GemmDeconvolution has no valid tactics for this config, skipping
[03/24/2023-12:56:58] [V] [TRT] --------------- Timing Runner: ConvTranspose_56 + BatchNormalization_57 + Relu_58 (CaskDeconvolution)
[03/24/2023-12:56:58] [V] [TRT] CaskDeconvolution has no valid tactics for this config, skipping
[03/24/2023-12:56:58] [V] [TRT] =============== Computing costs for 
[03/24/2023-12:56:58] [V] [TRT] *************** Autotuning format combination: Float(16588800,32400,180,1) -> Float(2073600,32400,180,1) ***************
[03/24/2023-12:56:58] [V] [TRT] --------------- Timing Runner: Conv_60 + Relu_61 (CudaDepthwiseConvolution)
[03/24/2023-12:56:58] [V] [TRT] CudaDepthwiseConvolution has no valid tactics for this config, skipping
[03/24/2023-12:56:58] [V] [TRT] --------------- Timing Runner: Conv_60 + Relu_61 (FusedConvActConvolution)
[03/24/2023-12:56:58] [V] [TRT] Tactic: 524287 Time: 1.35117
[03/24/2023-12:56:58] [V] [TRT] Tactic: 720895 Time: 1.3705
[03/24/2023-12:56:58] [V] [TRT] Tactic: 983039 Time: 1.13101
[03/24/2023-12:56:58] [V] [TRT] Tactic: 1048575 Time: 1.26528
[03/24/2023-12:56:58] [V] [TRT] Tactic: 1703935 Time: 1.20691
[03/24/2023-12:56:58] [V] [TRT] Tactic: 1769471 Time: 1.21984
[03/24/2023-12:56:58] [V] [TRT] Tactic: 1966079 Time: 1.52755
[03/24/2023-12:56:58] [V] [TRT] Tactic: 2031615 Time: 1.27834
[03/24/2023-12:56:58] [V] [TRT] Tactic: 2228223 Time: 1.28051
[03/24/2023-12:56:58] [V] [TRT] Tactic: 2424831 Time: 1.1936
[03/24/2023-12:56:59] [V] [TRT] Tactic: 2621439 Time: 1.19014
[03/24/2023-12:56:59] [V] [TRT] Tactic: 2752511 Time: 1.3225
[03/24/2023-12:56:59] [V] [TRT] Tactic: 2818047 Time: 2.24166
[03/24/2023-12:56:59] [V] [TRT] Tactic: 2883583 Time: 2.3863
[03/24/2023-12:56:59] [V] [TRT] Tactic: 3014655 Time: 1.28461
[03/24/2023-12:56:59] [V] [TRT] Tactic: 3145727 Time: 1.15584
[03/24/2023-12:56:59] [V] [TRT] Tactic: 3473407 Time: 2.49344
[03/24/2023-12:56:59] [V] [TRT] Tactic: 3604479 Time: 1.26195
[03/24/2023-12:56:59] [V] [TRT] Tactic: 3735551 Time: 2.33459
[03/24/2023-12:56:59] [V] [TRT] Tactic: 4390911 Time: 1.65005
[03/24/2023-12:56:59] [V] [TRT] Tactic: 5046271 Time: 1.28346
[03/24/2023-12:57:00] [V] [TRT] Tactic: 5963775 Time: 1.37946
[03/24/2023-12:57:00] [V] [TRT] Tactic: 6160383 Time: 1.34157
[03/24/2023-12:57:00] [V] [TRT] Tactic: 6488063 Time: 1.31904
[03/24/2023-12:57:00] [V] [TRT] Tactic: 6881279 Time: 1.36448
[03/24/2023-12:57:00] [V] [TRT] Tactic: 7274495 Time: 1.20256
[03/24/2023-12:57:00] [V] [TRT] Tactic: 7864319 Time: 1.18989
[03/24/2023-12:57:00] [V] [TRT] Tactic: 7995391 Time: 1.4217
[03/24/2023-12:57:00] [V] [TRT] Tactic: 8585215 Time: 1.40762
[03/24/2023-12:57:00] [V] [TRT] Tactic: 8847359 Time: 1.16774
[03/24/2023-12:57:00] [V] [TRT] Tactic: 8978431 Time: 1.38803
[03/24/2023-12:57:00] [V] [TRT] Tactic: 9043967 Time: 1.19501
[03/24/2023-12:57:00] [V] [TRT] Tactic: 9175039 Time: 1.2608
[03/24/2023-12:57:00] [V] [TRT] Tactic: 9502719 Time: 1.6489
[03/24/2023-12:57:01] [V] [TRT] Tactic: 9830399 Time: 2.37888
[03/24/2023-12:57:01] [V] [TRT] Tactic: 9961471 Time: 1.27539
[03/24/2023-12:57:01] [V] [TRT] Tactic: 10027007 Time: 1.21075
[03/24/2023-12:57:01] [V] [TRT] Tactic: 10092543 Time: 1.65043
[03/24/2023-12:57:01] [V] [TRT] Tactic: 10289151 Time: 1.52742
[03/24/2023-12:57:01] [V] [TRT] Tactic: 10485759 Time: 1.17542
[03/24/2023-12:57:01] [V] [TRT] Tactic: 10682367 Time: 1.19475
[03/24/2023-12:57:01] [V] [TRT] Tactic: 10813439 Time: 1.1712
[03/24/2023-12:57:01] [V] [TRT] Fastest Tactic: 983039 Time: 1.13101
[03/24/2023-12:57:01] [V] [TRT] --------------- Timing Runner: Conv_60 + Relu_61 (CudnnConvolution)
[03/24/2023-12:57:01] [V] [TRT] Tactic: 0 Time: 1.82131
[03/24/2023-12:57:01] [V] [TRT] Tactic: 1 Time: 0.348416
[03/24/2023-12:57:01] [V] [TRT] Tactic: 2 Time: 3.46739
[03/24/2023-12:57:01] [V] [TRT] Tactic: 4 skipped. Scratch requested: 17585799168, available: 4294967296
[03/24/2023-12:57:01] [V] [TRT] Tactic: 5 Time: 4.37786
[03/24/2023-12:57:01] [V] [TRT] Tactic: 6 Time: 0.676608
[03/24/2023-12:57:01] [V] [TRT] Tactic: 56 Time: 1.82541
[03/24/2023-12:57:01] [V] [TRT] Tactic: 57 Time: 0.348544
[03/24/2023-12:57:01] [V] [TRT] Tactic: 58 Time: 3.472
[03/24/2023-12:57:01] [V] [TRT] Tactic: 60 skipped. Scratch requested: 17585799168, available: 4294967296
[03/24/2023-12:57:01] [V] [TRT] Tactic: 61 Time: 4.38182
[03/24/2023-12:57:01] [V] [TRT] Tactic: 62 Time: 0.675968
[03/24/2023-12:57:01] [V] [TRT] Tactic: 112 Time: 1.82746
[03/24/2023-12:57:01] [V] [TRT] Tactic: 113 Time: 1.42221
[03/24/2023-12:57:02] [V] [TRT] Tactic: 114 Time: 3.47098
[03/24/2023-12:57:02] [V] [TRT] Tactic: 116 skipped. Scratch requested: 17585799168, available: 4294967296
[03/24/2023-12:57:02] [V] [TRT] Tactic: 117 Time: 4.38054
[03/24/2023-12:57:02] [V] [TRT] Tactic: 118 Time: 0.67648
[03/24/2023-12:57:02] [V] [TRT] Fastest Tactic: 1 Time: 0.348416
[03/24/2023-12:57:02] [V] [TRT] Setting workspace to 17585799168enables more tactics for profiling
[03/24/2023-12:57:02] [V] [TRT] --------------- Timing Runner: Conv_60 + Relu_61 (CaskConvolution)
[03/24/2023-12:57:02] [V] [TRT] Conv_60 + Relu_61 Set Tactic Name: ampere_scudnn_128x64_relu_small_nn_v1 Tactic: 4549827808004681195
[03/24/2023-12:57:02] [V] [TRT] Tactic: 4549827808004681195 Time: 1.3833
[03/24/2023-12:57:02] [V] [TRT] Conv_60 + Relu_61 Set Tactic Name: ampere_scudnn_128x128_relu_small_nn_v1 Tactic: 5779835512569528575
[03/24/2023-12:57:02] [V] [TRT] Tactic: 5779835512569528575 Time: 2.57254
[03/24/2023-12:57:02] [V] [TRT] Conv_60 + Relu_61 Set Tactic Name: ampere_scudnn_128x128_relu_xregs_large_nn_v1 Tactic: 6053873026024413720
[03/24/2023-12:57:02] [V] [TRT] Tactic: 6053873026024413720 Time: 2.65485
[03/24/2023-12:57:02] [V] [TRT] Conv_60 + Relu_61 Set Tactic Name: ampere_scudnn_128x64_relu_xregs_large_nn_v1 Tactic: 6767548733843469815
[03/24/2023-12:57:02] [V] [TRT] Tactic: 6767548733843469815 Time: 1.37907
[03/24/2023-12:57:02] [V] [TRT] Conv_60 + Relu_61 Set Tactic Name: ampere_scudnn_128x32_relu_small_nn_v1 Tactic: -6313876406580483184
[03/24/2023-12:57:02] [V] [TRT] Tactic: -6313876406580483184 Time: 1.60525
[03/24/2023-12:57:02] [V] [TRT] Conv_60 + Relu_61 Set Tactic Name: ampere_scudnn_128x128_relu_medium_nn_v1 Tactic: -1123676555321336786
[03/24/2023-12:57:02] [V] [TRT] Tactic: -1123676555321336786 Time: 2.57408
[03/24/2023-12:57:02] [V] [TRT] Conv_60 + Relu_61 Set Tactic Name: ampere_scudnn_128x64_relu_medium_nn_v1 Tactic: -701551393537224327
[03/24/2023-12:57:02] [V] [TRT] Tactic: -701551393537224327 Time: 1.40736
[03/24/2023-12:57:02] [V] [TRT] Fastest Tactic: 6767548733843469815 Time: 1.37907
[03/24/2023-12:57:02] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CudnnConvolution Tactic: 1
[03/24/2023-12:57:02] [V] [TRT] *************** Autotuning format combination: Float(16588800,1,92160,512) -> Float(2073600,1,11520,64) ***************
[03/24/2023-12:57:02] [V] [TRT] --------------- Timing Runner: Conv_60 + Relu_61 (CudnnConvolution)
[03/24/2023-12:57:02] [V] [TRT] CudnnConvolution has no valid tactics for this config, skipping
[03/24/2023-12:57:02] [V] [TRT] --------------- Timing Runner: Conv_60 + Relu_61 (CaskConvolution)
[03/24/2023-12:57:02] [V] [TRT] Conv_60 + Relu_61 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize64x128x8_stage3_warpsize1x4x1_g1_ffma_t1r3s3 Tactic: 2086609538387166260
[03/24/2023-12:57:02] [V] [TRT] Tactic: 2086609538387166260 Time: 2.13606
[03/24/2023-12:57:02] [V] [TRT] Conv_60 + Relu_61 Set Tactic Name: ampere_scudnn_128x64_sliced1x2_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: 2860655430572478466
[03/24/2023-12:57:02] [V] [TRT] Tactic: 2860655430572478466 Time: 1.32173
[03/24/2023-12:57:02] [V] [TRT] Conv_60 + Relu_61 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize64x128x8_stage3_warpsize1x4x1_g1_ffma Tactic: 3239733199291090177
[03/24/2023-12:57:02] [V] [TRT] Tactic: 3239733199291090177 Time: 2.1303
[03/24/2023-12:57:02] [V] [TRT] Conv_60 + Relu_61 Set Tactic Name: ampere_scudnn_128x32_sliced1x4_ldg4_relu_exp_medium_nhwc_tn_v1 Tactic: 4474630279712975759
[03/24/2023-12:57:02] [V] [TRT] Tactic: 4474630279712975759 Time: 1.11296
[03/24/2023-12:57:02] [V] [TRT] Conv_60 + Relu_61 Set Tactic Name: ampere_scudnn_128x32_sliced1x4_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: 4479823862704990365
[03/24/2023-12:57:02] [V] [TRT] Tactic: 4479823862704990365 Time: 1.1072
[03/24/2023-12:57:02] [V] [TRT] Conv_60 + Relu_61 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize64x256x8_stage3_warpsize1x4x1_g1_ffma Tactic: 4517590677127196184
[03/24/2023-12:57:02] [V] [TRT] Tactic: 4517590677127196184 Time: 5.23123
[03/24/2023-12:57:02] [V] [TRT] Conv_60 + Relu_61 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize128x128x8_stage3_warpsize2x4x1_g1_ffma_t1r3s3 Tactic: 4634080872644479428
[03/24/2023-12:57:02] [V] [TRT] Tactic: 4634080872644479428 Time: 2.57651
[03/24/2023-12:57:02] [V] [TRT] Conv_60 + Relu_61 Set Tactic Name: ampere_scudnn_128x64_sliced1x2_ldg4_relu_exp_medium_nhwc_tn_v1 Tactic: 4696204239951173149
[03/24/2023-12:57:02] [V] [TRT] Tactic: 4696204239951173149 Time: 1.32186
[03/24/2023-12:57:02] [V] [TRT] Conv_60 + Relu_61 Set Tactic Name: ampere_scudnn_128x128_relu_exp_small_nhwc_tn_v1 Tactic: 5778138195697110003
[03/24/2023-12:57:02] [V] [TRT] Tactic: 5778138195697110003 Time: 2.56909
[03/24/2023-12:57:02] [V] [TRT] Conv_60 + Relu_61 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize256x128x8_stage3_warpsize2x4x1_g1_ffma Tactic: 6310198979346901507
[03/24/2023-12:57:02] [V] [TRT] Tactic: 6310198979346901507 Time: 3.56774
[03/24/2023-12:57:02] [V] [TRT] Conv_60 + Relu_61 Set Tactic Name: ampere_scudnn_128x128_ldg4_relu_exp_large_nhwc_tn_v1 Tactic: 7155825427510256858
[03/24/2023-12:57:02] [V] [TRT] Tactic: 7155825427510256858 Time: 2.58368
[03/24/2023-12:57:02] [V] [TRT] Conv_60 + Relu_61 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize128x64x8_stage3_warpsize1x4x1_g1_ffma Tactic: 7222247112373541608
[03/24/2023-12:57:02] [V] [TRT] Tactic: 7222247112373541608 Time: 1.8185
[03/24/2023-12:57:02] [V] [TRT] Conv_60 + Relu_61 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize128x128x8_stage3_warpsize2x4x1_g1_ffma Tactic: 7472640475524677095
[03/24/2023-12:57:03] [V] [TRT] Tactic: 7472640475524677095 Time: 2.62643
[03/24/2023-12:57:03] [V] [TRT] Conv_60 + Relu_61 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize128x256x8_stage3_warpsize2x4x1_g1_ffma Tactic: 8498373915030836990
[03/24/2023-12:57:03] [V] [TRT] Tactic: 8498373915030836990 Time: 5.21242
[03/24/2023-12:57:03] [V] [TRT] Conv_60 + Relu_61 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize256x64x8_stage3_warpsize1x4x1_g1_ffma Tactic: 8869697132622550639
[03/24/2023-12:57:03] [V] [TRT] Tactic: 8869697132622550639 Time: 2.03725
[03/24/2023-12:57:03] [V] [TRT] Conv_60 + Relu_61 Set Tactic Name: ampere_scudnn_128x128_ldg4_relu_exp_medium_nhwc_tn_v1 Tactic: 8918020581761223752
[03/24/2023-12:57:03] [V] [TRT] Tactic: 8918020581761223752 Time: 2.56166
[03/24/2023-12:57:03] [V] [TRT] Conv_60 + Relu_61 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize256x128x8_stage3_warpsize2x4x1_g1_ffma_t1r3s3 Tactic: -8937725997228636978
[03/24/2023-12:57:03] [V] [TRT] Tactic: -8937725997228636978 Time: 3.43398
[03/24/2023-12:57:03] [V] [TRT] Conv_60 + Relu_61 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize128x256x8_stage3_warpsize2x4x1_g1_ffma_t1r3s3 Tactic: -8833858409138163072
[03/24/2023-12:57:03] [V] [TRT] Tactic: -8833858409138163072 Time: 5.10656
[03/24/2023-12:57:03] [V] [TRT] Conv_60 + Relu_61 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize64x64x8_stage3_warpsize1x4x1_g1_ffma_t1r3s3 Tactic: -7989138351613022500
[03/24/2023-12:57:03] [V] [TRT] Tactic: -7989138351613022500 Time: 1.09734
[03/24/2023-12:57:03] [V] [TRT] Conv_60 + Relu_61 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize256x128x8_stage3_warpsize2x4x1_g1_ffma Tactic: -7872883691240863058
[03/24/2023-12:57:03] [V] [TRT] Tactic: -7872883691240863058 Time: 3.56006
[03/24/2023-12:57:03] [V] [TRT] Conv_60 + Relu_61 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize128x128x8_stage3_warpsize2x4x1_g1_ffma Tactic: -6729618519651721910
[03/24/2023-12:57:03] [V] [TRT] Tactic: -6729618519651721910 Time: 2.59482
[03/24/2023-12:57:03] [V] [TRT] Conv_60 + Relu_61 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize256x64x8_stage3_warpsize1x4x1_g1_ffma Tactic: -5893833996418445881
[03/24/2023-12:57:03] [V] [TRT] Tactic: -5893833996418445881 Time: 1.95891
[03/24/2023-12:57:03] [V] [TRT] Conv_60 + Relu_61 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize128x256x8_stage3_warpsize2x4x1_g1_ffma Tactic: -5701562095007058349
[03/24/2023-12:57:03] [V] [TRT] Tactic: -5701562095007058349 Time: 5.13293
[03/24/2023-12:57:03] [V] [TRT] Conv_60 + Relu_61 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize128x64x8_stage3_warpsize1x4x1_g1_ffma Tactic: -5685503422376017600
[03/24/2023-12:57:03] [V] [TRT] Tactic: -5685503422376017600 Time: 1.75373
[03/24/2023-12:57:03] [V] [TRT] Conv_60 + Relu_61 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize64x64x8_stage3_warpsize1x4x1_g1_ffma Tactic: -5521125187060117489
[03/24/2023-12:57:03] [V] [TRT] Tactic: -5521125187060117489 Time: 1.19437
[03/24/2023-12:57:03] [V] [TRT] Conv_60 + Relu_61 Set Tactic Name: ampere_scudnn_128x64_sliced1x2_ldg4_relu_exp_large_nhwc_tn_v1 Tactic: -4756382386362004279
[03/24/2023-12:57:03] [V] [TRT] Tactic: -4756382386362004279 Time: 1.3047
[03/24/2023-12:57:03] [V] [TRT] Conv_60 + Relu_61 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize64x64x8_stage3_warpsize1x4x1_g1_ffma Tactic: -4615000974950361663
[03/24/2023-12:57:03] [V] [TRT] Tactic: -4615000974950361663 Time: 1.136
[03/24/2023-12:57:03] [V] [TRT] Conv_60 + Relu_61 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize256x64x8_stage3_warpsize1x4x1_g1_ffma_t1r3s3 Tactic: -4314913710375142296
[03/24/2023-12:57:03] [V] [TRT] Tactic: -4314913710375142296 Time: 1.91552
[03/24/2023-12:57:03] [V] [TRT] Conv_60 + Relu_61 Set Tactic Name: ampere_scudnn_128x128_relu_exp_large_nhwc_tn_v1 Tactic: -3855385237722507464
[03/24/2023-12:57:03] [V] [TRT] Tactic: -3855385237722507464 Time: 2.58138
[03/24/2023-12:57:03] [V] [TRT] Conv_60 + Relu_61 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize128x64x8_stage3_warpsize1x4x1_g1_ffma_t1r3s3 Tactic: -3697587361057948972
[03/24/2023-12:57:03] [V] [TRT] Tactic: -3697587361057948972 Time: 1.75898
[03/24/2023-12:57:03] [V] [TRT] Conv_60 + Relu_61 Set Tactic Name: ampere_scudnn_128x128_relu_exp_medium_nhwc_tn_v1 Tactic: -2809379259463049391
[03/24/2023-12:57:03] [V] [TRT] Tactic: -2809379259463049391 Time: 2.57779
[03/24/2023-12:57:03] [V] [TRT] Conv_60 + Relu_61 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize64x256x8_stage3_warpsize1x4x1_g1_ffma_t1r3s3 Tactic: -2747929399988666512
[03/24/2023-12:57:04] [V] [TRT] Tactic: -2747929399988666512 Time: 5.09709
[03/24/2023-12:57:04] [V] [TRT] Conv_60 + Relu_61 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize64x256x8_stage3_warpsize1x4x1_g1_ffma Tactic: -1472061967969061456
[03/24/2023-12:57:04] [V] [TRT] Tactic: -1472061967969061456 Time: 4.4105
[03/24/2023-12:57:04] [V] [TRT] Conv_60 + Relu_61 Set Tactic Name: ampere_scudnn_128x128_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: -504296718212024303
[03/24/2023-12:57:04] [V] [TRT] Tactic: -504296718212024303 Time: 2.55872
[03/24/2023-12:57:04] [V] [TRT] Conv_60 + Relu_61 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize64x128x8_stage3_warpsize1x4x1_g1_ffma Tactic: -444093195553988951
[03/24/2023-12:57:04] [V] [TRT] Tactic: -444093195553988951 Time: 2.24346
[03/24/2023-12:57:04] [V] [TRT] Fastest Tactic: -7989138351613022500 Time: 1.09734
[03/24/2023-12:57:04] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: -7989138351613022500
[03/24/2023-12:57:04] [V] [TRT] *************** Autotuning format combination: Float(4147200,1:4,23040,128) -> Float(518400,1:4,2880,16) ***************
[03/24/2023-12:57:04] [V] [TRT] --------------- Timing Runner: Conv_60 + Relu_61 (CudnnConvolution)
[03/24/2023-12:57:04] [V] [TRT] CudnnConvolution has no valid tactics for this config, skipping
[03/24/2023-12:57:04] [V] [TRT] --------------- Timing Runner: Conv_60 + Relu_61 (CaskConvolution)
[03/24/2023-12:57:04] [V] [TRT] Conv_60 + Relu_61 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize64x128x32_stage5_warpsize2x2x1_g1_tensor16x8x8 Tactic: 1237784342446422381
[03/24/2023-12:57:04] [V] [TRT] Tactic: 1237784342446422381 Time: 0.46272
[03/24/2023-12:57:04] [V] [TRT] Conv_60 + Relu_61 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x64x32_stage5_warpsize2x2x1_g1_tensor16x8x8 Tactic: 1426562292875733922
[03/24/2023-12:57:04] [V] [TRT] Tactic: 1426562292875733922 Time: 0.299136
[03/24/2023-12:57:04] [V] [TRT] Conv_60 + Relu_61 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize64x128x8_stage3_warpsize1x4x1_g1_ffma_t1r3s3 Tactic: 2086609538387166260
[03/24/2023-12:57:04] [V] [TRT] Tactic: 2086609538387166260 Time: 2.13645
[03/24/2023-12:57:04] [V] [TRT] Conv_60 + Relu_61 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize256x128x32_stage3_warpsize4x2x1_g1_tensor16x8x8_t1r3s3 Tactic: 2388153022056233219
[03/24/2023-12:57:04] [V] [TRT] Tactic: 2388153022056233219 Time: 0.483712
[03/24/2023-12:57:04] [V] [TRT] Conv_60 + Relu_61 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x128x32_stage4_warpsize2x2x1_g1_tensor16x8x8 Tactic: 2716437853123234317
[03/24/2023-12:57:04] [V] [TRT] Tactic: 2716437853123234317 Time: 0.381696
[03/24/2023-12:57:04] [V] [TRT] Conv_60 + Relu_61 Set Tactic Name: ampere_scudnn_128x64_sliced1x2_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: 2860655430572478466
[03/24/2023-12:57:04] [V] [TRT] Tactic: 2860655430572478466 Time: 1.32186
[03/24/2023-12:57:04] [V] [TRT] Conv_60 + Relu_61 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize64x128x8_stage3_warpsize1x4x1_g1_ffma Tactic: 3239733199291090177
[03/24/2023-12:57:04] [V] [TRT] Tactic: 3239733199291090177 Time: 2.13133
[03/24/2023-12:57:04] [V] [TRT] Conv_60 + Relu_61 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize64x64x64_stage4_warpsize2x2x1_g1_tensor16x8x8_t1r3s3 Tactic: 3278852197192504305
[03/24/2023-12:57:04] [V] [TRT] Tactic: 3278852197192504305 Time: 0.272384
[03/24/2023-12:57:04] [V] [TRT] Conv_60 + Relu_61 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize256x128x32_stage3_warpsize4x2x1_g1_tensor16x8x8 Tactic: 3904690393614050557
[03/24/2023-12:57:04] [V] [TRT] Tactic: 3904690393614050557 Time: 0.63936
[03/24/2023-12:57:04] [V] [TRT] Conv_60 + Relu_61 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize64x64x64_stage4_warpsize2x2x1_g1_tensor16x8x8 Tactic: 4061115162338989075
[03/24/2023-12:57:04] [V] [TRT] Tactic: 4061115162338989075 Time: 0.30592
[03/24/2023-12:57:04] [V] [TRT] Conv_60 + Relu_61 Set Tactic Name: ampere_scudnn_128x32_sliced1x4_ldg4_relu_exp_medium_nhwc_tn_v1 Tactic: 4474630279712975759
[03/24/2023-12:57:04] [V] [TRT] Tactic: 4474630279712975759 Time: 1.11411
[03/24/2023-12:57:04] [V] [TRT] Conv_60 + Relu_61 Set Tactic Name: ampere_scudnn_128x32_sliced1x4_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: 4479823862704990365
[03/24/2023-12:57:04] [V] [TRT] Tactic: 4479823862704990365 Time: 1.10848
[03/24/2023-12:57:04] [V] [TRT] Conv_60 + Relu_61 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize64x256x8_stage3_warpsize1x4x1_g1_ffma Tactic: 4517590677127196184
[03/24/2023-12:57:04] [V] [TRT] Tactic: 4517590677127196184 Time: 5.22611
[03/24/2023-12:57:04] [V] [TRT] Conv_60 + Relu_61 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize128x128x8_stage3_warpsize2x4x1_g1_ffma_t1r3s3 Tactic: 4634080872644479428
[03/24/2023-12:57:04] [V] [TRT] Tactic: 4634080872644479428 Time: 2.57434
[03/24/2023-12:57:04] [V] [TRT] Conv_60 + Relu_61 Set Tactic Name: ampere_scudnn_128x64_sliced1x2_ldg4_relu_exp_medium_nhwc_tn_v1 Tactic: 4696204239951173149
[03/24/2023-12:57:04] [V] [TRT] Tactic: 4696204239951173149 Time: 1.32442
[03/24/2023-12:57:04] [V] [TRT] Conv_60 + Relu_61 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x256x32_stage3_warpsize2x4x1_g1_tensor16x8x8 Tactic: 5200329514761435342
[03/24/2023-12:57:04] [V] [TRT] Tactic: 5200329514761435342 Time: 0.701952
[03/24/2023-12:57:04] [V] [TRT] Conv_60 + Relu_61 Set Tactic Name: ampere_scudnn_128x128_relu_exp_small_nhwc_tn_v1 Tactic: 5778138195697110003
[03/24/2023-12:57:04] [V] [TRT] Tactic: 5778138195697110003 Time: 2.56896
[03/24/2023-12:57:04] [V] [TRT] Conv_60 + Relu_61 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize256x128x8_stage3_warpsize2x4x1_g1_ffma Tactic: 6310198979346901507
[03/24/2023-12:57:04] [V] [TRT] Tactic: 6310198979346901507 Time: 3.5657
[03/24/2023-12:57:04] [V] [TRT] Conv_60 + Relu_61 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x256x32_stage3_warpsize2x4x1_g1_tensor16x8x8_t1r3s3 Tactic: 7011693366046809027
[03/24/2023-12:57:04] [V] [TRT] Tactic: 7011693366046809027 Time: 0.681344
[03/24/2023-12:57:04] [V] [TRT] Conv_60 + Relu_61 Set Tactic Name: ampere_scudnn_128x128_ldg4_relu_exp_large_nhwc_tn_v1 Tactic: 7155825427510256858
[03/24/2023-12:57:04] [V] [TRT] Tactic: 7155825427510256858 Time: 2.58522
[03/24/2023-12:57:04] [V] [TRT] Conv_60 + Relu_61 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize128x64x8_stage3_warpsize1x4x1_g1_ffma Tactic: 7222247112373541608
[03/24/2023-12:57:04] [V] [TRT] Tactic: 7222247112373541608 Time: 1.81517
[03/24/2023-12:57:04] [V] [TRT] Conv_60 + Relu_61 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x128x16_stage4_warpsize2x2x1_g1_tensor16x8x8 Tactic: 7342025736444949634
[03/24/2023-12:57:04] [V] [TRT] Tactic: 7342025736444949634 Time: 0.473088
[03/24/2023-12:57:04] [V] [TRT] Conv_60 + Relu_61 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize64x128x32_stage5_warpsize2x2x1_g1_tensor16x8x8 Tactic: 7347365539922924600
[03/24/2023-12:57:04] [V] [TRT] Tactic: 7347365539922924600 Time: 0.411008
[03/24/2023-12:57:04] [V] [TRT] Conv_60 + Relu_61 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x64x32_stage5_warpsize2x2x1_g1_tensor16x8x8 Tactic: 7428197830878119671
[03/24/2023-12:57:04] [V] [TRT] Tactic: 7428197830878119671 Time: 0.2592
[03/24/2023-12:57:04] [V] [TRT] Conv_60 + Relu_61 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize64x32x64_stage5_warpsize2x2x1_g1_tensor16x8x8_t1r3s3 Tactic: 7465323447915168822
[03/24/2023-12:57:04] [V] [TRT] Tactic: 7465323447915168822 Time: 0.393728
[03/24/2023-12:57:04] [V] [TRT] Conv_60 + Relu_61 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize128x128x8_stage3_warpsize2x4x1_g1_ffma Tactic: 7472640475524677095
[03/24/2023-12:57:05] [V] [TRT] Tactic: 7472640475524677095 Time: 2.62874
[03/24/2023-12:57:05] [V] [TRT] Conv_60 + Relu_61 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize64x32x64_stage5_warpsize2x2x1_g1_tensor16x8x8 Tactic: 7938223790021272801
[03/24/2023-12:57:05] [V] [TRT] Tactic: 7938223790021272801 Time: 0.401408
[03/24/2023-12:57:05] [V] [TRT] Conv_60 + Relu_61 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize128x256x8_stage3_warpsize2x4x1_g1_ffma Tactic: 8498373915030836990
[03/24/2023-12:57:05] [V] [TRT] Tactic: 8498373915030836990 Time: 5.20998
[03/24/2023-12:57:05] [V] [TRT] Conv_60 + Relu_61 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x64x32_stage5_warpsize2x2x1_g1_tensor16x8x8_t1r3s3 Tactic: 8836645772682419994
[03/24/2023-12:57:05] [V] [TRT] Tactic: 8836645772682419994 Time: 0.249728
[03/24/2023-12:57:05] [V] [TRT] Conv_60 + Relu_61 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize256x64x8_stage3_warpsize1x4x1_g1_ffma Tactic: 8869697132622550639
[03/24/2023-12:57:05] [V] [TRT] Tactic: 8869697132622550639 Time: 2.03584
[03/24/2023-12:57:05] [V] [TRT] Conv_60 + Relu_61 Set Tactic Name: ampere_scudnn_128x128_ldg4_relu_exp_medium_nhwc_tn_v1 Tactic: 8918020581761223752
[03/24/2023-12:57:05] [V] [TRT] Tactic: 8918020581761223752 Time: 2.5623
[03/24/2023-12:57:05] [V] [TRT] Conv_60 + Relu_61 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize64x64x64_stage4_warpsize2x2x1_g1_tensor16x8x8 Tactic: -9114138070928278731
[03/24/2023-12:57:05] [V] [TRT] Tactic: -9114138070928278731 Time: 0.278016
[03/24/2023-12:57:05] [V] [TRT] Conv_60 + Relu_61 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize256x128x8_stage3_warpsize2x4x1_g1_ffma_t1r3s3 Tactic: -8937725997228636978
[03/24/2023-12:57:05] [V] [TRT] Tactic: -8937725997228636978 Time: 3.43296
[03/24/2023-12:57:05] [V] [TRT] Conv_60 + Relu_61 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize128x256x8_stage3_warpsize2x4x1_g1_ffma_t1r3s3 Tactic: -8833858409138163072
[03/24/2023-12:57:05] [V] [TRT] Tactic: -8833858409138163072 Time: 5.11002
[03/24/2023-12:57:05] [V] [TRT] Conv_60 + Relu_61 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize64x64x8_stage3_warpsize1x4x1_g1_ffma_t1r3s3 Tactic: -7989138351613022500
[03/24/2023-12:57:05] [V] [TRT] Tactic: -7989138351613022500 Time: 1.09837
[03/24/2023-12:57:05] [V] [TRT] Conv_60 + Relu_61 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize256x128x8_stage3_warpsize2x4x1_g1_ffma Tactic: -7872883691240863058
[03/24/2023-12:57:05] [V] [TRT] Tactic: -7872883691240863058 Time: 3.55878
[03/24/2023-12:57:05] [V] [TRT] Conv_60 + Relu_61 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x256x32_stage3_warpsize2x4x1_g1_tensor16x8x8 Tactic: -7382359095196034537
[03/24/2023-12:57:05] [V] [TRT] Tactic: -7382359095196034537 Time: 0.706816
[03/24/2023-12:57:05] [V] [TRT] Conv_60 + Relu_61 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x128x16_stage4_warpsize2x2x1_g1_tensor16x8x8_t1r3s3 Tactic: -7377458734869418330
[03/24/2023-12:57:05] [V] [TRT] Tactic: -7377458734869418330 Time: 0.4224
[03/24/2023-12:57:05] [V] [TRT] Conv_60 + Relu_61 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize128x128x8_stage3_warpsize2x4x1_g1_ffma Tactic: -6729618519651721910
[03/24/2023-12:57:05] [V] [TRT] Tactic: -6729618519651721910 Time: 2.59405
[03/24/2023-12:57:05] [V] [TRT] Conv_60 + Relu_61 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize256x64x32_stage3_warpsize4x2x1_g1_tensor16x8x8_t1r3s3 Tactic: -6223854811627385844
[03/24/2023-12:57:05] [V] [TRT] Tactic: -6223854811627385844 Time: 0.280832
[03/24/2023-12:57:05] [V] [TRT] Conv_60 + Relu_61 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize256x64x8_stage3_warpsize1x4x1_g1_ffma Tactic: -5893833996418445881
[03/24/2023-12:57:05] [V] [TRT] Tactic: -5893833996418445881 Time: 1.95738
[03/24/2023-12:57:05] [V] [TRT] Conv_60 + Relu_61 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize128x256x8_stage3_warpsize2x4x1_g1_ffma Tactic: -5701562095007058349
[03/24/2023-12:57:05] [V] [TRT] Tactic: -5701562095007058349 Time: 5.13408
[03/24/2023-12:57:05] [V] [TRT] Conv_60 + Relu_61 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize128x64x8_stage3_warpsize1x4x1_g1_ffma Tactic: -5685503422376017600
[03/24/2023-12:57:05] [V] [TRT] Tactic: -5685503422376017600 Time: 1.75565
[03/24/2023-12:57:05] [V] [TRT] Conv_60 + Relu_61 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize64x64x8_stage3_warpsize1x4x1_g1_ffma Tactic: -5521125187060117489
[03/24/2023-12:57:05] [V] [TRT] Tactic: -5521125187060117489 Time: 1.1927
[03/24/2023-12:57:05] [V] [TRT] Conv_60 + Relu_61 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x128x16_stage4_warpsize2x2x1_g1_tensor16x8x8 Tactic: -5457304872213719461
[03/24/2023-12:57:05] [V] [TRT] Tactic: -5457304872213719461 Time: 0.434048
[03/24/2023-12:57:05] [V] [TRT] Conv_60 + Relu_61 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x64x64_stage3_warpsize2x2x1_g1_tensor16x8x8 Tactic: -5441054706931585554
[03/24/2023-12:57:05] [V] [TRT] Tactic: -5441054706931585554 Time: 0.281472
[03/24/2023-12:57:05] [V] [TRT] Conv_60 + Relu_61 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize256x64x32_stage3_warpsize4x2x1_g1_tensor16x8x8 Tactic: -5043603702497465467
[03/24/2023-12:57:05] [V] [TRT] Tactic: -5043603702497465467 Time: 0.356864
[03/24/2023-12:57:05] [V] [TRT] Conv_60 + Relu_61 Set Tactic Name: ampere_scudnn_128x64_sliced1x2_ldg4_relu_exp_large_nhwc_tn_v1 Tactic: -4756382386362004279
[03/24/2023-12:57:05] [V] [TRT] Tactic: -4756382386362004279 Time: 1.3065
[03/24/2023-12:57:05] [V] [TRT] Conv_60 + Relu_61 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize64x64x8_stage3_warpsize1x4x1_g1_ffma Tactic: -4615000974950361663
[03/24/2023-12:57:05] [V] [TRT] Tactic: -4615000974950361663 Time: 1.13664
[03/24/2023-12:57:05] [V] [TRT] Conv_60 + Relu_61 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x64x64_stage3_warpsize2x2x1_g1_tensor16x8x8 Tactic: -4564655677311401797
[03/24/2023-12:57:05] [V] [TRT] Tactic: -4564655677311401797 Time: 0.270208
[03/24/2023-12:57:05] [V] [TRT] Conv_60 + Relu_61 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize256x64x8_stage3_warpsize1x4x1_g1_ffma_t1r3s3 Tactic: -4314913710375142296
[03/24/2023-12:57:05] [V] [TRT] Tactic: -4314913710375142296 Time: 1.91437
[03/24/2023-12:57:05] [V] [TRT] Conv_60 + Relu_61 Set Tactic Name: ampere_scudnn_128x128_relu_exp_large_nhwc_tn_v1 Tactic: -3855385237722507464
[03/24/2023-12:57:05] [V] [TRT] Tactic: -3855385237722507464 Time: 2.58035
[03/24/2023-12:57:05] [V] [TRT] Conv_60 + Relu_61 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize128x64x8_stage3_warpsize1x4x1_g1_ffma_t1r3s3 Tactic: -3697587361057948972
[03/24/2023-12:57:05] [V] [TRT] Tactic: -3697587361057948972 Time: 1.76013
[03/24/2023-12:57:05] [V] [TRT] Conv_60 + Relu_61 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize256x64x32_stage3_warpsize4x2x1_g1_tensor16x8x8 Tactic: -3540975627865078064
[03/24/2023-12:57:06] [V] [TRT] Tactic: -3540975627865078064 Time: 0.300288
[03/24/2023-12:57:06] [V] [TRT] Conv_60 + Relu_61 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize64x128x32_stage5_warpsize2x2x1_g1_tensor16x8x8_t1r3s3 Tactic: -3151804561246216835
[03/24/2023-12:57:06] [V] [TRT] Tactic: -3151804561246216835 Time: 0.401664
[03/24/2023-12:57:06] [V] [TRT] Conv_60 + Relu_61 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize64x32x64_stage5_warpsize2x2x1_g1_tensor16x8x8 Tactic: -2885165284206163001
[03/24/2023-12:57:06] [V] [TRT] Tactic: -2885165284206163001 Time: 0.466048
[03/24/2023-12:57:06] [V] [TRT] Conv_60 + Relu_61 Set Tactic Name: ampere_scudnn_128x128_relu_exp_medium_nhwc_tn_v1 Tactic: -2809379259463049391
[03/24/2023-12:57:06] [V] [TRT] Tactic: -2809379259463049391 Time: 2.57894
[03/24/2023-12:57:06] [V] [TRT] Conv_60 + Relu_61 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x128x32_stage4_warpsize2x2x1_g1_tensor16x8x8_t1r3s3 Tactic: -2801041895330778813
[03/24/2023-12:57:06] [V] [TRT] Tactic: -2801041895330778813 Time: 0.41984
[03/24/2023-12:57:06] [V] [TRT] Conv_60 + Relu_61 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize64x256x8_stage3_warpsize1x4x1_g1_ffma_t1r3s3 Tactic: -2747929399988666512
[03/24/2023-12:57:06] [V] [TRT] Tactic: -2747929399988666512 Time: 5.09734
[03/24/2023-12:57:06] [V] [TRT] Conv_60 + Relu_61 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize256x128x32_stage3_warpsize4x2x1_g1_tensor16x8x8 Tactic: -1758690179295738332
[03/24/2023-12:57:06] [V] [TRT] Tactic: -1758690179295738332 Time: 0.512512
[03/24/2023-12:57:06] [V] [TRT] Conv_60 + Relu_61 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x64x64_stage3_warpsize2x2x1_g1_tensor16x8x8_t1r3s3 Tactic: -1484546572846226796
[03/24/2023-12:57:06] [V] [TRT] Tactic: -1484546572846226796 Time: 0.25664
[03/24/2023-12:57:06] [V] [TRT] Conv_60 + Relu_61 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize64x256x8_stage3_warpsize1x4x1_g1_ffma Tactic: -1472061967969061456
[03/24/2023-12:57:06] [V] [TRT] Tactic: -1472061967969061456 Time: 4.41062
[03/24/2023-12:57:06] [V] [TRT] Conv_60 + Relu_61 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x128x32_stage4_warpsize2x2x1_g1_tensor16x8x8 Tactic: -858667497925695276
[03/24/2023-12:57:06] [V] [TRT] Tactic: -858667497925695276 Time: 0.662528
[03/24/2023-12:57:06] [V] [TRT] Conv_60 + Relu_61 Set Tactic Name: ampere_scudnn_128x128_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: -504296718212024303
[03/24/2023-12:57:06] [V] [TRT] Tactic: -504296718212024303 Time: 2.55923
[03/24/2023-12:57:06] [V] [TRT] Conv_60 + Relu_61 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize64x128x8_stage3_warpsize1x4x1_g1_ffma Tactic: -444093195553988951
[03/24/2023-12:57:06] [V] [TRT] Tactic: -444093195553988951 Time: 2.24576
[03/24/2023-12:57:06] [V] [TRT] Fastest Tactic: 8836645772682419994 Time: 0.249728
[03/24/2023-12:57:06] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: 8836645772682419994
[03/24/2023-12:57:06] [V] [TRT] *************** Autotuning format combination: Half(16588800,32400,180,1) -> Half(2073600,32400,180,1) ***************
[03/24/2023-12:57:06] [V] [TRT] --------------- Timing Runner: Conv_60 + Relu_61 (CudnnConvolution)
[03/24/2023-12:57:06] [V] [TRT] Tactic: 0 Time: 3.1049
[03/24/2023-12:57:06] [V] [TRT] Tactic: 1 Time: 1.63955
[03/24/2023-12:57:06] [V] [TRT] Tactic: 2 Time: 3.22419
[03/24/2023-12:57:06] [V] [TRT] Tactic: 4 skipped. Scratch requested: 17585799168, available: 4294967296
[03/24/2023-12:57:06] [V] [TRT] Tactic: 5 Time: 4.36352
[03/24/2023-12:57:06] [V] [TRT] Tactic: 6 Time: 0.769664
[03/24/2023-12:57:06] [V] [TRT] Tactic: 56 Time: 3.10298
[03/24/2023-12:57:06] [V] [TRT] Tactic: 58 Time: 3.22458
[03/24/2023-12:57:06] [V] [TRT] Tactic: 60 skipped. Scratch requested: 17585799168, available: 4294967296
[03/24/2023-12:57:06] [V] [TRT] Tactic: 61 Time: 4.36531
[03/24/2023-12:57:06] [V] [TRT] Tactic: 62 Time: 0.76992
[03/24/2023-12:57:06] [V] [TRT] Fastest Tactic: 6 Time: 0.769664
[03/24/2023-12:57:06] [V] [TRT] Setting workspace to 17585799168enables more tactics for profiling
[03/24/2023-12:57:06] [V] [TRT] --------------- Timing Runner: Conv_60 + Relu_61 (CaskConvolution)
[03/24/2023-12:57:06] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[03/24/2023-12:57:06] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CudnnConvolution Tactic: 6
[03/24/2023-12:57:06] [V] [TRT] *************** Autotuning format combination: Half(8294400,32400:2,180,1) -> Half(1036800,32400:2,180,1) ***************
[03/24/2023-12:57:06] [V] [TRT] --------------- Timing Runner: Conv_60 + Relu_61 (FusedConvActConvolution)
[03/24/2023-12:57:06] [V] [TRT] Tactic: 524287 Time: 0.568448
[03/24/2023-12:57:06] [V] [TRT] Tactic: 720895 Time: 0.517504
[03/24/2023-12:57:07] [V] [TRT] Tactic: 983039 Time: 0.48704
[03/24/2023-12:57:07] [V] [TRT] Tactic: 1048575 Time: 0.518272
[03/24/2023-12:57:07] [V] [TRT] Tactic: 1703935 Time: 0.490368
[03/24/2023-12:57:07] [V] [TRT] Tactic: 1769471 Time: 0.56064
[03/24/2023-12:57:07] [V] [TRT] Tactic: 1966079 Time: 0.558976
[03/24/2023-12:57:07] [V] [TRT] Tactic: 2031615 Time: 0.449664
[03/24/2023-12:57:07] [V] [TRT] Tactic: 2228223 Time: 0.555008
[03/24/2023-12:57:07] [V] [TRT] Tactic: 2424831 Time: 0.551424
[03/24/2023-12:57:07] [V] [TRT] Tactic: 2621439 Time: 0.497792
[03/24/2023-12:57:07] [V] [TRT] Tactic: 2752511 Time: 0.49408
[03/24/2023-12:57:07] [V] [TRT] Tactic: 2818047 Time: 0.953728
[03/24/2023-12:57:07] [V] [TRT] Tactic: 2883583 Time: 1.04384
[03/24/2023-12:57:07] [V] [TRT] Tactic: 3014655 Time: 0.50048
[03/24/2023-12:57:07] [V] [TRT] Tactic: 3145727 Time: 0.444032
[03/24/2023-12:57:07] [V] [TRT] Tactic: 3473407 Time: 0.896384
[03/24/2023-12:57:07] [V] [TRT] Tactic: 3604479 Time: 0.523648
[03/24/2023-12:57:07] [V] [TRT] Tactic: 3735551 Time: 0.981504
[03/24/2023-12:57:07] [V] [TRT] Tactic: 4390911 Time: 0.5824
[03/24/2023-12:57:07] [V] [TRT] Tactic: 5046271 Time: 0.52928
[03/24/2023-12:57:07] [V] [TRT] Tactic: 5963775 Time: 0.520704
[03/24/2023-12:57:07] [V] [TRT] Tactic: 6160383 Time: 0.564352
[03/24/2023-12:57:07] [V] [TRT] Tactic: 6488063 Time: 0.549888
[03/24/2023-12:57:07] [V] [TRT] Tactic: 6881279 Time: 0.5216
[03/24/2023-12:57:07] [V] [TRT] Tactic: 7274495 Time: 0.538496
[03/24/2023-12:57:07] [V] [TRT] Tactic: 7864319 Time: 0.496128
[03/24/2023-12:57:08] [V] [TRT] Tactic: 7995391 Time: 0.589184
[03/24/2023-12:57:08] [V] [TRT] Tactic: 8585215 Time: 0.564224
[03/24/2023-12:57:08] [V] [TRT] Tactic: 8847359 Time: 0.490752
[03/24/2023-12:57:08] [V] [TRT] Tactic: 8978431 Time: 0.548992
[03/24/2023-12:57:08] [V] [TRT] Tactic: 9043967 Time: 0.481536
[03/24/2023-12:57:08] [V] [TRT] Tactic: 9175039 Time: 0.52352
[03/24/2023-12:57:08] [V] [TRT] Tactic: 9502719 Time: 0.577152
[03/24/2023-12:57:08] [V] [TRT] Tactic: 9830399 Time: 1.02016
[03/24/2023-12:57:08] [V] [TRT] Tactic: 9961471 Time: 0.60864
[03/24/2023-12:57:08] [V] [TRT] Tactic: 10027007 Time: 0.48064
[03/24/2023-12:57:08] [V] [TRT] Tactic: 10092543 Time: 0.5824
[03/24/2023-12:57:08] [V] [TRT] Tactic: 10289151 Time: 0.558848
[03/24/2023-12:57:08] [V] [TRT] Tactic: 10485759 Time: 0.473984
[03/24/2023-12:57:08] [V] [TRT] Tactic: 10682367 Time: 0.518016
[03/24/2023-12:57:08] [V] [TRT] Tactic: 10813439 Time: 0.573952
[03/24/2023-12:57:08] [V] [TRT] Fastest Tactic: 3145727 Time: 0.444032
[03/24/2023-12:57:08] [V] [TRT] --------------- Timing Runner: Conv_60 + Relu_61 (CudnnConvolution)
[03/24/2023-12:57:08] [V] [TRT] CudnnConvolution has no valid tactics for this config, skipping
[03/24/2023-12:57:08] [V] [TRT] --------------- Timing Runner: Conv_60 + Relu_61 (CaskConvolution)
[03/24/2023-12:57:08] [V] [TRT] Conv_60 + Relu_61 Set Tactic Name: ampere_fp16x2_hcudnn_fp16x2_128x32_relu_medium_nn_v1 Tactic: 2195670545862694453
[03/24/2023-12:57:08] [V] [TRT] Tactic: 2195670545862694453 Time: 0.760576
[03/24/2023-12:57:08] [V] [TRT] Conv_60 + Relu_61 Set Tactic Name: ampere_fp16x2_hcudnn_fp16x2_128x64_relu_large_nn_v1 Tactic: 3419182076704469245
[03/24/2023-12:57:08] [V] [TRT] Tactic: 3419182076704469245 Time: 0.72896
[03/24/2023-12:57:08] [V] [TRT] Conv_60 + Relu_61 Set Tactic Name: ampere_fp16x2_hcudnn_fp16x2_128x128_relu_medium_nn_v1 Tactic: 3891805945559659536
[03/24/2023-12:57:08] [V] [TRT] Tactic: 3891805945559659536 Time: 1.31712
[03/24/2023-12:57:08] [V] [TRT] Conv_60 + Relu_61 Set Tactic Name: ampere_fp16x2_hcudnn_fp16x2_128x64_relu_medium_nn_v1 Tactic: 5548126322150286555
[03/24/2023-12:57:08] [V] [TRT] Tactic: 5548126322150286555 Time: 0.717952
[03/24/2023-12:57:08] [V] [TRT] Conv_60 + Relu_61 Set Tactic Name: ampere_fp16x2_hcudnn_fp16x2_128x64_relu_small_nn_v1 Tactic: 6057304366605292508
[03/24/2023-12:57:08] [V] [TRT] Tactic: 6057304366605292508 Time: 0.704256
[03/24/2023-12:57:08] [V] [TRT] Conv_60 + Relu_61 Set Tactic Name: ampere_fp16x2_hcudnn_fp16x2_128x128_relu_large_nn_v1 Tactic: -7928611605886347652
[03/24/2023-12:57:08] [V] [TRT] Tactic: -7928611605886347652 Time: 1.36307
[03/24/2023-12:57:08] [V] [TRT] Conv_60 + Relu_61 Set Tactic Name: ampere_fp16x2_hcudnn_fp16x2_128x32_relu_large_nn_v1 Tactic: -5172391392092686714
[03/24/2023-12:57:08] [V] [TRT] Tactic: -5172391392092686714 Time: 0.759552
[03/24/2023-12:57:08] [V] [TRT] Conv_60 + Relu_61 Set Tactic Name: ampere_fp16x2_hcudnn_fp16x2_128x32_relu_small_nn_v1 Tactic: -4374269919094467161
[03/24/2023-12:57:08] [V] [TRT] Tactic: -4374269919094467161 Time: 0.736896
[03/24/2023-12:57:08] [V] [TRT] Conv_60 + Relu_61 Set Tactic Name: ampere_fp16x2_hcudnn_winograd_fp16x2_128x128_ldg1_ldg4_relu_tile148t_nt_v1 Tactic: -4083394051665370953
[03/24/2023-12:57:08] [V] [TRT] Tactic: -4083394051665370953 Time: 0.331776
[03/24/2023-12:57:08] [V] [TRT] Conv_60 + Relu_61 Set Tactic Name: ampere_fp16x2_hcudnn_fp16x2_128x128_relu_small_nn_v1 Tactic: -1546027692247304867
[03/24/2023-12:57:08] [V] [TRT] Tactic: -1546027692247304867 Time: 1.33197
[03/24/2023-12:57:08] [V] [TRT] Fastest Tactic: -4083394051665370953 Time: 0.331776
[03/24/2023-12:57:08] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: -4083394051665370953
[03/24/2023-12:57:08] [V] [TRT] *************** Autotuning format combination: Half(2073600,1:8,11520,64) -> Float(2073600,32400,180,1) ***************
[03/24/2023-12:57:08] [V] [TRT] --------------- Timing Runner: Conv_60 + Relu_61 (CudnnConvolution)
[03/24/2023-12:57:08] [V] [TRT] CudnnConvolution has no valid tactics for this config, skipping
[03/24/2023-12:57:08] [V] [TRT] --------------- Timing Runner: Conv_60 + Relu_61 (CaskConvolution)
[03/24/2023-12:57:08] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[03/24/2023-12:57:08] [V] [TRT] *************** Autotuning format combination: Half(2073600,1:8,11520,64) -> Half(259200,1:8,1440,8) ***************
[03/24/2023-12:57:08] [V] [TRT] --------------- Timing Runner: Conv_60 + Relu_61 (CudaDepthwiseConvolution)
[03/24/2023-12:57:08] [V] [TRT] CudaDepthwiseConvolution has no valid tactics for this config, skipping
[03/24/2023-12:57:08] [V] [TRT] --------------- Timing Runner: Conv_60 + Relu_61 (CudnnConvolution)
[03/24/2023-12:57:08] [V] [TRT] Tactic: 0 Time: 3.4007
[03/24/2023-12:57:08] [V] [TRT] Tactic: 1 Time: 3.02413
[03/24/2023-12:57:09] [V] [TRT] Tactic: 2 Time: 4.10086
[03/24/2023-12:57:09] [V] [TRT] Tactic: 6 Time: 0.769408
[03/24/2023-12:57:09] [V] [TRT] Tactic: 56 Time: 3.40109
[03/24/2023-12:57:09] [V] [TRT] Tactic: 58 Time: 4.10829
[03/24/2023-12:57:09] [V] [TRT] Tactic: 62 Time: 0.769408
[03/24/2023-12:57:09] [V] [TRT] Fastest Tactic: 6 Time: 0.769408
[03/24/2023-12:57:09] [V] [TRT] --------------- Timing Runner: Conv_60 + Relu_61 (CaskConvolution)
[03/24/2023-12:57:09] [V] [TRT] Conv_60 + Relu_61 Set Tactic Name: ampere_h16816cudnn_256x128_ldg8_relu_exp_medium_nhwc_tn_v1 Tactic: 254850674756030979
[03/24/2023-12:57:09] [V] [TRT] Tactic: 254850674756030979 Time: 0.253312
[03/24/2023-12:57:09] [V] [TRT] Conv_60 + Relu_61 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x128x32_stage3_warpsize4x2x1_g1_tensor16x8x16_t1r3s3 Tactic: 328038211831149625
[03/24/2023-12:57:09] [V] [TRT] Tactic: 328038211831149625 Time: 0.234624
[03/24/2023-12:57:09] [V] [TRT] Conv_60 + Relu_61 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x64x64_stage3_warpsize2x2x1_g1_tensor16x8x16_t1r3s3 Tactic: 411553864378931917
[03/24/2023-12:57:09] [V] [TRT] Tactic: 411553864378931917 Time: 0.139008
[03/24/2023-12:57:09] [V] [TRT] Conv_60 + Relu_61 Set Tactic Name: sm75_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x128x32_stage1_warpsize4x2x1_g1_tensor16x8x8_t1r3s3 Tactic: 864841579020773074
[03/24/2023-12:57:09] [V] [TRT] Tactic: 864841579020773074 Time: 0.317184
[03/24/2023-12:57:09] [V] [TRT] Conv_60 + Relu_61 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x128x32_stage4_warpsize2x2x1_g1_tensor16x8x16 Tactic: 1011057357468998345
[03/24/2023-12:57:09] [V] [TRT] Tactic: 1011057357468998345 Time: 0.19584
[03/24/2023-12:57:09] [V] [TRT] Conv_60 + Relu_61 Set Tactic Name: sm75_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x64x32_stage1_warpsize4x1x1_g1_tensor16x8x8 Tactic: 1013168150133367738
[03/24/2023-12:57:09] [V] [TRT] Tactic: 1013168150133367738 Time: 0.224128
[03/24/2023-12:57:09] [V] [TRT] Conv_60 + Relu_61 Set Tactic Name: ampere_h16816cudnn_256x128_ldg8_relu_exp_stages_64x3_small_nhwc_tn_v1 Tactic: 1016009564074305832
[03/24/2023-12:57:09] [V] [TRT] Tactic: 1016009564074305832 Time: 0.236544
[03/24/2023-12:57:09] [V] [TRT] Conv_60 + Relu_61 Set Tactic Name: sm75_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x128x32_stage1_warpsize2x2x1_g1_tensor16x8x8 Tactic: 1067227531433278814
[03/24/2023-12:57:09] [V] [TRT] Tactic: 1067227531433278814 Time: 0.278784
[03/24/2023-12:57:09] [V] [TRT] Conv_60 + Relu_61 Set Tactic Name: ampere_h1688cudnn_128x128_ldg8_relu_exp_medium_nhwc_tn_v1 Tactic: 1156328698016730421
[03/24/2023-12:57:09] [V] [TRT] Tactic: 1156328698016730421 Time: 0.287104
[03/24/2023-12:57:09] [V] [TRT] Conv_60 + Relu_61 Set Tactic Name: sm75_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x128x32_stage1_warpsize2x2x1_g1_tensor16x8x8 Tactic: 1579845938601132607
[03/24/2023-12:57:09] [V] [TRT] Tactic: 1579845938601132607 Time: 0.269568
[03/24/2023-12:57:09] [V] [TRT] Conv_60 + Relu_61 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x128x32_stage5_warpsize2x2x1_g1_tensor16x8x16_t1r3s3 Tactic: 1723736032573714698
[03/24/2023-12:57:09] [V] [TRT] Tactic: 1723736032573714698 Time: 0.175488
[03/24/2023-12:57:09] [V] [TRT] Conv_60 + Relu_61 Set Tactic Name: sm75_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x32x32_stage1_warpsize4x1x1_g1_tensor16x8x8 Tactic: 1796821236841789338
[03/24/2023-12:57:09] [V] [TRT] Tactic: 1796821236841789338 Time: 0.249216
[03/24/2023-12:57:09] [V] [TRT] Conv_60 + Relu_61 Set Tactic Name: ampere_h16816cudnn_128x64_ldg8_relu_exp_stages_64x4_medium_nhwc_tn_v1 Tactic: 1832046141070096030
[03/24/2023-12:57:09] [V] [TRT] Tactic: 1832046141070096030 Time: 0.12416
[03/24/2023-12:57:09] [V] [TRT] Conv_60 + Relu_61 Set Tactic Name: ampere_h16816cudnn_128x64_sliced1x2_ldg8_relu_exp_stages_64x3_small_nhwc_tn_v1 Tactic: 1838082074606840426
[03/24/2023-12:57:09] [V] [TRT] Tactic: 1838082074606840426 Time: 0.123904
[03/24/2023-12:57:09] [V] [TRT] Conv_60 + Relu_61 Set Tactic Name: ampere_h16816cudnn_64x64_sliced1x2_ldg8_relu_exp_stages_64x5_small_nhwc_tn_v1 Tactic: 1899296423087490472
[03/24/2023-12:57:09] [V] [TRT] Tactic: 1899296423087490472 Time: 0.140672
[03/24/2023-12:57:09] [V] [TRT] Conv_60 + Relu_61 Set Tactic Name: sm75_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x32x32_stage1_warpsize4x1x1_g1_tensor16x8x8 Tactic: 1948263663414159978
[03/24/2023-12:57:09] [V] [TRT] Tactic: 1948263663414159978 Time: 0.22976
[03/24/2023-12:57:09] [V] [TRT] Conv_60 + Relu_61 Set Tactic Name: sm75_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x256x64_stage1_warpsize1x4x2_g1_tensor16x8x8 Tactic: 2027733232253711640
[03/24/2023-12:57:09] [V] [TRT] Tactic: 2027733232253711640 Time: 0.402176
[03/24/2023-12:57:09] [V] [TRT] Conv_60 + Relu_61 Set Tactic Name: sm75_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x64x32_stage1_warpsize2x2x1_g1_tensor16x8x8_t1r3s3 Tactic: 2154731107061273008
[03/24/2023-12:57:09] [V] [TRT] Tactic: 2154731107061273008 Time: 0.19264
[03/24/2023-12:57:09] [V] [TRT] Conv_60 + Relu_61 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x64x64_stage3_warpsize2x2x1_g1_tensor16x8x16 Tactic: 2428167804343994714
[03/24/2023-12:57:09] [V] [TRT] Tactic: 2428167804343994714 Time: 0.12352
[03/24/2023-12:57:09] [V] [TRT] Conv_60 + Relu_61 Set Tactic Name: ampere_h16816cudnn_128x128_ldg8_relu_exp_medium_nhwc_tn_v1 Tactic: 2541579301352125276
[03/24/2023-12:57:09] [V] [TRT] Tactic: 2541579301352125276 Time: 0.198912
[03/24/2023-12:57:09] [V] [TRT] Conv_60 + Relu_61 Set Tactic Name: ampere_h16816cudnn_64x64_sliced1x2_ldg8_relu_exp_stages_64x6_small_nhwc_tn_v1 Tactic: 2657157263811141609
[03/24/2023-12:57:09] [V] [TRT] Tactic: 2657157263811141609 Time: 0.120832
[03/24/2023-12:57:09] [V] [TRT] Conv_60 + Relu_61 Set Tactic Name: ampere_h16816cudnn_64x128_sliced1x2_ldg8_relu_exp_stages_64x4_large_nhwc_tn_v1 Tactic: 2819719497590964443
[03/24/2023-12:57:09] [V] [TRT] Tactic: 2819719497590964443 Time: 0.187264
[03/24/2023-12:57:09] [V] [TRT] Conv_60 + Relu_61 Set Tactic Name: ampere_h16816cudnn_128x64_sliced1x2_ldg8_relu_exp_stages_64x3_medium_nhwc_tn_v1 Tactic: 2968605903460894194
[03/24/2023-12:57:09] [V] [TRT] Tactic: 2968605903460894194 Time: 0.125824
[03/24/2023-12:57:09] [V] [TRT] Conv_60 + Relu_61 Set Tactic Name: ampere_h16816cudnn_128x128_ldg8_relu_exp_large_nhwc_tn_v1 Tactic: 2986078304285316765
[03/24/2023-12:57:09] [V] [TRT] Tactic: 2986078304285316765 Time: 0.201984
[03/24/2023-12:57:09] [V] [TRT] Conv_60 + Relu_61 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x256x64_stage3_warpsize1x4x1_g1_tensor16x8x16 Tactic: 3016308193087082166
[03/24/2023-12:57:09] [V] [TRT] Tactic: 3016308193087082166 Time: 0.304512
[03/24/2023-12:57:09] [V] [TRT] Conv_60 + Relu_61 Set Tactic Name: ampere_h16816cudnn_256x64_ldg8_relu_exp_stages_64x3_large_nhwc_tn_v1 Tactic: 3221382575080507859
[03/24/2023-12:57:09] [V] [TRT] Tactic: 3221382575080507859 Time: 0.13248
[03/24/2023-12:57:09] [V] [TRT] Conv_60 + Relu_61 Set Tactic Name: ampere_h16816cudnn_128x128_ldg8_relu_exp_stages_64x3_medium_nhwc_tn_v1 Tactic: 3362537467505018070
[03/24/2023-12:57:09] [V] [TRT] Tactic: 3362537467505018070 Time: 0.190848
[03/24/2023-12:57:09] [V] [TRT] Conv_60 + Relu_61 Set Tactic Name: sm75_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x64x32_stage1_warpsize4x1x1_g1_tensor16x8x8_t1r3s3 Tactic: 3464689803495983377
[03/24/2023-12:57:09] [V] [TRT] Tactic: 3464689803495983377 Time: 0.209152
[03/24/2023-12:57:09] [V] [TRT] Conv_60 + Relu_61 Set Tactic Name: ampere_h1688cudnn_256x128_ldg8_relu_exp_medium_nhwc_tn_v1 Tactic: 3513075359009385578
[03/24/2023-12:57:09] [V] [TRT] Tactic: 3513075359009385578 Time: 0.306432
[03/24/2023-12:57:09] [V] [TRT] Conv_60 + Relu_61 Set Tactic Name: ampere_h16816cudnn_128x64_ldg8_relu_exp_stages_64x4_large_nhwc_tn_v1 Tactic: 3573559043797674382
[03/24/2023-12:57:09] [V] [TRT] Tactic: 3573559043797674382 Time: 0.126464
[03/24/2023-12:57:09] [V] [TRT] Conv_60 + Relu_61 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x64x64_stage4_warpsize2x2x1_g1_tensor16x8x16_t1r3s3 Tactic: 3591970081995419777
[03/24/2023-12:57:09] [V] [TRT] Tactic: 3591970081995419777 Time: 0.15296
[03/24/2023-12:57:09] [V] [TRT] Conv_60 + Relu_61 Set Tactic Name: sm75_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x128x32_stage1_warpsize2x2x1_g1_tensor16x8x8_t1r3s3 Tactic: 3636831327753843771
[03/24/2023-12:57:09] [V] [TRT] Tactic: 3636831327753843771 Time: 0.226432
[03/24/2023-12:57:09] [V] [TRT] Conv_60 + Relu_61 Set Tactic Name: ampere_h1688cudnn_128x128_ldg8_relu_exp_small_nhwc_tn_v1 Tactic: 3704534001553878387
[03/24/2023-12:57:09] [V] [TRT] Tactic: 3704534001553878387 Time: 0.29376
[03/24/2023-12:57:09] [V] [TRT] Conv_60 + Relu_61 Set Tactic Name: ampere_h16816cudnn_64x128_ldg8_relu_exp_stages_64x4_small_nhwc_tn_v1 Tactic: 4278315135102886928
[03/24/2023-12:57:09] [V] [TRT] Tactic: 4278315135102886928 Time: 0.189696
[03/24/2023-12:57:09] [V] [TRT] Conv_60 + Relu_61 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x32x32_stage4_warpsize4x1x1_g1_tensor16x8x16_t1r3s3 Tactic: 4503233883285355107
[03/24/2023-12:57:09] [V] [TRT] Tactic: 4503233883285355107 Time: 0.179456
[03/24/2023-12:57:09] [V] [TRT] Conv_60 + Relu_61 Set Tactic Name: ampere_h16816cudnn_256x64_ldg8_relu_exp_stages_64x3_medium_nhwc_tn_v1 Tactic: 4540505769798915372
[03/24/2023-12:57:09] [V] [TRT] Tactic: 4540505769798915372 Time: 0.132224
[03/24/2023-12:57:09] [V] [TRT] Conv_60 + Relu_61 Set Tactic Name: ampere_h16816cudnn_256x64_sliced1x2_ldg8_relu_exp_small_nhwc_tn_v1 Tactic: 4802447371470387646
[03/24/2023-12:57:09] [V] [TRT] Tactic: 4802447371470387646 Time: 0.194816
[03/24/2023-12:57:09] [V] [TRT] Conv_60 + Relu_61 Set Tactic Name: ampere_h16816cudnn_256x128_ldg8_relu_exp_small_nhwc_tn_v1 Tactic: 5059676457552313631
[03/24/2023-12:57:09] [V] [TRT] Tactic: 5059676457552313631 Time: 0.244608
[03/24/2023-12:57:09] [V] [TRT] Conv_60 + Relu_61 Set Tactic Name: sm75_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x128x64_stage1_warpsize2x2x1_g1_tensor16x8x8_t1r3s3 Tactic: 5263029549013613567
[03/24/2023-12:57:09] [V] [TRT] Tactic: 5263029549013613567 Time: 0.21632
[03/24/2023-12:57:09] [V] [TRT] Conv_60 + Relu_61 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x64x64_stage4_warpsize2x2x1_g1_tensor16x8x16 Tactic: 5368829646735632944
[03/24/2023-12:57:09] [V] [TRT] Tactic: 5368829646735632944 Time: 0.151168
[03/24/2023-12:57:09] [V] [TRT] Conv_60 + Relu_61 Set Tactic Name: ampere_h1688cudnn_256x64_sliced1x2_ldg8_relu_exp_small_nhwc_tn_v1 Tactic: 5398999388616959893
[03/24/2023-12:57:09] [V] [TRT] Tactic: 5398999388616959893 Time: 0.193024
[03/24/2023-12:57:09] [V] [TRT] Conv_60 + Relu_61 Set Tactic Name: sm75_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x256x32_stage1_warpsize2x4x1_g1_tensor16x8x8_t1r3s3 Tactic: 5506334059535811602
[03/24/2023-12:57:09] [V] [TRT] Tactic: 5506334059535811602 Time: 0.426624
[03/24/2023-12:57:09] [V] [TRT] Conv_60 + Relu_61 Set Tactic Name: ampere_h16816cudnn_64x128_sliced1x2_ldg8_relu_exp_stages_64x3_large_nhwc_tn_v1 Tactic: 5746691132547383910
[03/24/2023-12:57:09] [V] [TRT] Tactic: 5746691132547383910 Time: 0.1696
[03/24/2023-12:57:09] [V] [TRT] Conv_60 + Relu_61 Set Tactic Name: ampere_h16816cudnn_256x64_ldg8_relu_exp_large_nhwc_tn_v1 Tactic: 5770170567977052602
[03/24/2023-12:57:09] [V] [TRT] Tactic: 5770170567977052602 Time: 0.178432
[03/24/2023-12:57:09] [V] [TRT] Conv_60 + Relu_61 Set Tactic Name: sm75_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x32x64_stage1_warpsize2x1x2_g1_tensor16x8x8_t1r3s3 Tactic: 5932046018238429951
[03/24/2023-12:57:09] [V] [TRT] Tactic: 5932046018238429951 Time: 0.202368
[03/24/2023-12:57:09] [V] [TRT] Conv_60 + Relu_61 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x64x32_stage3_warpsize4x1x1_g1_tensor16x8x16_t1r3s3 Tactic: 5953552212833506549
[03/24/2023-12:57:09] [V] [TRT] Tactic: 5953552212833506549 Time: 0.131584
[03/24/2023-12:57:09] [V] [TRT] Conv_60 + Relu_61 Set Tactic Name: ampere_h16816cudnn_64x128_ldg8_relu_exp_stages_64x3_small_nhwc_tn_v1 Tactic: 6034364043891107501
[03/24/2023-12:57:09] [V] [TRT] Tactic: 6034364043891107501 Time: 0.190976
[03/24/2023-12:57:09] [V] [TRT] Conv_60 + Relu_61 Set Tactic Name: ampere_h16816cudnn_64x64_ldg8_relu_exp_stages_64x5_large_nhwc_tn_v1 Tactic: 6074229447555668232
[03/24/2023-12:57:09] [V] [TRT] Tactic: 6074229447555668232 Time: 0.168576
[03/24/2023-12:57:09] [V] [TRT] Conv_60 + Relu_61 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x64x64_stage3_warpsize2x2x1_g1_tensor16x8x16 Tactic: 6154447660803990543
[03/24/2023-12:57:09] [V] [TRT] Tactic: 6154447660803990543 Time: 0.127744
[03/24/2023-12:57:09] [V] [TRT] Conv_60 + Relu_61 Set Tactic Name: sm75_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x32x64_stage1_warpsize2x1x2_g1_tensor16x8x8 Tactic: 6195603576432354734
[03/24/2023-12:57:09] [V] [TRT] Tactic: 6195603576432354734 Time: 0.207616
[03/24/2023-12:57:09] [V] [TRT] Conv_60 + Relu_61 Set Tactic Name: sm75_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x32x32_stage1_warpsize4x1x1_g1_tensor16x8x8_t1r3s3 Tactic: 6252808259936499253
[03/24/2023-12:57:09] [V] [TRT] Tactic: 6252808259936499253 Time: 0.22912
[03/24/2023-12:57:09] [V] [TRT] Conv_60 + Relu_61 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x128x64_stage3_warpsize2x2x1_g1_tensor16x8x16 Tactic: 6325769668000961702
[03/24/2023-12:57:09] [V] [TRT] Tactic: 6325769668000961702 Time: 0.184704
[03/24/2023-12:57:09] [V] [TRT] Conv_60 + Relu_61 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x32x64_stage5_warpsize2x2x1_g1_tensor16x8x16 Tactic: 6350273239113254096
[03/24/2023-12:57:09] [V] [TRT] Tactic: 6350273239113254096 Time: 0.197888
[03/24/2023-12:57:09] [V] [TRT] Conv_60 + Relu_61 Set Tactic Name: ampere_h16816cudnn_128x128_ldg8_relu_exp_stages_64x3_small_nhwc_tn_v1 Tactic: 6377497238381488891
[03/24/2023-12:57:09] [V] [TRT] Tactic: 6377497238381488891 Time: 0.191616
[03/24/2023-12:57:09] [V] [TRT] Conv_60 + Relu_61 Set Tactic Name: sm75_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x64x64_stage1_warpsize2x2x1_g1_tensor16x8x8 Tactic: 6408235920257988861
[03/24/2023-12:57:09] [V] [TRT] Tactic: 6408235920257988861 Time: 0.166784
[03/24/2023-12:57:09] [V] [TRT] Conv_60 + Relu_61 Set Tactic Name: ampere_h16816cudnn_128x64_ldg8_relu_exp_stages_64x3_large_nhwc_tn_v1 Tactic: 6446388116965632819
[03/24/2023-12:57:09] [V] [TRT] Tactic: 6446388116965632819 Time: 0.13376
[03/24/2023-12:57:09] [V] [TRT] Conv_60 + Relu_61 Set Tactic Name: ampere_h16816cudnn_128x64_sliced1x2_ldg8_relu_exp_stages_64x4_medium_nhwc_tn_v1 Tactic: 6468794451065529747
[03/24/2023-12:57:09] [V] [TRT] Tactic: 6468794451065529747 Time: 0.11584
[03/24/2023-12:57:09] [V] [TRT] Conv_60 + Relu_61 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x128x64_stage3_warpsize4x2x1_g1_tensor16x8x16 Tactic: 6509152032538119080
[03/24/2023-12:57:09] [V] [TRT] Tactic: 6509152032538119080 Time: 0.233216
[03/24/2023-12:57:09] [V] [TRT] Conv_60 + Relu_61 Set Tactic Name: ampere_h1688cudnn_256x128_ldg8_relu_exp_large_nhwc_tn_v1 Tactic: 6642277870194067185
[03/24/2023-12:57:09] [V] [TRT] Tactic: 6642277870194067185 Time: 0.310272
[03/24/2023-12:57:09] [V] [TRT] Conv_60 + Relu_61 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x256x64_stage3_warpsize1x4x1_g1_tensor16x8x16 Tactic: 6703181542003057635
[03/24/2023-12:57:09] [V] [TRT] Tactic: 6703181542003057635 Time: 0.318336
[03/24/2023-12:57:09] [V] [TRT] Conv_60 + Relu_61 Set Tactic Name: ampere_h16816cudnn_64x64_ldg8_relu_exp_stages_64x5_medium_nhwc_tn_v1 Tactic: 6859477213531075460
[03/24/2023-12:57:09] [V] [TRT] Tactic: 6859477213531075460 Time: 0.169728
[03/24/2023-12:57:09] [V] [TRT] Conv_60 + Relu_61 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x128x32_stage4_warpsize2x2x1_g1_tensor16x8x16_t1r3s3 Tactic: 6972489290272968208
[03/24/2023-12:57:09] [V] [TRT] Tactic: 6972489290272968208 Time: 0.176896
[03/24/2023-12:57:09] [V] [TRT] Conv_60 + Relu_61 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x128x32_stage3_warpsize4x2x1_g1_tensor16x8x16 Tactic: 6979044990896381511
[03/24/2023-12:57:09] [V] [TRT] Tactic: 6979044990896381511 Time: 0.23232
[03/24/2023-12:57:09] [V] [TRT] Conv_60 + Relu_61 Set Tactic Name: ampere_h1688cudnn_256x64_ldg8_relu_exp_medium_nhwc_tn_v1 Tactic: 7216571380637776659
[03/24/2023-12:57:09] [V] [TRT] Tactic: 7216571380637776659 Time: 0.216192
[03/24/2023-12:57:09] [V] [TRT] Conv_60 + Relu_61 Set Tactic Name: ampere_h16816cudnn_128x64_ldg8_relu_exp_stages_64x3_medium_nhwc_tn_v1 Tactic: 7609923741161019135
[03/24/2023-12:57:09] [V] [TRT] Tactic: 7609923741161019135 Time: 0.133888
[03/24/2023-12:57:09] [V] [TRT] Conv_60 + Relu_61 Set Tactic Name: sm75_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x64x32_stage1_warpsize2x2x1_g1_tensor16x8x8 Tactic: 7612687199567064086
[03/24/2023-12:57:09] [V] [TRT] Tactic: 7612687199567064086 Time: 0.201728
[03/24/2023-12:57:09] [V] [TRT] Conv_60 + Relu_61 Set Tactic Name: ampere_h16816cudnn_64x64_ldg8_relu_exp_stages_64x6_large_nhwc_tn_v1 Tactic: 7705739241028240201
[03/24/2023-12:57:09] [V] [TRT] Tactic: 7705739241028240201 Time: 0.147328
[03/24/2023-12:57:09] [V] [TRT] Conv_60 + Relu_61 Set Tactic Name: sm75_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x128x32_stage1_warpsize2x2x1_g1_tensor16x8x8 Tactic: 7729555994715864793
[03/24/2023-12:57:09] [V] [TRT] Tactic: 7729555994715864793 Time: 0.281856
[03/24/2023-12:57:09] [V] [TRT] Conv_60 + Relu_61 Set Tactic Name: sm75_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x64x64_stage1_warpsize2x2x1_g1_tensor16x8x8_t1r3s3 Tactic: 7849296535223586261
[03/24/2023-12:57:09] [V] [TRT] Tactic: 7849296535223586261 Time: 0.165888
[03/24/2023-12:57:09] [V] [TRT] Conv_60 + Relu_61 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x256x32_stage3_warpsize2x4x1_g1_tensor16x8x16 Tactic: 8072087735545283117
[03/24/2023-12:57:09] [V] [TRT] Tactic: 8072087735545283117 Time: 0.350464
[03/24/2023-12:57:09] [V] [TRT] Conv_60 + Relu_61 Set Tactic Name: ampere_h16816cudnn_64x64_sliced1x2_ldg8_relu_exp_stages_64x5_medium_nhwc_tn_v1 Tactic: 8101703987960976805
[03/24/2023-12:57:09] [V] [TRT] Tactic: 8101703987960976805 Time: 0.141952
[03/24/2023-12:57:09] [V] [TRT] Conv_60 + Relu_61 Set Tactic Name: ampere_h16816cudnn_128x64_sliced1x2_ldg8_relu_exp_stages_64x4_small_nhwc_tn_v1 Tactic: 8170606396342855895
[03/24/2023-12:57:09] [V] [TRT] Tactic: 8170606396342855895 Time: 0.111872
[03/24/2023-12:57:09] [V] [TRT] Conv_60 + Relu_61 Set Tactic Name: sm75_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x32x64_stage1_warpsize2x1x2_g1_tensor16x8x8 Tactic: 8455608235315878803
[03/24/2023-12:57:09] [V] [TRT] Tactic: 8455608235315878803 Time: 0.225152
[03/24/2023-12:57:09] [V] [TRT] Conv_60 + Relu_61 Set Tactic Name: sm75_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x64x64_stage1_warpsize2x2x1_g1_tensor16x8x8 Tactic: 8668812313058150080
[03/24/2023-12:57:09] [V] [TRT] Tactic: 8668812313058150080 Time: 0.178176
[03/24/2023-12:57:09] [V] [TRT] Conv_60 + Relu_61 Set Tactic Name: ampere_h1688cudnn_256x64_ldg8_relu_exp_small_nhwc_tn_v1 Tactic: 8839784824303350101
[03/24/2023-12:57:09] [V] [TRT] Tactic: 8839784824303350101 Time: 0.197248
[03/24/2023-12:57:09] [V] [TRT] Conv_60 + Relu_61 Set Tactic Name: ampere_h16816cudnn_64x64_sliced1x2_ldg8_relu_exp_stages_64x5_large_nhwc_tn_v1 Tactic: -9217371357561775773
[03/24/2023-12:57:09] [V] [TRT] Tactic: -9217371357561775773 Time: 0.1408
[03/24/2023-12:57:09] [V] [TRT] Conv_60 + Relu_61 Set Tactic Name: ampere_h16816cudnn_256x64_sliced1x2_ldg8_relu_exp_medium_nhwc_tn_v1 Tactic: -9009272790678027912
[03/24/2023-12:57:09] [V] [TRT] Tactic: -9009272790678027912 Time: 0.21568
[03/24/2023-12:57:09] [V] [TRT] Conv_60 + Relu_61 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x32x32_stage4_warpsize4x1x1_g1_tensor16x8x16 Tactic: -8985224497679592364
[03/24/2023-12:57:09] [V] [TRT] Tactic: -8985224497679592364 Time: 0.172928
[03/24/2023-12:57:09] [V] [TRT] Conv_60 + Relu_61 Set Tactic Name: ampere_h16816cudnn_128x64_sliced1x2_ldg8_relu_exp_stages_64x3_large_nhwc_tn_v1 Tactic: -8949544755481315679
[03/24/2023-12:57:09] [V] [TRT] Tactic: -8949544755481315679 Time: 0.126976
[03/24/2023-12:57:09] [V] [TRT] Conv_60 + Relu_61 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x64x64_stage3_warpsize4x1x1_g1_tensor16x8x16_t1r3s3 Tactic: -8867999442759527766
[03/24/2023-12:57:09] [V] [TRT] Tactic: -8867999442759527766 Time: 0.135296
[03/24/2023-12:57:09] [V] [TRT] Conv_60 + Relu_61 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x128x64_stage3_warpsize2x2x1_g1_tensor16x8x16 Tactic: -8759929675070720385
[03/24/2023-12:57:09] [V] [TRT] Tactic: -8759929675070720385 Time: 0.18496
[03/24/2023-12:57:09] [V] [TRT] Conv_60 + Relu_61 Set Tactic Name: ampere_h16816cudnn_64x64_ldg8_relu_exp_stages_64x6_medium_nhwc_tn_v1 Tactic: -8604374562669615024
[03/24/2023-12:57:09] [V] [TRT] Tactic: -8604374562669615024 Time: 0.143616
[03/24/2023-12:57:09] [V] [TRT] Conv_60 + Relu_61 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x128x64_stage3_warpsize4x2x1_g1_tensor16x8x16 Tactic: -8362347876645295759
[03/24/2023-12:57:09] [V] [TRT] Tactic: -8362347876645295759 Time: 0.235904
[03/24/2023-12:57:09] [V] [TRT] Conv_60 + Relu_61 Set Tactic Name: sm75_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x128x32_stage1_warpsize4x2x1_g1_tensor16x8x8 Tactic: -8254009616492665198
[03/24/2023-12:57:09] [V] [TRT] Tactic: -8254009616492665198 Time: 0.30336
[03/24/2023-12:57:09] [V] [TRT] Conv_60 + Relu_61 Set Tactic Name: ampere_h16816cudnn_256x128_ldg8_relu_exp_stages_64x3_large_nhwc_tn_v1 Tactic: -7757610000269494813
[03/24/2023-12:57:09] [V] [TRT] Tactic: -7757610000269494813 Time: 0.23936
[03/24/2023-12:57:09] [V] [TRT] Conv_60 + Relu_61 Set Tactic Name: sm75_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x128x32_stage1_warpsize4x2x1_g1_tensor16x8x8 Tactic: -7615325597099025933
[03/24/2023-12:57:09] [V] [TRT] Tactic: -7615325597099025933 Time: 0.320512
[03/24/2023-12:57:09] [V] [TRT] Conv_60 + Relu_61 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x64x64_stage3_warpsize4x1x1_g1_tensor16x8x16 Tactic: -6917689122519989488
[03/24/2023-12:57:09] [V] [TRT] Tactic: -6917689122519989488 Time: 0.142592
[03/24/2023-12:57:09] [V] [TRT] Conv_60 + Relu_61 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x32x64_stage5_warpsize2x2x1_g1_tensor16x8x16_t1r3s3 Tactic: -6902925267326201166
[03/24/2023-12:57:10] [V] [TRT] Tactic: -6902925267326201166 Time: 0.19648
[03/24/2023-12:57:10] [V] [TRT] Conv_60 + Relu_61 Set Tactic Name: ampere_h16816cudnn_64x128_ldg8_relu_exp_stages_64x4_large_nhwc_tn_v1 Tactic: -6840588038605932325
[03/24/2023-12:57:10] [V] [TRT] Tactic: -6840588038605932325 Time: 0.190976
[03/24/2023-12:57:10] [V] [TRT] Conv_60 + Relu_61 Set Tactic Name: sm75_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x32x32_stage1_warpsize4x1x1_g1_tensor16x8x8 Tactic: -6828337260021572283
[03/24/2023-12:57:10] [V] [TRT] Tactic: -6828337260021572283 Time: 0.243456
[03/24/2023-12:57:10] [V] [TRT] Conv_60 + Relu_61 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x256x32_stage3_warpsize2x4x1_g1_tensor16x8x16 Tactic: -6799856376604253964
[03/24/2023-12:57:10] [V] [TRT] Tactic: -6799856376604253964 Time: 0.345728
[03/24/2023-12:57:10] [V] [TRT] Conv_60 + Relu_61 Set Tactic Name: sm75_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x32x32_stage1_warpsize4x1x1_g1_tensor16x8x8 Tactic: -6711815420995272523
[03/24/2023-12:57:10] [V] [TRT] Tactic: -6711815420995272523 Time: 0.25344
[03/24/2023-12:57:10] [V] [TRT] Conv_60 + Relu_61 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x32x32_stage4_warpsize4x1x1_g1_tensor16x8x16_t1r3s3 Tactic: -6625722781282978136
[03/24/2023-12:57:10] [V] [TRT] Tactic: -6625722781282978136 Time: 0.209664
[03/24/2023-12:57:10] [V] [TRT] Conv_60 + Relu_61 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x64x32_stage3_warpsize4x1x1_g1_tensor16x8x16 Tactic: -6525498856028268801
[03/24/2023-12:57:10] [V] [TRT] Tactic: -6525498856028268801 Time: 0.151424
[03/24/2023-12:57:10] [V] [TRT] Conv_60 + Relu_61 Set Tactic Name: sm75_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x256x64_stage1_warpsize1x4x2_g1_tensor16x8x8 Tactic: -6489479581011009593
[03/24/2023-12:57:10] [V] [TRT] Tactic: -6489479581011009593 Time: 0.391936
[03/24/2023-12:57:10] [V] [TRT] Conv_60 + Relu_61 Set Tactic Name: ampere_h16816cudnn_64x64_sliced1x2_ldg8_relu_exp_stages_64x6_medium_nhwc_tn_v1 Tactic: -6356316196810535311
[03/24/2023-12:57:10] [V] [TRT] Tactic: -6356316196810535311 Time: 0.132352
[03/24/2023-12:57:10] [V] [TRT] Conv_60 + Relu_61 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x32x32_stage4_warpsize4x1x1_g1_tensor16x8x16 Tactic: -6324345858751792783
[03/24/2023-12:57:10] [V] [TRT] Tactic: -6324345858751792783 Time: 0.202496
[03/24/2023-12:57:10] [V] [TRT] Conv_60 + Relu_61 Set Tactic Name: sm75_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x256x64_stage1_warpsize1x4x2_g1_tensor16x8x8_t1r3s3 Tactic: -6320761427625651496
[03/24/2023-12:57:10] [V] [TRT] Tactic: -6320761427625651496 Time: 0.39104
[03/24/2023-12:57:10] [V] [TRT] Conv_60 + Relu_61 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x256x32_stage3_warpsize2x4x1_g1_tensor16x8x16_t1r3s3 Tactic: -6262400699544994312
[03/24/2023-12:57:10] [V] [TRT] Tactic: -6262400699544994312 Time: 0.34304
[03/24/2023-12:57:10] [V] [TRT] Conv_60 + Relu_61 Set Tactic Name: ampere_h1688cudnn_128x128_ldg8_relu_exp_large_nhwc_tn_v1 Tactic: -6257787336162086472
[03/24/2023-12:57:10] [V] [TRT] Tactic: -6257787336162086472 Time: 0.294656
[03/24/2023-12:57:10] [V] [TRT] Conv_60 + Relu_61 Set Tactic Name: sm75_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x128x64_stage1_warpsize2x2x1_g1_tensor16x8x8 Tactic: -6080892721161662420
[03/24/2023-12:57:10] [V] [TRT] Tactic: -6080892721161662420 Time: 0.217472
[03/24/2023-12:57:10] [V] [TRT] Conv_60 + Relu_61 Set Tactic Name: ampere_h16816cudnn_128x64_ldg8_relu_exp_stages_64x4_small_nhwc_tn_v1 Tactic: -6063766379489217211
[03/24/2023-12:57:10] [V] [TRT] Tactic: -6063766379489217211 Time: 0.123008
[03/24/2023-12:57:10] [V] [TRT] Conv_60 + Relu_61 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x128x32_stage5_warpsize2x2x1_g1_tensor16x8x16 Tactic: -5777580938094193096
[03/24/2023-12:57:10] [V] [TRT] Tactic: -5777580938094193096 Time: 0.178816
[03/24/2023-12:57:10] [V] [TRT] Conv_60 + Relu_61 Set Tactic Name: sm75_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x128x64_stage1_warpsize2x2x1_g1_tensor16x8x8 Tactic: -5710735840878760115
[03/24/2023-12:57:10] [V] [TRT] Tactic: -5710735840878760115 Time: 0.228864
[03/24/2023-12:57:10] [V] [TRT] Conv_60 + Relu_61 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x128x32_stage3_warpsize4x2x1_g1_tensor16x8x16 Tactic: -5657273398217409378
[03/24/2023-12:57:10] [V] [TRT] Tactic: -5657273398217409378 Time: 0.242048
[03/24/2023-12:57:10] [V] [TRT] Conv_60 + Relu_61 Set Tactic Name: sm75_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x128x32_stage1_warpsize2x2x1_g1_tensor16x8x8_t1r3s3 Tactic: -5546257196173962281
[03/24/2023-12:57:10] [V] [TRT] Tactic: -5546257196173962281 Time: 0.269824
[03/24/2023-12:57:10] [V] [TRT] Conv_60 + Relu_61 Set Tactic Name: ampere_h16816cudnn_128x128_ldg8_relu_exp_small_nhwc_tn_v1 Tactic: -5530886555766748586
[03/24/2023-12:57:10] [V] [TRT] Tactic: -5530886555766748586 Time: 0.196736
[03/24/2023-12:57:10] [V] [TRT] Conv_60 + Relu_61 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x64x32_stage5_warpsize2x2x1_g1_tensor16x8x16_t1r3s3 Tactic: -5422685219138380548
[03/24/2023-12:57:10] [V] [TRT] Tactic: -5422685219138380548 Time: 0.141568
[03/24/2023-12:57:10] [V] [TRT] Conv_60 + Relu_61 Set Tactic Name: ampere_h16816cudnn_256x64_ldg8_relu_exp_stages_64x3_small_nhwc_tn_v1 Tactic: -5261787675443473128
[03/24/2023-12:57:10] [V] [TRT] Tactic: -5261787675443473128 Time: 0.131712
[03/24/2023-12:57:10] [V] [TRT] Conv_60 + Relu_61 Set Tactic Name: sm75_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x64x32_stage1_warpsize4x1x1_g1_tensor16x8x8 Tactic: -5198219374380660379
[03/24/2023-12:57:10] [V] [TRT] Tactic: -5198219374380660379 Time: 0.204544
[03/24/2023-12:57:10] [V] [TRT] Conv_60 + Relu_61 Set Tactic Name: ampere_h16816cudnn_64x128_sliced1x2_ldg8_relu_exp_stages_64x3_medium_nhwc_tn_v1 Tactic: -5161596964442251102
[03/24/2023-12:57:10] [V] [TRT] Tactic: -5161596964442251102 Time: 0.167552
[03/24/2023-12:57:10] [V] [TRT] Conv_60 + Relu_61 Set Tactic Name: ampere_h16816cudnn_64x128_ldg8_relu_exp_stages_64x3_medium_nhwc_tn_v1 Tactic: -5127240325355316006
[03/24/2023-12:57:10] [V] [TRT] Tactic: -5127240325355316006 Time: 0.190848
[03/24/2023-12:57:10] [V] [TRT] Conv_60 + Relu_61 Set Tactic Name: ampere_h16816cudnn_256x128_ldg8_relu_exp_stages_64x3_medium_nhwc_tn_v1 Tactic: -5109582882231362997
[03/24/2023-12:57:10] [V] [TRT] Tactic: -5109582882231362997 Time: 0.238336
[03/24/2023-12:57:10] [V] [TRT] Conv_60 + Relu_61 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x64x32_stage5_warpsize2x2x1_g1_tensor16x8x16 Tactic: -4825567853927730435
[03/24/2023-12:57:10] [V] [TRT] Tactic: -4825567853927730435 Time: 0.1504
[03/24/2023-12:57:10] [V] [TRT] Conv_60 + Relu_61 Set Tactic Name: ampere_h16816cudnn_64x128_sliced1x2_ldg8_relu_exp_stages_64x4_small_nhwc_tn_v1 Tactic: -4796511246675321840
[03/24/2023-12:57:10] [V] [TRT] Tactic: -4796511246675321840 Time: 0.1792
[03/24/2023-12:57:10] [V] [TRT] Conv_60 + Relu_61 Set Tactic Name: ampere_h16816cudnn_64x64_sliced1x2_ldg8_relu_exp_stages_64x6_large_nhwc_tn_v1 Tactic: -4706569565442112734
[03/24/2023-12:57:10] [V] [TRT] Tactic: -4706569565442112734 Time: 0.13248
[03/24/2023-12:57:10] [V] [TRT] Conv_60 + Relu_61 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x128x64_stage3_warpsize2x2x1_g1_tensor16x8x16_t1r3s3 Tactic: -4566599693570369588
[03/24/2023-12:57:10] [V] [TRT] Tactic: -4566599693570369588 Time: 0.186624
[03/24/2023-12:57:10] [V] [TRT] Conv_60 + Relu_61 Set Tactic Name: ampere_h16816cudnn_128x128_ldg8_relu_exp_stages_64x3_large_nhwc_tn_v1 Tactic: -4409144516525410768
[03/24/2023-12:57:10] [V] [TRT] Tactic: -4409144516525410768 Time: 0.190464
[03/24/2023-12:57:10] [V] [TRT] Conv_60 + Relu_61 Set Tactic Name: ampere_h16816cudnn_128x64_ldg8_relu_exp_stages_64x3_small_nhwc_tn_v1 Tactic: -4379519430184503304
[03/24/2023-12:57:10] [V] [TRT] Tactic: -4379519430184503304 Time: 0.132736
[03/24/2023-12:57:10] [V] [TRT] Conv_60 + Relu_61 Set Tactic Name: ampere_h1688cudnn_256x128_ldg8_relu_exp_small_nhwc_tn_v1 Tactic: -4152066959007262150
[03/24/2023-12:57:10] [V] [TRT] Tactic: -4152066959007262150 Time: 0.282752
[03/24/2023-12:57:10] [V] [TRT] Conv_60 + Relu_61 Set Tactic Name: ampere_h16816cudnn_64x128_ldg8_relu_exp_stages_64x4_medium_nhwc_tn_v1 Tactic: -4021926646879732549
[03/24/2023-12:57:10] [V] [TRT] Tactic: -4021926646879732549 Time: 0.189568
[03/24/2023-12:57:10] [V] [TRT] Conv_60 + Relu_61 Set Tactic Name: ampere_h16816cudnn_64x128_sliced1x2_ldg8_relu_exp_stages_64x4_medium_nhwc_tn_v1 Tactic: -3987638434926559037
[03/24/2023-12:57:10] [V] [TRT] Tactic: -3987638434926559037 Time: 0.176768
[03/24/2023-12:57:10] [V] [TRT] Conv_60 + Relu_61 Set Tactic Name: ampere_h1688cudnn_256x64_sliced1x2_ldg8_relu_exp_medium_nhwc_tn_v1 Tactic: -3905653247016903130
[03/24/2023-12:57:10] [V] [TRT] Tactic: -3905653247016903130 Time: 0.20928
[03/24/2023-12:57:10] [V] [TRT] Conv_60 + Relu_61 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x64x32_stage5_warpsize2x2x1_g1_tensor16x8x16 Tactic: -3903974568488493144
[03/24/2023-12:57:10] [V] [TRT] Tactic: -3903974568488493144 Time: 0.132224
[03/24/2023-12:57:10] [V] [TRT] Conv_60 + Relu_61 Set Tactic Name: ampere_h16816cudnn_64x128_ldg8_relu_exp_stages_64x3_large_nhwc_tn_v1 Tactic: -3895429239811098010
[03/24/2023-12:57:10] [V] [TRT] Tactic: -3895429239811098010 Time: 0.19136
[03/24/2023-12:57:10] [V] [TRT] Conv_60 + Relu_61 Set Tactic Name: ampere_h16816cudnn_256x64_ldg8_relu_exp_small_nhwc_tn_v1 Tactic: -3864869056275745423
[03/24/2023-12:57:10] [V] [TRT] Tactic: -3864869056275745423 Time: 0.173952
[03/24/2023-12:57:10] [V] [TRT] Conv_60 + Relu_61 Set Tactic Name: sm75_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x32x32_stage1_warpsize4x1x1_g1_tensor16x8x8_t1r3s3 Tactic: -3784342055748695733
[03/24/2023-12:57:10] [V] [TRT] Tactic: -3784342055748695733 Time: 0.224128
[03/24/2023-12:57:10] [V] [TRT] Conv_60 + Relu_61 Set Tactic Name: ampere_h16816cudnn_64x64_ldg8_relu_exp_stages_64x5_small_nhwc_tn_v1 Tactic: -3601464762214218301
[03/24/2023-12:57:10] [V] [TRT] Tactic: -3601464762214218301 Time: 0.172032
[03/24/2023-12:57:10] [V] [TRT] Conv_60 + Relu_61 Set Tactic Name: sm75_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x64x32_stage1_warpsize2x2x1_g1_tensor16x8x8 Tactic: -3425274793298557239
[03/24/2023-12:57:10] [V] [TRT] Tactic: -3425274793298557239 Time: 0.19328
[03/24/2023-12:57:10] [V] [TRT] Conv_60 + Relu_61 Set Tactic Name: ampere_h1688cudnn_256x64_sliced1x2_ldg8_relu_exp_large_nhwc_tn_v1 Tactic: -3412636942650049698
[03/24/2023-12:57:10] [V] [TRT] Tactic: -3412636942650049698 Time: 0.211328
[03/24/2023-12:57:10] [V] [TRT] Conv_60 + Relu_61 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x64x32_stage3_warpsize4x1x1_g1_tensor16x8x16 Tactic: -3338665856053412950
[03/24/2023-12:57:10] [V] [TRT] Tactic: -3338665856053412950 Time: 0.131456
[03/24/2023-12:57:10] [V] [TRT] Conv_60 + Relu_61 Set Tactic Name: sm75_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x128x32_stage1_warpsize2x2x1_g1_tensor16x8x8 Tactic: -3271955096576257018
[03/24/2023-12:57:10] [V] [TRT] Tactic: -3271955096576257018 Time: 0.277248
[03/24/2023-12:57:10] [V] [TRT] Conv_60 + Relu_61 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x128x64_stage3_warpsize4x2x1_g1_tensor16x8x16_t1r3s3 Tactic: -3243541398692466074
[03/24/2023-12:57:10] [V] [TRT] Tactic: -3243541398692466074 Time: 0.236032
[03/24/2023-12:57:10] [V] [TRT] Conv_60 + Relu_61 Set Tactic Name: ampere_h16816cudnn_64x128_sliced1x2_ldg8_relu_exp_stages_64x3_small_nhwc_tn_v1 Tactic: -3058330359340425555
[03/24/2023-12:57:10] [V] [TRT] Tactic: -3058330359340425555 Time: 0.168576
[03/24/2023-12:57:10] [V] [TRT] Conv_60 + Relu_61 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x256x64_stage3_warpsize1x4x1_g1_tensor16x8x16_t1r3s3 Tactic: -2899647483672319239
[03/24/2023-12:57:10] [V] [TRT] Tactic: -2899647483672319239 Time: 0.313728
[03/24/2023-12:57:10] [V] [TRT] Conv_60 + Relu_61 Set Tactic Name: ampere_h16816cudnn_256x64_sliced1x2_ldg8_relu_exp_large_nhwc_tn_v1 Tactic: -2816084650627734155
[03/24/2023-12:57:10] [V] [TRT] Tactic: -2816084650627734155 Time: 0.217856
[03/24/2023-12:57:10] [V] [TRT] Conv_60 + Relu_61 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x128x32_stage5_warpsize2x2x1_g1_tensor16x8x16 Tactic: -2662892962457732243
[03/24/2023-12:57:10] [V] [TRT] Tactic: -2662892962457732243 Time: 0.170368
[03/24/2023-12:57:10] [V] [TRT] Conv_60 + Relu_61 Set Tactic Name: ampere_h16816cudnn_256x128_ldg8_relu_exp_large_nhwc_tn_v1 Tactic: -2559894581585337900
[03/24/2023-12:57:10] [V] [TRT] Tactic: -2559894581585337900 Time: 0.25216
[03/24/2023-12:57:10] [V] [TRT] Conv_60 + Relu_61 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x32x32_stage4_warpsize4x1x1_g1_tensor16x8x16 Tactic: -2530740716768816092
[03/24/2023-12:57:10] [V] [TRT] Tactic: -2530740716768816092 Time: 0.171136
[03/24/2023-12:57:10] [V] [TRT] Conv_60 + Relu_61 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x128x32_stage4_warpsize2x2x1_g1_tensor16x8x16 Tactic: -2332828394978346992
[03/24/2023-12:57:10] [V] [TRT] Tactic: -2332828394978346992 Time: 0.179968
[03/24/2023-12:57:10] [V] [TRT] Conv_60 + Relu_61 Set Tactic Name: ampere_h1688cudnn_256x64_ldg8_relu_exp_large_nhwc_tn_v1 Tactic: -2241736083352441442
[03/24/2023-12:57:10] [V] [TRT] Tactic: -2241736083352441442 Time: 0.216448
[03/24/2023-12:57:10] [V] [TRT] Conv_60 + Relu_61 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x32x64_stage5_warpsize2x2x1_g1_tensor16x8x16 Tactic: -2161909437867201546
[03/24/2023-12:57:10] [V] [TRT] Tactic: -2161909437867201546 Time: 0.19584
[03/24/2023-12:57:10] [V] [TRT] Conv_60 + Relu_61 Set Tactic Name: ampere_h16816cudnn_256x64_ldg8_relu_exp_medium_nhwc_tn_v1 Tactic: -1985778916402815946
[03/24/2023-12:57:10] [V] [TRT] Tactic: -1985778916402815946 Time: 0.176256
[03/24/2023-12:57:10] [V] [TRT] Conv_60 + Relu_61 Set Tactic Name: sm75_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x256x32_stage1_warpsize2x4x1_g1_tensor16x8x8 Tactic: -1708101578041178688
[03/24/2023-12:57:10] [V] [TRT] Tactic: -1708101578041178688 Time: 0.43904
[03/24/2023-12:57:10] [V] [TRT] Conv_60 + Relu_61 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x64x64_stage3_warpsize4x1x1_g1_tensor16x8x16 Tactic: -1502788097503482299
[03/24/2023-12:57:10] [V] [TRT] Tactic: -1502788097503482299 Time: 0.135424
[03/24/2023-12:57:10] [V] [TRT] Conv_60 + Relu_61 Set Tactic Name: ampere_h16816cudnn_128x64_sliced1x2_ldg8_relu_exp_stages_64x4_large_nhwc_tn_v1 Tactic: -1500496213132463076
[03/24/2023-12:57:10] [V] [TRT] Tactic: -1500496213132463076 Time: 0.120448
[03/24/2023-12:57:10] [V] [TRT] Conv_60 + Relu_61 Set Tactic Name: ampere_h16816cudnn_64x64_ldg8_relu_exp_stages_64x6_small_nhwc_tn_v1 Tactic: -1099247066487349374
[03/24/2023-12:57:10] [V] [TRT] Tactic: -1099247066487349374 Time: 0.133888
[03/24/2023-12:57:10] [V] [TRT] Conv_60 + Relu_61 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x64x64_stage4_warpsize2x2x1_g1_tensor16x8x16 Tactic: -910286698936744682
[03/24/2023-12:57:10] [V] [TRT] Tactic: -910286698936744682 Time: 0.153856
[03/24/2023-12:57:10] [V] [TRT] Conv_60 + Relu_61 Set Tactic Name: sm75_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x256x32_stage1_warpsize2x4x1_g1_tensor16x8x8 Tactic: -907287437357565279
[03/24/2023-12:57:10] [V] [TRT] Tactic: -907287437357565279 Time: 0.42816
[03/24/2023-12:57:10] [V] [TRT] Conv_60 + Relu_61 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x32x32_stage4_warpsize4x1x1_g1_tensor16x8x16 Tactic: -606726295133751039
[03/24/2023-12:57:10] [V] [TRT] Tactic: -606726295133751039 Time: 0.162048
[03/24/2023-12:57:10] [V] [TRT] Fastest Tactic: 8170606396342855895 Time: 0.111872
[03/24/2023-12:57:10] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: 8170606396342855895
[03/24/2023-12:57:10] [V] [TRT] *************** Autotuning format combination: Half(1036800,1:16,5760,32) -> Half(129600,1:16,720,4) ***************
[03/24/2023-12:57:10] [V] [TRT] --------------- Timing Runner: Conv_60 + Relu_61 (CudnnConvolution)
[03/24/2023-12:57:10] [V] [TRT] CudnnConvolution has no valid tactics for this config, skipping
[03/24/2023-12:57:10] [V] [TRT] --------------- Timing Runner: Conv_60 + Relu_61 (CaskConvolution)
[03/24/2023-12:57:10] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[03/24/2023-12:57:10] [V] [TRT] =============== Computing costs for 
[03/24/2023-12:57:10] [V] [TRT] *************** Autotuning format combination: Float(2073600,32400,180,1) -> Float(16588800,32400,180,1) ***************
[03/24/2023-12:57:10] [V] [TRT] --------------- Timing Runner: Conv_62 + Relu_63 || Conv_65 + Relu_66 || Conv_68 + Relu_69 || Conv_71 + Relu_72 || Conv_74 + Relu_75 || Conv_77 + Relu_78 || Conv_80 + Relu_81 || Conv_83 + Relu_84 (CudaDepthwiseConvolution)
[03/24/2023-12:57:10] [V] [TRT] CudaDepthwiseConvolution has no valid tactics for this config, skipping
[03/24/2023-12:57:10] [V] [TRT] --------------- Timing Runner: Conv_62 + Relu_63 || Conv_65 + Relu_66 || Conv_68 + Relu_69 || Conv_71 + Relu_72 || Conv_74 + Relu_75 || Conv_77 + Relu_78 || Conv_80 + Relu_81 || Conv_83 + Relu_84 (FusedConvActConvolution)
[03/24/2023-12:57:10] [V] [TRT] FusedConvActConvolution has no valid tactics for this config, skipping
[03/24/2023-12:57:10] [V] [TRT] --------------- Timing Runner: Conv_62 + Relu_63 || Conv_65 + Relu_66 || Conv_68 + Relu_69 || Conv_71 + Relu_72 || Conv_74 + Relu_75 || Conv_77 + Relu_78 || Conv_80 + Relu_81 || Conv_83 + Relu_84 (CudnnConvolution)
[03/24/2023-12:57:10] [V] [TRT] Tactic: 0 Time: 1.61728
[03/24/2023-12:57:10] [V] [TRT] Tactic: 1 Time: 0.531968
[03/24/2023-12:57:10] [V] [TRT] Tactic: 2 Time: 1.62726
[03/24/2023-12:57:10] [V] [TRT] Tactic: 4 skipped. Scratch requested: 17349083136, available: 4294967296
[03/24/2023-12:57:10] [V] [TRT] Tactic: 5 Time: 4.82816
[03/24/2023-12:57:10] [V] [TRT] Tactic: 6 Time: 0.836096
[03/24/2023-12:57:10] [V] [TRT] Tactic: 56 Time: 1.61587
[03/24/2023-12:57:10] [V] [TRT] Tactic: 57 Time: 0.531456
[03/24/2023-12:57:10] [V] [TRT] Tactic: 58 Time: 1.62624
[03/24/2023-12:57:10] [V] [TRT] Tactic: 60 skipped. Scratch requested: 17349083136, available: 4294967296
[03/24/2023-12:57:10] [V] [TRT] Tactic: 61 Time: 4.82675
[03/24/2023-12:57:10] [V] [TRT] Tactic: 62 Time: 0.835712
[03/24/2023-12:57:10] [V] [TRT] Tactic: 112 Time: 1.61549
[03/24/2023-12:57:11] [V] [TRT] Tactic: 113 Time: 1.32518
[03/24/2023-12:57:11] [V] [TRT] Tactic: 114 Time: 1.62739
[03/24/2023-12:57:11] [V] [TRT] Tactic: 116 skipped. Scratch requested: 17349083136, available: 4294967296
[03/24/2023-12:57:11] [V] [TRT] Tactic: 117 Time: 4.82419
[03/24/2023-12:57:11] [V] [TRT] Tactic: 118 Time: 0.836224
[03/24/2023-12:57:11] [V] [TRT] Fastest Tactic: 57 Time: 0.531456
[03/24/2023-12:57:11] [V] [TRT] Setting workspace to 17349083136enables more tactics for profiling
[03/24/2023-12:57:11] [V] [TRT] --------------- Timing Runner: Conv_62 + Relu_63 || Conv_65 + Relu_66 || Conv_68 + Relu_69 || Conv_71 + Relu_72 || Conv_74 + Relu_75 || Conv_77 + Relu_78 || Conv_80 + Relu_81 || Conv_83 + Relu_84 (CaskConvolution)
[03/24/2023-12:57:11] [V] [TRT] Conv_62 + Relu_63 || Conv_65 + Relu_66 || Conv_68 + Relu_69 || Conv_71 + Relu_72 || Conv_74 + Relu_75 || Conv_77 + Relu_78 || Conv_80 + Relu_81 || Conv_83 + Relu_84 Set Tactic Name: ampere_scudnn_128x64_relu_small_nn_v1 Tactic: 4549827808004681195
[03/24/2023-12:57:11] [V] [TRT] Tactic: 4549827808004681195 Time: 1.06765
[03/24/2023-12:57:11] [V] [TRT] Conv_62 + Relu_63 || Conv_65 + Relu_66 || Conv_68 + Relu_69 || Conv_71 + Relu_72 || Conv_74 + Relu_75 || Conv_77 + Relu_78 || Conv_80 + Relu_81 || Conv_83 + Relu_84 Set Tactic Name: ampere_scudnn_128x128_relu_small_nn_v1 Tactic: 5779835512569528575
[03/24/2023-12:57:11] [V] [TRT] Tactic: 5779835512569528575 Time: 1.08915
[03/24/2023-12:57:11] [V] [TRT] Conv_62 + Relu_63 || Conv_65 + Relu_66 || Conv_68 + Relu_69 || Conv_71 + Relu_72 || Conv_74 + Relu_75 || Conv_77 + Relu_78 || Conv_80 + Relu_81 || Conv_83 + Relu_84 Set Tactic Name: ampere_scudnn_128x128_relu_xregs_large_nn_v1 Tactic: 6053873026024413720
[03/24/2023-12:57:11] [V] [TRT] Tactic: 6053873026024413720 Time: 1.17376
[03/24/2023-12:57:11] [V] [TRT] Conv_62 + Relu_63 || Conv_65 + Relu_66 || Conv_68 + Relu_69 || Conv_71 + Relu_72 || Conv_74 + Relu_75 || Conv_77 + Relu_78 || Conv_80 + Relu_81 || Conv_83 + Relu_84 Set Tactic Name: ampere_scudnn_128x64_relu_xregs_large_nn_v1 Tactic: 6767548733843469815
[03/24/2023-12:57:11] [V] [TRT] Tactic: 6767548733843469815 Time: 1.05382
[03/24/2023-12:57:11] [V] [TRT] Conv_62 + Relu_63 || Conv_65 + Relu_66 || Conv_68 + Relu_69 || Conv_71 + Relu_72 || Conv_74 + Relu_75 || Conv_77 + Relu_78 || Conv_80 + Relu_81 || Conv_83 + Relu_84 Set Tactic Name: ampere_scudnn_128x32_relu_small_nn_v1 Tactic: -6313876406580483184
[03/24/2023-12:57:11] [V] [TRT] Tactic: -6313876406580483184 Time: 1.1904
[03/24/2023-12:57:11] [V] [TRT] Conv_62 + Relu_63 || Conv_65 + Relu_66 || Conv_68 + Relu_69 || Conv_71 + Relu_72 || Conv_74 + Relu_75 || Conv_77 + Relu_78 || Conv_80 + Relu_81 || Conv_83 + Relu_84 Set Tactic Name: ampere_scudnn_128x128_relu_medium_nn_v1 Tactic: -1123676555321336786
[03/24/2023-12:57:11] [V] [TRT] Tactic: -1123676555321336786 Time: 1.08992
[03/24/2023-12:57:11] [V] [TRT] Conv_62 + Relu_63 || Conv_65 + Relu_66 || Conv_68 + Relu_69 || Conv_71 + Relu_72 || Conv_74 + Relu_75 || Conv_77 + Relu_78 || Conv_80 + Relu_81 || Conv_83 + Relu_84 Set Tactic Name: ampere_scudnn_128x64_relu_medium_nn_v1 Tactic: -701551393537224327
[03/24/2023-12:57:11] [V] [TRT] Tactic: -701551393537224327 Time: 1.07238
[03/24/2023-12:57:11] [V] [TRT] Fastest Tactic: 6767548733843469815 Time: 1.05382
[03/24/2023-12:57:11] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CudnnConvolution Tactic: 57
[03/24/2023-12:57:11] [V] [TRT] *************** Autotuning format combination: Float(2073600,1,11520,64) -> Float(16588800,1,92160,512) ***************
[03/24/2023-12:57:11] [V] [TRT] --------------- Timing Runner: Conv_62 + Relu_63 || Conv_65 + Relu_66 || Conv_68 + Relu_69 || Conv_71 + Relu_72 || Conv_74 + Relu_75 || Conv_77 + Relu_78 || Conv_80 + Relu_81 || Conv_83 + Relu_84 (CudnnConvolution)
[03/24/2023-12:57:11] [V] [TRT] CudnnConvolution has no valid tactics for this config, skipping
[03/24/2023-12:57:11] [V] [TRT] --------------- Timing Runner: Conv_62 + Relu_63 || Conv_65 + Relu_66 || Conv_68 + Relu_69 || Conv_71 + Relu_72 || Conv_74 + Relu_75 || Conv_77 + Relu_78 || Conv_80 + Relu_81 || Conv_83 + Relu_84 (CaskConvolution)
[03/24/2023-12:57:11] [V] [TRT] Conv_62 + Relu_63 || Conv_65 + Relu_66 || Conv_68 + Relu_69 || Conv_71 + Relu_72 || Conv_74 + Relu_75 || Conv_77 + Relu_78 || Conv_80 + Relu_81 || Conv_83 + Relu_84 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize64x128x8_stage3_warpsize1x4x1_g1_ffma_t1r3s3 Tactic: 2086609538387166260
[03/24/2023-12:57:11] [V] [TRT] Tactic: 2086609538387166260 Time: 1.03872
[03/24/2023-12:57:11] [V] [TRT] Conv_62 + Relu_63 || Conv_65 + Relu_66 || Conv_68 + Relu_69 || Conv_71 + Relu_72 || Conv_74 + Relu_75 || Conv_77 + Relu_78 || Conv_80 + Relu_81 || Conv_83 + Relu_84 Set Tactic Name: ampere_scudnn_128x64_sliced1x2_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: 2860655430572478466
[03/24/2023-12:57:11] [V] [TRT] Tactic: 2860655430572478466 Time: 1.06432
[03/24/2023-12:57:11] [V] [TRT] Conv_62 + Relu_63 || Conv_65 + Relu_66 || Conv_68 + Relu_69 || Conv_71 + Relu_72 || Conv_74 + Relu_75 || Conv_77 + Relu_78 || Conv_80 + Relu_81 || Conv_83 + Relu_84 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize64x128x8_stage3_warpsize1x4x1_g1_ffma Tactic: 3239733199291090177
[03/24/2023-12:57:11] [V] [TRT] Tactic: 3239733199291090177 Time: 1.03603
[03/24/2023-12:57:11] [V] [TRT] Conv_62 + Relu_63 || Conv_65 + Relu_66 || Conv_68 + Relu_69 || Conv_71 + Relu_72 || Conv_74 + Relu_75 || Conv_77 + Relu_78 || Conv_80 + Relu_81 || Conv_83 + Relu_84 Set Tactic Name: ampere_scudnn_128x32_sliced1x4_ldg4_relu_exp_medium_nhwc_tn_v1 Tactic: 4474630279712975759
[03/24/2023-12:57:11] [V] [TRT] Tactic: 4474630279712975759 Time: 1.09274
[03/24/2023-12:57:11] [V] [TRT] Conv_62 + Relu_63 || Conv_65 + Relu_66 || Conv_68 + Relu_69 || Conv_71 + Relu_72 || Conv_74 + Relu_75 || Conv_77 + Relu_78 || Conv_80 + Relu_81 || Conv_83 + Relu_84 Set Tactic Name: ampere_scudnn_128x32_sliced1x4_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: 4479823862704990365
[03/24/2023-12:57:11] [V] [TRT] Tactic: 4479823862704990365 Time: 1.08659
[03/24/2023-12:57:11] [V] [TRT] Conv_62 + Relu_63 || Conv_65 + Relu_66 || Conv_68 + Relu_69 || Conv_71 + Relu_72 || Conv_74 + Relu_75 || Conv_77 + Relu_78 || Conv_80 + Relu_81 || Conv_83 + Relu_84 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize64x256x8_stage3_warpsize1x4x1_g1_ffma Tactic: 4517590677127196184
[03/24/2023-12:57:11] [V] [TRT] Tactic: 4517590677127196184 Time: 1.13779
[03/24/2023-12:57:11] [V] [TRT] Conv_62 + Relu_63 || Conv_65 + Relu_66 || Conv_68 + Relu_69 || Conv_71 + Relu_72 || Conv_74 + Relu_75 || Conv_77 + Relu_78 || Conv_80 + Relu_81 || Conv_83 + Relu_84 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize128x128x8_stage3_warpsize2x4x1_g1_ffma_t1r3s3 Tactic: 4634080872644479428
[03/24/2023-12:57:11] [V] [TRT] Tactic: 4634080872644479428 Time: 1.12474
[03/24/2023-12:57:11] [V] [TRT] Conv_62 + Relu_63 || Conv_65 + Relu_66 || Conv_68 + Relu_69 || Conv_71 + Relu_72 || Conv_74 + Relu_75 || Conv_77 + Relu_78 || Conv_80 + Relu_81 || Conv_83 + Relu_84 Set Tactic Name: ampere_scudnn_128x64_sliced1x2_ldg4_relu_exp_medium_nhwc_tn_v1 Tactic: 4696204239951173149
[03/24/2023-12:57:11] [V] [TRT] Tactic: 4696204239951173149 Time: 1.06496
[03/24/2023-12:57:11] [V] [TRT] Conv_62 + Relu_63 || Conv_65 + Relu_66 || Conv_68 + Relu_69 || Conv_71 + Relu_72 || Conv_74 + Relu_75 || Conv_77 + Relu_78 || Conv_80 + Relu_81 || Conv_83 + Relu_84 Set Tactic Name: ampere_scudnn_128x128_relu_exp_small_nhwc_tn_v1 Tactic: 5778138195697110003
[03/24/2023-12:57:11] [V] [TRT] Tactic: 5778138195697110003 Time: 1.08326
[03/24/2023-12:57:11] [V] [TRT] Conv_62 + Relu_63 || Conv_65 + Relu_66 || Conv_68 + Relu_69 || Conv_71 + Relu_72 || Conv_74 + Relu_75 || Conv_77 + Relu_78 || Conv_80 + Relu_81 || Conv_83 + Relu_84 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize256x128x8_stage3_warpsize2x4x1_g1_ffma Tactic: 6310198979346901507
[03/24/2023-12:57:11] [V] [TRT] Tactic: 6310198979346901507 Time: 1.16736
[03/24/2023-12:57:11] [V] [TRT] Conv_62 + Relu_63 || Conv_65 + Relu_66 || Conv_68 + Relu_69 || Conv_71 + Relu_72 || Conv_74 + Relu_75 || Conv_77 + Relu_78 || Conv_80 + Relu_81 || Conv_83 + Relu_84 Set Tactic Name: ampere_scudnn_128x128_ldg4_relu_exp_large_nhwc_tn_v1 Tactic: 7155825427510256858
[03/24/2023-12:57:11] [V] [TRT] Tactic: 7155825427510256858 Time: 1.08403
[03/24/2023-12:57:11] [V] [TRT] Conv_62 + Relu_63 || Conv_65 + Relu_66 || Conv_68 + Relu_69 || Conv_71 + Relu_72 || Conv_74 + Relu_75 || Conv_77 + Relu_78 || Conv_80 + Relu_81 || Conv_83 + Relu_84 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize128x64x8_stage3_warpsize1x4x1_g1_ffma Tactic: 7222247112373541608
[03/24/2023-12:57:11] [V] [TRT] Tactic: 7222247112373541608 Time: 1.16774
[03/24/2023-12:57:11] [V] [TRT] Conv_62 + Relu_63 || Conv_65 + Relu_66 || Conv_68 + Relu_69 || Conv_71 + Relu_72 || Conv_74 + Relu_75 || Conv_77 + Relu_78 || Conv_80 + Relu_81 || Conv_83 + Relu_84 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize128x128x8_stage3_warpsize2x4x1_g1_ffma Tactic: 7472640475524677095
[03/24/2023-12:57:11] [V] [TRT] Tactic: 7472640475524677095 Time: 1.14547
[03/24/2023-12:57:11] [V] [TRT] Conv_62 + Relu_63 || Conv_65 + Relu_66 || Conv_68 + Relu_69 || Conv_71 + Relu_72 || Conv_74 + Relu_75 || Conv_77 + Relu_78 || Conv_80 + Relu_81 || Conv_83 + Relu_84 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize128x256x8_stage3_warpsize2x4x1_g1_ffma Tactic: 8498373915030836990
[03/24/2023-12:57:11] [V] [TRT] Tactic: 8498373915030836990 Time: 1.13818
[03/24/2023-12:57:11] [V] [TRT] Conv_62 + Relu_63 || Conv_65 + Relu_66 || Conv_68 + Relu_69 || Conv_71 + Relu_72 || Conv_74 + Relu_75 || Conv_77 + Relu_78 || Conv_80 + Relu_81 || Conv_83 + Relu_84 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize256x64x8_stage3_warpsize1x4x1_g1_ffma Tactic: 8869697132622550639
[03/24/2023-12:57:11] [V] [TRT] Tactic: 8869697132622550639 Time: 1.2832
[03/24/2023-12:57:11] [V] [TRT] Conv_62 + Relu_63 || Conv_65 + Relu_66 || Conv_68 + Relu_69 || Conv_71 + Relu_72 || Conv_74 + Relu_75 || Conv_77 + Relu_78 || Conv_80 + Relu_81 || Conv_83 + Relu_84 Set Tactic Name: ampere_scudnn_128x128_ldg4_relu_exp_medium_nhwc_tn_v1 Tactic: 8918020581761223752
[03/24/2023-12:57:11] [V] [TRT] Tactic: 8918020581761223752 Time: 1.07584
[03/24/2023-12:57:11] [V] [TRT] Conv_62 + Relu_63 || Conv_65 + Relu_66 || Conv_68 + Relu_69 || Conv_71 + Relu_72 || Conv_74 + Relu_75 || Conv_77 + Relu_78 || Conv_80 + Relu_81 || Conv_83 + Relu_84 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize256x128x8_stage3_warpsize2x4x1_g1_ffma_t1r3s3 Tactic: -8937725997228636978
[03/24/2023-12:57:11] [V] [TRT] Tactic: -8937725997228636978 Time: 1.12499
[03/24/2023-12:57:11] [V] [TRT] Conv_62 + Relu_63 || Conv_65 + Relu_66 || Conv_68 + Relu_69 || Conv_71 + Relu_72 || Conv_74 + Relu_75 || Conv_77 + Relu_78 || Conv_80 + Relu_81 || Conv_83 + Relu_84 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize128x256x8_stage3_warpsize2x4x1_g1_ffma_t1r3s3 Tactic: -8833858409138163072
[03/24/2023-12:57:11] [V] [TRT] Tactic: -8833858409138163072 Time: 1.11834
[03/24/2023-12:57:11] [V] [TRT] Conv_62 + Relu_63 || Conv_65 + Relu_66 || Conv_68 + Relu_69 || Conv_71 + Relu_72 || Conv_74 + Relu_75 || Conv_77 + Relu_78 || Conv_80 + Relu_81 || Conv_83 + Relu_84 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize64x64x8_stage3_warpsize1x4x1_g1_ffma_t1r3s3 Tactic: -7989138351613022500
[03/24/2023-12:57:11] [V] [TRT] Tactic: -7989138351613022500 Time: 1.04896
[03/24/2023-12:57:11] [V] [TRT] Conv_62 + Relu_63 || Conv_65 + Relu_66 || Conv_68 + Relu_69 || Conv_71 + Relu_72 || Conv_74 + Relu_75 || Conv_77 + Relu_78 || Conv_80 + Relu_81 || Conv_83 + Relu_84 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize256x128x8_stage3_warpsize2x4x1_g1_ffma Tactic: -7872883691240863058
[03/24/2023-12:57:11] [V] [TRT] Tactic: -7872883691240863058 Time: 1.16685
[03/24/2023-12:57:11] [V] [TRT] Conv_62 + Relu_63 || Conv_65 + Relu_66 || Conv_68 + Relu_69 || Conv_71 + Relu_72 || Conv_74 + Relu_75 || Conv_77 + Relu_78 || Conv_80 + Relu_81 || Conv_83 + Relu_84 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize128x128x8_stage3_warpsize2x4x1_g1_ffma Tactic: -6729618519651721910
[03/24/2023-12:57:11] [V] [TRT] Tactic: -6729618519651721910 Time: 1.13382
[03/24/2023-12:57:11] [V] [TRT] Conv_62 + Relu_63 || Conv_65 + Relu_66 || Conv_68 + Relu_69 || Conv_71 + Relu_72 || Conv_74 + Relu_75 || Conv_77 + Relu_78 || Conv_80 + Relu_81 || Conv_83 + Relu_84 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize256x64x8_stage3_warpsize1x4x1_g1_ffma Tactic: -5893833996418445881
[03/24/2023-12:57:11] [V] [TRT] Tactic: -5893833996418445881 Time: 1.25274
[03/24/2023-12:57:11] [V] [TRT] Conv_62 + Relu_63 || Conv_65 + Relu_66 || Conv_68 + Relu_69 || Conv_71 + Relu_72 || Conv_74 + Relu_75 || Conv_77 + Relu_78 || Conv_80 + Relu_81 || Conv_83 + Relu_84 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize128x256x8_stage3_warpsize2x4x1_g1_ffma Tactic: -5701562095007058349
[03/24/2023-12:57:11] [V] [TRT] Tactic: -5701562095007058349 Time: 1.12294
[03/24/2023-12:57:11] [V] [TRT] Conv_62 + Relu_63 || Conv_65 + Relu_66 || Conv_68 + Relu_69 || Conv_71 + Relu_72 || Conv_74 + Relu_75 || Conv_77 + Relu_78 || Conv_80 + Relu_81 || Conv_83 + Relu_84 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize128x64x8_stage3_warpsize1x4x1_g1_ffma Tactic: -5685503422376017600
[03/24/2023-12:57:11] [V] [TRT] Tactic: -5685503422376017600 Time: 1.13088
[03/24/2023-12:57:11] [V] [TRT] Conv_62 + Relu_63 || Conv_65 + Relu_66 || Conv_68 + Relu_69 || Conv_71 + Relu_72 || Conv_74 + Relu_75 || Conv_77 + Relu_78 || Conv_80 + Relu_81 || Conv_83 + Relu_84 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize64x64x8_stage3_warpsize1x4x1_g1_ffma Tactic: -5521125187060117489
[03/24/2023-12:57:12] [V] [TRT] Tactic: -5521125187060117489 Time: 1.13907
[03/24/2023-12:57:12] [V] [TRT] Conv_62 + Relu_63 || Conv_65 + Relu_66 || Conv_68 + Relu_69 || Conv_71 + Relu_72 || Conv_74 + Relu_75 || Conv_77 + Relu_78 || Conv_80 + Relu_81 || Conv_83 + Relu_84 Set Tactic Name: ampere_scudnn_128x64_sliced1x2_ldg4_relu_exp_large_nhwc_tn_v1 Tactic: -4756382386362004279
[03/24/2023-12:57:12] [V] [TRT] Tactic: -4756382386362004279 Time: 1.05088
[03/24/2023-12:57:12] [V] [TRT] Conv_62 + Relu_63 || Conv_65 + Relu_66 || Conv_68 + Relu_69 || Conv_71 + Relu_72 || Conv_74 + Relu_75 || Conv_77 + Relu_78 || Conv_80 + Relu_81 || Conv_83 + Relu_84 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize64x64x8_stage3_warpsize1x4x1_g1_ffma Tactic: -4615000974950361663
[03/24/2023-12:57:12] [V] [TRT] Tactic: -4615000974950361663 Time: 1.0903
[03/24/2023-12:57:12] [V] [TRT] Conv_62 + Relu_63 || Conv_65 + Relu_66 || Conv_68 + Relu_69 || Conv_71 + Relu_72 || Conv_74 + Relu_75 || Conv_77 + Relu_78 || Conv_80 + Relu_81 || Conv_83 + Relu_84 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize256x64x8_stage3_warpsize1x4x1_g1_ffma_t1r3s3 Tactic: -4314913710375142296
[03/24/2023-12:57:12] [V] [TRT] Tactic: -4314913710375142296 Time: 1.20666
[03/24/2023-12:57:12] [V] [TRT] Conv_62 + Relu_63 || Conv_65 + Relu_66 || Conv_68 + Relu_69 || Conv_71 + Relu_72 || Conv_74 + Relu_75 || Conv_77 + Relu_78 || Conv_80 + Relu_81 || Conv_83 + Relu_84 Set Tactic Name: ampere_scudnn_128x128_relu_exp_large_nhwc_tn_v1 Tactic: -3855385237722507464
[03/24/2023-12:57:12] [V] [TRT] Tactic: -3855385237722507464 Time: 1.08826
[03/24/2023-12:57:12] [V] [TRT] Conv_62 + Relu_63 || Conv_65 + Relu_66 || Conv_68 + Relu_69 || Conv_71 + Relu_72 || Conv_74 + Relu_75 || Conv_77 + Relu_78 || Conv_80 + Relu_81 || Conv_83 + Relu_84 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize128x64x8_stage3_warpsize1x4x1_g1_ffma_t1r3s3 Tactic: -3697587361057948972
[03/24/2023-12:57:12] [V] [TRT] Tactic: -3697587361057948972 Time: 1.13434
[03/24/2023-12:57:12] [V] [TRT] Conv_62 + Relu_63 || Conv_65 + Relu_66 || Conv_68 + Relu_69 || Conv_71 + Relu_72 || Conv_74 + Relu_75 || Conv_77 + Relu_78 || Conv_80 + Relu_81 || Conv_83 + Relu_84 Set Tactic Name: ampere_scudnn_128x128_relu_exp_medium_nhwc_tn_v1 Tactic: -2809379259463049391
[03/24/2023-12:57:12] [V] [TRT] Tactic: -2809379259463049391 Time: 1.088
[03/24/2023-12:57:12] [V] [TRT] Conv_62 + Relu_63 || Conv_65 + Relu_66 || Conv_68 + Relu_69 || Conv_71 + Relu_72 || Conv_74 + Relu_75 || Conv_77 + Relu_78 || Conv_80 + Relu_81 || Conv_83 + Relu_84 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize64x256x8_stage3_warpsize1x4x1_g1_ffma_t1r3s3 Tactic: -2747929399988666512
[03/24/2023-12:57:12] [V] [TRT] Tactic: -2747929399988666512 Time: 1.11386
[03/24/2023-12:57:12] [V] [TRT] Conv_62 + Relu_63 || Conv_65 + Relu_66 || Conv_68 + Relu_69 || Conv_71 + Relu_72 || Conv_74 + Relu_75 || Conv_77 + Relu_78 || Conv_80 + Relu_81 || Conv_83 + Relu_84 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize64x256x8_stage3_warpsize1x4x1_g1_ffma Tactic: -1472061967969061456
[03/24/2023-12:57:12] [V] [TRT] Tactic: -1472061967969061456 Time: 1.13958
[03/24/2023-12:57:12] [V] [TRT] Conv_62 + Relu_63 || Conv_65 + Relu_66 || Conv_68 + Relu_69 || Conv_71 + Relu_72 || Conv_74 + Relu_75 || Conv_77 + Relu_78 || Conv_80 + Relu_81 || Conv_83 + Relu_84 Set Tactic Name: ampere_scudnn_128x128_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: -504296718212024303
[03/24/2023-12:57:12] [V] [TRT] Tactic: -504296718212024303 Time: 1.0761
[03/24/2023-12:57:12] [V] [TRT] Conv_62 + Relu_63 || Conv_65 + Relu_66 || Conv_68 + Relu_69 || Conv_71 + Relu_72 || Conv_74 + Relu_75 || Conv_77 + Relu_78 || Conv_80 + Relu_81 || Conv_83 + Relu_84 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize64x128x8_stage3_warpsize1x4x1_g1_ffma Tactic: -444093195553988951
[03/24/2023-12:57:12] [V] [TRT] Tactic: -444093195553988951 Time: 1.08877
[03/24/2023-12:57:12] [V] [TRT] Fastest Tactic: 3239733199291090177 Time: 1.03603
[03/24/2023-12:57:12] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: 3239733199291090177
[03/24/2023-12:57:12] [V] [TRT] *************** Autotuning format combination: Float(518400,1:4,2880,16) -> Float(4147200,1:4,23040,128) ***************
[03/24/2023-12:57:12] [V] [TRT] --------------- Timing Runner: Conv_62 + Relu_63 || Conv_65 + Relu_66 || Conv_68 + Relu_69 || Conv_71 + Relu_72 || Conv_74 + Relu_75 || Conv_77 + Relu_78 || Conv_80 + Relu_81 || Conv_83 + Relu_84 (CudnnConvolution)
[03/24/2023-12:57:12] [V] [TRT] CudnnConvolution has no valid tactics for this config, skipping
[03/24/2023-12:57:12] [V] [TRT] --------------- Timing Runner: Conv_62 + Relu_63 || Conv_65 + Relu_66 || Conv_68 + Relu_69 || Conv_71 + Relu_72 || Conv_74 + Relu_75 || Conv_77 + Relu_78 || Conv_80 + Relu_81 || Conv_83 + Relu_84 (CaskConvolution)
[03/24/2023-12:57:12] [V] [TRT] Conv_62 + Relu_63 || Conv_65 + Relu_66 || Conv_68 + Relu_69 || Conv_71 + Relu_72 || Conv_74 + Relu_75 || Conv_77 + Relu_78 || Conv_80 + Relu_81 || Conv_83 + Relu_84 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize64x128x32_stage5_warpsize2x2x1_g1_tensor16x8x8 Tactic: 1237784342446422381
[03/24/2023-12:57:12] [V] [TRT] Tactic: 1237784342446422381 Time: 0.287488
[03/24/2023-12:57:12] [V] [TRT] Conv_62 + Relu_63 || Conv_65 + Relu_66 || Conv_68 + Relu_69 || Conv_71 + Relu_72 || Conv_74 + Relu_75 || Conv_77 + Relu_78 || Conv_80 + Relu_81 || Conv_83 + Relu_84 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x64x32_stage5_warpsize2x2x1_g1_tensor16x8x8 Tactic: 1426562292875733922
[03/24/2023-12:57:12] [V] [TRT] Tactic: 1426562292875733922 Time: 0.306944
[03/24/2023-12:57:12] [V] [TRT] Conv_62 + Relu_63 || Conv_65 + Relu_66 || Conv_68 + Relu_69 || Conv_71 + Relu_72 || Conv_74 + Relu_75 || Conv_77 + Relu_78 || Conv_80 + Relu_81 || Conv_83 + Relu_84 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize64x128x8_stage3_warpsize1x4x1_g1_ffma_t1r3s3 Tactic: 2086609538387166260
[03/24/2023-12:57:12] [V] [TRT] Tactic: 2086609538387166260 Time: 1.03821
[03/24/2023-12:57:12] [V] [TRT] Conv_62 + Relu_63 || Conv_65 + Relu_66 || Conv_68 + Relu_69 || Conv_71 + Relu_72 || Conv_74 + Relu_75 || Conv_77 + Relu_78 || Conv_80 + Relu_81 || Conv_83 + Relu_84 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize256x128x32_stage3_warpsize4x2x1_g1_tensor16x8x8_t1r3s3 Tactic: 2388153022056233219
[03/24/2023-12:57:12] [V] [TRT] Tactic: 2388153022056233219 Time: 0.205696
[03/24/2023-12:57:12] [V] [TRT] Conv_62 + Relu_63 || Conv_65 + Relu_66 || Conv_68 + Relu_69 || Conv_71 + Relu_72 || Conv_74 + Relu_75 || Conv_77 + Relu_78 || Conv_80 + Relu_81 || Conv_83 + Relu_84 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x128x32_stage4_warpsize2x2x1_g1_tensor16x8x8 Tactic: 2716437853123234317
[03/24/2023-12:57:12] [V] [TRT] Tactic: 2716437853123234317 Time: 0.224512
[03/24/2023-12:57:12] [V] [TRT] Conv_62 + Relu_63 || Conv_65 + Relu_66 || Conv_68 + Relu_69 || Conv_71 + Relu_72 || Conv_74 + Relu_75 || Conv_77 + Relu_78 || Conv_80 + Relu_81 || Conv_83 + Relu_84 Set Tactic Name: ampere_scudnn_128x64_sliced1x2_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: 2860655430572478466
[03/24/2023-12:57:12] [V] [TRT] Tactic: 2860655430572478466 Time: 1.06406
[03/24/2023-12:57:12] [V] [TRT] Conv_62 + Relu_63 || Conv_65 + Relu_66 || Conv_68 + Relu_69 || Conv_71 + Relu_72 || Conv_74 + Relu_75 || Conv_77 + Relu_78 || Conv_80 + Relu_81 || Conv_83 + Relu_84 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize64x128x8_stage3_warpsize1x4x1_g1_ffma Tactic: 3239733199291090177
[03/24/2023-12:57:12] [V] [TRT] Tactic: 3239733199291090177 Time: 1.03629
[03/24/2023-12:57:12] [V] [TRT] Conv_62 + Relu_63 || Conv_65 + Relu_66 || Conv_68 + Relu_69 || Conv_71 + Relu_72 || Conv_74 + Relu_75 || Conv_77 + Relu_78 || Conv_80 + Relu_81 || Conv_83 + Relu_84 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize64x64x64_stage4_warpsize2x2x1_g1_tensor16x8x8_t1r3s3 Tactic: 3278852197192504305
[03/24/2023-12:57:12] [V] [TRT] Tactic: 3278852197192504305 Time: 0.38976
[03/24/2023-12:57:12] [V] [TRT] Conv_62 + Relu_63 || Conv_65 + Relu_66 || Conv_68 + Relu_69 || Conv_71 + Relu_72 || Conv_74 + Relu_75 || Conv_77 + Relu_78 || Conv_80 + Relu_81 || Conv_83 + Relu_84 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize256x128x32_stage3_warpsize4x2x1_g1_tensor16x8x8 Tactic: 3904690393614050557
[03/24/2023-12:57:12] [V] [TRT] Tactic: 3904690393614050557 Time: 0.251264
[03/24/2023-12:57:12] [V] [TRT] Conv_62 + Relu_63 || Conv_65 + Relu_66 || Conv_68 + Relu_69 || Conv_71 + Relu_72 || Conv_74 + Relu_75 || Conv_77 + Relu_78 || Conv_80 + Relu_81 || Conv_83 + Relu_84 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize64x64x64_stage4_warpsize2x2x1_g1_tensor16x8x8 Tactic: 4061115162338989075
[03/24/2023-12:57:12] [V] [TRT] Tactic: 4061115162338989075 Time: 0.390912
[03/24/2023-12:57:12] [V] [TRT] Conv_62 + Relu_63 || Conv_65 + Relu_66 || Conv_68 + Relu_69 || Conv_71 + Relu_72 || Conv_74 + Relu_75 || Conv_77 + Relu_78 || Conv_80 + Relu_81 || Conv_83 + Relu_84 Set Tactic Name: ampere_scudnn_128x32_sliced1x4_ldg4_relu_exp_medium_nhwc_tn_v1 Tactic: 4474630279712975759
[03/24/2023-12:57:12] [V] [TRT] Tactic: 4474630279712975759 Time: 1.09286
[03/24/2023-12:57:12] [V] [TRT] Conv_62 + Relu_63 || Conv_65 + Relu_66 || Conv_68 + Relu_69 || Conv_71 + Relu_72 || Conv_74 + Relu_75 || Conv_77 + Relu_78 || Conv_80 + Relu_81 || Conv_83 + Relu_84 Set Tactic Name: ampere_scudnn_128x32_sliced1x4_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: 4479823862704990365
[03/24/2023-12:57:12] [V] [TRT] Tactic: 4479823862704990365 Time: 1.08672
[03/24/2023-12:57:12] [V] [TRT] Conv_62 + Relu_63 || Conv_65 + Relu_66 || Conv_68 + Relu_69 || Conv_71 + Relu_72 || Conv_74 + Relu_75 || Conv_77 + Relu_78 || Conv_80 + Relu_81 || Conv_83 + Relu_84 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize64x256x8_stage3_warpsize1x4x1_g1_ffma Tactic: 4517590677127196184
[03/24/2023-12:57:12] [V] [TRT] Tactic: 4517590677127196184 Time: 1.13792
[03/24/2023-12:57:12] [V] [TRT] Conv_62 + Relu_63 || Conv_65 + Relu_66 || Conv_68 + Relu_69 || Conv_71 + Relu_72 || Conv_74 + Relu_75 || Conv_77 + Relu_78 || Conv_80 + Relu_81 || Conv_83 + Relu_84 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize128x128x8_stage3_warpsize2x4x1_g1_ffma_t1r3s3 Tactic: 4634080872644479428
[03/24/2023-12:57:12] [V] [TRT] Tactic: 4634080872644479428 Time: 1.12486
[03/24/2023-12:57:12] [V] [TRT] Conv_62 + Relu_63 || Conv_65 + Relu_66 || Conv_68 + Relu_69 || Conv_71 + Relu_72 || Conv_74 + Relu_75 || Conv_77 + Relu_78 || Conv_80 + Relu_81 || Conv_83 + Relu_84 Set Tactic Name: ampere_scudnn_128x64_sliced1x2_ldg4_relu_exp_medium_nhwc_tn_v1 Tactic: 4696204239951173149
[03/24/2023-12:57:12] [V] [TRT] Tactic: 4696204239951173149 Time: 1.06509
[03/24/2023-12:57:12] [V] [TRT] Conv_62 + Relu_63 || Conv_65 + Relu_66 || Conv_68 + Relu_69 || Conv_71 + Relu_72 || Conv_74 + Relu_75 || Conv_77 + Relu_78 || Conv_80 + Relu_81 || Conv_83 + Relu_84 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x256x32_stage3_warpsize2x4x1_g1_tensor16x8x8 Tactic: 5200329514761435342
[03/24/2023-12:57:12] [V] [TRT] Tactic: 5200329514761435342 Time: 0.199808
[03/24/2023-12:57:12] [V] [TRT] Conv_62 + Relu_63 || Conv_65 + Relu_66 || Conv_68 + Relu_69 || Conv_71 + Relu_72 || Conv_74 + Relu_75 || Conv_77 + Relu_78 || Conv_80 + Relu_81 || Conv_83 + Relu_84 Set Tactic Name: ampere_scudnn_128x128_relu_exp_small_nhwc_tn_v1 Tactic: 5778138195697110003
[03/24/2023-12:57:12] [V] [TRT] Tactic: 5778138195697110003 Time: 1.08314
[03/24/2023-12:57:12] [V] [TRT] Conv_62 + Relu_63 || Conv_65 + Relu_66 || Conv_68 + Relu_69 || Conv_71 + Relu_72 || Conv_74 + Relu_75 || Conv_77 + Relu_78 || Conv_80 + Relu_81 || Conv_83 + Relu_84 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize256x128x8_stage3_warpsize2x4x1_g1_ffma Tactic: 6310198979346901507
[03/24/2023-12:57:12] [V] [TRT] Tactic: 6310198979346901507 Time: 1.1671
[03/24/2023-12:57:12] [V] [TRT] Conv_62 + Relu_63 || Conv_65 + Relu_66 || Conv_68 + Relu_69 || Conv_71 + Relu_72 || Conv_74 + Relu_75 || Conv_77 + Relu_78 || Conv_80 + Relu_81 || Conv_83 + Relu_84 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x256x32_stage3_warpsize2x4x1_g1_tensor16x8x8_t1r3s3 Tactic: 7011693366046809027
[03/24/2023-12:57:12] [V] [TRT] Tactic: 7011693366046809027 Time: 0.196992
[03/24/2023-12:57:12] [V] [TRT] Conv_62 + Relu_63 || Conv_65 + Relu_66 || Conv_68 + Relu_69 || Conv_71 + Relu_72 || Conv_74 + Relu_75 || Conv_77 + Relu_78 || Conv_80 + Relu_81 || Conv_83 + Relu_84 Set Tactic Name: ampere_scudnn_128x128_ldg4_relu_exp_large_nhwc_tn_v1 Tactic: 7155825427510256858
[03/24/2023-12:57:12] [V] [TRT] Tactic: 7155825427510256858 Time: 1.08365
[03/24/2023-12:57:12] [V] [TRT] Conv_62 + Relu_63 || Conv_65 + Relu_66 || Conv_68 + Relu_69 || Conv_71 + Relu_72 || Conv_74 + Relu_75 || Conv_77 + Relu_78 || Conv_80 + Relu_81 || Conv_83 + Relu_84 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize128x64x8_stage3_warpsize1x4x1_g1_ffma Tactic: 7222247112373541608
[03/24/2023-12:57:12] [V] [TRT] Tactic: 7222247112373541608 Time: 1.16774
[03/24/2023-12:57:12] [V] [TRT] Conv_62 + Relu_63 || Conv_65 + Relu_66 || Conv_68 + Relu_69 || Conv_71 + Relu_72 || Conv_74 + Relu_75 || Conv_77 + Relu_78 || Conv_80 + Relu_81 || Conv_83 + Relu_84 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x128x16_stage4_warpsize2x2x1_g1_tensor16x8x8 Tactic: 7342025736444949634
[03/24/2023-12:57:12] [V] [TRT] Tactic: 7342025736444949634 Time: 0.22016
[03/24/2023-12:57:12] [V] [TRT] Conv_62 + Relu_63 || Conv_65 + Relu_66 || Conv_68 + Relu_69 || Conv_71 + Relu_72 || Conv_74 + Relu_75 || Conv_77 + Relu_78 || Conv_80 + Relu_81 || Conv_83 + Relu_84 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize64x128x32_stage5_warpsize2x2x1_g1_tensor16x8x8 Tactic: 7347365539922924600
[03/24/2023-12:57:12] [V] [TRT] Tactic: 7347365539922924600 Time: 0.273792
[03/24/2023-12:57:12] [V] [TRT] Conv_62 + Relu_63 || Conv_65 + Relu_66 || Conv_68 + Relu_69 || Conv_71 + Relu_72 || Conv_74 + Relu_75 || Conv_77 + Relu_78 || Conv_80 + Relu_81 || Conv_83 + Relu_84 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x64x32_stage5_warpsize2x2x1_g1_tensor16x8x8 Tactic: 7428197830878119671
[03/24/2023-12:57:12] [V] [TRT] Tactic: 7428197830878119671 Time: 0.297088
[03/24/2023-12:57:12] [V] [TRT] Conv_62 + Relu_63 || Conv_65 + Relu_66 || Conv_68 + Relu_69 || Conv_71 + Relu_72 || Conv_74 + Relu_75 || Conv_77 + Relu_78 || Conv_80 + Relu_81 || Conv_83 + Relu_84 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize64x32x64_stage5_warpsize2x2x1_g1_tensor16x8x8_t1r3s3 Tactic: 7465323447915168822
[03/24/2023-12:57:12] [V] [TRT] Tactic: 7465323447915168822 Time: 0.596224
[03/24/2023-12:57:12] [V] [TRT] Conv_62 + Relu_63 || Conv_65 + Relu_66 || Conv_68 + Relu_69 || Conv_71 + Relu_72 || Conv_74 + Relu_75 || Conv_77 + Relu_78 || Conv_80 + Relu_81 || Conv_83 + Relu_84 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize128x128x8_stage3_warpsize2x4x1_g1_ffma Tactic: 7472640475524677095
[03/24/2023-12:57:12] [V] [TRT] Tactic: 7472640475524677095 Time: 1.1465
[03/24/2023-12:57:12] [V] [TRT] Conv_62 + Relu_63 || Conv_65 + Relu_66 || Conv_68 + Relu_69 || Conv_71 + Relu_72 || Conv_74 + Relu_75 || Conv_77 + Relu_78 || Conv_80 + Relu_81 || Conv_83 + Relu_84 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize64x32x64_stage5_warpsize2x2x1_g1_tensor16x8x8 Tactic: 7938223790021272801
[03/24/2023-12:57:12] [V] [TRT] Tactic: 7938223790021272801 Time: 0.638592
[03/24/2023-12:57:12] [V] [TRT] Conv_62 + Relu_63 || Conv_65 + Relu_66 || Conv_68 + Relu_69 || Conv_71 + Relu_72 || Conv_74 + Relu_75 || Conv_77 + Relu_78 || Conv_80 + Relu_81 || Conv_83 + Relu_84 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize128x256x8_stage3_warpsize2x4x1_g1_ffma Tactic: 8498373915030836990
[03/24/2023-12:57:12] [V] [TRT] Tactic: 8498373915030836990 Time: 1.13869
[03/24/2023-12:57:12] [V] [TRT] Conv_62 + Relu_63 || Conv_65 + Relu_66 || Conv_68 + Relu_69 || Conv_71 + Relu_72 || Conv_74 + Relu_75 || Conv_77 + Relu_78 || Conv_80 + Relu_81 || Conv_83 + Relu_84 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x64x32_stage5_warpsize2x2x1_g1_tensor16x8x8_t1r3s3 Tactic: 8836645772682419994
[03/24/2023-12:57:12] [V] [TRT] Tactic: 8836645772682419994 Time: 0.283264
[03/24/2023-12:57:12] [V] [TRT] Conv_62 + Relu_63 || Conv_65 + Relu_66 || Conv_68 + Relu_69 || Conv_71 + Relu_72 || Conv_74 + Relu_75 || Conv_77 + Relu_78 || Conv_80 + Relu_81 || Conv_83 + Relu_84 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize256x64x8_stage3_warpsize1x4x1_g1_ffma Tactic: 8869697132622550639
[03/24/2023-12:57:12] [V] [TRT] Tactic: 8869697132622550639 Time: 1.28486
[03/24/2023-12:57:12] [V] [TRT] Conv_62 + Relu_63 || Conv_65 + Relu_66 || Conv_68 + Relu_69 || Conv_71 + Relu_72 || Conv_74 + Relu_75 || Conv_77 + Relu_78 || Conv_80 + Relu_81 || Conv_83 + Relu_84 Set Tactic Name: ampere_scudnn_128x128_ldg4_relu_exp_medium_nhwc_tn_v1 Tactic: 8918020581761223752
[03/24/2023-12:57:12] [V] [TRT] Tactic: 8918020581761223752 Time: 1.07597
[03/24/2023-12:57:12] [V] [TRT] Conv_62 + Relu_63 || Conv_65 + Relu_66 || Conv_68 + Relu_69 || Conv_71 + Relu_72 || Conv_74 + Relu_75 || Conv_77 + Relu_78 || Conv_80 + Relu_81 || Conv_83 + Relu_84 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize64x64x64_stage4_warpsize2x2x1_g1_tensor16x8x8 Tactic: -9114138070928278731
[03/24/2023-12:57:12] [V] [TRT] Tactic: -9114138070928278731 Time: 0.413696
[03/24/2023-12:57:12] [V] [TRT] Conv_62 + Relu_63 || Conv_65 + Relu_66 || Conv_68 + Relu_69 || Conv_71 + Relu_72 || Conv_74 + Relu_75 || Conv_77 + Relu_78 || Conv_80 + Relu_81 || Conv_83 + Relu_84 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize256x128x8_stage3_warpsize2x4x1_g1_ffma_t1r3s3 Tactic: -8937725997228636978
[03/24/2023-12:57:12] [V] [TRT] Tactic: -8937725997228636978 Time: 1.12512
[03/24/2023-12:57:12] [V] [TRT] Conv_62 + Relu_63 || Conv_65 + Relu_66 || Conv_68 + Relu_69 || Conv_71 + Relu_72 || Conv_74 + Relu_75 || Conv_77 + Relu_78 || Conv_80 + Relu_81 || Conv_83 + Relu_84 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize128x256x8_stage3_warpsize2x4x1_g1_ffma_t1r3s3 Tactic: -8833858409138163072
[03/24/2023-12:57:12] [V] [TRT] Tactic: -8833858409138163072 Time: 1.11808
[03/24/2023-12:57:12] [V] [TRT] Conv_62 + Relu_63 || Conv_65 + Relu_66 || Conv_68 + Relu_69 || Conv_71 + Relu_72 || Conv_74 + Relu_75 || Conv_77 + Relu_78 || Conv_80 + Relu_81 || Conv_83 + Relu_84 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize64x64x8_stage3_warpsize1x4x1_g1_ffma_t1r3s3 Tactic: -7989138351613022500
[03/24/2023-12:57:12] [V] [TRT] Tactic: -7989138351613022500 Time: 1.04947
[03/24/2023-12:57:12] [V] [TRT] Conv_62 + Relu_63 || Conv_65 + Relu_66 || Conv_68 + Relu_69 || Conv_71 + Relu_72 || Conv_74 + Relu_75 || Conv_77 + Relu_78 || Conv_80 + Relu_81 || Conv_83 + Relu_84 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize256x128x8_stage3_warpsize2x4x1_g1_ffma Tactic: -7872883691240863058
[03/24/2023-12:57:12] [V] [TRT] Tactic: -7872883691240863058 Time: 1.16749
[03/24/2023-12:57:12] [V] [TRT] Conv_62 + Relu_63 || Conv_65 + Relu_66 || Conv_68 + Relu_69 || Conv_71 + Relu_72 || Conv_74 + Relu_75 || Conv_77 + Relu_78 || Conv_80 + Relu_81 || Conv_83 + Relu_84 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x256x32_stage3_warpsize2x4x1_g1_tensor16x8x8 Tactic: -7382359095196034537
[03/24/2023-12:57:12] [V] [TRT] Tactic: -7382359095196034537 Time: 0.202368
[03/24/2023-12:57:12] [V] [TRT] Conv_62 + Relu_63 || Conv_65 + Relu_66 || Conv_68 + Relu_69 || Conv_71 + Relu_72 || Conv_74 + Relu_75 || Conv_77 + Relu_78 || Conv_80 + Relu_81 || Conv_83 + Relu_84 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x128x16_stage4_warpsize2x2x1_g1_tensor16x8x8_t1r3s3 Tactic: -7377458734869418330
[03/24/2023-12:57:12] [V] [TRT] Tactic: -7377458734869418330 Time: 0.207872
[03/24/2023-12:57:12] [V] [TRT] Conv_62 + Relu_63 || Conv_65 + Relu_66 || Conv_68 + Relu_69 || Conv_71 + Relu_72 || Conv_74 + Relu_75 || Conv_77 + Relu_78 || Conv_80 + Relu_81 || Conv_83 + Relu_84 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize128x128x8_stage3_warpsize2x4x1_g1_ffma Tactic: -6729618519651721910
[03/24/2023-12:57:13] [V] [TRT] Tactic: -6729618519651721910 Time: 1.13382
[03/24/2023-12:57:13] [V] [TRT] Conv_62 + Relu_63 || Conv_65 + Relu_66 || Conv_68 + Relu_69 || Conv_71 + Relu_72 || Conv_74 + Relu_75 || Conv_77 + Relu_78 || Conv_80 + Relu_81 || Conv_83 + Relu_84 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize256x64x32_stage3_warpsize4x2x1_g1_tensor16x8x8_t1r3s3 Tactic: -6223854811627385844
[03/24/2023-12:57:13] [V] [TRT] Tactic: -6223854811627385844 Time: 0.24
[03/24/2023-12:57:13] [V] [TRT] Conv_62 + Relu_63 || Conv_65 + Relu_66 || Conv_68 + Relu_69 || Conv_71 + Relu_72 || Conv_74 + Relu_75 || Conv_77 + Relu_78 || Conv_80 + Relu_81 || Conv_83 + Relu_84 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize256x64x8_stage3_warpsize1x4x1_g1_ffma Tactic: -5893833996418445881
[03/24/2023-12:57:13] [V] [TRT] Tactic: -5893833996418445881 Time: 1.25312
[03/24/2023-12:57:13] [V] [TRT] Conv_62 + Relu_63 || Conv_65 + Relu_66 || Conv_68 + Relu_69 || Conv_71 + Relu_72 || Conv_74 + Relu_75 || Conv_77 + Relu_78 || Conv_80 + Relu_81 || Conv_83 + Relu_84 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize128x256x8_stage3_warpsize2x4x1_g1_ffma Tactic: -5701562095007058349
[03/24/2023-12:57:13] [V] [TRT] Tactic: -5701562095007058349 Time: 1.12333
[03/24/2023-12:57:13] [V] [TRT] Conv_62 + Relu_63 || Conv_65 + Relu_66 || Conv_68 + Relu_69 || Conv_71 + Relu_72 || Conv_74 + Relu_75 || Conv_77 + Relu_78 || Conv_80 + Relu_81 || Conv_83 + Relu_84 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize128x64x8_stage3_warpsize1x4x1_g1_ffma Tactic: -5685503422376017600
[03/24/2023-12:57:13] [V] [TRT] Tactic: -5685503422376017600 Time: 1.13075
[03/24/2023-12:57:13] [V] [TRT] Conv_62 + Relu_63 || Conv_65 + Relu_66 || Conv_68 + Relu_69 || Conv_71 + Relu_72 || Conv_74 + Relu_75 || Conv_77 + Relu_78 || Conv_80 + Relu_81 || Conv_83 + Relu_84 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize64x64x8_stage3_warpsize1x4x1_g1_ffma Tactic: -5521125187060117489
[03/24/2023-12:57:13] [V] [TRT] Tactic: -5521125187060117489 Time: 1.13894
[03/24/2023-12:57:13] [V] [TRT] Conv_62 + Relu_63 || Conv_65 + Relu_66 || Conv_68 + Relu_69 || Conv_71 + Relu_72 || Conv_74 + Relu_75 || Conv_77 + Relu_78 || Conv_80 + Relu_81 || Conv_83 + Relu_84 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x128x16_stage4_warpsize2x2x1_g1_tensor16x8x8 Tactic: -5457304872213719461
[03/24/2023-12:57:13] [V] [TRT] Tactic: -5457304872213719461 Time: 0.212224
[03/24/2023-12:57:13] [V] [TRT] Conv_62 + Relu_63 || Conv_65 + Relu_66 || Conv_68 + Relu_69 || Conv_71 + Relu_72 || Conv_74 + Relu_75 || Conv_77 + Relu_78 || Conv_80 + Relu_81 || Conv_83 + Relu_84 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x64x64_stage3_warpsize2x2x1_g1_tensor16x8x8 Tactic: -5441054706931585554
[03/24/2023-12:57:13] [V] [TRT] Tactic: -5441054706931585554 Time: 0.3104
[03/24/2023-12:57:13] [V] [TRT] Conv_62 + Relu_63 || Conv_65 + Relu_66 || Conv_68 + Relu_69 || Conv_71 + Relu_72 || Conv_74 + Relu_75 || Conv_77 + Relu_78 || Conv_80 + Relu_81 || Conv_83 + Relu_84 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize256x64x32_stage3_warpsize4x2x1_g1_tensor16x8x8 Tactic: -5043603702497465467
[03/24/2023-12:57:13] [V] [TRT] Tactic: -5043603702497465467 Time: 0.273408
[03/24/2023-12:57:13] [V] [TRT] Conv_62 + Relu_63 || Conv_65 + Relu_66 || Conv_68 + Relu_69 || Conv_71 + Relu_72 || Conv_74 + Relu_75 || Conv_77 + Relu_78 || Conv_80 + Relu_81 || Conv_83 + Relu_84 Set Tactic Name: ampere_scudnn_128x64_sliced1x2_ldg4_relu_exp_large_nhwc_tn_v1 Tactic: -4756382386362004279
[03/24/2023-12:57:13] [V] [TRT] Tactic: -4756382386362004279 Time: 1.05062
[03/24/2023-12:57:13] [V] [TRT] Conv_62 + Relu_63 || Conv_65 + Relu_66 || Conv_68 + Relu_69 || Conv_71 + Relu_72 || Conv_74 + Relu_75 || Conv_77 + Relu_78 || Conv_80 + Relu_81 || Conv_83 + Relu_84 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize64x64x8_stage3_warpsize1x4x1_g1_ffma Tactic: -4615000974950361663
[03/24/2023-12:57:13] [V] [TRT] Tactic: -4615000974950361663 Time: 1.09043
[03/24/2023-12:57:13] [V] [TRT] Conv_62 + Relu_63 || Conv_65 + Relu_66 || Conv_68 + Relu_69 || Conv_71 + Relu_72 || Conv_74 + Relu_75 || Conv_77 + Relu_78 || Conv_80 + Relu_81 || Conv_83 + Relu_84 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x64x64_stage3_warpsize2x2x1_g1_tensor16x8x8 Tactic: -4564655677311401797
[03/24/2023-12:57:13] [V] [TRT] Tactic: -4564655677311401797 Time: 0.325248
[03/24/2023-12:57:13] [V] [TRT] Conv_62 + Relu_63 || Conv_65 + Relu_66 || Conv_68 + Relu_69 || Conv_71 + Relu_72 || Conv_74 + Relu_75 || Conv_77 + Relu_78 || Conv_80 + Relu_81 || Conv_83 + Relu_84 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize256x64x8_stage3_warpsize1x4x1_g1_ffma_t1r3s3 Tactic: -4314913710375142296
[03/24/2023-12:57:13] [V] [TRT] Tactic: -4314913710375142296 Time: 1.20525
[03/24/2023-12:57:13] [V] [TRT] Conv_62 + Relu_63 || Conv_65 + Relu_66 || Conv_68 + Relu_69 || Conv_71 + Relu_72 || Conv_74 + Relu_75 || Conv_77 + Relu_78 || Conv_80 + Relu_81 || Conv_83 + Relu_84 Set Tactic Name: ampere_scudnn_128x128_relu_exp_large_nhwc_tn_v1 Tactic: -3855385237722507464
[03/24/2023-12:57:13] [V] [TRT] Tactic: -3855385237722507464 Time: 1.088
[03/24/2023-12:57:13] [V] [TRT] Conv_62 + Relu_63 || Conv_65 + Relu_66 || Conv_68 + Relu_69 || Conv_71 + Relu_72 || Conv_74 + Relu_75 || Conv_77 + Relu_78 || Conv_80 + Relu_81 || Conv_83 + Relu_84 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize128x64x8_stage3_warpsize1x4x1_g1_ffma_t1r3s3 Tactic: -3697587361057948972
[03/24/2023-12:57:13] [V] [TRT] Tactic: -3697587361057948972 Time: 1.13421
[03/24/2023-12:57:13] [V] [TRT] Conv_62 + Relu_63 || Conv_65 + Relu_66 || Conv_68 + Relu_69 || Conv_71 + Relu_72 || Conv_74 + Relu_75 || Conv_77 + Relu_78 || Conv_80 + Relu_81 || Conv_83 + Relu_84 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize256x64x32_stage3_warpsize4x2x1_g1_tensor16x8x8 Tactic: -3540975627865078064
[03/24/2023-12:57:13] [V] [TRT] Tactic: -3540975627865078064 Time: 0.251648
[03/24/2023-12:57:13] [V] [TRT] Conv_62 + Relu_63 || Conv_65 + Relu_66 || Conv_68 + Relu_69 || Conv_71 + Relu_72 || Conv_74 + Relu_75 || Conv_77 + Relu_78 || Conv_80 + Relu_81 || Conv_83 + Relu_84 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize64x128x32_stage5_warpsize2x2x1_g1_tensor16x8x8_t1r3s3 Tactic: -3151804561246216835
[03/24/2023-12:57:13] [V] [TRT] Tactic: -3151804561246216835 Time: 0.266752
[03/24/2023-12:57:13] [V] [TRT] Conv_62 + Relu_63 || Conv_65 + Relu_66 || Conv_68 + Relu_69 || Conv_71 + Relu_72 || Conv_74 + Relu_75 || Conv_77 + Relu_78 || Conv_80 + Relu_81 || Conv_83 + Relu_84 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize64x32x64_stage5_warpsize2x2x1_g1_tensor16x8x8 Tactic: -2885165284206163001
[03/24/2023-12:57:13] [V] [TRT] Tactic: -2885165284206163001 Time: 0.621184
[03/24/2023-12:57:13] [V] [TRT] Conv_62 + Relu_63 || Conv_65 + Relu_66 || Conv_68 + Relu_69 || Conv_71 + Relu_72 || Conv_74 + Relu_75 || Conv_77 + Relu_78 || Conv_80 + Relu_81 || Conv_83 + Relu_84 Set Tactic Name: ampere_scudnn_128x128_relu_exp_medium_nhwc_tn_v1 Tactic: -2809379259463049391
[03/24/2023-12:57:13] [V] [TRT] Tactic: -2809379259463049391 Time: 1.088
[03/24/2023-12:57:13] [V] [TRT] Conv_62 + Relu_63 || Conv_65 + Relu_66 || Conv_68 + Relu_69 || Conv_71 + Relu_72 || Conv_74 + Relu_75 || Conv_77 + Relu_78 || Conv_80 + Relu_81 || Conv_83 + Relu_84 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x128x32_stage4_warpsize2x2x1_g1_tensor16x8x8_t1r3s3 Tactic: -2801041895330778813
[03/24/2023-12:57:13] [V] [TRT] Tactic: -2801041895330778813 Time: 0.240512
[03/24/2023-12:57:13] [V] [TRT] Conv_62 + Relu_63 || Conv_65 + Relu_66 || Conv_68 + Relu_69 || Conv_71 + Relu_72 || Conv_74 + Relu_75 || Conv_77 + Relu_78 || Conv_80 + Relu_81 || Conv_83 + Relu_84 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize64x256x8_stage3_warpsize1x4x1_g1_ffma_t1r3s3 Tactic: -2747929399988666512
[03/24/2023-12:57:13] [V] [TRT] Tactic: -2747929399988666512 Time: 1.11398
[03/24/2023-12:57:13] [V] [TRT] Conv_62 + Relu_63 || Conv_65 + Relu_66 || Conv_68 + Relu_69 || Conv_71 + Relu_72 || Conv_74 + Relu_75 || Conv_77 + Relu_78 || Conv_80 + Relu_81 || Conv_83 + Relu_84 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize256x128x32_stage3_warpsize4x2x1_g1_tensor16x8x8 Tactic: -1758690179295738332
[03/24/2023-12:57:13] [V] [TRT] Tactic: -1758690179295738332 Time: 0.214784
[03/24/2023-12:57:13] [V] [TRT] Conv_62 + Relu_63 || Conv_65 + Relu_66 || Conv_68 + Relu_69 || Conv_71 + Relu_72 || Conv_74 + Relu_75 || Conv_77 + Relu_78 || Conv_80 + Relu_81 || Conv_83 + Relu_84 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x64x64_stage3_warpsize2x2x1_g1_tensor16x8x8_t1r3s3 Tactic: -1484546572846226796
[03/24/2023-12:57:13] [V] [TRT] Tactic: -1484546572846226796 Time: 0.315392
[03/24/2023-12:57:13] [V] [TRT] Conv_62 + Relu_63 || Conv_65 + Relu_66 || Conv_68 + Relu_69 || Conv_71 + Relu_72 || Conv_74 + Relu_75 || Conv_77 + Relu_78 || Conv_80 + Relu_81 || Conv_83 + Relu_84 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize64x256x8_stage3_warpsize1x4x1_g1_ffma Tactic: -1472061967969061456
[03/24/2023-12:57:13] [V] [TRT] Tactic: -1472061967969061456 Time: 1.13946
[03/24/2023-12:57:13] [V] [TRT] Conv_62 + Relu_63 || Conv_65 + Relu_66 || Conv_68 + Relu_69 || Conv_71 + Relu_72 || Conv_74 + Relu_75 || Conv_77 + Relu_78 || Conv_80 + Relu_81 || Conv_83 + Relu_84 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x128x32_stage4_warpsize2x2x1_g1_tensor16x8x8 Tactic: -858667497925695276
[03/24/2023-12:57:13] [V] [TRT] Tactic: -858667497925695276 Time: 0.333824
[03/24/2023-12:57:13] [V] [TRT] Conv_62 + Relu_63 || Conv_65 + Relu_66 || Conv_68 + Relu_69 || Conv_71 + Relu_72 || Conv_74 + Relu_75 || Conv_77 + Relu_78 || Conv_80 + Relu_81 || Conv_83 + Relu_84 Set Tactic Name: ampere_scudnn_128x128_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: -504296718212024303
[03/24/2023-12:57:13] [V] [TRT] Tactic: -504296718212024303 Time: 1.07622
[03/24/2023-12:57:13] [V] [TRT] Conv_62 + Relu_63 || Conv_65 + Relu_66 || Conv_68 + Relu_69 || Conv_71 + Relu_72 || Conv_74 + Relu_75 || Conv_77 + Relu_78 || Conv_80 + Relu_81 || Conv_83 + Relu_84 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize64x128x8_stage3_warpsize1x4x1_g1_ffma Tactic: -444093195553988951
[03/24/2023-12:57:13] [V] [TRT] Tactic: -444093195553988951 Time: 1.08864
[03/24/2023-12:57:13] [V] [TRT] Fastest Tactic: 7011693366046809027 Time: 0.196992
[03/24/2023-12:57:13] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: 7011693366046809027
[03/24/2023-12:57:13] [V] [TRT] *************** Autotuning format combination: Half(2073600,32400,180,1) -> Half(16588800,32400,180,1) ***************
[03/24/2023-12:57:13] [V] [TRT] --------------- Timing Runner: Conv_62 + Relu_63 || Conv_65 + Relu_66 || Conv_68 + Relu_69 || Conv_71 + Relu_72 || Conv_74 + Relu_75 || Conv_77 + Relu_78 || Conv_80 + Relu_81 || Conv_83 + Relu_84 (CudnnConvolution)
[03/24/2023-12:57:13] [V] [TRT] Tactic: 0 Time: 1.52973
[03/24/2023-12:57:13] [V] [TRT] Tactic: 1 Time: 1.45651
[03/24/2023-12:57:13] [V] [TRT] Tactic: 2 Time: 1.56531
[03/24/2023-12:57:13] [V] [TRT] Tactic: 4 skipped. Scratch requested: 17349083136, available: 4294967296
[03/24/2023-12:57:13] [V] [TRT] Tactic: 5 Time: 4.75264
[03/24/2023-12:57:13] [V] [TRT] Tactic: 6 Time: 0.896
[03/24/2023-12:57:13] [V] [TRT] Tactic: 56 Time: 1.5287
[03/24/2023-12:57:13] [V] [TRT] Tactic: 58 Time: 1.56582
[03/24/2023-12:57:13] [V] [TRT] Tactic: 60 skipped. Scratch requested: 17349083136, available: 4294967296
[03/24/2023-12:57:13] [V] [TRT] Tactic: 61 Time: 4.75046
[03/24/2023-12:57:13] [V] [TRT] Tactic: 62 Time: 0.896
[03/24/2023-12:57:13] [V] [TRT] Fastest Tactic: 6 Time: 0.896
[03/24/2023-12:57:13] [V] [TRT] Setting workspace to 17349083136enables more tactics for profiling
[03/24/2023-12:57:13] [V] [TRT] --------------- Timing Runner: Conv_62 + Relu_63 || Conv_65 + Relu_66 || Conv_68 + Relu_69 || Conv_71 + Relu_72 || Conv_74 + Relu_75 || Conv_77 + Relu_78 || Conv_80 + Relu_81 || Conv_83 + Relu_84 (CaskConvolution)
[03/24/2023-12:57:13] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[03/24/2023-12:57:13] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CudnnConvolution Tactic: 6
[03/24/2023-12:57:13] [V] [TRT] *************** Autotuning format combination: Half(1036800,32400:2,180,1) -> Half(8294400,32400:2,180,1) ***************
[03/24/2023-12:57:13] [V] [TRT] --------------- Timing Runner: Conv_62 + Relu_63 || Conv_65 + Relu_66 || Conv_68 + Relu_69 || Conv_71 + Relu_72 || Conv_74 + Relu_75 || Conv_77 + Relu_78 || Conv_80 + Relu_81 || Conv_83 + Relu_84 (FusedConvActConvolution)
[03/24/2023-12:57:13] [V] [TRT] FusedConvActConvolution has no valid tactics for this config, skipping
[03/24/2023-12:57:13] [V] [TRT] --------------- Timing Runner: Conv_62 + Relu_63 || Conv_65 + Relu_66 || Conv_68 + Relu_69 || Conv_71 + Relu_72 || Conv_74 + Relu_75 || Conv_77 + Relu_78 || Conv_80 + Relu_81 || Conv_83 + Relu_84 (CudnnConvolution)
[03/24/2023-12:57:13] [V] [TRT] CudnnConvolution has no valid tactics for this config, skipping
[03/24/2023-12:57:13] [V] [TRT] --------------- Timing Runner: Conv_62 + Relu_63 || Conv_65 + Relu_66 || Conv_68 + Relu_69 || Conv_71 + Relu_72 || Conv_74 + Relu_75 || Conv_77 + Relu_78 || Conv_80 + Relu_81 || Conv_83 + Relu_84 (CaskConvolution)
[03/24/2023-12:57:13] [V] [TRT] Conv_62 + Relu_63 || Conv_65 + Relu_66 || Conv_68 + Relu_69 || Conv_71 + Relu_72 || Conv_74 + Relu_75 || Conv_77 + Relu_78 || Conv_80 + Relu_81 || Conv_83 + Relu_84 Set Tactic Name: ampere_fp16x2_hcudnn_fp16x2_128x32_relu_medium_nn_v1 Tactic: 2195670545862694453
[03/24/2023-12:57:13] [V] [TRT] Tactic: 2195670545862694453 Time: 0.603904
[03/24/2023-12:57:13] [V] [TRT] Conv_62 + Relu_63 || Conv_65 + Relu_66 || Conv_68 + Relu_69 || Conv_71 + Relu_72 || Conv_74 + Relu_75 || Conv_77 + Relu_78 || Conv_80 + Relu_81 || Conv_83 + Relu_84 Set Tactic Name: ampere_fp16x2_hcudnn_fp16x2_128x64_relu_large_nn_v1 Tactic: 3419182076704469245
[03/24/2023-12:57:13] [V] [TRT] Tactic: 3419182076704469245 Time: 0.55808
[03/24/2023-12:57:13] [V] [TRT] Conv_62 + Relu_63 || Conv_65 + Relu_66 || Conv_68 + Relu_69 || Conv_71 + Relu_72 || Conv_74 + Relu_75 || Conv_77 + Relu_78 || Conv_80 + Relu_81 || Conv_83 + Relu_84 Set Tactic Name: ampere_fp16x2_hcudnn_fp16x2_128x128_relu_medium_nn_v1 Tactic: 3891805945559659536
[03/24/2023-12:57:13] [V] [TRT] Tactic: 3891805945559659536 Time: 0.593152
[03/24/2023-12:57:13] [V] [TRT] Conv_62 + Relu_63 || Conv_65 + Relu_66 || Conv_68 + Relu_69 || Conv_71 + Relu_72 || Conv_74 + Relu_75 || Conv_77 + Relu_78 || Conv_80 + Relu_81 || Conv_83 + Relu_84 Set Tactic Name: ampere_fp16x2_hcudnn_fp16x2_128x64_relu_medium_nn_v1 Tactic: 5548126322150286555
[03/24/2023-12:57:13] [V] [TRT] Tactic: 5548126322150286555 Time: 0.553344
[03/24/2023-12:57:13] [V] [TRT] Conv_62 + Relu_63 || Conv_65 + Relu_66 || Conv_68 + Relu_69 || Conv_71 + Relu_72 || Conv_74 + Relu_75 || Conv_77 + Relu_78 || Conv_80 + Relu_81 || Conv_83 + Relu_84 Set Tactic Name: ampere_fp16x2_hcudnn_fp16x2_128x64_relu_small_nn_v1 Tactic: 6057304366605292508
[03/24/2023-12:57:13] [V] [TRT] Tactic: 6057304366605292508 Time: 0.547584
[03/24/2023-12:57:13] [V] [TRT] Conv_62 + Relu_63 || Conv_65 + Relu_66 || Conv_68 + Relu_69 || Conv_71 + Relu_72 || Conv_74 + Relu_75 || Conv_77 + Relu_78 || Conv_80 + Relu_81 || Conv_83 + Relu_84 Set Tactic Name: ampere_fp16x2_hcudnn_fp16x2_128x128_relu_large_nn_v1 Tactic: -7928611605886347652
[03/24/2023-12:57:14] [V] [TRT] Tactic: -7928611605886347652 Time: 0.612608
[03/24/2023-12:57:14] [V] [TRT] Conv_62 + Relu_63 || Conv_65 + Relu_66 || Conv_68 + Relu_69 || Conv_71 + Relu_72 || Conv_74 + Relu_75 || Conv_77 + Relu_78 || Conv_80 + Relu_81 || Conv_83 + Relu_84 Set Tactic Name: ampere_fp16x2_hcudnn_fp16x2_128x32_relu_large_nn_v1 Tactic: -5172391392092686714
[03/24/2023-12:57:14] [V] [TRT] Tactic: -5172391392092686714 Time: 0.610304
[03/24/2023-12:57:14] [V] [TRT] Conv_62 + Relu_63 || Conv_65 + Relu_66 || Conv_68 + Relu_69 || Conv_71 + Relu_72 || Conv_74 + Relu_75 || Conv_77 + Relu_78 || Conv_80 + Relu_81 || Conv_83 + Relu_84 Set Tactic Name: ampere_fp16x2_hcudnn_fp16x2_128x32_relu_small_nn_v1 Tactic: -4374269919094467161
[03/24/2023-12:57:14] [V] [TRT] Tactic: -4374269919094467161 Time: 0.59648
[03/24/2023-12:57:14] [V] [TRT] Conv_62 + Relu_63 || Conv_65 + Relu_66 || Conv_68 + Relu_69 || Conv_71 + Relu_72 || Conv_74 + Relu_75 || Conv_77 + Relu_78 || Conv_80 + Relu_81 || Conv_83 + Relu_84 Set Tactic Name: ampere_fp16x2_hcudnn_winograd_fp16x2_128x128_ldg1_ldg4_relu_tile148t_nt_v1 Tactic: -4083394051665370953
[03/24/2023-12:57:14] [V] [TRT] Tactic: -4083394051665370953 Time: 0.334848
[03/24/2023-12:57:14] [V] [TRT] Conv_62 + Relu_63 || Conv_65 + Relu_66 || Conv_68 + Relu_69 || Conv_71 + Relu_72 || Conv_74 + Relu_75 || Conv_77 + Relu_78 || Conv_80 + Relu_81 || Conv_83 + Relu_84 Set Tactic Name: ampere_fp16x2_hcudnn_fp16x2_128x128_relu_small_nn_v1 Tactic: -1546027692247304867
[03/24/2023-12:57:14] [V] [TRT] Tactic: -1546027692247304867 Time: 0.59968
[03/24/2023-12:57:14] [V] [TRT] Fastest Tactic: -4083394051665370953 Time: 0.334848
[03/24/2023-12:57:14] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: -4083394051665370953
[03/24/2023-12:57:14] [V] [TRT] *************** Autotuning format combination: Half(259200,1:8,1440,8) -> Float(16588800,32400,180,1) ***************
[03/24/2023-12:57:14] [V] [TRT] --------------- Timing Runner: Conv_62 + Relu_63 || Conv_65 + Relu_66 || Conv_68 + Relu_69 || Conv_71 + Relu_72 || Conv_74 + Relu_75 || Conv_77 + Relu_78 || Conv_80 + Relu_81 || Conv_83 + Relu_84 (CudnnConvolution)
[03/24/2023-12:57:14] [V] [TRT] CudnnConvolution has no valid tactics for this config, skipping
[03/24/2023-12:57:14] [V] [TRT] --------------- Timing Runner: Conv_62 + Relu_63 || Conv_65 + Relu_66 || Conv_68 + Relu_69 || Conv_71 + Relu_72 || Conv_74 + Relu_75 || Conv_77 + Relu_78 || Conv_80 + Relu_81 || Conv_83 + Relu_84 (CaskConvolution)
[03/24/2023-12:57:14] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[03/24/2023-12:57:14] [V] [TRT] *************** Autotuning format combination: Half(259200,1:8,1440,8) -> Half(2073600,1:8,11520,64) ***************
[03/24/2023-12:57:14] [V] [TRT] --------------- Timing Runner: Conv_62 + Relu_63 || Conv_65 + Relu_66 || Conv_68 + Relu_69 || Conv_71 + Relu_72 || Conv_74 + Relu_75 || Conv_77 + Relu_78 || Conv_80 + Relu_81 || Conv_83 + Relu_84 (CudaDepthwiseConvolution)
[03/24/2023-12:57:14] [V] [TRT] CudaDepthwiseConvolution has no valid tactics for this config, skipping
[03/24/2023-12:57:14] [V] [TRT] --------------- Timing Runner: Conv_62 + Relu_63 || Conv_65 + Relu_66 || Conv_68 + Relu_69 || Conv_71 + Relu_72 || Conv_74 + Relu_75 || Conv_77 + Relu_78 || Conv_80 + Relu_81 || Conv_83 + Relu_84 (CudnnConvolution)
[03/24/2023-12:57:14] [V] [TRT] Tactic: 0 Time: 1.7696
[03/24/2023-12:57:14] [V] [TRT] Tactic: 1 Time: 3.2416
[03/24/2023-12:57:14] [V] [TRT] Tactic: 2 Time: 1.75603
[03/24/2023-12:57:14] [V] [TRT] Tactic: 6 Time: 0.888576
[03/24/2023-12:57:14] [V] [TRT] Tactic: 56 Time: 1.76896
[03/24/2023-12:57:14] [V] [TRT] Tactic: 58 Time: 1.75642
[03/24/2023-12:57:14] [V] [TRT] Tactic: 62 Time: 0.890368
[03/24/2023-12:57:14] [V] [TRT] Fastest Tactic: 6 Time: 0.888576
[03/24/2023-12:57:14] [V] [TRT] --------------- Timing Runner: Conv_62 + Relu_63 || Conv_65 + Relu_66 || Conv_68 + Relu_69 || Conv_71 + Relu_72 || Conv_74 + Relu_75 || Conv_77 + Relu_78 || Conv_80 + Relu_81 || Conv_83 + Relu_84 (CaskConvolution)
[03/24/2023-12:57:14] [V] [TRT] Conv_62 + Relu_63 || Conv_65 + Relu_66 || Conv_68 + Relu_69 || Conv_71 + Relu_72 || Conv_74 + Relu_75 || Conv_77 + Relu_78 || Conv_80 + Relu_81 || Conv_83 + Relu_84 Set Tactic Name: ampere_h16816cudnn_256x128_ldg8_relu_exp_medium_nhwc_tn_v1 Tactic: 254850674756030979
[03/24/2023-12:57:14] [V] [TRT] Tactic: 254850674756030979 Time: 0.113536
[03/24/2023-12:57:14] [V] [TRT] Conv_62 + Relu_63 || Conv_65 + Relu_66 || Conv_68 + Relu_69 || Conv_71 + Relu_72 || Conv_74 + Relu_75 || Conv_77 + Relu_78 || Conv_80 + Relu_81 || Conv_83 + Relu_84 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x128x32_stage3_warpsize4x2x1_g1_tensor16x8x16_t1r3s3 Tactic: 328038211831149625
[03/24/2023-12:57:14] [V] [TRT] Tactic: 328038211831149625 Time: 0.106752
[03/24/2023-12:57:14] [V] [TRT] Conv_62 + Relu_63 || Conv_65 + Relu_66 || Conv_68 + Relu_69 || Conv_71 + Relu_72 || Conv_74 + Relu_75 || Conv_77 + Relu_78 || Conv_80 + Relu_81 || Conv_83 + Relu_84 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x64x64_stage3_warpsize2x2x1_g1_tensor16x8x16_t1r3s3 Tactic: 411553864378931917
[03/24/2023-12:57:14] [V] [TRT] Tactic: 411553864378931917 Time: 0.141184
[03/24/2023-12:57:14] [V] [TRT] Conv_62 + Relu_63 || Conv_65 + Relu_66 || Conv_68 + Relu_69 || Conv_71 + Relu_72 || Conv_74 + Relu_75 || Conv_77 + Relu_78 || Conv_80 + Relu_81 || Conv_83 + Relu_84 Set Tactic Name: sm75_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x128x32_stage1_warpsize4x2x1_g1_tensor16x8x8_t1r3s3 Tactic: 864841579020773074
[03/24/2023-12:57:14] [V] [TRT] Tactic: 864841579020773074 Time: 0.12416
[03/24/2023-12:57:14] [V] [TRT] Conv_62 + Relu_63 || Conv_65 + Relu_66 || Conv_68 + Relu_69 || Conv_71 + Relu_72 || Conv_74 + Relu_75 || Conv_77 + Relu_78 || Conv_80 + Relu_81 || Conv_83 + Relu_84 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x128x32_stage4_warpsize2x2x1_g1_tensor16x8x16 Tactic: 1011057357468998345
[03/24/2023-12:57:14] [V] [TRT] Tactic: 1011057357468998345 Time: 0.104704
[03/24/2023-12:57:14] [V] [TRT] Conv_62 + Relu_63 || Conv_65 + Relu_66 || Conv_68 + Relu_69 || Conv_71 + Relu_72 || Conv_74 + Relu_75 || Conv_77 + Relu_78 || Conv_80 + Relu_81 || Conv_83 + Relu_84 Set Tactic Name: sm75_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x64x32_stage1_warpsize4x1x1_g1_tensor16x8x8 Tactic: 1013168150133367738
[03/24/2023-12:57:14] [V] [TRT] Tactic: 1013168150133367738 Time: 0.142848
[03/24/2023-12:57:14] [V] [TRT] Conv_62 + Relu_63 || Conv_65 + Relu_66 || Conv_68 + Relu_69 || Conv_71 + Relu_72 || Conv_74 + Relu_75 || Conv_77 + Relu_78 || Conv_80 + Relu_81 || Conv_83 + Relu_84 Set Tactic Name: ampere_h16816cudnn_256x128_ldg8_relu_exp_stages_64x3_small_nhwc_tn_v1 Tactic: 1016009564074305832
[03/24/2023-12:57:14] [V] [TRT] Tactic: 1016009564074305832 Time: 0.11584
[03/24/2023-12:57:14] [V] [TRT] Conv_62 + Relu_63 || Conv_65 + Relu_66 || Conv_68 + Relu_69 || Conv_71 + Relu_72 || Conv_74 + Relu_75 || Conv_77 + Relu_78 || Conv_80 + Relu_81 || Conv_83 + Relu_84 Set Tactic Name: sm75_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x128x32_stage1_warpsize2x2x1_g1_tensor16x8x8 Tactic: 1067227531433278814
[03/24/2023-12:57:14] [V] [TRT] Tactic: 1067227531433278814 Time: 0.125952
[03/24/2023-12:57:14] [V] [TRT] Conv_62 + Relu_63 || Conv_65 + Relu_66 || Conv_68 + Relu_69 || Conv_71 + Relu_72 || Conv_74 + Relu_75 || Conv_77 + Relu_78 || Conv_80 + Relu_81 || Conv_83 + Relu_84 Set Tactic Name: ampere_h1688cudnn_128x128_ldg8_relu_exp_medium_nhwc_tn_v1 Tactic: 1156328698016730421
[03/24/2023-12:57:14] [V] [TRT] Tactic: 1156328698016730421 Time: 0.129536
[03/24/2023-12:57:14] [V] [TRT] Conv_62 + Relu_63 || Conv_65 + Relu_66 || Conv_68 + Relu_69 || Conv_71 + Relu_72 || Conv_74 + Relu_75 || Conv_77 + Relu_78 || Conv_80 + Relu_81 || Conv_83 + Relu_84 Set Tactic Name: sm75_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x128x32_stage1_warpsize2x2x1_g1_tensor16x8x8 Tactic: 1579845938601132607
[03/24/2023-12:57:14] [V] [TRT] Tactic: 1579845938601132607 Time: 0.12288
[03/24/2023-12:57:14] [V] [TRT] Conv_62 + Relu_63 || Conv_65 + Relu_66 || Conv_68 + Relu_69 || Conv_71 + Relu_72 || Conv_74 + Relu_75 || Conv_77 + Relu_78 || Conv_80 + Relu_81 || Conv_83 + Relu_84 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x128x32_stage5_warpsize2x2x1_g1_tensor16x8x16_t1r3s3 Tactic: 1723736032573714698
[03/24/2023-12:57:14] [V] [TRT] Tactic: 1723736032573714698 Time: 0.123264
[03/24/2023-12:57:14] [V] [TRT] Conv_62 + Relu_63 || Conv_65 + Relu_66 || Conv_68 + Relu_69 || Conv_71 + Relu_72 || Conv_74 + Relu_75 || Conv_77 + Relu_78 || Conv_80 + Relu_81 || Conv_83 + Relu_84 Set Tactic Name: sm75_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x32x32_stage1_warpsize4x1x1_g1_tensor16x8x8 Tactic: 1796821236841789338
[03/24/2023-12:57:14] [V] [TRT] Tactic: 1796821236841789338 Time: 0.220416
[03/24/2023-12:57:14] [V] [TRT] Conv_62 + Relu_63 || Conv_65 + Relu_66 || Conv_68 + Relu_69 || Conv_71 + Relu_72 || Conv_74 + Relu_75 || Conv_77 + Relu_78 || Conv_80 + Relu_81 || Conv_83 + Relu_84 Set Tactic Name: ampere_h16816cudnn_128x64_ldg8_relu_exp_stages_64x4_medium_nhwc_tn_v1 Tactic: 1832046141070096030
[03/24/2023-12:57:14] [V] [TRT] Tactic: 1832046141070096030 Time: 0.1664
[03/24/2023-12:57:14] [V] [TRT] Conv_62 + Relu_63 || Conv_65 + Relu_66 || Conv_68 + Relu_69 || Conv_71 + Relu_72 || Conv_74 + Relu_75 || Conv_77 + Relu_78 || Conv_80 + Relu_81 || Conv_83 + Relu_84 Set Tactic Name: ampere_h16816cudnn_128x64_sliced1x2_ldg8_relu_exp_stages_64x3_small_nhwc_tn_v1 Tactic: 1838082074606840426
[03/24/2023-12:57:14] [V] [TRT] Tactic: 1838082074606840426 Time: 0.129664
[03/24/2023-12:57:14] [V] [TRT] Conv_62 + Relu_63 || Conv_65 + Relu_66 || Conv_68 + Relu_69 || Conv_71 + Relu_72 || Conv_74 + Relu_75 || Conv_77 + Relu_78 || Conv_80 + Relu_81 || Conv_83 + Relu_84 Set Tactic Name: ampere_h16816cudnn_64x64_sliced1x2_ldg8_relu_exp_stages_64x5_small_nhwc_tn_v1 Tactic: 1899296423087490472
[03/24/2023-12:57:14] [V] [TRT] Tactic: 1899296423087490472 Time: 0.189952
[03/24/2023-12:57:14] [V] [TRT] Conv_62 + Relu_63 || Conv_65 + Relu_66 || Conv_68 + Relu_69 || Conv_71 + Relu_72 || Conv_74 + Relu_75 || Conv_77 + Relu_78 || Conv_80 + Relu_81 || Conv_83 + Relu_84 Set Tactic Name: sm75_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x32x32_stage1_warpsize4x1x1_g1_tensor16x8x8 Tactic: 1948263663414159978
[03/24/2023-12:57:14] [V] [TRT] Tactic: 1948263663414159978 Time: 0.191616
[03/24/2023-12:57:14] [V] [TRT] Conv_62 + Relu_63 || Conv_65 + Relu_66 || Conv_68 + Relu_69 || Conv_71 + Relu_72 || Conv_74 + Relu_75 || Conv_77 + Relu_78 || Conv_80 + Relu_81 || Conv_83 + Relu_84 Set Tactic Name: sm75_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x256x64_stage1_warpsize1x4x2_g1_tensor16x8x8 Tactic: 2027733232253711640
[03/24/2023-12:57:14] [V] [TRT] Tactic: 2027733232253711640 Time: 0.146816
[03/24/2023-12:57:14] [V] [TRT] Conv_62 + Relu_63 || Conv_65 + Relu_66 || Conv_68 + Relu_69 || Conv_71 + Relu_72 || Conv_74 + Relu_75 || Conv_77 + Relu_78 || Conv_80 + Relu_81 || Conv_83 + Relu_84 Set Tactic Name: sm75_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x64x32_stage1_warpsize2x2x1_g1_tensor16x8x8_t1r3s3 Tactic: 2154731107061273008
[03/24/2023-12:57:14] [V] [TRT] Tactic: 2154731107061273008 Time: 0.148736
[03/24/2023-12:57:14] [V] [TRT] Conv_62 + Relu_63 || Conv_65 + Relu_66 || Conv_68 + Relu_69 || Conv_71 + Relu_72 || Conv_74 + Relu_75 || Conv_77 + Relu_78 || Conv_80 + Relu_81 || Conv_83 + Relu_84 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x64x64_stage3_warpsize2x2x1_g1_tensor16x8x16 Tactic: 2428167804343994714
[03/24/2023-12:57:14] [V] [TRT] Tactic: 2428167804343994714 Time: 0.134528
[03/24/2023-12:57:14] [V] [TRT] Conv_62 + Relu_63 || Conv_65 + Relu_66 || Conv_68 + Relu_69 || Conv_71 + Relu_72 || Conv_74 + Relu_75 || Conv_77 + Relu_78 || Conv_80 + Relu_81 || Conv_83 + Relu_84 Set Tactic Name: ampere_h16816cudnn_128x128_ldg8_relu_exp_medium_nhwc_tn_v1 Tactic: 2541579301352125276
[03/24/2023-12:57:14] [V] [TRT] Tactic: 2541579301352125276 Time: 0.106624
[03/24/2023-12:57:14] [V] [TRT] Conv_62 + Relu_63 || Conv_65 + Relu_66 || Conv_68 + Relu_69 || Conv_71 + Relu_72 || Conv_74 + Relu_75 || Conv_77 + Relu_78 || Conv_80 + Relu_81 || Conv_83 + Relu_84 Set Tactic Name: ampere_h16816cudnn_64x64_sliced1x2_ldg8_relu_exp_stages_64x6_small_nhwc_tn_v1 Tactic: 2657157263811141609
[03/24/2023-12:57:14] [V] [TRT] Tactic: 2657157263811141609 Time: 0.244096
[03/24/2023-12:57:14] [V] [TRT] Conv_62 + Relu_63 || Conv_65 + Relu_66 || Conv_68 + Relu_69 || Conv_71 + Relu_72 || Conv_74 + Relu_75 || Conv_77 + Relu_78 || Conv_80 + Relu_81 || Conv_83 + Relu_84 Set Tactic Name: ampere_h16816cudnn_64x128_sliced1x2_ldg8_relu_exp_stages_64x4_large_nhwc_tn_v1 Tactic: 2819719497590964443
[03/24/2023-12:57:14] [V] [TRT] Tactic: 2819719497590964443 Time: 0.17024
[03/24/2023-12:57:14] [V] [TRT] Conv_62 + Relu_63 || Conv_65 + Relu_66 || Conv_68 + Relu_69 || Conv_71 + Relu_72 || Conv_74 + Relu_75 || Conv_77 + Relu_78 || Conv_80 + Relu_81 || Conv_83 + Relu_84 Set Tactic Name: ampere_h16816cudnn_128x64_sliced1x2_ldg8_relu_exp_stages_64x3_medium_nhwc_tn_v1 Tactic: 2968605903460894194
[03/24/2023-12:57:14] [V] [TRT] Tactic: 2968605903460894194 Time: 0.132992
[03/24/2023-12:57:14] [V] [TRT] Conv_62 + Relu_63 || Conv_65 + Relu_66 || Conv_68 + Relu_69 || Conv_71 + Relu_72 || Conv_74 + Relu_75 || Conv_77 + Relu_78 || Conv_80 + Relu_81 || Conv_83 + Relu_84 Set Tactic Name: ampere_h16816cudnn_128x128_ldg8_relu_exp_large_nhwc_tn_v1 Tactic: 2986078304285316765
[03/24/2023-12:57:14] [V] [TRT] Tactic: 2986078304285316765 Time: 0.10688
[03/24/2023-12:57:14] [V] [TRT] Conv_62 + Relu_63 || Conv_65 + Relu_66 || Conv_68 + Relu_69 || Conv_71 + Relu_72 || Conv_74 + Relu_75 || Conv_77 + Relu_78 || Conv_80 + Relu_81 || Conv_83 + Relu_84 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x256x64_stage3_warpsize1x4x1_g1_tensor16x8x16 Tactic: 3016308193087082166
[03/24/2023-12:57:14] [V] [TRT] Tactic: 3016308193087082166 Time: 0.138496
[03/24/2023-12:57:14] [V] [TRT] Conv_62 + Relu_63 || Conv_65 + Relu_66 || Conv_68 + Relu_69 || Conv_71 + Relu_72 || Conv_74 + Relu_75 || Conv_77 + Relu_78 || Conv_80 + Relu_81 || Conv_83 + Relu_84 Set Tactic Name: ampere_h16816cudnn_256x64_ldg8_relu_exp_stages_64x3_large_nhwc_tn_v1 Tactic: 3221382575080507859
[03/24/2023-12:57:14] [V] [TRT] Tactic: 3221382575080507859 Time: 0.135296
[03/24/2023-12:57:14] [V] [TRT] Conv_62 + Relu_63 || Conv_65 + Relu_66 || Conv_68 + Relu_69 || Conv_71 + Relu_72 || Conv_74 + Relu_75 || Conv_77 + Relu_78 || Conv_80 + Relu_81 || Conv_83 + Relu_84 Set Tactic Name: ampere_h16816cudnn_128x128_ldg8_relu_exp_stages_64x3_medium_nhwc_tn_v1 Tactic: 3362537467505018070
[03/24/2023-12:57:14] [V] [TRT] Tactic: 3362537467505018070 Time: 0.129152
[03/24/2023-12:57:14] [V] [TRT] Conv_62 + Relu_63 || Conv_65 + Relu_66 || Conv_68 + Relu_69 || Conv_71 + Relu_72 || Conv_74 + Relu_75 || Conv_77 + Relu_78 || Conv_80 + Relu_81 || Conv_83 + Relu_84 Set Tactic Name: sm75_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x64x32_stage1_warpsize4x1x1_g1_tensor16x8x8_t1r3s3 Tactic: 3464689803495983377
[03/24/2023-12:57:14] [V] [TRT] Tactic: 3464689803495983377 Time: 0.1344
[03/24/2023-12:57:14] [V] [TRT] Conv_62 + Relu_63 || Conv_65 + Relu_66 || Conv_68 + Relu_69 || Conv_71 + Relu_72 || Conv_74 + Relu_75 || Conv_77 + Relu_78 || Conv_80 + Relu_81 || Conv_83 + Relu_84 Set Tactic Name: ampere_h1688cudnn_256x128_ldg8_relu_exp_medium_nhwc_tn_v1 Tactic: 3513075359009385578
[03/24/2023-12:57:14] [V] [TRT] Tactic: 3513075359009385578 Time: 0.133248
[03/24/2023-12:57:14] [V] [TRT] Conv_62 + Relu_63 || Conv_65 + Relu_66 || Conv_68 + Relu_69 || Conv_71 + Relu_72 || Conv_74 + Relu_75 || Conv_77 + Relu_78 || Conv_80 + Relu_81 || Conv_83 + Relu_84 Set Tactic Name: ampere_h16816cudnn_128x64_ldg8_relu_exp_stages_64x4_large_nhwc_tn_v1 Tactic: 3573559043797674382
[03/24/2023-12:57:14] [V] [TRT] Tactic: 3573559043797674382 Time: 0.169984
[03/24/2023-12:57:14] [V] [TRT] Conv_62 + Relu_63 || Conv_65 + Relu_66 || Conv_68 + Relu_69 || Conv_71 + Relu_72 || Conv_74 + Relu_75 || Conv_77 + Relu_78 || Conv_80 + Relu_81 || Conv_83 + Relu_84 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x64x64_stage4_warpsize2x2x1_g1_tensor16x8x16_t1r3s3 Tactic: 3591970081995419777
[03/24/2023-12:57:14] [V] [TRT] Tactic: 3591970081995419777 Time: 0.175872
[03/24/2023-12:57:14] [V] [TRT] Conv_62 + Relu_63 || Conv_65 + Relu_66 || Conv_68 + Relu_69 || Conv_71 + Relu_72 || Conv_74 + Relu_75 || Conv_77 + Relu_78 || Conv_80 + Relu_81 || Conv_83 + Relu_84 Set Tactic Name: sm75_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x128x32_stage1_warpsize2x2x1_g1_tensor16x8x8_t1r3s3 Tactic: 3636831327753843771
[03/24/2023-12:57:14] [V] [TRT] Tactic: 3636831327753843771 Time: 0.11392
[03/24/2023-12:57:14] [V] [TRT] Conv_62 + Relu_63 || Conv_65 + Relu_66 || Conv_68 + Relu_69 || Conv_71 + Relu_72 || Conv_74 + Relu_75 || Conv_77 + Relu_78 || Conv_80 + Relu_81 || Conv_83 + Relu_84 Set Tactic Name: ampere_h1688cudnn_128x128_ldg8_relu_exp_small_nhwc_tn_v1 Tactic: 3704534001553878387
[03/24/2023-12:57:14] [V] [TRT] Tactic: 3704534001553878387 Time: 0.1248
[03/24/2023-12:57:14] [V] [TRT] Conv_62 + Relu_63 || Conv_65 + Relu_66 || Conv_68 + Relu_69 || Conv_71 + Relu_72 || Conv_74 + Relu_75 || Conv_77 + Relu_78 || Conv_80 + Relu_81 || Conv_83 + Relu_84 Set Tactic Name: ampere_h16816cudnn_64x128_ldg8_relu_exp_stages_64x4_small_nhwc_tn_v1 Tactic: 4278315135102886928
[03/24/2023-12:57:14] [V] [TRT] Tactic: 4278315135102886928 Time: 0.154496
[03/24/2023-12:57:14] [V] [TRT] Conv_62 + Relu_63 || Conv_65 + Relu_66 || Conv_68 + Relu_69 || Conv_71 + Relu_72 || Conv_74 + Relu_75 || Conv_77 + Relu_78 || Conv_80 + Relu_81 || Conv_83 + Relu_84 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x32x32_stage4_warpsize4x1x1_g1_tensor16x8x16_t1r3s3 Tactic: 4503233883285355107
[03/24/2023-12:57:14] [V] [TRT] Tactic: 4503233883285355107 Time: 0.172032
[03/24/2023-12:57:14] [V] [TRT] Conv_62 + Relu_63 || Conv_65 + Relu_66 || Conv_68 + Relu_69 || Conv_71 + Relu_72 || Conv_74 + Relu_75 || Conv_77 + Relu_78 || Conv_80 + Relu_81 || Conv_83 + Relu_84 Set Tactic Name: ampere_h16816cudnn_256x64_ldg8_relu_exp_stages_64x3_medium_nhwc_tn_v1 Tactic: 4540505769798915372
[03/24/2023-12:57:14] [V] [TRT] Tactic: 4540505769798915372 Time: 0.134144
[03/24/2023-12:57:14] [V] [TRT] Conv_62 + Relu_63 || Conv_65 + Relu_66 || Conv_68 + Relu_69 || Conv_71 + Relu_72 || Conv_74 + Relu_75 || Conv_77 + Relu_78 || Conv_80 + Relu_81 || Conv_83 + Relu_84 Set Tactic Name: ampere_h16816cudnn_256x64_sliced1x2_ldg8_relu_exp_small_nhwc_tn_v1 Tactic: 4802447371470387646
[03/24/2023-12:57:14] [V] [TRT] Tactic: 4802447371470387646 Time: 0.152064
[03/24/2023-12:57:14] [V] [TRT] Conv_62 + Relu_63 || Conv_65 + Relu_66 || Conv_68 + Relu_69 || Conv_71 + Relu_72 || Conv_74 + Relu_75 || Conv_77 + Relu_78 || Conv_80 + Relu_81 || Conv_83 + Relu_84 Set Tactic Name: ampere_h16816cudnn_256x128_ldg8_relu_exp_small_nhwc_tn_v1 Tactic: 5059676457552313631
[03/24/2023-12:57:14] [V] [TRT] Tactic: 5059676457552313631 Time: 0.111744
[03/24/2023-12:57:14] [V] [TRT] Conv_62 + Relu_63 || Conv_65 + Relu_66 || Conv_68 + Relu_69 || Conv_71 + Relu_72 || Conv_74 + Relu_75 || Conv_77 + Relu_78 || Conv_80 + Relu_81 || Conv_83 + Relu_84 Set Tactic Name: sm75_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x128x64_stage1_warpsize2x2x1_g1_tensor16x8x8_t1r3s3 Tactic: 5263029549013613567
[03/24/2023-12:57:14] [V] [TRT] Tactic: 5263029549013613567 Time: 0.113664
[03/24/2023-12:57:14] [V] [TRT] Conv_62 + Relu_63 || Conv_65 + Relu_66 || Conv_68 + Relu_69 || Conv_71 + Relu_72 || Conv_74 + Relu_75 || Conv_77 + Relu_78 || Conv_80 + Relu_81 || Conv_83 + Relu_84 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x64x64_stage4_warpsize2x2x1_g1_tensor16x8x16 Tactic: 5368829646735632944
[03/24/2023-12:57:14] [V] [TRT] Tactic: 5368829646735632944 Time: 0.176128
[03/24/2023-12:57:14] [V] [TRT] Conv_62 + Relu_63 || Conv_65 + Relu_66 || Conv_68 + Relu_69 || Conv_71 + Relu_72 || Conv_74 + Relu_75 || Conv_77 + Relu_78 || Conv_80 + Relu_81 || Conv_83 + Relu_84 Set Tactic Name: ampere_h1688cudnn_256x64_sliced1x2_ldg8_relu_exp_small_nhwc_tn_v1 Tactic: 5398999388616959893
[03/24/2023-12:57:14] [V] [TRT] Tactic: 5398999388616959893 Time: 0.160384
[03/24/2023-12:57:14] [V] [TRT] Conv_62 + Relu_63 || Conv_65 + Relu_66 || Conv_68 + Relu_69 || Conv_71 + Relu_72 || Conv_74 + Relu_75 || Conv_77 + Relu_78 || Conv_80 + Relu_81 || Conv_83 + Relu_84 Set Tactic Name: sm75_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x256x32_stage1_warpsize2x4x1_g1_tensor16x8x8_t1r3s3 Tactic: 5506334059535811602
[03/24/2023-12:57:14] [V] [TRT] Tactic: 5506334059535811602 Time: 0.121216
[03/24/2023-12:57:14] [V] [TRT] Conv_62 + Relu_63 || Conv_65 + Relu_66 || Conv_68 + Relu_69 || Conv_71 + Relu_72 || Conv_74 + Relu_75 || Conv_77 + Relu_78 || Conv_80 + Relu_81 || Conv_83 + Relu_84 Set Tactic Name: ampere_h16816cudnn_64x128_sliced1x2_ldg8_relu_exp_stages_64x3_large_nhwc_tn_v1 Tactic: 5746691132547383910
[03/24/2023-12:57:14] [V] [TRT] Tactic: 5746691132547383910 Time: 0.131712
[03/24/2023-12:57:14] [V] [TRT] Conv_62 + Relu_63 || Conv_65 + Relu_66 || Conv_68 + Relu_69 || Conv_71 + Relu_72 || Conv_74 + Relu_75 || Conv_77 + Relu_78 || Conv_80 + Relu_81 || Conv_83 + Relu_84 Set Tactic Name: ampere_h16816cudnn_256x64_ldg8_relu_exp_large_nhwc_tn_v1 Tactic: 5770170567977052602
[03/24/2023-12:57:14] [V] [TRT] Tactic: 5770170567977052602 Time: 0.129152
[03/24/2023-12:57:14] [V] [TRT] Conv_62 + Relu_63 || Conv_65 + Relu_66 || Conv_68 + Relu_69 || Conv_71 + Relu_72 || Conv_74 + Relu_75 || Conv_77 + Relu_78 || Conv_80 + Relu_81 || Conv_83 + Relu_84 Set Tactic Name: sm75_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x32x64_stage1_warpsize2x1x2_g1_tensor16x8x8_t1r3s3 Tactic: 5932046018238429951
[03/24/2023-12:57:14] [V] [TRT] Tactic: 5932046018238429951 Time: 0.211712
[03/24/2023-12:57:14] [V] [TRT] Conv_62 + Relu_63 || Conv_65 + Relu_66 || Conv_68 + Relu_69 || Conv_71 + Relu_72 || Conv_74 + Relu_75 || Conv_77 + Relu_78 || Conv_80 + Relu_81 || Conv_83 + Relu_84 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x64x32_stage3_warpsize4x1x1_g1_tensor16x8x16_t1r3s3 Tactic: 5953552212833506549
[03/24/2023-12:57:14] [V] [TRT] Tactic: 5953552212833506549 Time: 0.10816
[03/24/2023-12:57:14] [V] [TRT] Conv_62 + Relu_63 || Conv_65 + Relu_66 || Conv_68 + Relu_69 || Conv_71 + Relu_72 || Conv_74 + Relu_75 || Conv_77 + Relu_78 || Conv_80 + Relu_81 || Conv_83 + Relu_84 Set Tactic Name: ampere_h16816cudnn_64x128_ldg8_relu_exp_stages_64x3_small_nhwc_tn_v1 Tactic: 6034364043891107501
[03/24/2023-12:57:14] [V] [TRT] Tactic: 6034364043891107501 Time: 0.134656
[03/24/2023-12:57:14] [V] [TRT] Conv_62 + Relu_63 || Conv_65 + Relu_66 || Conv_68 + Relu_69 || Conv_71 + Relu_72 || Conv_74 + Relu_75 || Conv_77 + Relu_78 || Conv_80 + Relu_81 || Conv_83 + Relu_84 Set Tactic Name: ampere_h16816cudnn_64x64_ldg8_relu_exp_stages_64x5_large_nhwc_tn_v1 Tactic: 6074229447555668232
[03/24/2023-12:57:14] [V] [TRT] Tactic: 6074229447555668232 Time: 0.205696
[03/24/2023-12:57:14] [V] [TRT] Conv_62 + Relu_63 || Conv_65 + Relu_66 || Conv_68 + Relu_69 || Conv_71 + Relu_72 || Conv_74 + Relu_75 || Conv_77 + Relu_78 || Conv_80 + Relu_81 || Conv_83 + Relu_84 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x64x64_stage3_warpsize2x2x1_g1_tensor16x8x16 Tactic: 6154447660803990543
[03/24/2023-12:57:14] [V] [TRT] Tactic: 6154447660803990543 Time: 0.145152
[03/24/2023-12:57:14] [V] [TRT] Conv_62 + Relu_63 || Conv_65 + Relu_66 || Conv_68 + Relu_69 || Conv_71 + Relu_72 || Conv_74 + Relu_75 || Conv_77 + Relu_78 || Conv_80 + Relu_81 || Conv_83 + Relu_84 Set Tactic Name: sm75_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x32x64_stage1_warpsize2x1x2_g1_tensor16x8x8 Tactic: 6195603576432354734
[03/24/2023-12:57:14] [V] [TRT] Tactic: 6195603576432354734 Time: 0.221312
[03/24/2023-12:57:14] [V] [TRT] Conv_62 + Relu_63 || Conv_65 + Relu_66 || Conv_68 + Relu_69 || Conv_71 + Relu_72 || Conv_74 + Relu_75 || Conv_77 + Relu_78 || Conv_80 + Relu_81 || Conv_83 + Relu_84 Set Tactic Name: sm75_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x32x32_stage1_warpsize4x1x1_g1_tensor16x8x8_t1r3s3 Tactic: 6252808259936499253
[03/24/2023-12:57:14] [V] [TRT] Tactic: 6252808259936499253 Time: 0.19136
[03/24/2023-12:57:14] [V] [TRT] Conv_62 + Relu_63 || Conv_65 + Relu_66 || Conv_68 + Relu_69 || Conv_71 + Relu_72 || Conv_74 + Relu_75 || Conv_77 + Relu_78 || Conv_80 + Relu_81 || Conv_83 + Relu_84 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x128x64_stage3_warpsize2x2x1_g1_tensor16x8x16 Tactic: 6325769668000961702
[03/24/2023-12:57:14] [V] [TRT] Tactic: 6325769668000961702 Time: 0.129792
[03/24/2023-12:57:14] [V] [TRT] Conv_62 + Relu_63 || Conv_65 + Relu_66 || Conv_68 + Relu_69 || Conv_71 + Relu_72 || Conv_74 + Relu_75 || Conv_77 + Relu_78 || Conv_80 + Relu_81 || Conv_83 + Relu_84 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x32x64_stage5_warpsize2x2x1_g1_tensor16x8x16 Tactic: 6350273239113254096
[03/24/2023-12:57:14] [V] [TRT] Tactic: 6350273239113254096 Time: 0.295552
[03/24/2023-12:57:14] [V] [TRT] Conv_62 + Relu_63 || Conv_65 + Relu_66 || Conv_68 + Relu_69 || Conv_71 + Relu_72 || Conv_74 + Relu_75 || Conv_77 + Relu_78 || Conv_80 + Relu_81 || Conv_83 + Relu_84 Set Tactic Name: ampere_h16816cudnn_128x128_ldg8_relu_exp_stages_64x3_small_nhwc_tn_v1 Tactic: 6377497238381488891
[03/24/2023-12:57:14] [V] [TRT] Tactic: 6377497238381488891 Time: 0.129408
[03/24/2023-12:57:14] [V] [TRT] Conv_62 + Relu_63 || Conv_65 + Relu_66 || Conv_68 + Relu_69 || Conv_71 + Relu_72 || Conv_74 + Relu_75 || Conv_77 + Relu_78 || Conv_80 + Relu_81 || Conv_83 + Relu_84 Set Tactic Name: sm75_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x64x64_stage1_warpsize2x2x1_g1_tensor16x8x8 Tactic: 6408235920257988861
[03/24/2023-12:57:14] [V] [TRT] Tactic: 6408235920257988861 Time: 0.162944
[03/24/2023-12:57:14] [V] [TRT] Conv_62 + Relu_63 || Conv_65 + Relu_66 || Conv_68 + Relu_69 || Conv_71 + Relu_72 || Conv_74 + Relu_75 || Conv_77 + Relu_78 || Conv_80 + Relu_81 || Conv_83 + Relu_84 Set Tactic Name: ampere_h16816cudnn_128x64_ldg8_relu_exp_stages_64x3_large_nhwc_tn_v1 Tactic: 6446388116965632819
[03/24/2023-12:57:14] [V] [TRT] Tactic: 6446388116965632819 Time: 0.13824
[03/24/2023-12:57:14] [V] [TRT] Conv_62 + Relu_63 || Conv_65 + Relu_66 || Conv_68 + Relu_69 || Conv_71 + Relu_72 || Conv_74 + Relu_75 || Conv_77 + Relu_78 || Conv_80 + Relu_81 || Conv_83 + Relu_84 Set Tactic Name: ampere_h16816cudnn_128x64_sliced1x2_ldg8_relu_exp_stages_64x4_medium_nhwc_tn_v1 Tactic: 6468794451065529747
[03/24/2023-12:57:14] [V] [TRT] Tactic: 6468794451065529747 Time: 0.169472
[03/24/2023-12:57:14] [V] [TRT] Conv_62 + Relu_63 || Conv_65 + Relu_66 || Conv_68 + Relu_69 || Conv_71 + Relu_72 || Conv_74 + Relu_75 || Conv_77 + Relu_78 || Conv_80 + Relu_81 || Conv_83 + Relu_84 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x128x64_stage3_warpsize4x2x1_g1_tensor16x8x16 Tactic: 6509152032538119080
[03/24/2023-12:57:14] [V] [TRT] Tactic: 6509152032538119080 Time: 0.113152
[03/24/2023-12:57:14] [V] [TRT] Conv_62 + Relu_63 || Conv_65 + Relu_66 || Conv_68 + Relu_69 || Conv_71 + Relu_72 || Conv_74 + Relu_75 || Conv_77 + Relu_78 || Conv_80 + Relu_81 || Conv_83 + Relu_84 Set Tactic Name: ampere_h1688cudnn_256x128_ldg8_relu_exp_large_nhwc_tn_v1 Tactic: 6642277870194067185
[03/24/2023-12:57:14] [V] [TRT] Tactic: 6642277870194067185 Time: 0.134784
[03/24/2023-12:57:14] [V] [TRT] Conv_62 + Relu_63 || Conv_65 + Relu_66 || Conv_68 + Relu_69 || Conv_71 + Relu_72 || Conv_74 + Relu_75 || Conv_77 + Relu_78 || Conv_80 + Relu_81 || Conv_83 + Relu_84 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x256x64_stage3_warpsize1x4x1_g1_tensor16x8x16 Tactic: 6703181542003057635
[03/24/2023-12:57:14] [V] [TRT] Tactic: 6703181542003057635 Time: 0.133248
[03/24/2023-12:57:14] [V] [TRT] Conv_62 + Relu_63 || Conv_65 + Relu_66 || Conv_68 + Relu_69 || Conv_71 + Relu_72 || Conv_74 + Relu_75 || Conv_77 + Relu_78 || Conv_80 + Relu_81 || Conv_83 + Relu_84 Set Tactic Name: ampere_h16816cudnn_64x64_ldg8_relu_exp_stages_64x5_medium_nhwc_tn_v1 Tactic: 6859477213531075460
[03/24/2023-12:57:14] [V] [TRT] Tactic: 6859477213531075460 Time: 0.20352
[03/24/2023-12:57:14] [V] [TRT] Conv_62 + Relu_63 || Conv_65 + Relu_66 || Conv_68 + Relu_69 || Conv_71 + Relu_72 || Conv_74 + Relu_75 || Conv_77 + Relu_78 || Conv_80 + Relu_81 || Conv_83 + Relu_84 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x128x32_stage4_warpsize2x2x1_g1_tensor16x8x16_t1r3s3 Tactic: 6972489290272968208
[03/24/2023-12:57:14] [V] [TRT] Tactic: 6972489290272968208 Time: 0.096512
[03/24/2023-12:57:14] [V] [TRT] Conv_62 + Relu_63 || Conv_65 + Relu_66 || Conv_68 + Relu_69 || Conv_71 + Relu_72 || Conv_74 + Relu_75 || Conv_77 + Relu_78 || Conv_80 + Relu_81 || Conv_83 + Relu_84 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x128x32_stage3_warpsize4x2x1_g1_tensor16x8x16 Tactic: 6979044990896381511
[03/24/2023-12:57:14] [V] [TRT] Tactic: 6979044990896381511 Time: 0.107648
[03/24/2023-12:57:14] [V] [TRT] Conv_62 + Relu_63 || Conv_65 + Relu_66 || Conv_68 + Relu_69 || Conv_71 + Relu_72 || Conv_74 + Relu_75 || Conv_77 + Relu_78 || Conv_80 + Relu_81 || Conv_83 + Relu_84 Set Tactic Name: ampere_h1688cudnn_256x64_ldg8_relu_exp_medium_nhwc_tn_v1 Tactic: 7216571380637776659
[03/24/2023-12:57:14] [V] [TRT] Tactic: 7216571380637776659 Time: 0.150912
[03/24/2023-12:57:14] [V] [TRT] Conv_62 + Relu_63 || Conv_65 + Relu_66 || Conv_68 + Relu_69 || Conv_71 + Relu_72 || Conv_74 + Relu_75 || Conv_77 + Relu_78 || Conv_80 + Relu_81 || Conv_83 + Relu_84 Set Tactic Name: ampere_h16816cudnn_128x64_ldg8_relu_exp_stages_64x3_medium_nhwc_tn_v1 Tactic: 7609923741161019135
[03/24/2023-12:57:14] [V] [TRT] Tactic: 7609923741161019135 Time: 0.142592
[03/24/2023-12:57:14] [V] [TRT] Conv_62 + Relu_63 || Conv_65 + Relu_66 || Conv_68 + Relu_69 || Conv_71 + Relu_72 || Conv_74 + Relu_75 || Conv_77 + Relu_78 || Conv_80 + Relu_81 || Conv_83 + Relu_84 Set Tactic Name: sm75_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x64x32_stage1_warpsize2x2x1_g1_tensor16x8x8 Tactic: 7612687199567064086
[03/24/2023-12:57:14] [V] [TRT] Tactic: 7612687199567064086 Time: 0.156672
[03/24/2023-12:57:14] [V] [TRT] Conv_62 + Relu_63 || Conv_65 + Relu_66 || Conv_68 + Relu_69 || Conv_71 + Relu_72 || Conv_74 + Relu_75 || Conv_77 + Relu_78 || Conv_80 + Relu_81 || Conv_83 + Relu_84 Set Tactic Name: ampere_h16816cudnn_64x64_ldg8_relu_exp_stages_64x6_large_nhwc_tn_v1 Tactic: 7705739241028240201
[03/24/2023-12:57:14] [V] [TRT] Tactic: 7705739241028240201 Time: 0.256256
[03/24/2023-12:57:14] [V] [TRT] Conv_62 + Relu_63 || Conv_65 + Relu_66 || Conv_68 + Relu_69 || Conv_71 + Relu_72 || Conv_74 + Relu_75 || Conv_77 + Relu_78 || Conv_80 + Relu_81 || Conv_83 + Relu_84 Set Tactic Name: sm75_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x128x32_stage1_warpsize2x2x1_g1_tensor16x8x8 Tactic: 7729555994715864793
[03/24/2023-12:57:14] [V] [TRT] Tactic: 7729555994715864793 Time: 0.151936
[03/24/2023-12:57:14] [V] [TRT] Conv_62 + Relu_63 || Conv_65 + Relu_66 || Conv_68 + Relu_69 || Conv_71 + Relu_72 || Conv_74 + Relu_75 || Conv_77 + Relu_78 || Conv_80 + Relu_81 || Conv_83 + Relu_84 Set Tactic Name: sm75_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x64x64_stage1_warpsize2x2x1_g1_tensor16x8x8_t1r3s3 Tactic: 7849296535223586261
[03/24/2023-12:57:14] [V] [TRT] Tactic: 7849296535223586261 Time: 0.16192
[03/24/2023-12:57:14] [V] [TRT] Conv_62 + Relu_63 || Conv_65 + Relu_66 || Conv_68 + Relu_69 || Conv_71 + Relu_72 || Conv_74 + Relu_75 || Conv_77 + Relu_78 || Conv_80 + Relu_81 || Conv_83 + Relu_84 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x256x32_stage3_warpsize2x4x1_g1_tensor16x8x16 Tactic: 8072087735545283117
[03/24/2023-12:57:14] [V] [TRT] Tactic: 8072087735545283117 Time: 0.106368
[03/24/2023-12:57:14] [V] [TRT] Conv_62 + Relu_63 || Conv_65 + Relu_66 || Conv_68 + Relu_69 || Conv_71 + Relu_72 || Conv_74 + Relu_75 || Conv_77 + Relu_78 || Conv_80 + Relu_81 || Conv_83 + Relu_84 Set Tactic Name: ampere_h16816cudnn_64x64_sliced1x2_ldg8_relu_exp_stages_64x5_medium_nhwc_tn_v1 Tactic: 8101703987960976805
[03/24/2023-12:57:14] [V] [TRT] Tactic: 8101703987960976805 Time: 0.19264
[03/24/2023-12:57:14] [V] [TRT] Conv_62 + Relu_63 || Conv_65 + Relu_66 || Conv_68 + Relu_69 || Conv_71 + Relu_72 || Conv_74 + Relu_75 || Conv_77 + Relu_78 || Conv_80 + Relu_81 || Conv_83 + Relu_84 Set Tactic Name: ampere_h16816cudnn_128x64_sliced1x2_ldg8_relu_exp_stages_64x4_small_nhwc_tn_v1 Tactic: 8170606396342855895
[03/24/2023-12:57:14] [V] [TRT] Tactic: 8170606396342855895 Time: 0.163968
[03/24/2023-12:57:14] [V] [TRT] Conv_62 + Relu_63 || Conv_65 + Relu_66 || Conv_68 + Relu_69 || Conv_71 + Relu_72 || Conv_74 + Relu_75 || Conv_77 + Relu_78 || Conv_80 + Relu_81 || Conv_83 + Relu_84 Set Tactic Name: sm75_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x32x64_stage1_warpsize2x1x2_g1_tensor16x8x8 Tactic: 8455608235315878803
[03/24/2023-12:57:14] [V] [TRT] Tactic: 8455608235315878803 Time: 0.235776
[03/24/2023-12:57:14] [V] [TRT] Conv_62 + Relu_63 || Conv_65 + Relu_66 || Conv_68 + Relu_69 || Conv_71 + Relu_72 || Conv_74 + Relu_75 || Conv_77 + Relu_78 || Conv_80 + Relu_81 || Conv_83 + Relu_84 Set Tactic Name: sm75_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x64x64_stage1_warpsize2x2x1_g1_tensor16x8x8 Tactic: 8668812313058150080
[03/24/2023-12:57:14] [V] [TRT] Tactic: 8668812313058150080 Time: 0.17216
[03/24/2023-12:57:14] [V] [TRT] Conv_62 + Relu_63 || Conv_65 + Relu_66 || Conv_68 + Relu_69 || Conv_71 + Relu_72 || Conv_74 + Relu_75 || Conv_77 + Relu_78 || Conv_80 + Relu_81 || Conv_83 + Relu_84 Set Tactic Name: ampere_h1688cudnn_256x64_ldg8_relu_exp_small_nhwc_tn_v1 Tactic: 8839784824303350101
[03/24/2023-12:57:14] [V] [TRT] Tactic: 8839784824303350101 Time: 0.142976
[03/24/2023-12:57:14] [V] [TRT] Conv_62 + Relu_63 || Conv_65 + Relu_66 || Conv_68 + Relu_69 || Conv_71 + Relu_72 || Conv_74 + Relu_75 || Conv_77 + Relu_78 || Conv_80 + Relu_81 || Conv_83 + Relu_84 Set Tactic Name: ampere_h16816cudnn_64x64_sliced1x2_ldg8_relu_exp_stages_64x5_large_nhwc_tn_v1 Tactic: -9217371357561775773
[03/24/2023-12:57:14] [V] [TRT] Tactic: -9217371357561775773 Time: 0.193024
[03/24/2023-12:57:14] [V] [TRT] Conv_62 + Relu_63 || Conv_65 + Relu_66 || Conv_68 + Relu_69 || Conv_71 + Relu_72 || Conv_74 + Relu_75 || Conv_77 + Relu_78 || Conv_80 + Relu_81 || Conv_83 + Relu_84 Set Tactic Name: ampere_h16816cudnn_256x64_sliced1x2_ldg8_relu_exp_medium_nhwc_tn_v1 Tactic: -9009272790678027912
[03/24/2023-12:57:14] [V] [TRT] Tactic: -9009272790678027912 Time: 0.164992
[03/24/2023-12:57:14] [V] [TRT] Conv_62 + Relu_63 || Conv_65 + Relu_66 || Conv_68 + Relu_69 || Conv_71 + Relu_72 || Conv_74 + Relu_75 || Conv_77 + Relu_78 || Conv_80 + Relu_81 || Conv_83 + Relu_84 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x32x32_stage4_warpsize4x1x1_g1_tensor16x8x16 Tactic: -8985224497679592364
[03/24/2023-12:57:14] [V] [TRT] Tactic: -8985224497679592364 Time: 0.173312
[03/24/2023-12:57:14] [V] [TRT] Conv_62 + Relu_63 || Conv_65 + Relu_66 || Conv_68 + Relu_69 || Conv_71 + Relu_72 || Conv_74 + Relu_75 || Conv_77 + Relu_78 || Conv_80 + Relu_81 || Conv_83 + Relu_84 Set Tactic Name: ampere_h16816cudnn_128x64_sliced1x2_ldg8_relu_exp_stages_64x3_large_nhwc_tn_v1 Tactic: -8949544755481315679
[03/24/2023-12:57:14] [V] [TRT] Tactic: -8949544755481315679 Time: 0.133376
[03/24/2023-12:57:14] [V] [TRT] Conv_62 + Relu_63 || Conv_65 + Relu_66 || Conv_68 + Relu_69 || Conv_71 + Relu_72 || Conv_74 + Relu_75 || Conv_77 + Relu_78 || Conv_80 + Relu_81 || Conv_83 + Relu_84 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x64x64_stage3_warpsize4x1x1_g1_tensor16x8x16_t1r3s3 Tactic: -8867999442759527766
[03/24/2023-12:57:14] [V] [TRT] Tactic: -8867999442759527766 Time: 0.145408
[03/24/2023-12:57:14] [V] [TRT] Conv_62 + Relu_63 || Conv_65 + Relu_66 || Conv_68 + Relu_69 || Conv_71 + Relu_72 || Conv_74 + Relu_75 || Conv_77 + Relu_78 || Conv_80 + Relu_81 || Conv_83 + Relu_84 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x128x64_stage3_warpsize2x2x1_g1_tensor16x8x16 Tactic: -8759929675070720385
[03/24/2023-12:57:14] [V] [TRT] Tactic: -8759929675070720385 Time: 0.124288
[03/24/2023-12:57:14] [V] [TRT] Conv_62 + Relu_63 || Conv_65 + Relu_66 || Conv_68 + Relu_69 || Conv_71 + Relu_72 || Conv_74 + Relu_75 || Conv_77 + Relu_78 || Conv_80 + Relu_81 || Conv_83 + Relu_84 Set Tactic Name: ampere_h16816cudnn_64x64_ldg8_relu_exp_stages_64x6_medium_nhwc_tn_v1 Tactic: -8604374562669615024
[03/24/2023-12:57:14] [V] [TRT] Tactic: -8604374562669615024 Time: 0.249216
[03/24/2023-12:57:14] [V] [TRT] Conv_62 + Relu_63 || Conv_65 + Relu_66 || Conv_68 + Relu_69 || Conv_71 + Relu_72 || Conv_74 + Relu_75 || Conv_77 + Relu_78 || Conv_80 + Relu_81 || Conv_83 + Relu_84 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x128x64_stage3_warpsize4x2x1_g1_tensor16x8x16 Tactic: -8362347876645295759
[03/24/2023-12:57:14] [V] [TRT] Tactic: -8362347876645295759 Time: 0.109824
[03/24/2023-12:57:14] [V] [TRT] Conv_62 + Relu_63 || Conv_65 + Relu_66 || Conv_68 + Relu_69 || Conv_71 + Relu_72 || Conv_74 + Relu_75 || Conv_77 + Relu_78 || Conv_80 + Relu_81 || Conv_83 + Relu_84 Set Tactic Name: sm75_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x128x32_stage1_warpsize4x2x1_g1_tensor16x8x8 Tactic: -8254009616492665198
[03/24/2023-12:57:14] [V] [TRT] Tactic: -8254009616492665198 Time: 0.122624
[03/24/2023-12:57:14] [V] [TRT] Conv_62 + Relu_63 || Conv_65 + Relu_66 || Conv_68 + Relu_69 || Conv_71 + Relu_72 || Conv_74 + Relu_75 || Conv_77 + Relu_78 || Conv_80 + Relu_81 || Conv_83 + Relu_84 Set Tactic Name: ampere_h16816cudnn_256x128_ldg8_relu_exp_stages_64x3_large_nhwc_tn_v1 Tactic: -7757610000269494813
[03/24/2023-12:57:14] [V] [TRT] Tactic: -7757610000269494813 Time: 0.117248
[03/24/2023-12:57:14] [V] [TRT] Conv_62 + Relu_63 || Conv_65 + Relu_66 || Conv_68 + Relu_69 || Conv_71 + Relu_72 || Conv_74 + Relu_75 || Conv_77 + Relu_78 || Conv_80 + Relu_81 || Conv_83 + Relu_84 Set Tactic Name: sm75_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x128x32_stage1_warpsize4x2x1_g1_tensor16x8x8 Tactic: -7615325597099025933
[03/24/2023-12:57:14] [V] [TRT] Tactic: -7615325597099025933 Time: 0.127104
[03/24/2023-12:57:14] [V] [TRT] Conv_62 + Relu_63 || Conv_65 + Relu_66 || Conv_68 + Relu_69 || Conv_71 + Relu_72 || Conv_74 + Relu_75 || Conv_77 + Relu_78 || Conv_80 + Relu_81 || Conv_83 + Relu_84 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x64x64_stage3_warpsize4x1x1_g1_tensor16x8x16 Tactic: -6917689122519989488
[03/24/2023-12:57:15] [V] [TRT] Tactic: -6917689122519989488 Time: 0.142464
[03/24/2023-12:57:15] [V] [TRT] Conv_62 + Relu_63 || Conv_65 + Relu_66 || Conv_68 + Relu_69 || Conv_71 + Relu_72 || Conv_74 + Relu_75 || Conv_77 + Relu_78 || Conv_80 + Relu_81 || Conv_83 + Relu_84 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x32x64_stage5_warpsize2x2x1_g1_tensor16x8x16_t1r3s3 Tactic: -6902925267326201166
[03/24/2023-12:57:15] [V] [TRT] Tactic: -6902925267326201166 Time: 0.283392
[03/24/2023-12:57:15] [V] [TRT] Conv_62 + Relu_63 || Conv_65 + Relu_66 || Conv_68 + Relu_69 || Conv_71 + Relu_72 || Conv_74 + Relu_75 || Conv_77 + Relu_78 || Conv_80 + Relu_81 || Conv_83 + Relu_84 Set Tactic Name: ampere_h16816cudnn_64x128_ldg8_relu_exp_stages_64x4_large_nhwc_tn_v1 Tactic: -6840588038605932325
[03/24/2023-12:57:15] [V] [TRT] Tactic: -6840588038605932325 Time: 0.157568
[03/24/2023-12:57:15] [V] [TRT] Conv_62 + Relu_63 || Conv_65 + Relu_66 || Conv_68 + Relu_69 || Conv_71 + Relu_72 || Conv_74 + Relu_75 || Conv_77 + Relu_78 || Conv_80 + Relu_81 || Conv_83 + Relu_84 Set Tactic Name: sm75_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x32x32_stage1_warpsize4x1x1_g1_tensor16x8x8 Tactic: -6828337260021572283
[03/24/2023-12:57:15] [V] [TRT] Tactic: -6828337260021572283 Time: 0.235136
[03/24/2023-12:57:15] [V] [TRT] Conv_62 + Relu_63 || Conv_65 + Relu_66 || Conv_68 + Relu_69 || Conv_71 + Relu_72 || Conv_74 + Relu_75 || Conv_77 + Relu_78 || Conv_80 + Relu_81 || Conv_83 + Relu_84 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x256x32_stage3_warpsize2x4x1_g1_tensor16x8x16 Tactic: -6799856376604253964
[03/24/2023-12:57:15] [V] [TRT] Tactic: -6799856376604253964 Time: 0.10688
[03/24/2023-12:57:15] [V] [TRT] Conv_62 + Relu_63 || Conv_65 + Relu_66 || Conv_68 + Relu_69 || Conv_71 + Relu_72 || Conv_74 + Relu_75 || Conv_77 + Relu_78 || Conv_80 + Relu_81 || Conv_83 + Relu_84 Set Tactic Name: sm75_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x32x32_stage1_warpsize4x1x1_g1_tensor16x8x8 Tactic: -6711815420995272523
[03/24/2023-12:57:15] [V] [TRT] Tactic: -6711815420995272523 Time: 0.210304
[03/24/2023-12:57:15] [V] [TRT] Conv_62 + Relu_63 || Conv_65 + Relu_66 || Conv_68 + Relu_69 || Conv_71 + Relu_72 || Conv_74 + Relu_75 || Conv_77 + Relu_78 || Conv_80 + Relu_81 || Conv_83 + Relu_84 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x32x32_stage4_warpsize4x1x1_g1_tensor16x8x16_t1r3s3 Tactic: -6625722781282978136
[03/24/2023-12:57:15] [V] [TRT] Tactic: -6625722781282978136 Time: 0.182528
[03/24/2023-12:57:15] [V] [TRT] Conv_62 + Relu_63 || Conv_65 + Relu_66 || Conv_68 + Relu_69 || Conv_71 + Relu_72 || Conv_74 + Relu_75 || Conv_77 + Relu_78 || Conv_80 + Relu_81 || Conv_83 + Relu_84 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x64x32_stage3_warpsize4x1x1_g1_tensor16x8x16 Tactic: -6525498856028268801
[03/24/2023-12:57:15] [V] [TRT] Tactic: -6525498856028268801 Time: 0.10944
[03/24/2023-12:57:15] [V] [TRT] Conv_62 + Relu_63 || Conv_65 + Relu_66 || Conv_68 + Relu_69 || Conv_71 + Relu_72 || Conv_74 + Relu_75 || Conv_77 + Relu_78 || Conv_80 + Relu_81 || Conv_83 + Relu_84 Set Tactic Name: sm75_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x256x64_stage1_warpsize1x4x2_g1_tensor16x8x8 Tactic: -6489479581011009593
[03/24/2023-12:57:15] [V] [TRT] Tactic: -6489479581011009593 Time: 0.145536
[03/24/2023-12:57:15] [V] [TRT] Conv_62 + Relu_63 || Conv_65 + Relu_66 || Conv_68 + Relu_69 || Conv_71 + Relu_72 || Conv_74 + Relu_75 || Conv_77 + Relu_78 || Conv_80 + Relu_81 || Conv_83 + Relu_84 Set Tactic Name: ampere_h16816cudnn_64x64_sliced1x2_ldg8_relu_exp_stages_64x6_medium_nhwc_tn_v1 Tactic: -6356316196810535311
[03/24/2023-12:57:15] [V] [TRT] Tactic: -6356316196810535311 Time: 0.260096
[03/24/2023-12:57:15] [V] [TRT] Conv_62 + Relu_63 || Conv_65 + Relu_66 || Conv_68 + Relu_69 || Conv_71 + Relu_72 || Conv_74 + Relu_75 || Conv_77 + Relu_78 || Conv_80 + Relu_81 || Conv_83 + Relu_84 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x32x32_stage4_warpsize4x1x1_g1_tensor16x8x16 Tactic: -6324345858751792783
[03/24/2023-12:57:15] [V] [TRT] Tactic: -6324345858751792783 Time: 0.18496
[03/24/2023-12:57:15] [V] [TRT] Conv_62 + Relu_63 || Conv_65 + Relu_66 || Conv_68 + Relu_69 || Conv_71 + Relu_72 || Conv_74 + Relu_75 || Conv_77 + Relu_78 || Conv_80 + Relu_81 || Conv_83 + Relu_84 Set Tactic Name: sm75_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x256x64_stage1_warpsize1x4x2_g1_tensor16x8x8_t1r3s3 Tactic: -6320761427625651496
[03/24/2023-12:57:15] [V] [TRT] Tactic: -6320761427625651496 Time: 0.144
[03/24/2023-12:57:15] [V] [TRT] Conv_62 + Relu_63 || Conv_65 + Relu_66 || Conv_68 + Relu_69 || Conv_71 + Relu_72 || Conv_74 + Relu_75 || Conv_77 + Relu_78 || Conv_80 + Relu_81 || Conv_83 + Relu_84 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x256x32_stage3_warpsize2x4x1_g1_tensor16x8x16_t1r3s3 Tactic: -6262400699544994312
[03/24/2023-12:57:15] [V] [TRT] Tactic: -6262400699544994312 Time: 0.104832
[03/24/2023-12:57:15] [V] [TRT] Conv_62 + Relu_63 || Conv_65 + Relu_66 || Conv_68 + Relu_69 || Conv_71 + Relu_72 || Conv_74 + Relu_75 || Conv_77 + Relu_78 || Conv_80 + Relu_81 || Conv_83 + Relu_84 Set Tactic Name: ampere_h1688cudnn_128x128_ldg8_relu_exp_large_nhwc_tn_v1 Tactic: -6257787336162086472
[03/24/2023-12:57:15] [V] [TRT] Tactic: -6257787336162086472 Time: 0.130176
[03/24/2023-12:57:15] [V] [TRT] Conv_62 + Relu_63 || Conv_65 + Relu_66 || Conv_68 + Relu_69 || Conv_71 + Relu_72 || Conv_74 + Relu_75 || Conv_77 + Relu_78 || Conv_80 + Relu_81 || Conv_83 + Relu_84 Set Tactic Name: sm75_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x128x64_stage1_warpsize2x2x1_g1_tensor16x8x8 Tactic: -6080892721161662420
[03/24/2023-12:57:15] [V] [TRT] Tactic: -6080892721161662420 Time: 0.114688
[03/24/2023-12:57:15] [V] [TRT] Conv_62 + Relu_63 || Conv_65 + Relu_66 || Conv_68 + Relu_69 || Conv_71 + Relu_72 || Conv_74 + Relu_75 || Conv_77 + Relu_78 || Conv_80 + Relu_81 || Conv_83 + Relu_84 Set Tactic Name: ampere_h16816cudnn_128x64_ldg8_relu_exp_stages_64x4_small_nhwc_tn_v1 Tactic: -6063766379489217211
[03/24/2023-12:57:15] [V] [TRT] Tactic: -6063766379489217211 Time: 0.163072
[03/24/2023-12:57:15] [V] [TRT] Conv_62 + Relu_63 || Conv_65 + Relu_66 || Conv_68 + Relu_69 || Conv_71 + Relu_72 || Conv_74 + Relu_75 || Conv_77 + Relu_78 || Conv_80 + Relu_81 || Conv_83 + Relu_84 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x128x32_stage5_warpsize2x2x1_g1_tensor16x8x16 Tactic: -5777580938094193096
[03/24/2023-12:57:15] [V] [TRT] Tactic: -5777580938094193096 Time: 0.120576
[03/24/2023-12:57:15] [V] [TRT] Conv_62 + Relu_63 || Conv_65 + Relu_66 || Conv_68 + Relu_69 || Conv_71 + Relu_72 || Conv_74 + Relu_75 || Conv_77 + Relu_78 || Conv_80 + Relu_81 || Conv_83 + Relu_84 Set Tactic Name: sm75_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x128x64_stage1_warpsize2x2x1_g1_tensor16x8x8 Tactic: -5710735840878760115
[03/24/2023-12:57:15] [V] [TRT] Tactic: -5710735840878760115 Time: 0.118656
[03/24/2023-12:57:15] [V] [TRT] Conv_62 + Relu_63 || Conv_65 + Relu_66 || Conv_68 + Relu_69 || Conv_71 + Relu_72 || Conv_74 + Relu_75 || Conv_77 + Relu_78 || Conv_80 + Relu_81 || Conv_83 + Relu_84 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x128x32_stage3_warpsize4x2x1_g1_tensor16x8x16 Tactic: -5657273398217409378
[03/24/2023-12:57:15] [V] [TRT] Tactic: -5657273398217409378 Time: 0.107776
[03/24/2023-12:57:15] [V] [TRT] Conv_62 + Relu_63 || Conv_65 + Relu_66 || Conv_68 + Relu_69 || Conv_71 + Relu_72 || Conv_74 + Relu_75 || Conv_77 + Relu_78 || Conv_80 + Relu_81 || Conv_83 + Relu_84 Set Tactic Name: sm75_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x128x32_stage1_warpsize2x2x1_g1_tensor16x8x8_t1r3s3 Tactic: -5546257196173962281
[03/24/2023-12:57:15] [V] [TRT] Tactic: -5546257196173962281 Time: 0.14784
[03/24/2023-12:57:15] [V] [TRT] Conv_62 + Relu_63 || Conv_65 + Relu_66 || Conv_68 + Relu_69 || Conv_71 + Relu_72 || Conv_74 + Relu_75 || Conv_77 + Relu_78 || Conv_80 + Relu_81 || Conv_83 + Relu_84 Set Tactic Name: ampere_h16816cudnn_128x128_ldg8_relu_exp_small_nhwc_tn_v1 Tactic: -5530886555766748586
[03/24/2023-12:57:15] [V] [TRT] Tactic: -5530886555766748586 Time: 0.105088
[03/24/2023-12:57:15] [V] [TRT] Conv_62 + Relu_63 || Conv_65 + Relu_66 || Conv_68 + Relu_69 || Conv_71 + Relu_72 || Conv_74 + Relu_75 || Conv_77 + Relu_78 || Conv_80 + Relu_81 || Conv_83 + Relu_84 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x64x32_stage5_warpsize2x2x1_g1_tensor16x8x16_t1r3s3 Tactic: -5422685219138380548
[03/24/2023-12:57:15] [V] [TRT] Tactic: -5422685219138380548 Time: 0.128896
[03/24/2023-12:57:15] [V] [TRT] Conv_62 + Relu_63 || Conv_65 + Relu_66 || Conv_68 + Relu_69 || Conv_71 + Relu_72 || Conv_74 + Relu_75 || Conv_77 + Relu_78 || Conv_80 + Relu_81 || Conv_83 + Relu_84 Set Tactic Name: ampere_h16816cudnn_256x64_ldg8_relu_exp_stages_64x3_small_nhwc_tn_v1 Tactic: -5261787675443473128
[03/24/2023-12:57:15] [V] [TRT] Tactic: -5261787675443473128 Time: 0.133248
[03/24/2023-12:57:15] [V] [TRT] Conv_62 + Relu_63 || Conv_65 + Relu_66 || Conv_68 + Relu_69 || Conv_71 + Relu_72 || Conv_74 + Relu_75 || Conv_77 + Relu_78 || Conv_80 + Relu_81 || Conv_83 + Relu_84 Set Tactic Name: sm75_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x64x32_stage1_warpsize4x1x1_g1_tensor16x8x8 Tactic: -5198219374380660379
[03/24/2023-12:57:15] [V] [TRT] Tactic: -5198219374380660379 Time: 0.135424
[03/24/2023-12:57:15] [V] [TRT] Conv_62 + Relu_63 || Conv_65 + Relu_66 || Conv_68 + Relu_69 || Conv_71 + Relu_72 || Conv_74 + Relu_75 || Conv_77 + Relu_78 || Conv_80 + Relu_81 || Conv_83 + Relu_84 Set Tactic Name: ampere_h16816cudnn_64x128_sliced1x2_ldg8_relu_exp_stages_64x3_medium_nhwc_tn_v1 Tactic: -5161596964442251102
[03/24/2023-12:57:15] [V] [TRT] Tactic: -5161596964442251102 Time: 0.130688
[03/24/2023-12:57:15] [V] [TRT] Conv_62 + Relu_63 || Conv_65 + Relu_66 || Conv_68 + Relu_69 || Conv_71 + Relu_72 || Conv_74 + Relu_75 || Conv_77 + Relu_78 || Conv_80 + Relu_81 || Conv_83 + Relu_84 Set Tactic Name: ampere_h16816cudnn_64x128_ldg8_relu_exp_stages_64x3_medium_nhwc_tn_v1 Tactic: -5127240325355316006
[03/24/2023-12:57:15] [V] [TRT] Tactic: -5127240325355316006 Time: 0.13504
[03/24/2023-12:57:15] [V] [TRT] Conv_62 + Relu_63 || Conv_65 + Relu_66 || Conv_68 + Relu_69 || Conv_71 + Relu_72 || Conv_74 + Relu_75 || Conv_77 + Relu_78 || Conv_80 + Relu_81 || Conv_83 + Relu_84 Set Tactic Name: ampere_h16816cudnn_256x128_ldg8_relu_exp_stages_64x3_medium_nhwc_tn_v1 Tactic: -5109582882231362997
[03/24/2023-12:57:15] [V] [TRT] Tactic: -5109582882231362997 Time: 0.116608
[03/24/2023-12:57:15] [V] [TRT] Conv_62 + Relu_63 || Conv_65 + Relu_66 || Conv_68 + Relu_69 || Conv_71 + Relu_72 || Conv_74 + Relu_75 || Conv_77 + Relu_78 || Conv_80 + Relu_81 || Conv_83 + Relu_84 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x64x32_stage5_warpsize2x2x1_g1_tensor16x8x16 Tactic: -4825567853927730435
[03/24/2023-12:57:15] [V] [TRT] Tactic: -4825567853927730435 Time: 0.137856
[03/24/2023-12:57:15] [V] [TRT] Conv_62 + Relu_63 || Conv_65 + Relu_66 || Conv_68 + Relu_69 || Conv_71 + Relu_72 || Conv_74 + Relu_75 || Conv_77 + Relu_78 || Conv_80 + Relu_81 || Conv_83 + Relu_84 Set Tactic Name: ampere_h16816cudnn_64x128_sliced1x2_ldg8_relu_exp_stages_64x4_small_nhwc_tn_v1 Tactic: -4796511246675321840
[03/24/2023-12:57:15] [V] [TRT] Tactic: -4796511246675321840 Time: 0.164224
[03/24/2023-12:57:15] [V] [TRT] Conv_62 + Relu_63 || Conv_65 + Relu_66 || Conv_68 + Relu_69 || Conv_71 + Relu_72 || Conv_74 + Relu_75 || Conv_77 + Relu_78 || Conv_80 + Relu_81 || Conv_83 + Relu_84 Set Tactic Name: ampere_h16816cudnn_64x64_sliced1x2_ldg8_relu_exp_stages_64x6_large_nhwc_tn_v1 Tactic: -4706569565442112734
[03/24/2023-12:57:15] [V] [TRT] Tactic: -4706569565442112734 Time: 0.263936
[03/24/2023-12:57:15] [V] [TRT] Conv_62 + Relu_63 || Conv_65 + Relu_66 || Conv_68 + Relu_69 || Conv_71 + Relu_72 || Conv_74 + Relu_75 || Conv_77 + Relu_78 || Conv_80 + Relu_81 || Conv_83 + Relu_84 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x128x64_stage3_warpsize2x2x1_g1_tensor16x8x16_t1r3s3 Tactic: -4566599693570369588
[03/24/2023-12:57:15] [V] [TRT] Tactic: -4566599693570369588 Time: 0.127616
[03/24/2023-12:57:15] [V] [TRT] Conv_62 + Relu_63 || Conv_65 + Relu_66 || Conv_68 + Relu_69 || Conv_71 + Relu_72 || Conv_74 + Relu_75 || Conv_77 + Relu_78 || Conv_80 + Relu_81 || Conv_83 + Relu_84 Set Tactic Name: ampere_h16816cudnn_128x128_ldg8_relu_exp_stages_64x3_large_nhwc_tn_v1 Tactic: -4409144516525410768
[03/24/2023-12:57:15] [V] [TRT] Tactic: -4409144516525410768 Time: 0.129536
[03/24/2023-12:57:15] [V] [TRT] Conv_62 + Relu_63 || Conv_65 + Relu_66 || Conv_68 + Relu_69 || Conv_71 + Relu_72 || Conv_74 + Relu_75 || Conv_77 + Relu_78 || Conv_80 + Relu_81 || Conv_83 + Relu_84 Set Tactic Name: ampere_h16816cudnn_128x64_ldg8_relu_exp_stages_64x3_small_nhwc_tn_v1 Tactic: -4379519430184503304
[03/24/2023-12:57:15] [V] [TRT] Tactic: -4379519430184503304 Time: 0.137344
[03/24/2023-12:57:15] [V] [TRT] Conv_62 + Relu_63 || Conv_65 + Relu_66 || Conv_68 + Relu_69 || Conv_71 + Relu_72 || Conv_74 + Relu_75 || Conv_77 + Relu_78 || Conv_80 + Relu_81 || Conv_83 + Relu_84 Set Tactic Name: ampere_h1688cudnn_256x128_ldg8_relu_exp_small_nhwc_tn_v1 Tactic: -4152066959007262150
[03/24/2023-12:57:15] [V] [TRT] Tactic: -4152066959007262150 Time: 0.125824
[03/24/2023-12:57:15] [V] [TRT] Conv_62 + Relu_63 || Conv_65 + Relu_66 || Conv_68 + Relu_69 || Conv_71 + Relu_72 || Conv_74 + Relu_75 || Conv_77 + Relu_78 || Conv_80 + Relu_81 || Conv_83 + Relu_84 Set Tactic Name: ampere_h16816cudnn_64x128_ldg8_relu_exp_stages_64x4_medium_nhwc_tn_v1 Tactic: -4021926646879732549
[03/24/2023-12:57:15] [V] [TRT] Tactic: -4021926646879732549 Time: 0.155776
[03/24/2023-12:57:15] [V] [TRT] Conv_62 + Relu_63 || Conv_65 + Relu_66 || Conv_68 + Relu_69 || Conv_71 + Relu_72 || Conv_74 + Relu_75 || Conv_77 + Relu_78 || Conv_80 + Relu_81 || Conv_83 + Relu_84 Set Tactic Name: ampere_h16816cudnn_64x128_sliced1x2_ldg8_relu_exp_stages_64x4_medium_nhwc_tn_v1 Tactic: -3987638434926559037
[03/24/2023-12:57:15] [V] [TRT] Tactic: -3987638434926559037 Time: 0.164864
[03/24/2023-12:57:15] [V] [TRT] Conv_62 + Relu_63 || Conv_65 + Relu_66 || Conv_68 + Relu_69 || Conv_71 + Relu_72 || Conv_74 + Relu_75 || Conv_77 + Relu_78 || Conv_80 + Relu_81 || Conv_83 + Relu_84 Set Tactic Name: ampere_h1688cudnn_256x64_sliced1x2_ldg8_relu_exp_medium_nhwc_tn_v1 Tactic: -3905653247016903130
[03/24/2023-12:57:15] [V] [TRT] Tactic: -3905653247016903130 Time: 0.1728
[03/24/2023-12:57:15] [V] [TRT] Conv_62 + Relu_63 || Conv_65 + Relu_66 || Conv_68 + Relu_69 || Conv_71 + Relu_72 || Conv_74 + Relu_75 || Conv_77 + Relu_78 || Conv_80 + Relu_81 || Conv_83 + Relu_84 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x64x32_stage5_warpsize2x2x1_g1_tensor16x8x16 Tactic: -3903974568488493144
[03/24/2023-12:57:15] [V] [TRT] Tactic: -3903974568488493144 Time: 0.130048
[03/24/2023-12:57:15] [V] [TRT] Conv_62 + Relu_63 || Conv_65 + Relu_66 || Conv_68 + Relu_69 || Conv_71 + Relu_72 || Conv_74 + Relu_75 || Conv_77 + Relu_78 || Conv_80 + Relu_81 || Conv_83 + Relu_84 Set Tactic Name: ampere_h16816cudnn_64x128_ldg8_relu_exp_stages_64x3_large_nhwc_tn_v1 Tactic: -3895429239811098010
[03/24/2023-12:57:15] [V] [TRT] Tactic: -3895429239811098010 Time: 0.134912
[03/24/2023-12:57:15] [V] [TRT] Conv_62 + Relu_63 || Conv_65 + Relu_66 || Conv_68 + Relu_69 || Conv_71 + Relu_72 || Conv_74 + Relu_75 || Conv_77 + Relu_78 || Conv_80 + Relu_81 || Conv_83 + Relu_84 Set Tactic Name: ampere_h16816cudnn_256x64_ldg8_relu_exp_small_nhwc_tn_v1 Tactic: -3864869056275745423
[03/24/2023-12:57:15] [V] [TRT] Tactic: -3864869056275745423 Time: 0.123904
[03/24/2023-12:57:15] [V] [TRT] Conv_62 + Relu_63 || Conv_65 + Relu_66 || Conv_68 + Relu_69 || Conv_71 + Relu_72 || Conv_74 + Relu_75 || Conv_77 + Relu_78 || Conv_80 + Relu_81 || Conv_83 + Relu_84 Set Tactic Name: sm75_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x32x32_stage1_warpsize4x1x1_g1_tensor16x8x8_t1r3s3 Tactic: -3784342055748695733
[03/24/2023-12:57:15] [V] [TRT] Tactic: -3784342055748695733 Time: 0.217344
[03/24/2023-12:57:15] [V] [TRT] Conv_62 + Relu_63 || Conv_65 + Relu_66 || Conv_68 + Relu_69 || Conv_71 + Relu_72 || Conv_74 + Relu_75 || Conv_77 + Relu_78 || Conv_80 + Relu_81 || Conv_83 + Relu_84 Set Tactic Name: ampere_h16816cudnn_64x64_ldg8_relu_exp_stages_64x5_small_nhwc_tn_v1 Tactic: -3601464762214218301
[03/24/2023-12:57:15] [V] [TRT] Tactic: -3601464762214218301 Time: 0.201856
[03/24/2023-12:57:15] [V] [TRT] Conv_62 + Relu_63 || Conv_65 + Relu_66 || Conv_68 + Relu_69 || Conv_71 + Relu_72 || Conv_74 + Relu_75 || Conv_77 + Relu_78 || Conv_80 + Relu_81 || Conv_83 + Relu_84 Set Tactic Name: sm75_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x64x32_stage1_warpsize2x2x1_g1_tensor16x8x8 Tactic: -3425274793298557239
[03/24/2023-12:57:15] [V] [TRT] Tactic: -3425274793298557239 Time: 0.148736
[03/24/2023-12:57:15] [V] [TRT] Conv_62 + Relu_63 || Conv_65 + Relu_66 || Conv_68 + Relu_69 || Conv_71 + Relu_72 || Conv_74 + Relu_75 || Conv_77 + Relu_78 || Conv_80 + Relu_81 || Conv_83 + Relu_84 Set Tactic Name: ampere_h1688cudnn_256x64_sliced1x2_ldg8_relu_exp_large_nhwc_tn_v1 Tactic: -3412636942650049698
[03/24/2023-12:57:15] [V] [TRT] Tactic: -3412636942650049698 Time: 0.174976
[03/24/2023-12:57:15] [V] [TRT] Conv_62 + Relu_63 || Conv_65 + Relu_66 || Conv_68 + Relu_69 || Conv_71 + Relu_72 || Conv_74 + Relu_75 || Conv_77 + Relu_78 || Conv_80 + Relu_81 || Conv_83 + Relu_84 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x64x32_stage3_warpsize4x1x1_g1_tensor16x8x16 Tactic: -3338665856053412950
[03/24/2023-12:57:15] [V] [TRT] Tactic: -3338665856053412950 Time: 0.108928
[03/24/2023-12:57:15] [V] [TRT] Conv_62 + Relu_63 || Conv_65 + Relu_66 || Conv_68 + Relu_69 || Conv_71 + Relu_72 || Conv_74 + Relu_75 || Conv_77 + Relu_78 || Conv_80 + Relu_81 || Conv_83 + Relu_84 Set Tactic Name: sm75_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x128x32_stage1_warpsize2x2x1_g1_tensor16x8x8 Tactic: -3271955096576257018
[03/24/2023-12:57:15] [V] [TRT] Tactic: -3271955096576257018 Time: 0.148992
[03/24/2023-12:57:15] [V] [TRT] Conv_62 + Relu_63 || Conv_65 + Relu_66 || Conv_68 + Relu_69 || Conv_71 + Relu_72 || Conv_74 + Relu_75 || Conv_77 + Relu_78 || Conv_80 + Relu_81 || Conv_83 + Relu_84 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x128x64_stage3_warpsize4x2x1_g1_tensor16x8x16_t1r3s3 Tactic: -3243541398692466074
[03/24/2023-12:57:15] [V] [TRT] Tactic: -3243541398692466074 Time: 0.112768
[03/24/2023-12:57:15] [V] [TRT] Conv_62 + Relu_63 || Conv_65 + Relu_66 || Conv_68 + Relu_69 || Conv_71 + Relu_72 || Conv_74 + Relu_75 || Conv_77 + Relu_78 || Conv_80 + Relu_81 || Conv_83 + Relu_84 Set Tactic Name: ampere_h16816cudnn_64x128_sliced1x2_ldg8_relu_exp_stages_64x3_small_nhwc_tn_v1 Tactic: -3058330359340425555
[03/24/2023-12:57:15] [V] [TRT] Tactic: -3058330359340425555 Time: 0.131072
[03/24/2023-12:57:15] [V] [TRT] Conv_62 + Relu_63 || Conv_65 + Relu_66 || Conv_68 + Relu_69 || Conv_71 + Relu_72 || Conv_74 + Relu_75 || Conv_77 + Relu_78 || Conv_80 + Relu_81 || Conv_83 + Relu_84 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x256x64_stage3_warpsize1x4x1_g1_tensor16x8x16_t1r3s3 Tactic: -2899647483672319239
[03/24/2023-12:57:15] [V] [TRT] Tactic: -2899647483672319239 Time: 0.135552
[03/24/2023-12:57:15] [V] [TRT] Conv_62 + Relu_63 || Conv_65 + Relu_66 || Conv_68 + Relu_69 || Conv_71 + Relu_72 || Conv_74 + Relu_75 || Conv_77 + Relu_78 || Conv_80 + Relu_81 || Conv_83 + Relu_84 Set Tactic Name: ampere_h16816cudnn_256x64_sliced1x2_ldg8_relu_exp_large_nhwc_tn_v1 Tactic: -2816084650627734155
[03/24/2023-12:57:15] [V] [TRT] Tactic: -2816084650627734155 Time: 0.166912
[03/24/2023-12:57:15] [V] [TRT] Conv_62 + Relu_63 || Conv_65 + Relu_66 || Conv_68 + Relu_69 || Conv_71 + Relu_72 || Conv_74 + Relu_75 || Conv_77 + Relu_78 || Conv_80 + Relu_81 || Conv_83 + Relu_84 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x128x32_stage5_warpsize2x2x1_g1_tensor16x8x16 Tactic: -2662892962457732243
[03/24/2023-12:57:15] [V] [TRT] Tactic: -2662892962457732243 Time: 0.120064
[03/24/2023-12:57:15] [V] [TRT] Conv_62 + Relu_63 || Conv_65 + Relu_66 || Conv_68 + Relu_69 || Conv_71 + Relu_72 || Conv_74 + Relu_75 || Conv_77 + Relu_78 || Conv_80 + Relu_81 || Conv_83 + Relu_84 Set Tactic Name: ampere_h16816cudnn_256x128_ldg8_relu_exp_large_nhwc_tn_v1 Tactic: -2559894581585337900
[03/24/2023-12:57:15] [V] [TRT] Tactic: -2559894581585337900 Time: 0.113664
[03/24/2023-12:57:15] [V] [TRT] Conv_62 + Relu_63 || Conv_65 + Relu_66 || Conv_68 + Relu_69 || Conv_71 + Relu_72 || Conv_74 + Relu_75 || Conv_77 + Relu_78 || Conv_80 + Relu_81 || Conv_83 + Relu_84 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x32x32_stage4_warpsize4x1x1_g1_tensor16x8x16 Tactic: -2530740716768816092
[03/24/2023-12:57:15] [V] [TRT] Tactic: -2530740716768816092 Time: 0.170624
[03/24/2023-12:57:15] [V] [TRT] Conv_62 + Relu_63 || Conv_65 + Relu_66 || Conv_68 + Relu_69 || Conv_71 + Relu_72 || Conv_74 + Relu_75 || Conv_77 + Relu_78 || Conv_80 + Relu_81 || Conv_83 + Relu_84 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x128x32_stage4_warpsize2x2x1_g1_tensor16x8x16 Tactic: -2332828394978346992
[03/24/2023-12:57:15] [V] [TRT] Tactic: -2332828394978346992 Time: 0.09856
[03/24/2023-12:57:15] [V] [TRT] Conv_62 + Relu_63 || Conv_65 + Relu_66 || Conv_68 + Relu_69 || Conv_71 + Relu_72 || Conv_74 + Relu_75 || Conv_77 + Relu_78 || Conv_80 + Relu_81 || Conv_83 + Relu_84 Set Tactic Name: ampere_h1688cudnn_256x64_ldg8_relu_exp_large_nhwc_tn_v1 Tactic: -2241736083352441442
[03/24/2023-12:57:15] [V] [TRT] Tactic: -2241736083352441442 Time: 0.150656
[03/24/2023-12:57:15] [V] [TRT] Conv_62 + Relu_63 || Conv_65 + Relu_66 || Conv_68 + Relu_69 || Conv_71 + Relu_72 || Conv_74 + Relu_75 || Conv_77 + Relu_78 || Conv_80 + Relu_81 || Conv_83 + Relu_84 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x32x64_stage5_warpsize2x2x1_g1_tensor16x8x16 Tactic: -2161909437867201546
[03/24/2023-12:57:15] [V] [TRT] Tactic: -2161909437867201546 Time: 0.278272
[03/24/2023-12:57:15] [V] [TRT] Conv_62 + Relu_63 || Conv_65 + Relu_66 || Conv_68 + Relu_69 || Conv_71 + Relu_72 || Conv_74 + Relu_75 || Conv_77 + Relu_78 || Conv_80 + Relu_81 || Conv_83 + Relu_84 Set Tactic Name: ampere_h16816cudnn_256x64_ldg8_relu_exp_medium_nhwc_tn_v1 Tactic: -1985778916402815946
[03/24/2023-12:57:15] [V] [TRT] Tactic: -1985778916402815946 Time: 0.127744
[03/24/2023-12:57:15] [V] [TRT] Conv_62 + Relu_63 || Conv_65 + Relu_66 || Conv_68 + Relu_69 || Conv_71 + Relu_72 || Conv_74 + Relu_75 || Conv_77 + Relu_78 || Conv_80 + Relu_81 || Conv_83 + Relu_84 Set Tactic Name: sm75_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x256x32_stage1_warpsize2x4x1_g1_tensor16x8x8 Tactic: -1708101578041178688
[03/24/2023-12:57:15] [V] [TRT] Tactic: -1708101578041178688 Time: 0.124928
[03/24/2023-12:57:15] [V] [TRT] Conv_62 + Relu_63 || Conv_65 + Relu_66 || Conv_68 + Relu_69 || Conv_71 + Relu_72 || Conv_74 + Relu_75 || Conv_77 + Relu_78 || Conv_80 + Relu_81 || Conv_83 + Relu_84 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x64x64_stage3_warpsize4x1x1_g1_tensor16x8x16 Tactic: -1502788097503482299
[03/24/2023-12:57:15] [V] [TRT] Tactic: -1502788097503482299 Time: 0.14912
[03/24/2023-12:57:15] [V] [TRT] Conv_62 + Relu_63 || Conv_65 + Relu_66 || Conv_68 + Relu_69 || Conv_71 + Relu_72 || Conv_74 + Relu_75 || Conv_77 + Relu_78 || Conv_80 + Relu_81 || Conv_83 + Relu_84 Set Tactic Name: ampere_h16816cudnn_128x64_sliced1x2_ldg8_relu_exp_stages_64x4_large_nhwc_tn_v1 Tactic: -1500496213132463076
[03/24/2023-12:57:15] [V] [TRT] Tactic: -1500496213132463076 Time: 0.174976
[03/24/2023-12:57:15] [V] [TRT] Conv_62 + Relu_63 || Conv_65 + Relu_66 || Conv_68 + Relu_69 || Conv_71 + Relu_72 || Conv_74 + Relu_75 || Conv_77 + Relu_78 || Conv_80 + Relu_81 || Conv_83 + Relu_84 Set Tactic Name: ampere_h16816cudnn_64x64_ldg8_relu_exp_stages_64x6_small_nhwc_tn_v1 Tactic: -1099247066487349374
[03/24/2023-12:57:15] [V] [TRT] Tactic: -1099247066487349374 Time: 0.235136
[03/24/2023-12:57:15] [V] [TRT] Conv_62 + Relu_63 || Conv_65 + Relu_66 || Conv_68 + Relu_69 || Conv_71 + Relu_72 || Conv_74 + Relu_75 || Conv_77 + Relu_78 || Conv_80 + Relu_81 || Conv_83 + Relu_84 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x64x64_stage4_warpsize2x2x1_g1_tensor16x8x16 Tactic: -910286698936744682
[03/24/2023-12:57:15] [V] [TRT] Tactic: -910286698936744682 Time: 0.18304
[03/24/2023-12:57:15] [V] [TRT] Conv_62 + Relu_63 || Conv_65 + Relu_66 || Conv_68 + Relu_69 || Conv_71 + Relu_72 || Conv_74 + Relu_75 || Conv_77 + Relu_78 || Conv_80 + Relu_81 || Conv_83 + Relu_84 Set Tactic Name: sm75_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x256x32_stage1_warpsize2x4x1_g1_tensor16x8x8 Tactic: -907287437357565279
[03/24/2023-12:57:15] [V] [TRT] Tactic: -907287437357565279 Time: 0.122624
[03/24/2023-12:57:15] [V] [TRT] Conv_62 + Relu_63 || Conv_65 + Relu_66 || Conv_68 + Relu_69 || Conv_71 + Relu_72 || Conv_74 + Relu_75 || Conv_77 + Relu_78 || Conv_80 + Relu_81 || Conv_83 + Relu_84 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x32x32_stage4_warpsize4x1x1_g1_tensor16x8x16 Tactic: -606726295133751039
[03/24/2023-12:57:15] [V] [TRT] Tactic: -606726295133751039 Time: 0.190464
[03/24/2023-12:57:15] [V] [TRT] Fastest Tactic: 6972489290272968208 Time: 0.096512
[03/24/2023-12:57:15] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: 6972489290272968208
[03/24/2023-12:57:15] [V] [TRT] *************** Autotuning format combination: Half(129600,1:16,720,4) -> Half(1036800,1:16,5760,32) ***************
[03/24/2023-12:57:15] [V] [TRT] --------------- Timing Runner: Conv_62 + Relu_63 || Conv_65 + Relu_66 || Conv_68 + Relu_69 || Conv_71 + Relu_72 || Conv_74 + Relu_75 || Conv_77 + Relu_78 || Conv_80 + Relu_81 || Conv_83 + Relu_84 (CudnnConvolution)
[03/24/2023-12:57:15] [V] [TRT] CudnnConvolution has no valid tactics for this config, skipping
[03/24/2023-12:57:15] [V] [TRT] --------------- Timing Runner: Conv_62 + Relu_63 || Conv_65 + Relu_66 || Conv_68 + Relu_69 || Conv_71 + Relu_72 || Conv_74 + Relu_75 || Conv_77 + Relu_78 || Conv_80 + Relu_81 || Conv_83 + Relu_84 (CaskConvolution)
[03/24/2023-12:57:15] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[03/24/2023-12:57:15] [V] [TRT] =============== Computing costs for 
[03/24/2023-12:57:15] [V] [TRT] *************** Autotuning format combination: Float(16588800,32400,180,1) -> Float(64800,32400,180,1) ***************
[03/24/2023-12:57:15] [V] [TRT] --------------- Timing Runner: Conv_64 (CudaDepthwiseConvolution)
[03/24/2023-12:57:15] [V] [TRT] CudaDepthwiseConvolution has no valid tactics for this config, skipping
[03/24/2023-12:57:15] [V] [TRT] --------------- Timing Runner: Conv_64 (FusedConvActConvolution)
[03/24/2023-12:57:15] [V] [TRT] Tactic: 524287 Time: 0.0992
[03/24/2023-12:57:15] [V] [TRT] Tactic: 720895 Time: 0.173952
[03/24/2023-12:57:15] [V] [TRT] Tactic: 983039 Time: 0.147584
[03/24/2023-12:57:15] [V] [TRT] Tactic: 1048575 Time: 0.09088
[03/24/2023-12:57:15] [V] [TRT] Tactic: 1703935 Time: 0.08704
[03/24/2023-12:57:15] [V] [TRT] Tactic: 1769471 Time: 0.170624
[03/24/2023-12:57:15] [V] [TRT] Tactic: 1966079 Time: 0.188288
[03/24/2023-12:57:15] [V] [TRT] Tactic: 2031615 Time: 0.153728
[03/24/2023-12:57:15] [V] [TRT] Tactic: 2228223 Time: 0.102272
[03/24/2023-12:57:15] [V] [TRT] Tactic: 2424831 Time: 0.104064
[03/24/2023-12:57:15] [V] [TRT] Tactic: 2621439 Time: 0.08704
[03/24/2023-12:57:15] [V] [TRT] Tactic: 2752511 Time: 0.1696
[03/24/2023-12:57:15] [V] [TRT] Tactic: 3014655 Time: 0.090112
[03/24/2023-12:57:15] [V] [TRT] Tactic: 3145727 Time: 0.150528
[03/24/2023-12:57:15] [V] [TRT] Tactic: 3604479 Time: 0.089088
[03/24/2023-12:57:15] [V] [TRT] Tactic: 4390911 Time: 0.204928
[03/24/2023-12:57:15] [V] [TRT] Tactic: 5046271 Time: 0.093824
[03/24/2023-12:57:15] [V] [TRT] Tactic: 5963775 Time: 0.169088
[03/24/2023-12:57:15] [V] [TRT] Tactic: 6160383 Time: 0.095104
[03/24/2023-12:57:15] [V] [TRT] Tactic: 6488063 Time: 0.105344
[03/24/2023-12:57:15] [V] [TRT] Tactic: 6881279 Time: 0.167936
[03/24/2023-12:57:15] [V] [TRT] Tactic: 7274495 Time: 0.156416
[03/24/2023-12:57:15] [V] [TRT] Tactic: 7864319 Time: 0.09152
[03/24/2023-12:57:15] [V] [TRT] Tactic: 7995391 Time: 0.181248
[03/24/2023-12:57:15] [V] [TRT] Tactic: 8585215 Time: 0.11712
[03/24/2023-12:57:15] [V] [TRT] Tactic: 8847359 Time: 0.091136
[03/24/2023-12:57:15] [V] [TRT] Tactic: 8978431 Time: 0.169088
[03/24/2023-12:57:15] [V] [TRT] Tactic: 9043967 Time: 0.091008
[03/24/2023-12:57:15] [V] [TRT] Tactic: 9175039 Time: 0.089088
[03/24/2023-12:57:15] [V] [TRT] Tactic: 9502719 Time: 0.205056
[03/24/2023-12:57:15] [V] [TRT] Tactic: 9961471 Time: 0.09728
[03/24/2023-12:57:15] [V] [TRT] Tactic: 10027007 Time: 0.094848
[03/24/2023-12:57:16] [V] [TRT] Tactic: 10092543 Time: 0.20544
[03/24/2023-12:57:16] [V] [TRT] Tactic: 10289151 Time: 0.188416
[03/24/2023-12:57:16] [V] [TRT] Tactic: 10485759 Time: 0.084608
[03/24/2023-12:57:16] [V] [TRT] Tactic: 10682367 Time: 0.08704
[03/24/2023-12:57:16] [V] [TRT] Tactic: 10813439 Time: 0.152832
[03/24/2023-12:57:16] [V] [TRT] Fastest Tactic: 10485759 Time: 0.084608
[03/24/2023-12:57:16] [V] [TRT] --------------- Timing Runner: Conv_64 (CudnnConvolution)
[03/24/2023-12:57:16] [V] [TRT] Tactic: 0 Time: 0.144256
[03/24/2023-12:57:16] [V] [TRT] Tactic: 1 Time: 0.086016
[03/24/2023-12:57:16] [V] [TRT] Tactic: 2 Time: 0.20992
[03/24/2023-12:57:16] [V] [TRT] Tactic: 4 Time: 0.343552
[03/24/2023-12:57:16] [V] [TRT] Tactic: 5 Time: 0.47296
[03/24/2023-12:57:16] [V] [TRT] Tactic: 6 Time: 0.066944
[03/24/2023-12:57:16] [V] [TRT] Tactic: 56 Time: 0.15872
[03/24/2023-12:57:16] [V] [TRT] Tactic: 57 Time: 0.091392
[03/24/2023-12:57:16] [V] [TRT] Tactic: 58 Time: 0.225024
[03/24/2023-12:57:16] [V] [TRT] Tactic: 60 Time: 0.35008
[03/24/2023-12:57:16] [V] [TRT] Tactic: 61 Time: 0.451712
[03/24/2023-12:57:16] [V] [TRT] Tactic: 62 Time: 0.066816
[03/24/2023-12:57:16] [V] [TRT] Tactic: 112 Time: 0.158464
[03/24/2023-12:57:16] [V] [TRT] Tactic: 113 Time: 0.211456
[03/24/2023-12:57:16] [V] [TRT] Tactic: 114 Time: 0.225152
[03/24/2023-12:57:16] [V] [TRT] Tactic: 116 Time: 0.350464
[03/24/2023-12:57:16] [V] [TRT] Tactic: 117 Time: 0.483584
[03/24/2023-12:57:16] [V] [TRT] Tactic: 118 Time: 0.066944
[03/24/2023-12:57:16] [V] [TRT] Fastest Tactic: 62 Time: 0.066816
[03/24/2023-12:57:16] [V] [TRT] --------------- Timing Runner: Conv_64 (CaskConvolution)
[03/24/2023-12:57:16] [V] [TRT] Conv_64 Set Tactic Name: ampere_scudnn_128x64_relu_small_nn_v1 Tactic: 4549827808004681195
[03/24/2023-12:57:16] [V] [TRT] Tactic: 4549827808004681195 Time: 0.20224
[03/24/2023-12:57:16] [V] [TRT] Conv_64 Set Tactic Name: ampere_scudnn_128x128_relu_small_nn_v1 Tactic: 5779835512569528575
[03/24/2023-12:57:16] [V] [TRT] Tactic: 5779835512569528575 Time: 0.370944
[03/24/2023-12:57:16] [V] [TRT] Conv_64 Set Tactic Name: ampere_scudnn_128x128_relu_xregs_large_nn_v1 Tactic: 6053873026024413720
[03/24/2023-12:57:16] [V] [TRT] Tactic: 6053873026024413720 Time: 0.39168
[03/24/2023-12:57:16] [V] [TRT] Conv_64 Set Tactic Name: ampere_scudnn_128x64_relu_xregs_large_nn_v1 Tactic: 6767548733843469815
[03/24/2023-12:57:16] [V] [TRT] Tactic: 6767548733843469815 Time: 0.203904
[03/24/2023-12:57:16] [V] [TRT] Conv_64 Set Tactic Name: ampere_scudnn_128x32_relu_small_nn_v1 Tactic: -6313876406580483184
[03/24/2023-12:57:16] [V] [TRT] Tactic: -6313876406580483184 Time: 0.15168
[03/24/2023-12:57:16] [V] [TRT] Conv_64 Set Tactic Name: ampere_scudnn_128x128_relu_medium_nn_v1 Tactic: -1123676555321336786
[03/24/2023-12:57:16] [V] [TRT] Tactic: -1123676555321336786 Time: 0.370944
[03/24/2023-12:57:16] [V] [TRT] Conv_64 Set Tactic Name: ampere_scudnn_128x64_relu_medium_nn_v1 Tactic: -701551393537224327
[03/24/2023-12:57:16] [V] [TRT] Tactic: -701551393537224327 Time: 0.206464
[03/24/2023-12:57:16] [V] [TRT] Fastest Tactic: -6313876406580483184 Time: 0.15168
[03/24/2023-12:57:16] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CudnnConvolution Tactic: 62
[03/24/2023-12:57:16] [V] [TRT] *************** Autotuning format combination: Float(16588800,1,92160,512) -> Float(64800,1,360,2) ***************
[03/24/2023-12:57:16] [V] [TRT] --------------- Timing Runner: Conv_64 (CudnnConvolution)
[03/24/2023-12:57:16] [V] [TRT] CudnnConvolution has no valid tactics for this config, skipping
[03/24/2023-12:57:16] [V] [TRT] --------------- Timing Runner: Conv_64 (CaskConvolution)
[03/24/2023-12:57:16] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[03/24/2023-12:57:16] [V] [TRT] *************** Autotuning format combination: Float(4147200,1:4,23040,128) -> Float(32400,1:4,180,1) ***************
[03/24/2023-12:57:16] [V] [TRT] --------------- Timing Runner: Conv_64 (CudnnConvolution)
[03/24/2023-12:57:16] [V] [TRT] CudnnConvolution has no valid tactics for this config, skipping
[03/24/2023-12:57:16] [V] [TRT] --------------- Timing Runner: Conv_64 (CaskConvolution)
[03/24/2023-12:57:16] [V] [TRT] Conv_64 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize64x128x32_stage5_warpsize2x2x1_g1_tensor16x8x8 Tactic: 1237784342446422381
[03/24/2023-12:57:16] [V] [TRT] Tactic: 1237784342446422381 Time: 0.080896
[03/24/2023-12:57:16] [V] [TRT] Conv_64 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x64x32_stage5_warpsize2x2x1_g1_tensor16x8x8 Tactic: 1426562292875733922
[03/24/2023-12:57:16] [V] [TRT] Tactic: 1426562292875733922 Time: 0.054272
[03/24/2023-12:57:16] [V] [TRT] Conv_64 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize64x128x8_stage3_warpsize1x4x1_g1_ffma_t1r3s3 Tactic: 2086609538387166260
[03/24/2023-12:57:16] [V] [TRT] Tactic: 2086609538387166260 Time: 0.280576
[03/24/2023-12:57:16] [V] [TRT] Conv_64 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize256x128x32_stage3_warpsize4x2x1_g1_tensor16x8x8_t1r3s3 Tactic: 2388153022056233219
[03/24/2023-12:57:16] [V] [TRT] Tactic: 2388153022056233219 Time: 0.079744
[03/24/2023-12:57:16] [V] [TRT] Conv_64 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x128x32_stage4_warpsize2x2x1_g1_tensor16x8x8 Tactic: 2716437853123234317
[03/24/2023-12:57:16] [V] [TRT] Tactic: 2716437853123234317 Time: 0.071296
[03/24/2023-12:57:16] [V] [TRT] Conv_64 Set Tactic Name: ampere_scudnn_128x64_sliced1x2_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: 2860655430572478466
[03/24/2023-12:57:16] [V] [TRT] Tactic: 2860655430572478466 Time: 0.176768
[03/24/2023-12:57:16] [V] [TRT] Conv_64 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize64x128x8_stage3_warpsize1x4x1_g1_ffma Tactic: 3239733199291090177
[03/24/2023-12:57:16] [V] [TRT] Tactic: 3239733199291090177 Time: 0.279296
[03/24/2023-12:57:16] [V] [TRT] Conv_64 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize64x64x64_stage4_warpsize2x2x1_g1_tensor16x8x8_t1r3s3 Tactic: 3278852197192504305
[03/24/2023-12:57:16] [V] [TRT] Tactic: 3278852197192504305 Time: 0.053248
[03/24/2023-12:57:16] [V] [TRT] Conv_64 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize256x128x32_stage3_warpsize4x2x1_g1_tensor16x8x8 Tactic: 3904690393614050557
[03/24/2023-12:57:16] [V] [TRT] Tactic: 3904690393614050557 Time: 0.098688
[03/24/2023-12:57:16] [V] [TRT] Conv_64 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize64x64x64_stage4_warpsize2x2x1_g1_tensor16x8x8 Tactic: 4061115162338989075
[03/24/2023-12:57:16] [V] [TRT] Tactic: 4061115162338989075 Time: 0.058368
[03/24/2023-12:57:16] [V] [TRT] Conv_64 Set Tactic Name: ampere_scudnn_128x32_sliced1x4_ldg4_relu_exp_medium_nhwc_tn_v1 Tactic: 4474630279712975759
[03/24/2023-12:57:16] [V] [TRT] Tactic: 4474630279712975759 Time: 0.096128
[03/24/2023-12:57:16] [V] [TRT] Conv_64 Set Tactic Name: ampere_scudnn_128x32_sliced1x4_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: 4479823862704990365
[03/24/2023-12:57:16] [V] [TRT] Tactic: 4479823862704990365 Time: 0.09536
[03/24/2023-12:57:16] [V] [TRT] Conv_64 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize64x256x8_stage3_warpsize1x4x1_g1_ffma Tactic: 4517590677127196184
[03/24/2023-12:57:16] [V] [TRT] Tactic: 4517590677127196184 Time: 0.662784
[03/24/2023-12:57:16] [V] [TRT] Conv_64 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize128x128x8_stage3_warpsize2x4x1_g1_ffma_t1r3s3 Tactic: 4634080872644479428
[03/24/2023-12:57:16] [V] [TRT] Tactic: 4634080872644479428 Time: 0.33792
[03/24/2023-12:57:16] [V] [TRT] Conv_64 Set Tactic Name: ampere_scudnn_128x64_sliced1x2_ldg4_relu_exp_medium_nhwc_tn_v1 Tactic: 4696204239951173149
[03/24/2023-12:57:16] [V] [TRT] Tactic: 4696204239951173149 Time: 0.177152
[03/24/2023-12:57:16] [V] [TRT] Conv_64 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x256x32_stage3_warpsize2x4x1_g1_tensor16x8x8 Tactic: 5200329514761435342
[03/24/2023-12:57:16] [V] [TRT] Tactic: 5200329514761435342 Time: 0.110464
[03/24/2023-12:57:16] [V] [TRT] Conv_64 Set Tactic Name: ampere_scudnn_128x128_relu_exp_small_nhwc_tn_v1 Tactic: 5778138195697110003
[03/24/2023-12:57:16] [V] [TRT] Tactic: 5778138195697110003 Time: 0.332544
[03/24/2023-12:57:16] [V] [TRT] Conv_64 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize256x128x8_stage3_warpsize2x4x1_g1_ffma Tactic: 6310198979346901507
[03/24/2023-12:57:16] [V] [TRT] Tactic: 6310198979346901507 Time: 0.464
[03/24/2023-12:57:16] [V] [TRT] Conv_64 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x256x32_stage3_warpsize2x4x1_g1_tensor16x8x8_t1r3s3 Tactic: 7011693366046809027
[03/24/2023-12:57:16] [V] [TRT] Tactic: 7011693366046809027 Time: 0.108928
[03/24/2023-12:57:16] [V] [TRT] Conv_64 Set Tactic Name: ampere_scudnn_128x128_ldg4_relu_exp_large_nhwc_tn_v1 Tactic: 7155825427510256858
[03/24/2023-12:57:16] [V] [TRT] Tactic: 7155825427510256858 Time: 0.334848
[03/24/2023-12:57:16] [V] [TRT] Conv_64 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize128x64x8_stage3_warpsize1x4x1_g1_ffma Tactic: 7222247112373541608
[03/24/2023-12:57:16] [V] [TRT] Tactic: 7222247112373541608 Time: 0.23744
[03/24/2023-12:57:16] [V] [TRT] Conv_64 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x128x16_stage4_warpsize2x2x1_g1_tensor16x8x8 Tactic: 7342025736444949634
[03/24/2023-12:57:16] [V] [TRT] Tactic: 7342025736444949634 Time: 0.07424
[03/24/2023-12:57:16] [V] [TRT] Conv_64 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize64x128x32_stage5_warpsize2x2x1_g1_tensor16x8x8 Tactic: 7347365539922924600
[03/24/2023-12:57:16] [V] [TRT] Tactic: 7347365539922924600 Time: 0.078848
[03/24/2023-12:57:16] [V] [TRT] Conv_64 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x64x32_stage5_warpsize2x2x1_g1_tensor16x8x8 Tactic: 7428197830878119671
[03/24/2023-12:57:16] [V] [TRT] Tactic: 7428197830878119671 Time: 0.051072
[03/24/2023-12:57:16] [V] [TRT] Conv_64 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize64x32x64_stage5_warpsize2x2x1_g1_tensor16x8x8_t1r3s3 Tactic: 7465323447915168822
[03/24/2023-12:57:16] [V] [TRT] Tactic: 7465323447915168822 Time: 0.044032
[03/24/2023-12:57:16] [V] [TRT] Conv_64 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize128x128x8_stage3_warpsize2x4x1_g1_ffma Tactic: 7472640475524677095
[03/24/2023-12:57:16] [V] [TRT] Tactic: 7472640475524677095 Time: 0.345088
[03/24/2023-12:57:16] [V] [TRT] Conv_64 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize64x32x64_stage5_warpsize2x2x1_g1_tensor16x8x8 Tactic: 7938223790021272801
[03/24/2023-12:57:16] [V] [TRT] Tactic: 7938223790021272801 Time: 0.046848
[03/24/2023-12:57:16] [V] [TRT] Conv_64 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize128x256x8_stage3_warpsize2x4x1_g1_ffma Tactic: 8498373915030836990
[03/24/2023-12:57:16] [V] [TRT] Tactic: 8498373915030836990 Time: 0.672768
[03/24/2023-12:57:16] [V] [TRT] Conv_64 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x64x32_stage5_warpsize2x2x1_g1_tensor16x8x8_t1r3s3 Tactic: 8836645772682419994
[03/24/2023-12:57:16] [V] [TRT] Tactic: 8836645772682419994 Time: 0.049152
[03/24/2023-12:57:16] [V] [TRT] Conv_64 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize256x64x8_stage3_warpsize1x4x1_g1_ffma Tactic: 8869697132622550639
[03/24/2023-12:57:16] [V] [TRT] Tactic: 8869697132622550639 Time: 0.262784
[03/24/2023-12:57:16] [V] [TRT] Conv_64 Set Tactic Name: ampere_scudnn_128x128_ldg4_relu_exp_medium_nhwc_tn_v1 Tactic: 8918020581761223752
[03/24/2023-12:57:16] [V] [TRT] Tactic: 8918020581761223752 Time: 0.331648
[03/24/2023-12:57:16] [V] [TRT] Conv_64 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize64x64x64_stage4_warpsize2x2x1_g1_tensor16x8x8 Tactic: -9114138070928278731
[03/24/2023-12:57:16] [V] [TRT] Tactic: -9114138070928278731 Time: 0.05824
[03/24/2023-12:57:16] [V] [TRT] Conv_64 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize256x128x8_stage3_warpsize2x4x1_g1_ffma_t1r3s3 Tactic: -8937725997228636978
[03/24/2023-12:57:16] [V] [TRT] Tactic: -8937725997228636978 Time: 0.447488
[03/24/2023-12:57:16] [V] [TRT] Conv_64 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize128x256x8_stage3_warpsize2x4x1_g1_ffma_t1r3s3 Tactic: -8833858409138163072
[03/24/2023-12:57:16] [V] [TRT] Tactic: -8833858409138163072 Time: 0.660224
[03/24/2023-12:57:16] [V] [TRT] Conv_64 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize64x64x8_stage3_warpsize1x4x1_g1_ffma_t1r3s3 Tactic: -7989138351613022500
[03/24/2023-12:57:16] [V] [TRT] Tactic: -7989138351613022500 Time: 0.154112
[03/24/2023-12:57:16] [V] [TRT] Conv_64 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize256x128x8_stage3_warpsize2x4x1_g1_ffma Tactic: -7872883691240863058
[03/24/2023-12:57:16] [V] [TRT] Tactic: -7872883691240863058 Time: 0.464128
[03/24/2023-12:57:16] [V] [TRT] Conv_64 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x256x32_stage3_warpsize2x4x1_g1_tensor16x8x8 Tactic: -7382359095196034537
[03/24/2023-12:57:16] [V] [TRT] Tactic: -7382359095196034537 Time: 0.112896
[03/24/2023-12:57:16] [V] [TRT] Conv_64 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x128x16_stage4_warpsize2x2x1_g1_tensor16x8x8_t1r3s3 Tactic: -7377458734869418330
[03/24/2023-12:57:16] [V] [TRT] Tactic: -7377458734869418330 Time: 0.068864
[03/24/2023-12:57:16] [V] [TRT] Conv_64 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize128x128x8_stage3_warpsize2x4x1_g1_ffma Tactic: -6729618519651721910
[03/24/2023-12:57:16] [V] [TRT] Tactic: -6729618519651721910 Time: 0.341376
[03/24/2023-12:57:16] [V] [TRT] Conv_64 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize256x64x32_stage3_warpsize4x2x1_g1_tensor16x8x8_t1r3s3 Tactic: -6223854811627385844
[03/24/2023-12:57:16] [V] [TRT] Tactic: -6223854811627385844 Time: 0.050304
[03/24/2023-12:57:16] [V] [TRT] Conv_64 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize256x64x8_stage3_warpsize1x4x1_g1_ffma Tactic: -5893833996418445881
[03/24/2023-12:57:16] [V] [TRT] Tactic: -5893833996418445881 Time: 0.256256
[03/24/2023-12:57:16] [V] [TRT] Conv_64 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize128x256x8_stage3_warpsize2x4x1_g1_ffma Tactic: -5701562095007058349
[03/24/2023-12:57:16] [V] [TRT] Tactic: -5701562095007058349 Time: 0.664576
[03/24/2023-12:57:16] [V] [TRT] Conv_64 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize128x64x8_stage3_warpsize1x4x1_g1_ffma Tactic: -5685503422376017600
[03/24/2023-12:57:16] [V] [TRT] Tactic: -5685503422376017600 Time: 0.2304
[03/24/2023-12:57:16] [V] [TRT] Conv_64 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize64x64x8_stage3_warpsize1x4x1_g1_ffma Tactic: -5521125187060117489
[03/24/2023-12:57:16] [V] [TRT] Tactic: -5521125187060117489 Time: 0.160768
[03/24/2023-12:57:16] [V] [TRT] Conv_64 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x128x16_stage4_warpsize2x2x1_g1_tensor16x8x8 Tactic: -5457304872213719461
[03/24/2023-12:57:16] [V] [TRT] Tactic: -5457304872213719461 Time: 0.068992
[03/24/2023-12:57:16] [V] [TRT] Conv_64 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x64x64_stage3_warpsize2x2x1_g1_tensor16x8x8 Tactic: -5441054706931585554
[03/24/2023-12:57:16] [V] [TRT] Tactic: -5441054706931585554 Time: 0.052096
[03/24/2023-12:57:16] [V] [TRT] Conv_64 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize256x64x32_stage3_warpsize4x2x1_g1_tensor16x8x8 Tactic: -5043603702497465467
[03/24/2023-12:57:16] [V] [TRT] Tactic: -5043603702497465467 Time: 0.059136
[03/24/2023-12:57:16] [V] [TRT] Conv_64 Set Tactic Name: ampere_scudnn_128x64_sliced1x2_ldg4_relu_exp_large_nhwc_tn_v1 Tactic: -4756382386362004279
[03/24/2023-12:57:16] [V] [TRT] Tactic: -4756382386362004279 Time: 0.174976
[03/24/2023-12:57:16] [V] [TRT] Conv_64 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize64x64x8_stage3_warpsize1x4x1_g1_ffma Tactic: -4615000974950361663
[03/24/2023-12:57:16] [V] [TRT] Tactic: -4615000974950361663 Time: 0.1536
[03/24/2023-12:57:16] [V] [TRT] Conv_64 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x64x64_stage3_warpsize2x2x1_g1_tensor16x8x8 Tactic: -4564655677311401797
[03/24/2023-12:57:16] [V] [TRT] Tactic: -4564655677311401797 Time: 0.05312
[03/24/2023-12:57:16] [V] [TRT] Conv_64 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize256x64x8_stage3_warpsize1x4x1_g1_ffma_t1r3s3 Tactic: -4314913710375142296
[03/24/2023-12:57:16] [V] [TRT] Tactic: -4314913710375142296 Time: 0.246528
[03/24/2023-12:57:16] [V] [TRT] Conv_64 Set Tactic Name: ampere_scudnn_128x128_relu_exp_large_nhwc_tn_v1 Tactic: -3855385237722507464
[03/24/2023-12:57:16] [V] [TRT] Tactic: -3855385237722507464 Time: 0.334848
[03/24/2023-12:57:16] [V] [TRT] Conv_64 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize128x64x8_stage3_warpsize1x4x1_g1_ffma_t1r3s3 Tactic: -3697587361057948972
[03/24/2023-12:57:16] [V] [TRT] Tactic: -3697587361057948972 Time: 0.231168
[03/24/2023-12:57:16] [V] [TRT] Conv_64 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize256x64x32_stage3_warpsize4x2x1_g1_tensor16x8x8 Tactic: -3540975627865078064
[03/24/2023-12:57:16] [V] [TRT] Tactic: -3540975627865078064 Time: 0.053632
[03/24/2023-12:57:16] [V] [TRT] Conv_64 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize64x128x32_stage5_warpsize2x2x1_g1_tensor16x8x8_t1r3s3 Tactic: -3151804561246216835
[03/24/2023-12:57:16] [V] [TRT] Tactic: -3151804561246216835 Time: 0.074752
[03/24/2023-12:57:16] [V] [TRT] Conv_64 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize64x32x64_stage5_warpsize2x2x1_g1_tensor16x8x8 Tactic: -2885165284206163001
[03/24/2023-12:57:16] [V] [TRT] Tactic: -2885165284206163001 Time: 0.048384
[03/24/2023-12:57:16] [V] [TRT] Conv_64 Set Tactic Name: ampere_scudnn_128x128_relu_exp_medium_nhwc_tn_v1 Tactic: -2809379259463049391
[03/24/2023-12:57:16] [V] [TRT] Tactic: -2809379259463049391 Time: 0.333952
[03/24/2023-12:57:16] [V] [TRT] Conv_64 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x128x32_stage4_warpsize2x2x1_g1_tensor16x8x8_t1r3s3 Tactic: -2801041895330778813
[03/24/2023-12:57:16] [V] [TRT] Tactic: -2801041895330778813 Time: 0.074624
[03/24/2023-12:57:16] [V] [TRT] Conv_64 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize64x256x8_stage3_warpsize1x4x1_g1_ffma_t1r3s3 Tactic: -2747929399988666512
[03/24/2023-12:57:16] [V] [TRT] Tactic: -2747929399988666512 Time: 0.658432
[03/24/2023-12:57:16] [V] [TRT] Conv_64 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize256x128x32_stage3_warpsize4x2x1_g1_tensor16x8x8 Tactic: -1758690179295738332
[03/24/2023-12:57:16] [V] [TRT] Tactic: -1758690179295738332 Time: 0.084096
[03/24/2023-12:57:16] [V] [TRT] Conv_64 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x64x64_stage3_warpsize2x2x1_g1_tensor16x8x8_t1r3s3 Tactic: -1484546572846226796
[03/24/2023-12:57:16] [V] [TRT] Tactic: -1484546572846226796 Time: 0.050176
[03/24/2023-12:57:16] [V] [TRT] Conv_64 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize64x256x8_stage3_warpsize1x4x1_g1_ffma Tactic: -1472061967969061456
[03/24/2023-12:57:16] [V] [TRT] Tactic: -1472061967969061456 Time: 0.675072
[03/24/2023-12:57:16] [V] [TRT] Conv_64 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x128x32_stage4_warpsize2x2x1_g1_tensor16x8x8 Tactic: -858667497925695276
[03/24/2023-12:57:16] [V] [TRT] Tactic: -858667497925695276 Time: 0.105472
[03/24/2023-12:57:16] [V] [TRT] Conv_64 Set Tactic Name: ampere_scudnn_128x128_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: -504296718212024303
[03/24/2023-12:57:16] [V] [TRT] Tactic: -504296718212024303 Time: 0.331648
[03/24/2023-12:57:16] [V] [TRT] Conv_64 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize64x128x8_stage3_warpsize1x4x1_g1_ffma Tactic: -444093195553988951
[03/24/2023-12:57:16] [V] [TRT] Tactic: -444093195553988951 Time: 0.294016
[03/24/2023-12:57:16] [V] [TRT] Fastest Tactic: 7465323447915168822 Time: 0.044032
[03/24/2023-12:57:16] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: 7465323447915168822
[03/24/2023-12:57:16] [V] [TRT] *************** Autotuning format combination: Half(16588800,32400,180,1) -> Half(64800,32400,180,1) ***************
[03/24/2023-12:57:16] [V] [TRT] --------------- Timing Runner: Conv_64 (CudnnConvolution)
[03/24/2023-12:57:16] [V] [TRT] Tactic: 0 Time: 0.36096
[03/24/2023-12:57:16] [V] [TRT] Tactic: 1 Time: 0.146432
[03/24/2023-12:57:16] [V] [TRT] Tactic: 2 Time: 0.431232
[03/24/2023-12:57:16] [V] [TRT] Tactic: 4 Time: 0.342016
[03/24/2023-12:57:16] [V] [TRT] Tactic: 5 Time: 0.44672
[03/24/2023-12:57:16] [V] [TRT] Tactic: 6 Time: 0.39232
[03/24/2023-12:57:16] [V] [TRT] Tactic: 56 Time: 0.360832
[03/24/2023-12:57:16] [V] [TRT] Tactic: 58 Time: 0.430976
[03/24/2023-12:57:16] [V] [TRT] Tactic: 60 Time: 0.342656
[03/24/2023-12:57:16] [V] [TRT] Tactic: 61 Time: 0.418688
[03/24/2023-12:57:17] [V] [TRT] Tactic: 62 Time: 0.395264
[03/24/2023-12:57:17] [V] [TRT] Fastest Tactic: 1 Time: 0.146432
[03/24/2023-12:57:17] [V] [TRT] --------------- Timing Runner: Conv_64 (CaskConvolution)
[03/24/2023-12:57:17] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[03/24/2023-12:57:17] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CudnnConvolution Tactic: 1
[03/24/2023-12:57:17] [V] [TRT] *************** Autotuning format combination: Half(8294400,32400:2,180,1) -> Half(32400,32400:2,180,1) ***************
[03/24/2023-12:57:17] [V] [TRT] --------------- Timing Runner: Conv_64 (FusedConvActConvolution)
[03/24/2023-12:57:17] [V] [TRT] Tactic: 524287 Time: 0.047872
[03/24/2023-12:57:17] [V] [TRT] Tactic: 720895 Time: 0.072576
[03/24/2023-12:57:17] [V] [TRT] Tactic: 983039 Time: 0.067584
[03/24/2023-12:57:17] [V] [TRT] Tactic: 1048575 Time: 0.043904
[03/24/2023-12:57:17] [V] [TRT] Tactic: 1703935 Time: 0.043648
[03/24/2023-12:57:17] [V] [TRT] Tactic: 1769471 Time: 0.082816
[03/24/2023-12:57:17] [V] [TRT] Tactic: 1966079 Time: 0.0768
[03/24/2023-12:57:17] [V] [TRT] Tactic: 2031615 Time: 0.06336
[03/24/2023-12:57:17] [V] [TRT] Tactic: 2228223 Time: 0.058368
[03/24/2023-12:57:17] [V] [TRT] Tactic: 2424831 Time: 0.060416
[03/24/2023-12:57:17] [V] [TRT] Tactic: 2621439 Time: 0.045056
[03/24/2023-12:57:17] [V] [TRT] Tactic: 2752511 Time: 0.072064
[03/24/2023-12:57:17] [V] [TRT] Tactic: 3014655 Time: 0.044416
[03/24/2023-12:57:17] [V] [TRT] Tactic: 3145727 Time: 0.067456
[03/24/2023-12:57:17] [V] [TRT] Tactic: 3604479 Time: 0.045056
[03/24/2023-12:57:17] [V] [TRT] Tactic: 4390911 Time: 0.082432
[03/24/2023-12:57:17] [V] [TRT] Tactic: 5046271 Time: 0.045056
[03/24/2023-12:57:17] [V] [TRT] Tactic: 5963775 Time: 0.069504
[03/24/2023-12:57:17] [V] [TRT] Tactic: 6160383 Time: 0.047104
[03/24/2023-12:57:17] [V] [TRT] Tactic: 6488063 Time: 0.052096
[03/24/2023-12:57:17] [V] [TRT] Tactic: 6881279 Time: 0.072576
[03/24/2023-12:57:17] [V] [TRT] Tactic: 7274495 Time: 0.078336
[03/24/2023-12:57:17] [V] [TRT] Tactic: 7864319 Time: 0.048128
[03/24/2023-12:57:17] [V] [TRT] Tactic: 7995391 Time: 0.07872
[03/24/2023-12:57:17] [V] [TRT] Tactic: 8585215 Time: 0.055296
[03/24/2023-12:57:17] [V] [TRT] Tactic: 8847359 Time: 0.048384
[03/24/2023-12:57:17] [V] [TRT] Tactic: 8978431 Time: 0.069632
[03/24/2023-12:57:17] [V] [TRT] Tactic: 9043967 Time: 0.044672
[03/24/2023-12:57:17] [V] [TRT] Tactic: 9175039 Time: 0.044928
[03/24/2023-12:57:17] [V] [TRT] Tactic: 9502719 Time: 0.080896
[03/24/2023-12:57:17] [V] [TRT] Tactic: 9961471 Time: 0.058368
[03/24/2023-12:57:17] [V] [TRT] Tactic: 10027007 Time: 0.044928
[03/24/2023-12:57:17] [V] [TRT] Tactic: 10092543 Time: 0.08256
[03/24/2023-12:57:17] [V] [TRT] Tactic: 10289151 Time: 0.077056
[03/24/2023-12:57:17] [V] [TRT] Tactic: 10485759 Time: 0.042112
[03/24/2023-12:57:17] [V] [TRT] Tactic: 10682367 Time: 0.046976
[03/24/2023-12:57:17] [V] [TRT] Tactic: 10813439 Time: 0.077824
[03/24/2023-12:57:17] [V] [TRT] Fastest Tactic: 10485759 Time: 0.042112
[03/24/2023-12:57:17] [V] [TRT] --------------- Timing Runner: Conv_64 (CudnnConvolution)
[03/24/2023-12:57:17] [V] [TRT] CudnnConvolution has no valid tactics for this config, skipping
[03/24/2023-12:57:17] [V] [TRT] --------------- Timing Runner: Conv_64 (CaskConvolution)
[03/24/2023-12:57:17] [V] [TRT] Conv_64 Set Tactic Name: ampere_fp16x2_hcudnn_fp16x2_128x32_relu_medium_nn_v1 Tactic: 2195670545862694453
[03/24/2023-12:57:17] [V] [TRT] Tactic: 2195670545862694453 Time: 0.0736
[03/24/2023-12:57:17] [V] [TRT] Conv_64 Set Tactic Name: ampere_fp16x2_hcudnn_fp16x2_128x64_relu_large_nn_v1 Tactic: 3419182076704469245
[03/24/2023-12:57:17] [V] [TRT] Tactic: 3419182076704469245 Time: 0.101376
[03/24/2023-12:57:17] [V] [TRT] Conv_64 Set Tactic Name: ampere_fp16x2_hcudnn_fp16x2_128x128_relu_medium_nn_v1 Tactic: 3891805945559659536
[03/24/2023-12:57:17] [V] [TRT] Tactic: 3891805945559659536 Time: 0.182272
[03/24/2023-12:57:17] [V] [TRT] Conv_64 Set Tactic Name: ampere_fp16x2_hcudnn_fp16x2_128x64_relu_medium_nn_v1 Tactic: 5548126322150286555
[03/24/2023-12:57:17] [V] [TRT] Tactic: 5548126322150286555 Time: 0.100224
[03/24/2023-12:57:17] [V] [TRT] Conv_64 Set Tactic Name: ampere_fp16x2_hcudnn_fp16x2_128x64_relu_small_nn_v1 Tactic: 6057304366605292508
[03/24/2023-12:57:17] [V] [TRT] Tactic: 6057304366605292508 Time: 0.097792
[03/24/2023-12:57:17] [V] [TRT] Conv_64 Set Tactic Name: ampere_fp16x2_hcudnn_fp16x2_128x128_relu_large_nn_v1 Tactic: -7928611605886347652
[03/24/2023-12:57:17] [V] [TRT] Tactic: -7928611605886347652 Time: 0.187648
[03/24/2023-12:57:17] [V] [TRT] Conv_64 Set Tactic Name: ampere_fp16x2_hcudnn_fp16x2_128x32_relu_large_nn_v1 Tactic: -5172391392092686714
[03/24/2023-12:57:17] [V] [TRT] Tactic: -5172391392092686714 Time: 0.074112
[03/24/2023-12:57:17] [V] [TRT] Conv_64 Set Tactic Name: ampere_fp16x2_hcudnn_fp16x2_128x32_relu_small_nn_v1 Tactic: -4374269919094467161
[03/24/2023-12:57:17] [V] [TRT] Tactic: -4374269919094467161 Time: 0.071552
[03/24/2023-12:57:17] [V] [TRT] Conv_64 Set Tactic Name: ampere_fp16x2_hcudnn_winograd_fp16x2_128x128_ldg1_ldg4_relu_tile148t_nt_v1 Tactic: -4083394051665370953
[03/24/2023-12:57:17] [V] [TRT] Tactic: -4083394051665370953 Time: 0.032384
[03/24/2023-12:57:17] [V] [TRT] Conv_64 Set Tactic Name: ampere_fp16x2_hcudnn_fp16x2_128x128_relu_small_nn_v1 Tactic: -1546027692247304867
[03/24/2023-12:57:17] [V] [TRT] Tactic: -1546027692247304867 Time: 0.183296
[03/24/2023-12:57:17] [V] [TRT] Fastest Tactic: -4083394051665370953 Time: 0.032384
[03/24/2023-12:57:17] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: -4083394051665370953
[03/24/2023-12:57:17] [V] [TRT] *************** Autotuning format combination: Half(2073600,1:8,11520,64) -> Float(64800,32400,180,1) ***************
[03/24/2023-12:57:17] [V] [TRT] --------------- Timing Runner: Conv_64 (CudnnConvolution)
[03/24/2023-12:57:17] [V] [TRT] CudnnConvolution has no valid tactics for this config, skipping
[03/24/2023-12:57:17] [V] [TRT] --------------- Timing Runner: Conv_64 (CaskConvolution)
[03/24/2023-12:57:17] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[03/24/2023-12:57:17] [V] [TRT] *************** Autotuning format combination: Half(2073600,1:8,11520,64) -> Half(32400,1:8,180,1) ***************
[03/24/2023-12:57:17] [V] [TRT] --------------- Timing Runner: Conv_64 (CudaDepthwiseConvolution)
[03/24/2023-12:57:17] [V] [TRT] CudaDepthwiseConvolution has no valid tactics for this config, skipping
[03/24/2023-12:57:17] [V] [TRT] --------------- Timing Runner: Conv_64 (CudnnConvolution)
[03/24/2023-12:57:17] [V] [TRT] CudnnConvolution has no valid tactics for this config, skipping
[03/24/2023-12:57:17] [V] [TRT] --------------- Timing Runner: Conv_64 (CaskConvolution)
[03/24/2023-12:57:17] [V] [TRT] Conv_64 Set Tactic Name: ampere_h16816cudnn_256x128_ldg8_relu_exp_medium_nhwc_tn_v1 Tactic: 254850674756030979
[03/24/2023-12:57:17] [V] [TRT] Tactic: 254850674756030979 Time: 0.044928
[03/24/2023-12:57:17] [V] [TRT] Conv_64 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x128x32_stage3_warpsize4x2x1_g1_tensor16x8x16_t1r3s3 Tactic: 328038211831149625
[03/24/2023-12:57:17] [V] [TRT] Tactic: 328038211831149625 Time: 0.043008
[03/24/2023-12:57:17] [V] [TRT] Conv_64 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x64x64_stage3_warpsize2x2x1_g1_tensor16x8x16_t1r3s3 Tactic: 411553864378931917
[03/24/2023-12:57:17] [V] [TRT] Tactic: 411553864378931917 Time: 0.024576
[03/24/2023-12:57:17] [V] [TRT] Conv_64 Set Tactic Name: sm75_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x128x32_stage1_warpsize4x2x1_g1_tensor16x8x8_t1r3s3 Tactic: 864841579020773074
[03/24/2023-12:57:17] [V] [TRT] Tactic: 864841579020773074 Time: 0.050176
[03/24/2023-12:57:17] [V] [TRT] Conv_64 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x128x32_stage4_warpsize2x2x1_g1_tensor16x8x16 Tactic: 1011057357468998345
[03/24/2023-12:57:17] [V] [TRT] Tactic: 1011057357468998345 Time: 0.037248
[03/24/2023-12:57:17] [V] [TRT] Conv_64 Set Tactic Name: sm75_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x64x32_stage1_warpsize4x1x1_g1_tensor16x8x8 Tactic: 1013168150133367738
[03/24/2023-12:57:17] [V] [TRT] Tactic: 1013168150133367738 Time: 0.033792
[03/24/2023-12:57:17] [V] [TRT] Conv_64 Set Tactic Name: ampere_h16816cudnn_256x128_ldg8_relu_exp_stages_64x3_small_nhwc_tn_v1 Tactic: 1016009564074305832
[03/24/2023-12:57:17] [V] [TRT] Tactic: 1016009564074305832 Time: 0.045056
[03/24/2023-12:57:17] [V] [TRT] Conv_64 Set Tactic Name: sm75_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x128x32_stage1_warpsize2x2x1_g1_tensor16x8x8 Tactic: 1067227531433278814
[03/24/2023-12:57:17] [V] [TRT] Tactic: 1067227531433278814 Time: 0.040832
[03/24/2023-12:57:17] [V] [TRT] Conv_64 Set Tactic Name: ampere_h1688cudnn_128x128_ldg8_relu_exp_medium_nhwc_tn_v1 Tactic: 1156328698016730421
[03/24/2023-12:57:17] [V] [TRT] Tactic: 1156328698016730421 Time: 0.048768
[03/24/2023-12:57:17] [V] [TRT] Conv_64 Set Tactic Name: sm75_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x128x32_stage1_warpsize2x2x1_g1_tensor16x8x8 Tactic: 1579845938601132607
[03/24/2023-12:57:17] [V] [TRT] Tactic: 1579845938601132607 Time: 0.040832
[03/24/2023-12:57:17] [V] [TRT] Conv_64 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x128x32_stage5_warpsize2x2x1_g1_tensor16x8x16_t1r3s3 Tactic: 1723736032573714698
[03/24/2023-12:57:17] [V] [TRT] Tactic: 1723736032573714698 Time: 0.035584
[03/24/2023-12:57:17] [V] [TRT] Conv_64 Set Tactic Name: sm75_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x32x32_stage1_warpsize4x1x1_g1_tensor16x8x8 Tactic: 1796821236841789338
[03/24/2023-12:57:17] [V] [TRT] Tactic: 1796821236841789338 Time: 0.025344
[03/24/2023-12:57:17] [V] [TRT] Conv_64 Set Tactic Name: ampere_h16816cudnn_128x64_ldg8_relu_exp_stages_64x4_medium_nhwc_tn_v1 Tactic: 1832046141070096030
[03/24/2023-12:57:17] [V] [TRT] Tactic: 1832046141070096030 Time: 0.03072
[03/24/2023-12:57:17] [V] [TRT] Conv_64 Set Tactic Name: ampere_h16816cudnn_128x64_sliced1x2_ldg8_relu_exp_stages_64x3_small_nhwc_tn_v1 Tactic: 1838082074606840426
[03/24/2023-12:57:17] [V] [TRT] Tactic: 1838082074606840426 Time: 0.026112
[03/24/2023-12:57:17] [V] [TRT] Conv_64 Set Tactic Name: ampere_h16816cudnn_64x64_sliced1x2_ldg8_relu_exp_stages_64x5_small_nhwc_tn_v1 Tactic: 1899296423087490472
[03/24/2023-12:57:17] [V] [TRT] Tactic: 1899296423087490472 Time: 0.031616
[03/24/2023-12:57:17] [V] [TRT] Conv_64 Set Tactic Name: sm75_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x32x32_stage1_warpsize4x1x1_g1_tensor16x8x8 Tactic: 1948263663414159978
[03/24/2023-12:57:17] [V] [TRT] Tactic: 1948263663414159978 Time: 0.028288
[03/24/2023-12:57:17] [V] [TRT] Conv_64 Set Tactic Name: sm75_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x256x64_stage1_warpsize1x4x2_g1_tensor16x8x8 Tactic: 2027733232253711640
[03/24/2023-12:57:17] [V] [TRT] Tactic: 2027733232253711640 Time: 0.070656
[03/24/2023-12:57:17] [V] [TRT] Conv_64 Set Tactic Name: sm75_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x64x32_stage1_warpsize2x2x1_g1_tensor16x8x8_t1r3s3 Tactic: 2154731107061273008
[03/24/2023-12:57:17] [V] [TRT] Tactic: 2154731107061273008 Time: 0.029568
[03/24/2023-12:57:17] [V] [TRT] Conv_64 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x64x64_stage3_warpsize2x2x1_g1_tensor16x8x16 Tactic: 2428167804343994714
[03/24/2023-12:57:17] [V] [TRT] Tactic: 2428167804343994714 Time: 0.0256
[03/24/2023-12:57:17] [V] [TRT] Conv_64 Set Tactic Name: ampere_h16816cudnn_128x128_ldg8_relu_exp_medium_nhwc_tn_v1 Tactic: 2541579301352125276
[03/24/2023-12:57:17] [V] [TRT] Tactic: 2541579301352125276 Time: 0.034944
[03/24/2023-12:57:17] [V] [TRT] Conv_64 Set Tactic Name: ampere_h16816cudnn_64x64_sliced1x2_ldg8_relu_exp_stages_64x6_small_nhwc_tn_v1 Tactic: 2657157263811141609
[03/24/2023-12:57:17] [V] [TRT] Tactic: 2657157263811141609 Time: 0.036864
[03/24/2023-12:57:17] [V] [TRT] Conv_64 Set Tactic Name: ampere_h16816cudnn_64x128_sliced1x2_ldg8_relu_exp_stages_64x4_large_nhwc_tn_v1 Tactic: 2819719497590964443
[03/24/2023-12:57:17] [V] [TRT] Tactic: 2819719497590964443 Time: 0.049024
[03/24/2023-12:57:17] [V] [TRT] Conv_64 Set Tactic Name: ampere_h16816cudnn_128x64_sliced1x2_ldg8_relu_exp_stages_64x3_medium_nhwc_tn_v1 Tactic: 2968605903460894194
[03/24/2023-12:57:17] [V] [TRT] Tactic: 2968605903460894194 Time: 0.026496
[03/24/2023-12:57:17] [V] [TRT] Conv_64 Set Tactic Name: ampere_h16816cudnn_128x128_ldg8_relu_exp_large_nhwc_tn_v1 Tactic: 2986078304285316765
[03/24/2023-12:57:17] [V] [TRT] Tactic: 2986078304285316765 Time: 0.035584
[03/24/2023-12:57:17] [V] [TRT] Conv_64 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x256x64_stage3_warpsize1x4x1_g1_tensor16x8x16 Tactic: 3016308193087082166
[03/24/2023-12:57:17] [V] [TRT] Tactic: 3016308193087082166 Time: 0.065536
[03/24/2023-12:57:17] [V] [TRT] Conv_64 Set Tactic Name: ampere_h16816cudnn_256x64_ldg8_relu_exp_stages_64x3_large_nhwc_tn_v1 Tactic: 3221382575080507859
[03/24/2023-12:57:17] [V] [TRT] Tactic: 3221382575080507859 Time: 0.030848
[03/24/2023-12:57:17] [V] [TRT] Conv_64 Set Tactic Name: ampere_h16816cudnn_128x128_ldg8_relu_exp_stages_64x3_medium_nhwc_tn_v1 Tactic: 3362537467505018070
[03/24/2023-12:57:17] [V] [TRT] Tactic: 3362537467505018070 Time: 0.040704
[03/24/2023-12:57:17] [V] [TRT] Conv_64 Set Tactic Name: sm75_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x64x32_stage1_warpsize4x1x1_g1_tensor16x8x8_t1r3s3 Tactic: 3464689803495983377
[03/24/2023-12:57:17] [V] [TRT] Tactic: 3464689803495983377 Time: 0.032768
[03/24/2023-12:57:17] [V] [TRT] Conv_64 Set Tactic Name: ampere_h1688cudnn_256x128_ldg8_relu_exp_medium_nhwc_tn_v1 Tactic: 3513075359009385578
[03/24/2023-12:57:17] [V] [TRT] Tactic: 3513075359009385578 Time: 0.05312
[03/24/2023-12:57:17] [V] [TRT] Conv_64 Set Tactic Name: ampere_h16816cudnn_128x64_ldg8_relu_exp_stages_64x4_large_nhwc_tn_v1 Tactic: 3573559043797674382
[03/24/2023-12:57:17] [V] [TRT] Tactic: 3573559043797674382 Time: 0.031744
[03/24/2023-12:57:17] [V] [TRT] Conv_64 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x64x64_stage4_warpsize2x2x1_g1_tensor16x8x16_t1r3s3 Tactic: 3591970081995419777
[03/24/2023-12:57:17] [V] [TRT] Tactic: 3591970081995419777 Time: 0.028544
[03/24/2023-12:57:17] [V] [TRT] Conv_64 Set Tactic Name: sm75_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x128x32_stage1_warpsize2x2x1_g1_tensor16x8x8_t1r3s3 Tactic: 3636831327753843771
[03/24/2023-12:57:17] [V] [TRT] Tactic: 3636831327753843771 Time: 0.037888
[03/24/2023-12:57:17] [V] [TRT] Conv_64 Set Tactic Name: ampere_h1688cudnn_128x128_ldg8_relu_exp_small_nhwc_tn_v1 Tactic: 3704534001553878387
[03/24/2023-12:57:17] [V] [TRT] Tactic: 3704534001553878387 Time: 0.045952
[03/24/2023-12:57:17] [V] [TRT] Conv_64 Set Tactic Name: ampere_h16816cudnn_64x128_ldg8_relu_exp_stages_64x4_small_nhwc_tn_v1 Tactic: 4278315135102886928
[03/24/2023-12:57:17] [V] [TRT] Tactic: 4278315135102886928 Time: 0.043136
[03/24/2023-12:57:17] [V] [TRT] Conv_64 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x32x32_stage4_warpsize4x1x1_g1_tensor16x8x16_t1r3s3 Tactic: 4503233883285355107
[03/24/2023-12:57:17] [V] [TRT] Tactic: 4503233883285355107 Time: 0.02048
[03/24/2023-12:57:17] [V] [TRT] Conv_64 Set Tactic Name: ampere_h16816cudnn_256x64_ldg8_relu_exp_stages_64x3_medium_nhwc_tn_v1 Tactic: 4540505769798915372
[03/24/2023-12:57:17] [V] [TRT] Tactic: 4540505769798915372 Time: 0.030592
[03/24/2023-12:57:17] [V] [TRT] Conv_64 Set Tactic Name: ampere_h16816cudnn_256x64_sliced1x2_ldg8_relu_exp_small_nhwc_tn_v1 Tactic: 4802447371470387646
[03/24/2023-12:57:17] [V] [TRT] Tactic: 4802447371470387646 Time: 0.03264
[03/24/2023-12:57:17] [V] [TRT] Conv_64 Set Tactic Name: ampere_h16816cudnn_256x128_ldg8_relu_exp_small_nhwc_tn_v1 Tactic: 5059676457552313631
[03/24/2023-12:57:17] [V] [TRT] Tactic: 5059676457552313631 Time: 0.044928
[03/24/2023-12:57:17] [V] [TRT] Conv_64 Set Tactic Name: sm75_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x128x64_stage1_warpsize2x2x1_g1_tensor16x8x8_t1r3s3 Tactic: 5263029549013613567
[03/24/2023-12:57:17] [V] [TRT] Tactic: 5263029549013613567 Time: 0.038912
[03/24/2023-12:57:17] [V] [TRT] Conv_64 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x64x64_stage4_warpsize2x2x1_g1_tensor16x8x16 Tactic: 5368829646735632944
[03/24/2023-12:57:17] [V] [TRT] Tactic: 5368829646735632944 Time: 0.03008
[03/24/2023-12:57:17] [V] [TRT] Conv_64 Set Tactic Name: ampere_h1688cudnn_256x64_sliced1x2_ldg8_relu_exp_small_nhwc_tn_v1 Tactic: 5398999388616959893
[03/24/2023-12:57:17] [V] [TRT] Tactic: 5398999388616959893 Time: 0.035712
[03/24/2023-12:57:17] [V] [TRT] Conv_64 Set Tactic Name: sm75_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x256x32_stage1_warpsize2x4x1_g1_tensor16x8x8_t1r3s3 Tactic: 5506334059535811602
[03/24/2023-12:57:17] [V] [TRT] Tactic: 5506334059535811602 Time: 0.06912
[03/24/2023-12:57:17] [V] [TRT] Conv_64 Set Tactic Name: ampere_h16816cudnn_64x128_sliced1x2_ldg8_relu_exp_stages_64x3_large_nhwc_tn_v1 Tactic: 5746691132547383910
[03/24/2023-12:57:17] [V] [TRT] Tactic: 5746691132547383910 Time: 0.036736
[03/24/2023-12:57:17] [V] [TRT] Conv_64 Set Tactic Name: ampere_h16816cudnn_256x64_ldg8_relu_exp_large_nhwc_tn_v1 Tactic: 5770170567977052602
[03/24/2023-12:57:17] [V] [TRT] Tactic: 5770170567977052602 Time: 0.031872
[03/24/2023-12:57:17] [V] [TRT] Conv_64 Set Tactic Name: sm75_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x32x64_stage1_warpsize2x1x2_g1_tensor16x8x8_t1r3s3 Tactic: 5932046018238429951
[03/24/2023-12:57:17] [V] [TRT] Tactic: 5932046018238429951 Time: 0.022272
[03/24/2023-12:57:17] [V] [TRT] Conv_64 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x64x32_stage3_warpsize4x1x1_g1_tensor16x8x16_t1r3s3 Tactic: 5953552212833506549
[03/24/2023-12:57:17] [V] [TRT] Tactic: 5953552212833506549 Time: 0.026752
[03/24/2023-12:57:17] [V] [TRT] Conv_64 Set Tactic Name: ampere_h16816cudnn_64x128_ldg8_relu_exp_stages_64x3_small_nhwc_tn_v1 Tactic: 6034364043891107501
[03/24/2023-12:57:17] [V] [TRT] Tactic: 6034364043891107501 Time: 0.037888
[03/24/2023-12:57:17] [V] [TRT] Conv_64 Set Tactic Name: ampere_h16816cudnn_64x64_ldg8_relu_exp_stages_64x5_large_nhwc_tn_v1 Tactic: 6074229447555668232
[03/24/2023-12:57:17] [V] [TRT] Tactic: 6074229447555668232 Time: 0.033664
[03/24/2023-12:57:17] [V] [TRT] Conv_64 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x64x64_stage3_warpsize2x2x1_g1_tensor16x8x16 Tactic: 6154447660803990543
[03/24/2023-12:57:17] [V] [TRT] Tactic: 6154447660803990543 Time: 0.0256
[03/24/2023-12:57:17] [V] [TRT] Conv_64 Set Tactic Name: sm75_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x32x64_stage1_warpsize2x1x2_g1_tensor16x8x8 Tactic: 6195603576432354734
[03/24/2023-12:57:17] [V] [TRT] Tactic: 6195603576432354734 Time: 0.024448
[03/24/2023-12:57:17] [V] [TRT] Conv_64 Set Tactic Name: sm75_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x32x32_stage1_warpsize4x1x1_g1_tensor16x8x8_t1r3s3 Tactic: 6252808259936499253
[03/24/2023-12:57:17] [V] [TRT] Tactic: 6252808259936499253 Time: 0.02816
[03/24/2023-12:57:17] [V] [TRT] Conv_64 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x128x64_stage3_warpsize2x2x1_g1_tensor16x8x16 Tactic: 6325769668000961702
[03/24/2023-12:57:17] [V] [TRT] Tactic: 6325769668000961702 Time: 0.04224
[03/24/2023-12:57:17] [V] [TRT] Conv_64 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x32x64_stage5_warpsize2x2x1_g1_tensor16x8x16 Tactic: 6350273239113254096
[03/24/2023-12:57:17] [V] [TRT] Tactic: 6350273239113254096 Time: 0.026624
[03/24/2023-12:57:17] [V] [TRT] Conv_64 Set Tactic Name: ampere_h16816cudnn_128x128_ldg8_relu_exp_stages_64x3_small_nhwc_tn_v1 Tactic: 6377497238381488891
[03/24/2023-12:57:17] [V] [TRT] Tactic: 6377497238381488891 Time: 0.040448
[03/24/2023-12:57:17] [V] [TRT] Conv_64 Set Tactic Name: sm75_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x64x64_stage1_warpsize2x2x1_g1_tensor16x8x8 Tactic: 6408235920257988861
[03/24/2023-12:57:17] [V] [TRT] Tactic: 6408235920257988861 Time: 0.0288
[03/24/2023-12:57:17] [V] [TRT] Conv_64 Set Tactic Name: ampere_h16816cudnn_128x64_ldg8_relu_exp_stages_64x3_large_nhwc_tn_v1 Tactic: 6446388116965632819
[03/24/2023-12:57:17] [V] [TRT] Tactic: 6446388116965632819 Time: 0.028416
[03/24/2023-12:57:17] [V] [TRT] Conv_64 Set Tactic Name: ampere_h16816cudnn_128x64_sliced1x2_ldg8_relu_exp_stages_64x4_medium_nhwc_tn_v1 Tactic: 6468794451065529747
[03/24/2023-12:57:18] [V] [TRT] Tactic: 6468794451065529747 Time: 0.031616
[03/24/2023-12:57:18] [V] [TRT] Conv_64 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x128x64_stage3_warpsize4x2x1_g1_tensor16x8x16 Tactic: 6509152032538119080
[03/24/2023-12:57:18] [V] [TRT] Tactic: 6509152032538119080 Time: 0.046464
[03/24/2023-12:57:18] [V] [TRT] Conv_64 Set Tactic Name: ampere_h1688cudnn_256x128_ldg8_relu_exp_large_nhwc_tn_v1 Tactic: 6642277870194067185
[03/24/2023-12:57:18] [V] [TRT] Tactic: 6642277870194067185 Time: 0.054016
[03/24/2023-12:57:18] [V] [TRT] Conv_64 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x256x64_stage3_warpsize1x4x1_g1_tensor16x8x16 Tactic: 6703181542003057635
[03/24/2023-12:57:18] [V] [TRT] Tactic: 6703181542003057635 Time: 0.064768
[03/24/2023-12:57:18] [V] [TRT] Conv_64 Set Tactic Name: ampere_h16816cudnn_64x64_ldg8_relu_exp_stages_64x5_medium_nhwc_tn_v1 Tactic: 6859477213531075460
[03/24/2023-12:57:18] [V] [TRT] Tactic: 6859477213531075460 Time: 0.033024
[03/24/2023-12:57:18] [V] [TRT] Conv_64 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x128x32_stage4_warpsize2x2x1_g1_tensor16x8x16_t1r3s3 Tactic: 6972489290272968208
[03/24/2023-12:57:18] [V] [TRT] Tactic: 6972489290272968208 Time: 0.033536
[03/24/2023-12:57:18] [V] [TRT] Conv_64 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x128x32_stage3_warpsize4x2x1_g1_tensor16x8x16 Tactic: 6979044990896381511
[03/24/2023-12:57:18] [V] [TRT] Tactic: 6979044990896381511 Time: 0.044032
[03/24/2023-12:57:18] [V] [TRT] Conv_64 Set Tactic Name: ampere_h1688cudnn_256x64_ldg8_relu_exp_medium_nhwc_tn_v1 Tactic: 7216571380637776659
[03/24/2023-12:57:18] [V] [TRT] Tactic: 7216571380637776659 Time: 0.035584
[03/24/2023-12:57:18] [V] [TRT] Conv_64 Set Tactic Name: ampere_h16816cudnn_128x64_ldg8_relu_exp_stages_64x3_medium_nhwc_tn_v1 Tactic: 7609923741161019135
[03/24/2023-12:57:18] [V] [TRT] Tactic: 7609923741161019135 Time: 0.02816
[03/24/2023-12:57:18] [V] [TRT] Conv_64 Set Tactic Name: sm75_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x64x32_stage1_warpsize2x2x1_g1_tensor16x8x8 Tactic: 7612687199567064086
[03/24/2023-12:57:18] [V] [TRT] Tactic: 7612687199567064086 Time: 0.03072
[03/24/2023-12:57:18] [V] [TRT] Conv_64 Set Tactic Name: ampere_h16816cudnn_64x64_ldg8_relu_exp_stages_64x6_large_nhwc_tn_v1 Tactic: 7705739241028240201
[03/24/2023-12:57:18] [V] [TRT] Tactic: 7705739241028240201 Time: 0.038912
[03/24/2023-12:57:18] [V] [TRT] Conv_64 Set Tactic Name: sm75_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x128x32_stage1_warpsize2x2x1_g1_tensor16x8x8 Tactic: 7729555994715864793
[03/24/2023-12:57:18] [V] [TRT] Tactic: 7729555994715864793 Time: 0.040832
[03/24/2023-12:57:18] [V] [TRT] Conv_64 Set Tactic Name: sm75_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x64x64_stage1_warpsize2x2x1_g1_tensor16x8x8_t1r3s3 Tactic: 7849296535223586261
[03/24/2023-12:57:18] [V] [TRT] Tactic: 7849296535223586261 Time: 0.028416
[03/24/2023-12:57:18] [V] [TRT] Conv_64 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x256x32_stage3_warpsize2x4x1_g1_tensor16x8x16 Tactic: 8072087735545283117
[03/24/2023-12:57:18] [V] [TRT] Tactic: 8072087735545283117 Time: 0.061312
[03/24/2023-12:57:18] [V] [TRT] Conv_64 Set Tactic Name: ampere_h16816cudnn_64x64_sliced1x2_ldg8_relu_exp_stages_64x5_medium_nhwc_tn_v1 Tactic: 8101703987960976805
[03/24/2023-12:57:18] [V] [TRT] Tactic: 8101703987960976805 Time: 0.03072
[03/24/2023-12:57:18] [V] [TRT] Conv_64 Set Tactic Name: ampere_h16816cudnn_128x64_sliced1x2_ldg8_relu_exp_stages_64x4_small_nhwc_tn_v1 Tactic: 8170606396342855895
[03/24/2023-12:57:18] [V] [TRT] Tactic: 8170606396342855895 Time: 0.030592
[03/24/2023-12:57:18] [V] [TRT] Conv_64 Set Tactic Name: sm75_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x32x64_stage1_warpsize2x1x2_g1_tensor16x8x8 Tactic: 8455608235315878803
[03/24/2023-12:57:18] [V] [TRT] Tactic: 8455608235315878803 Time: 0.025344
[03/24/2023-12:57:18] [V] [TRT] Conv_64 Set Tactic Name: sm75_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x64x64_stage1_warpsize2x2x1_g1_tensor16x8x8 Tactic: 8668812313058150080
[03/24/2023-12:57:18] [V] [TRT] Tactic: 8668812313058150080 Time: 0.029696
[03/24/2023-12:57:18] [V] [TRT] Conv_64 Set Tactic Name: ampere_h1688cudnn_256x64_ldg8_relu_exp_small_nhwc_tn_v1 Tactic: 8839784824303350101
[03/24/2023-12:57:18] [V] [TRT] Tactic: 8839784824303350101 Time: 0.033664
[03/24/2023-12:57:18] [V] [TRT] Conv_64 Set Tactic Name: ampere_h16816cudnn_64x64_sliced1x2_ldg8_relu_exp_stages_64x5_large_nhwc_tn_v1 Tactic: -9217371357561775773
[03/24/2023-12:57:18] [V] [TRT] Tactic: -9217371357561775773 Time: 0.030592
[03/24/2023-12:57:18] [V] [TRT] Conv_64 Set Tactic Name: ampere_h16816cudnn_256x64_sliced1x2_ldg8_relu_exp_medium_nhwc_tn_v1 Tactic: -9009272790678027912
[03/24/2023-12:57:18] [V] [TRT] Tactic: -9009272790678027912 Time: 0.035712
[03/24/2023-12:57:18] [V] [TRT] Conv_64 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x32x32_stage4_warpsize4x1x1_g1_tensor16x8x16 Tactic: -8985224497679592364
[03/24/2023-12:57:18] [V] [TRT] Tactic: -8985224497679592364 Time: 0.02048
[03/24/2023-12:57:18] [V] [TRT] Conv_64 Set Tactic Name: ampere_h16816cudnn_128x64_sliced1x2_ldg8_relu_exp_stages_64x3_large_nhwc_tn_v1 Tactic: -8949544755481315679
[03/24/2023-12:57:18] [V] [TRT] Tactic: -8949544755481315679 Time: 0.026752
[03/24/2023-12:57:18] [V] [TRT] Conv_64 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x64x64_stage3_warpsize4x1x1_g1_tensor16x8x16_t1r3s3 Tactic: -8867999442759527766
[03/24/2023-12:57:18] [V] [TRT] Tactic: -8867999442759527766 Time: 0.03264
[03/24/2023-12:57:18] [V] [TRT] Conv_64 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x128x64_stage3_warpsize2x2x1_g1_tensor16x8x16 Tactic: -8759929675070720385
[03/24/2023-12:57:18] [V] [TRT] Tactic: -8759929675070720385 Time: 0.04096
[03/24/2023-12:57:18] [V] [TRT] Conv_64 Set Tactic Name: ampere_h16816cudnn_64x64_ldg8_relu_exp_stages_64x6_medium_nhwc_tn_v1 Tactic: -8604374562669615024
[03/24/2023-12:57:18] [V] [TRT] Tactic: -8604374562669615024 Time: 0.0384
[03/24/2023-12:57:18] [V] [TRT] Conv_64 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x128x64_stage3_warpsize4x2x1_g1_tensor16x8x16 Tactic: -8362347876645295759
[03/24/2023-12:57:18] [V] [TRT] Tactic: -8362347876645295759 Time: 0.044928
[03/24/2023-12:57:18] [V] [TRT] Conv_64 Set Tactic Name: sm75_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x128x32_stage1_warpsize4x2x1_g1_tensor16x8x8 Tactic: -8254009616492665198
[03/24/2023-12:57:18] [V] [TRT] Tactic: -8254009616492665198 Time: 0.050176
[03/24/2023-12:57:18] [V] [TRT] Conv_64 Set Tactic Name: ampere_h16816cudnn_256x128_ldg8_relu_exp_stages_64x3_large_nhwc_tn_v1 Tactic: -7757610000269494813
[03/24/2023-12:57:18] [V] [TRT] Tactic: -7757610000269494813 Time: 0.04608
[03/24/2023-12:57:18] [V] [TRT] Conv_64 Set Tactic Name: sm75_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x128x32_stage1_warpsize4x2x1_g1_tensor16x8x8 Tactic: -7615325597099025933
[03/24/2023-12:57:18] [V] [TRT] Tactic: -7615325597099025933 Time: 0.0512
[03/24/2023-12:57:18] [V] [TRT] Conv_64 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x64x64_stage3_warpsize4x1x1_g1_tensor16x8x16 Tactic: -6917689122519989488
[03/24/2023-12:57:18] [V] [TRT] Tactic: -6917689122519989488 Time: 0.031616
[03/24/2023-12:57:18] [V] [TRT] Conv_64 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x32x64_stage5_warpsize2x2x1_g1_tensor16x8x16_t1r3s3 Tactic: -6902925267326201166
[03/24/2023-12:57:18] [V] [TRT] Tactic: -6902925267326201166 Time: 0.0256
[03/24/2023-12:57:18] [V] [TRT] Conv_64 Set Tactic Name: ampere_h16816cudnn_64x128_ldg8_relu_exp_stages_64x4_large_nhwc_tn_v1 Tactic: -6840588038605932325
[03/24/2023-12:57:18] [V] [TRT] Tactic: -6840588038605932325 Time: 0.044288
[03/24/2023-12:57:18] [V] [TRT] Conv_64 Set Tactic Name: sm75_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x32x32_stage1_warpsize4x1x1_g1_tensor16x8x8 Tactic: -6828337260021572283
[03/24/2023-12:57:18] [V] [TRT] Tactic: -6828337260021572283 Time: 0.026496
[03/24/2023-12:57:18] [V] [TRT] Conv_64 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x256x32_stage3_warpsize2x4x1_g1_tensor16x8x16 Tactic: -6799856376604253964
[03/24/2023-12:57:18] [V] [TRT] Tactic: -6799856376604253964 Time: 0.061568
[03/24/2023-12:57:18] [V] [TRT] Conv_64 Set Tactic Name: sm75_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x32x32_stage1_warpsize4x1x1_g1_tensor16x8x8 Tactic: -6711815420995272523
[03/24/2023-12:57:18] [V] [TRT] Tactic: -6711815420995272523 Time: 0.030336
[03/24/2023-12:57:18] [V] [TRT] Conv_64 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x32x32_stage4_warpsize4x1x1_g1_tensor16x8x16_t1r3s3 Tactic: -6625722781282978136
[03/24/2023-12:57:18] [V] [TRT] Tactic: -6625722781282978136 Time: 0.021504
[03/24/2023-12:57:18] [V] [TRT] Conv_64 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x64x32_stage3_warpsize4x1x1_g1_tensor16x8x16 Tactic: -6525498856028268801
[03/24/2023-12:57:18] [V] [TRT] Tactic: -6525498856028268801 Time: 0.028544
[03/24/2023-12:57:18] [V] [TRT] Conv_64 Set Tactic Name: sm75_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x256x64_stage1_warpsize1x4x2_g1_tensor16x8x8 Tactic: -6489479581011009593
[03/24/2023-12:57:18] [V] [TRT] Tactic: -6489479581011009593 Time: 0.070656
[03/24/2023-12:57:18] [V] [TRT] Conv_64 Set Tactic Name: ampere_h16816cudnn_64x64_sliced1x2_ldg8_relu_exp_stages_64x6_medium_nhwc_tn_v1 Tactic: -6356316196810535311
[03/24/2023-12:57:18] [V] [TRT] Tactic: -6356316196810535311 Time: 0.039808
[03/24/2023-12:57:18] [V] [TRT] Conv_64 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x32x32_stage4_warpsize4x1x1_g1_tensor16x8x16 Tactic: -6324345858751792783
[03/24/2023-12:57:18] [V] [TRT] Tactic: -6324345858751792783 Time: 0.022528
[03/24/2023-12:57:18] [V] [TRT] Conv_64 Set Tactic Name: sm75_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x256x64_stage1_warpsize1x4x2_g1_tensor16x8x8_t1r3s3 Tactic: -6320761427625651496
[03/24/2023-12:57:18] [V] [TRT] Tactic: -6320761427625651496 Time: 0.069632
[03/24/2023-12:57:18] [V] [TRT] Conv_64 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x256x32_stage3_warpsize2x4x1_g1_tensor16x8x16_t1r3s3 Tactic: -6262400699544994312
[03/24/2023-12:57:18] [V] [TRT] Tactic: -6262400699544994312 Time: 0.060288
[03/24/2023-12:57:18] [V] [TRT] Conv_64 Set Tactic Name: ampere_h1688cudnn_128x128_ldg8_relu_exp_large_nhwc_tn_v1 Tactic: -6257787336162086472
[03/24/2023-12:57:18] [V] [TRT] Tactic: -6257787336162086472 Time: 0.052096
[03/24/2023-12:57:18] [V] [TRT] Conv_64 Set Tactic Name: sm75_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x128x64_stage1_warpsize2x2x1_g1_tensor16x8x8 Tactic: -6080892721161662420
[03/24/2023-12:57:18] [V] [TRT] Tactic: -6080892721161662420 Time: 0.040192
[03/24/2023-12:57:18] [V] [TRT] Conv_64 Set Tactic Name: ampere_h16816cudnn_128x64_ldg8_relu_exp_stages_64x4_small_nhwc_tn_v1 Tactic: -6063766379489217211
[03/24/2023-12:57:18] [V] [TRT] Tactic: -6063766379489217211 Time: 0.030592
[03/24/2023-12:57:18] [V] [TRT] Conv_64 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x128x32_stage5_warpsize2x2x1_g1_tensor16x8x16 Tactic: -5777580938094193096
[03/24/2023-12:57:18] [V] [TRT] Tactic: -5777580938094193096 Time: 0.035456
[03/24/2023-12:57:18] [V] [TRT] Conv_64 Set Tactic Name: sm75_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x128x64_stage1_warpsize2x2x1_g1_tensor16x8x8 Tactic: -5710735840878760115
[03/24/2023-12:57:18] [V] [TRT] Tactic: -5710735840878760115 Time: 0.04096
[03/24/2023-12:57:18] [V] [TRT] Conv_64 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x128x32_stage3_warpsize4x2x1_g1_tensor16x8x16 Tactic: -5657273398217409378
[03/24/2023-12:57:18] [V] [TRT] Tactic: -5657273398217409378 Time: 0.043904
[03/24/2023-12:57:18] [V] [TRT] Conv_64 Set Tactic Name: sm75_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x128x32_stage1_warpsize2x2x1_g1_tensor16x8x8_t1r3s3 Tactic: -5546257196173962281
[03/24/2023-12:57:18] [V] [TRT] Tactic: -5546257196173962281 Time: 0.03968
[03/24/2023-12:57:18] [V] [TRT] Conv_64 Set Tactic Name: ampere_h16816cudnn_128x128_ldg8_relu_exp_small_nhwc_tn_v1 Tactic: -5530886555766748586
[03/24/2023-12:57:18] [V] [TRT] Tactic: -5530886555766748586 Time: 0.034688
[03/24/2023-12:57:18] [V] [TRT] Conv_64 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x64x32_stage5_warpsize2x2x1_g1_tensor16x8x16_t1r3s3 Tactic: -5422685219138380548
[03/24/2023-12:57:18] [V] [TRT] Tactic: -5422685219138380548 Time: 0.025088
[03/24/2023-12:57:18] [V] [TRT] Conv_64 Set Tactic Name: ampere_h16816cudnn_256x64_ldg8_relu_exp_stages_64x3_small_nhwc_tn_v1 Tactic: -5261787675443473128
[03/24/2023-12:57:18] [V] [TRT] Tactic: -5261787675443473128 Time: 0.030208
[03/24/2023-12:57:18] [V] [TRT] Conv_64 Set Tactic Name: sm75_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x64x32_stage1_warpsize4x1x1_g1_tensor16x8x8 Tactic: -5198219374380660379
[03/24/2023-12:57:18] [V] [TRT] Tactic: -5198219374380660379 Time: 0.033024
[03/24/2023-12:57:18] [V] [TRT] Conv_64 Set Tactic Name: ampere_h16816cudnn_64x128_sliced1x2_ldg8_relu_exp_stages_64x3_medium_nhwc_tn_v1 Tactic: -5161596964442251102
[03/24/2023-12:57:18] [V] [TRT] Tactic: -5161596964442251102 Time: 0.035968
[03/24/2023-12:57:18] [V] [TRT] Conv_64 Set Tactic Name: ampere_h16816cudnn_64x128_ldg8_relu_exp_stages_64x3_medium_nhwc_tn_v1 Tactic: -5127240325355316006
[03/24/2023-12:57:18] [V] [TRT] Tactic: -5127240325355316006 Time: 0.037888
[03/24/2023-12:57:18] [V] [TRT] Conv_64 Set Tactic Name: ampere_h16816cudnn_256x128_ldg8_relu_exp_stages_64x3_medium_nhwc_tn_v1 Tactic: -5109582882231362997
[03/24/2023-12:57:18] [V] [TRT] Tactic: -5109582882231362997 Time: 0.045824
[03/24/2023-12:57:18] [V] [TRT] Conv_64 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x64x32_stage5_warpsize2x2x1_g1_tensor16x8x16 Tactic: -4825567853927730435
[03/24/2023-12:57:18] [V] [TRT] Tactic: -4825567853927730435 Time: 0.029696
[03/24/2023-12:57:18] [V] [TRT] Conv_64 Set Tactic Name: ampere_h16816cudnn_64x128_sliced1x2_ldg8_relu_exp_stages_64x4_small_nhwc_tn_v1 Tactic: -4796511246675321840
[03/24/2023-12:57:18] [V] [TRT] Tactic: -4796511246675321840 Time: 0.046592
[03/24/2023-12:57:18] [V] [TRT] Conv_64 Set Tactic Name: ampere_h16816cudnn_64x64_sliced1x2_ldg8_relu_exp_stages_64x6_large_nhwc_tn_v1 Tactic: -4706569565442112734
[03/24/2023-12:57:18] [V] [TRT] Tactic: -4706569565442112734 Time: 0.04032
[03/24/2023-12:57:18] [V] [TRT] Conv_64 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x128x64_stage3_warpsize2x2x1_g1_tensor16x8x16_t1r3s3 Tactic: -4566599693570369588
[03/24/2023-12:57:18] [V] [TRT] Tactic: -4566599693570369588 Time: 0.041216
[03/24/2023-12:57:18] [V] [TRT] Conv_64 Set Tactic Name: ampere_h16816cudnn_128x128_ldg8_relu_exp_stages_64x3_large_nhwc_tn_v1 Tactic: -4409144516525410768
[03/24/2023-12:57:18] [V] [TRT] Tactic: -4409144516525410768 Time: 0.040832
[03/24/2023-12:57:18] [V] [TRT] Conv_64 Set Tactic Name: ampere_h16816cudnn_128x64_ldg8_relu_exp_stages_64x3_small_nhwc_tn_v1 Tactic: -4379519430184503304
[03/24/2023-12:57:18] [V] [TRT] Tactic: -4379519430184503304 Time: 0.028416
[03/24/2023-12:57:18] [V] [TRT] Conv_64 Set Tactic Name: ampere_h1688cudnn_256x128_ldg8_relu_exp_small_nhwc_tn_v1 Tactic: -4152066959007262150
[03/24/2023-12:57:18] [V] [TRT] Tactic: -4152066959007262150 Time: 0.050176
[03/24/2023-12:57:18] [V] [TRT] Conv_64 Set Tactic Name: ampere_h16816cudnn_64x128_ldg8_relu_exp_stages_64x4_medium_nhwc_tn_v1 Tactic: -4021926646879732549
[03/24/2023-12:57:18] [V] [TRT] Tactic: -4021926646879732549 Time: 0.044032
[03/24/2023-12:57:18] [V] [TRT] Conv_64 Set Tactic Name: ampere_h16816cudnn_64x128_sliced1x2_ldg8_relu_exp_stages_64x4_medium_nhwc_tn_v1 Tactic: -3987638434926559037
[03/24/2023-12:57:18] [V] [TRT] Tactic: -3987638434926559037 Time: 0.046976
[03/24/2023-12:57:18] [V] [TRT] Conv_64 Set Tactic Name: ampere_h1688cudnn_256x64_sliced1x2_ldg8_relu_exp_medium_nhwc_tn_v1 Tactic: -3905653247016903130
[03/24/2023-12:57:18] [V] [TRT] Tactic: -3905653247016903130 Time: 0.038144
[03/24/2023-12:57:18] [V] [TRT] Conv_64 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x64x32_stage5_warpsize2x2x1_g1_tensor16x8x16 Tactic: -3903974568488493144
[03/24/2023-12:57:18] [V] [TRT] Tactic: -3903974568488493144 Time: 0.029312
[03/24/2023-12:57:18] [V] [TRT] Conv_64 Set Tactic Name: ampere_h16816cudnn_64x128_ldg8_relu_exp_stages_64x3_large_nhwc_tn_v1 Tactic: -3895429239811098010
[03/24/2023-12:57:18] [V] [TRT] Tactic: -3895429239811098010 Time: 0.038016
[03/24/2023-12:57:18] [V] [TRT] Conv_64 Set Tactic Name: ampere_h16816cudnn_256x64_ldg8_relu_exp_small_nhwc_tn_v1 Tactic: -3864869056275745423
[03/24/2023-12:57:18] [V] [TRT] Tactic: -3864869056275745423 Time: 0.030592
[03/24/2023-12:57:18] [V] [TRT] Conv_64 Set Tactic Name: sm75_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x32x32_stage1_warpsize4x1x1_g1_tensor16x8x8_t1r3s3 Tactic: -3784342055748695733
[03/24/2023-12:57:18] [V] [TRT] Tactic: -3784342055748695733 Time: 0.024704
[03/24/2023-12:57:18] [V] [TRT] Conv_64 Set Tactic Name: ampere_h16816cudnn_64x64_ldg8_relu_exp_stages_64x5_small_nhwc_tn_v1 Tactic: -3601464762214218301
[03/24/2023-12:57:18] [V] [TRT] Tactic: -3601464762214218301 Time: 0.03264
[03/24/2023-12:57:18] [V] [TRT] Conv_64 Set Tactic Name: sm75_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x64x32_stage1_warpsize2x2x1_g1_tensor16x8x8 Tactic: -3425274793298557239
[03/24/2023-12:57:18] [V] [TRT] Tactic: -3425274793298557239 Time: 0.030336
[03/24/2023-12:57:18] [V] [TRT] Conv_64 Set Tactic Name: ampere_h1688cudnn_256x64_sliced1x2_ldg8_relu_exp_large_nhwc_tn_v1 Tactic: -3412636942650049698
[03/24/2023-12:57:18] [V] [TRT] Tactic: -3412636942650049698 Time: 0.038784
[03/24/2023-12:57:18] [V] [TRT] Conv_64 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x64x32_stage3_warpsize4x1x1_g1_tensor16x8x16 Tactic: -3338665856053412950
[03/24/2023-12:57:18] [V] [TRT] Tactic: -3338665856053412950 Time: 0.027008
[03/24/2023-12:57:18] [V] [TRT] Conv_64 Set Tactic Name: sm75_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x128x32_stage1_warpsize2x2x1_g1_tensor16x8x8 Tactic: -3271955096576257018
[03/24/2023-12:57:18] [V] [TRT] Tactic: -3271955096576257018 Time: 0.039808
[03/24/2023-12:57:18] [V] [TRT] Conv_64 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x128x64_stage3_warpsize4x2x1_g1_tensor16x8x16_t1r3s3 Tactic: -3243541398692466074
[03/24/2023-12:57:18] [V] [TRT] Tactic: -3243541398692466074 Time: 0.045952
[03/24/2023-12:57:18] [V] [TRT] Conv_64 Set Tactic Name: ampere_h16816cudnn_64x128_sliced1x2_ldg8_relu_exp_stages_64x3_small_nhwc_tn_v1 Tactic: -3058330359340425555
[03/24/2023-12:57:18] [V] [TRT] Tactic: -3058330359340425555 Time: 0.036096
[03/24/2023-12:57:18] [V] [TRT] Conv_64 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x256x64_stage3_warpsize1x4x1_g1_tensor16x8x16_t1r3s3 Tactic: -2899647483672319239
[03/24/2023-12:57:18] [V] [TRT] Tactic: -2899647483672319239 Time: 0.06336
[03/24/2023-12:57:18] [V] [TRT] Conv_64 Set Tactic Name: ampere_h16816cudnn_256x64_sliced1x2_ldg8_relu_exp_large_nhwc_tn_v1 Tactic: -2816084650627734155
[03/24/2023-12:57:18] [V] [TRT] Tactic: -2816084650627734155 Time: 0.036096
[03/24/2023-12:57:18] [V] [TRT] Conv_64 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x128x32_stage5_warpsize2x2x1_g1_tensor16x8x16 Tactic: -2662892962457732243
[03/24/2023-12:57:18] [V] [TRT] Tactic: -2662892962457732243 Time: 0.03456
[03/24/2023-12:57:18] [V] [TRT] Conv_64 Set Tactic Name: ampere_h16816cudnn_256x128_ldg8_relu_exp_large_nhwc_tn_v1 Tactic: -2559894581585337900
[03/24/2023-12:57:18] [V] [TRT] Tactic: -2559894581585337900 Time: 0.045184
[03/24/2023-12:57:18] [V] [TRT] Conv_64 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x32x32_stage4_warpsize4x1x1_g1_tensor16x8x16 Tactic: -2530740716768816092
[03/24/2023-12:57:18] [V] [TRT] Tactic: -2530740716768816092 Time: 0.023296
[03/24/2023-12:57:18] [V] [TRT] Conv_64 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x128x32_stage4_warpsize2x2x1_g1_tensor16x8x16 Tactic: -2332828394978346992
[03/24/2023-12:57:18] [V] [TRT] Tactic: -2332828394978346992 Time: 0.034816
[03/24/2023-12:57:18] [V] [TRT] Conv_64 Set Tactic Name: ampere_h1688cudnn_256x64_ldg8_relu_exp_large_nhwc_tn_v1 Tactic: -2241736083352441442
[03/24/2023-12:57:18] [V] [TRT] Tactic: -2241736083352441442 Time: 0.034816
[03/24/2023-12:57:18] [V] [TRT] Conv_64 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x32x64_stage5_warpsize2x2x1_g1_tensor16x8x16 Tactic: -2161909437867201546
[03/24/2023-12:57:18] [V] [TRT] Tactic: -2161909437867201546 Time: 0.026368
[03/24/2023-12:57:18] [V] [TRT] Conv_64 Set Tactic Name: ampere_h16816cudnn_256x64_ldg8_relu_exp_medium_nhwc_tn_v1 Tactic: -1985778916402815946
[03/24/2023-12:57:18] [V] [TRT] Tactic: -1985778916402815946 Time: 0.03072
[03/24/2023-12:57:18] [V] [TRT] Conv_64 Set Tactic Name: sm75_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x256x32_stage1_warpsize2x4x1_g1_tensor16x8x8 Tactic: -1708101578041178688
[03/24/2023-12:57:18] [V] [TRT] Tactic: -1708101578041178688 Time: 0.070528
[03/24/2023-12:57:18] [V] [TRT] Conv_64 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x64x64_stage3_warpsize4x1x1_g1_tensor16x8x16 Tactic: -1502788097503482299
[03/24/2023-12:57:18] [V] [TRT] Tactic: -1502788097503482299 Time: 0.03264
[03/24/2023-12:57:18] [V] [TRT] Conv_64 Set Tactic Name: ampere_h16816cudnn_128x64_sliced1x2_ldg8_relu_exp_stages_64x4_large_nhwc_tn_v1 Tactic: -1500496213132463076
[03/24/2023-12:57:18] [V] [TRT] Tactic: -1500496213132463076 Time: 0.032768
[03/24/2023-12:57:18] [V] [TRT] Conv_64 Set Tactic Name: ampere_h16816cudnn_64x64_ldg8_relu_exp_stages_64x6_small_nhwc_tn_v1 Tactic: -1099247066487349374
[03/24/2023-12:57:18] [V] [TRT] Tactic: -1099247066487349374 Time: 0.03648
[03/24/2023-12:57:18] [V] [TRT] Conv_64 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x64x64_stage4_warpsize2x2x1_g1_tensor16x8x16 Tactic: -910286698936744682
[03/24/2023-12:57:18] [V] [TRT] Tactic: -910286698936744682 Time: 0.029952
[03/24/2023-12:57:18] [V] [TRT] Conv_64 Set Tactic Name: sm75_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x256x32_stage1_warpsize2x4x1_g1_tensor16x8x8 Tactic: -907287437357565279
[03/24/2023-12:57:18] [V] [TRT] Tactic: -907287437357565279 Time: 0.069632
[03/24/2023-12:57:18] [V] [TRT] Conv_64 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x32x32_stage4_warpsize4x1x1_g1_tensor16x8x16 Tactic: -606726295133751039
[03/24/2023-12:57:18] [V] [TRT] Tactic: -606726295133751039 Time: 0.030592
[03/24/2023-12:57:18] [V] [TRT] Fastest Tactic: 4503233883285355107 Time: 0.02048
[03/24/2023-12:57:18] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: 4503233883285355107
[03/24/2023-12:57:18] [V] [TRT] *************** Autotuning format combination: Half(1036800,1:16,5760,32) -> Half(32400,1:16,180,1) ***************
[03/24/2023-12:57:18] [V] [TRT] --------------- Timing Runner: Conv_64 (CudnnConvolution)
[03/24/2023-12:57:18] [V] [TRT] CudnnConvolution has no valid tactics for this config, skipping
[03/24/2023-12:57:18] [V] [TRT] --------------- Timing Runner: Conv_64 (CaskConvolution)
[03/24/2023-12:57:18] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[03/24/2023-12:57:18] [V] [TRT] =============== Computing costs for 
[03/24/2023-12:57:18] [V] [TRT] *************** Autotuning format combination: Float(16588800,32400,180,1) -> Float(32400,32400,180,1) ***************
[03/24/2023-12:57:18] [V] [TRT] --------------- Timing Runner: Conv_67 (CudaDepthwiseConvolution)
[03/24/2023-12:57:18] [V] [TRT] CudaDepthwiseConvolution has no valid tactics for this config, skipping
[03/24/2023-12:57:18] [V] [TRT] --------------- Timing Runner: Conv_67 (FusedConvActConvolution)
[03/24/2023-12:57:18] [V] [TRT] Tactic: 524287 Time: 0.164224
[03/24/2023-12:57:18] [V] [TRT] Tactic: 1048575 Time: 0.1504
[03/24/2023-12:57:18] [V] [TRT] Tactic: 1703935 Time: 0.143616
[03/24/2023-12:57:18] [V] [TRT] Tactic: 2228223 Time: 0.169472
[03/24/2023-12:57:18] [V] [TRT] Tactic: 2424831 Time: 0.172416
[03/24/2023-12:57:18] [V] [TRT] Tactic: 2621439 Time: 0.144128
[03/24/2023-12:57:18] [V] [TRT] Tactic: 3014655 Time: 0.14912
[03/24/2023-12:57:18] [V] [TRT] Tactic: 3604479 Time: 0.147456
[03/24/2023-12:57:18] [V] [TRT] Tactic: 5046271 Time: 0.155136
[03/24/2023-12:57:18] [V] [TRT] Tactic: 6160383 Time: 0.157696
[03/24/2023-12:57:18] [V] [TRT] Tactic: 6488063 Time: 0.174592
[03/24/2023-12:57:18] [V] [TRT] Tactic: 7864319 Time: 0.154368
[03/24/2023-12:57:18] [V] [TRT] Tactic: 8585215 Time: 0.198144
[03/24/2023-12:57:18] [V] [TRT] Tactic: 8847359 Time: 0.153216
[03/24/2023-12:57:18] [V] [TRT] Tactic: 9043967 Time: 0.1536
[03/24/2023-12:57:19] [V] [TRT] Tactic: 9175039 Time: 0.150528
[03/24/2023-12:57:19] [V] [TRT] Tactic: 9961471 Time: 0.163968
[03/24/2023-12:57:19] [V] [TRT] Tactic: 10027007 Time: 0.159744
[03/24/2023-12:57:19] [V] [TRT] Tactic: 10485759 Time: 0.142336
[03/24/2023-12:57:19] [V] [TRT] Tactic: 10682367 Time: 0.14656
[03/24/2023-12:57:19] [V] [TRT] Fastest Tactic: 10485759 Time: 0.142336
[03/24/2023-12:57:19] [V] [TRT] --------------- Timing Runner: Conv_67 (CudnnConvolution)
[03/24/2023-12:57:19] [V] [TRT] Tactic: 0 Time: 0.243584
[03/24/2023-12:57:19] [V] [TRT] Tactic: 1 Time: 0.128384
[03/24/2023-12:57:19] [V] [TRT] Tactic: 2 Time: 0.32768
[03/24/2023-12:57:19] [V] [TRT] Tactic: 4 Time: 0.355712
[03/24/2023-12:57:19] [V] [TRT] Tactic: 5 Time: 0.683392
[03/24/2023-12:57:19] [V] [TRT] Tactic: 6 Time: 0.098304
[03/24/2023-12:57:19] [V] [TRT] Tactic: 56 Time: 0.234368
[03/24/2023-12:57:19] [V] [TRT] Tactic: 57 Time: 0.123008
[03/24/2023-12:57:19] [V] [TRT] Tactic: 58 Time: 0.315264
[03/24/2023-12:57:19] [V] [TRT] Tactic: 60 Time: 0.34432
[03/24/2023-12:57:19] [V] [TRT] Tactic: 61 Time: 0.663552
[03/24/2023-12:57:19] [V] [TRT] Tactic: 62 Time: 0.09728
[03/24/2023-12:57:19] [V] [TRT] Tactic: 112 Time: 0.234496
[03/24/2023-12:57:19] [V] [TRT] Tactic: 113 Time: 0.313472
[03/24/2023-12:57:19] [V] [TRT] Tactic: 114 Time: 0.315264
[03/24/2023-12:57:19] [V] [TRT] Tactic: 116 Time: 0.34496
[03/24/2023-12:57:19] [V] [TRT] Tactic: 117 Time: 0.668672
[03/24/2023-12:57:19] [V] [TRT] Tactic: 118 Time: 0.097408
[03/24/2023-12:57:19] [V] [TRT] Fastest Tactic: 62 Time: 0.09728
[03/24/2023-12:57:19] [V] [TRT] --------------- Timing Runner: Conv_67 (CaskConvolution)
[03/24/2023-12:57:19] [V] [TRT] Conv_67 Set Tactic Name: ampere_scudnn_128x64_relu_small_nn_v1 Tactic: 4549827808004681195
[03/24/2023-12:57:19] [V] [TRT] Tactic: 4549827808004681195 Time: 0.300288
[03/24/2023-12:57:19] [V] [TRT] Conv_67 Set Tactic Name: ampere_scudnn_128x128_relu_small_nn_v1 Tactic: 5779835512569528575
[03/24/2023-12:57:19] [V] [TRT] Tactic: 5779835512569528575 Time: 0.551808
[03/24/2023-12:57:19] [V] [TRT] Conv_67 Set Tactic Name: ampere_scudnn_128x128_relu_xregs_large_nn_v1 Tactic: 6053873026024413720
[03/24/2023-12:57:19] [V] [TRT] Tactic: 6053873026024413720 Time: 0.583296
[03/24/2023-12:57:19] [V] [TRT] Conv_67 Set Tactic Name: ampere_scudnn_128x64_relu_xregs_large_nn_v1 Tactic: 6767548733843469815
[03/24/2023-12:57:19] [V] [TRT] Tactic: 6767548733843469815 Time: 0.30272
[03/24/2023-12:57:19] [V] [TRT] Conv_67 Set Tactic Name: ampere_scudnn_128x32_relu_small_nn_v1 Tactic: -6313876406580483184
[03/24/2023-12:57:19] [V] [TRT] Tactic: -6313876406580483184 Time: 0.225152
[03/24/2023-12:57:19] [V] [TRT] Conv_67 Set Tactic Name: ampere_scudnn_128x128_relu_medium_nn_v1 Tactic: -1123676555321336786
[03/24/2023-12:57:19] [V] [TRT] Tactic: -1123676555321336786 Time: 0.431232
[03/24/2023-12:57:19] [V] [TRT] Conv_67 Set Tactic Name: ampere_scudnn_128x64_relu_medium_nn_v1 Tactic: -701551393537224327
[03/24/2023-12:57:19] [V] [TRT] Tactic: -701551393537224327 Time: 0.24
[03/24/2023-12:57:19] [V] [TRT] Fastest Tactic: -6313876406580483184 Time: 0.225152
[03/24/2023-12:57:19] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CudnnConvolution Tactic: 62
[03/24/2023-12:57:19] [V] [TRT] *************** Autotuning format combination: Float(16588800,1,92160,512) -> Float(32400,1,180,1) ***************
[03/24/2023-12:57:19] [V] [TRT] --------------- Timing Runner: Conv_67 (CudnnConvolution)
[03/24/2023-12:57:19] [V] [TRT] CudnnConvolution has no valid tactics for this config, skipping
[03/24/2023-12:57:19] [V] [TRT] --------------- Timing Runner: Conv_67 (CaskConvolution)
[03/24/2023-12:57:19] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[03/24/2023-12:57:19] [V] [TRT] *************** Autotuning format combination: Float(4147200,1:4,23040,128) -> Float(32400,1:4,180,1) ***************
[03/24/2023-12:57:19] [V] [TRT] --------------- Timing Runner: Conv_67 (CudnnConvolution)
[03/24/2023-12:57:19] [V] [TRT] CudnnConvolution has no valid tactics for this config, skipping
[03/24/2023-12:57:19] [V] [TRT] --------------- Timing Runner: Conv_67 (CaskConvolution)
[03/24/2023-12:57:19] [V] [TRT] Conv_67 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize64x128x32_stage5_warpsize2x2x1_g1_tensor16x8x8 Tactic: 1237784342446422381
[03/24/2023-12:57:19] [V] [TRT] Tactic: 1237784342446422381 Time: 0.103424
[03/24/2023-12:57:19] [V] [TRT] Conv_67 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x64x32_stage5_warpsize2x2x1_g1_tensor16x8x8 Tactic: 1426562292875733922
[03/24/2023-12:57:19] [V] [TRT] Tactic: 1426562292875733922 Time: 0.068992
[03/24/2023-12:57:19] [V] [TRT] Conv_67 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize64x128x8_stage3_warpsize1x4x1_g1_ffma_t1r3s3 Tactic: 2086609538387166260
[03/24/2023-12:57:19] [V] [TRT] Tactic: 2086609538387166260 Time: 0.359552
[03/24/2023-12:57:19] [V] [TRT] Conv_67 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize256x128x32_stage3_warpsize4x2x1_g1_tensor16x8x8_t1r3s3 Tactic: 2388153022056233219
[03/24/2023-12:57:19] [V] [TRT] Tactic: 2388153022056233219 Time: 0.10176
[03/24/2023-12:57:19] [V] [TRT] Conv_67 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x128x32_stage4_warpsize2x2x1_g1_tensor16x8x8 Tactic: 2716437853123234317
[03/24/2023-12:57:19] [V] [TRT] Tactic: 2716437853123234317 Time: 0.091264
[03/24/2023-12:57:19] [V] [TRT] Conv_67 Set Tactic Name: ampere_scudnn_128x64_sliced1x2_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: 2860655430572478466
[03/24/2023-12:57:19] [V] [TRT] Tactic: 2860655430572478466 Time: 0.226304
[03/24/2023-12:57:19] [V] [TRT] Conv_67 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize64x128x8_stage3_warpsize1x4x1_g1_ffma Tactic: 3239733199291090177
[03/24/2023-12:57:19] [V] [TRT] Tactic: 3239733199291090177 Time: 0.358912
[03/24/2023-12:57:19] [V] [TRT] Conv_67 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize64x64x64_stage4_warpsize2x2x1_g1_tensor16x8x8_t1r3s3 Tactic: 3278852197192504305
[03/24/2023-12:57:19] [V] [TRT] Tactic: 3278852197192504305 Time: 0.068096
[03/24/2023-12:57:19] [V] [TRT] Conv_67 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize256x128x32_stage3_warpsize4x2x1_g1_tensor16x8x8 Tactic: 3904690393614050557
[03/24/2023-12:57:19] [V] [TRT] Tactic: 3904690393614050557 Time: 0.125696
[03/24/2023-12:57:19] [V] [TRT] Conv_67 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize64x64x64_stage4_warpsize2x2x1_g1_tensor16x8x8 Tactic: 4061115162338989075
[03/24/2023-12:57:19] [V] [TRT] Tactic: 4061115162338989075 Time: 0.074752
[03/24/2023-12:57:19] [V] [TRT] Conv_67 Set Tactic Name: ampere_scudnn_128x32_sliced1x4_ldg4_relu_exp_medium_nhwc_tn_v1 Tactic: 4474630279712975759
[03/24/2023-12:57:19] [V] [TRT] Tactic: 4474630279712975759 Time: 0.122624
[03/24/2023-12:57:19] [V] [TRT] Conv_67 Set Tactic Name: ampere_scudnn_128x32_sliced1x4_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: 4479823862704990365
[03/24/2023-12:57:19] [V] [TRT] Tactic: 4479823862704990365 Time: 0.121856
[03/24/2023-12:57:19] [V] [TRT] Conv_67 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize64x256x8_stage3_warpsize1x4x1_g1_ffma Tactic: 4517590677127196184
[03/24/2023-12:57:19] [V] [TRT] Tactic: 4517590677127196184 Time: 0.853632
[03/24/2023-12:57:19] [V] [TRT] Conv_67 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize128x128x8_stage3_warpsize2x4x1_g1_ffma_t1r3s3 Tactic: 4634080872644479428
[03/24/2023-12:57:19] [V] [TRT] Tactic: 4634080872644479428 Time: 0.434304
[03/24/2023-12:57:19] [V] [TRT] Conv_67 Set Tactic Name: ampere_scudnn_128x64_sliced1x2_ldg4_relu_exp_medium_nhwc_tn_v1 Tactic: 4696204239951173149
[03/24/2023-12:57:19] [V] [TRT] Tactic: 4696204239951173149 Time: 0.226688
[03/24/2023-12:57:19] [V] [TRT] Conv_67 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x256x32_stage3_warpsize2x4x1_g1_tensor16x8x8 Tactic: 5200329514761435342
[03/24/2023-12:57:19] [V] [TRT] Tactic: 5200329514761435342 Time: 0.141568
[03/24/2023-12:57:19] [V] [TRT] Conv_67 Set Tactic Name: ampere_scudnn_128x128_relu_exp_small_nhwc_tn_v1 Tactic: 5778138195697110003
[03/24/2023-12:57:19] [V] [TRT] Tactic: 5778138195697110003 Time: 0.427392
[03/24/2023-12:57:19] [V] [TRT] Conv_67 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize256x128x8_stage3_warpsize2x4x1_g1_ffma Tactic: 6310198979346901507
[03/24/2023-12:57:19] [V] [TRT] Tactic: 6310198979346901507 Time: 0.585856
[03/24/2023-12:57:19] [V] [TRT] Conv_67 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x256x32_stage3_warpsize2x4x1_g1_tensor16x8x8_t1r3s3 Tactic: 7011693366046809027
[03/24/2023-12:57:19] [V] [TRT] Tactic: 7011693366046809027 Time: 0.133632
[03/24/2023-12:57:19] [V] [TRT] Conv_67 Set Tactic Name: ampere_scudnn_128x128_ldg4_relu_exp_large_nhwc_tn_v1 Tactic: 7155825427510256858
[03/24/2023-12:57:19] [V] [TRT] Tactic: 7155825427510256858 Time: 0.412544
[03/24/2023-12:57:19] [V] [TRT] Conv_67 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize128x64x8_stage3_warpsize1x4x1_g1_ffma Tactic: 7222247112373541608
[03/24/2023-12:57:19] [V] [TRT] Tactic: 7222247112373541608 Time: 0.29248
[03/24/2023-12:57:19] [V] [TRT] Conv_67 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x128x16_stage4_warpsize2x2x1_g1_tensor16x8x8 Tactic: 7342025736444949634
[03/24/2023-12:57:19] [V] [TRT] Tactic: 7342025736444949634 Time: 0.091008
[03/24/2023-12:57:19] [V] [TRT] Conv_67 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize64x128x32_stage5_warpsize2x2x1_g1_tensor16x8x8 Tactic: 7347365539922924600
[03/24/2023-12:57:19] [V] [TRT] Tactic: 7347365539922924600 Time: 0.096256
[03/24/2023-12:57:19] [V] [TRT] Conv_67 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x64x32_stage5_warpsize2x2x1_g1_tensor16x8x8 Tactic: 7428197830878119671
[03/24/2023-12:57:19] [V] [TRT] Tactic: 7428197830878119671 Time: 0.062464
[03/24/2023-12:57:19] [V] [TRT] Conv_67 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize64x32x64_stage5_warpsize2x2x1_g1_tensor16x8x8_t1r3s3 Tactic: 7465323447915168822
[03/24/2023-12:57:19] [V] [TRT] Tactic: 7465323447915168822 Time: 0.053504
[03/24/2023-12:57:19] [V] [TRT] Conv_67 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize128x128x8_stage3_warpsize2x4x1_g1_ffma Tactic: 7472640475524677095
[03/24/2023-12:57:19] [V] [TRT] Tactic: 7472640475524677095 Time: 0.426112
[03/24/2023-12:57:19] [V] [TRT] Conv_67 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize64x32x64_stage5_warpsize2x2x1_g1_tensor16x8x8 Tactic: 7938223790021272801
[03/24/2023-12:57:19] [V] [TRT] Tactic: 7938223790021272801 Time: 0.057472
[03/24/2023-12:57:19] [V] [TRT] Conv_67 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize128x256x8_stage3_warpsize2x4x1_g1_ffma Tactic: 8498373915030836990
[03/24/2023-12:57:19] [V] [TRT] Tactic: 8498373915030836990 Time: 0.832512
[03/24/2023-12:57:19] [V] [TRT] Conv_67 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x64x32_stage5_warpsize2x2x1_g1_tensor16x8x8_t1r3s3 Tactic: 8836645772682419994
[03/24/2023-12:57:19] [V] [TRT] Tactic: 8836645772682419994 Time: 0.059648
[03/24/2023-12:57:19] [V] [TRT] Conv_67 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize256x64x8_stage3_warpsize1x4x1_g1_ffma Tactic: 8869697132622550639
[03/24/2023-12:57:19] [V] [TRT] Tactic: 8869697132622550639 Time: 0.32576
[03/24/2023-12:57:19] [V] [TRT] Conv_67 Set Tactic Name: ampere_scudnn_128x128_ldg4_relu_exp_medium_nhwc_tn_v1 Tactic: 8918020581761223752
[03/24/2023-12:57:19] [V] [TRT] Tactic: 8918020581761223752 Time: 0.410624
[03/24/2023-12:57:19] [V] [TRT] Conv_67 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize64x64x64_stage4_warpsize2x2x1_g1_tensor16x8x8 Tactic: -9114138070928278731
[03/24/2023-12:57:19] [V] [TRT] Tactic: -9114138070928278731 Time: 0.07168
[03/24/2023-12:57:19] [V] [TRT] Conv_67 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize256x128x8_stage3_warpsize2x4x1_g1_ffma_t1r3s3 Tactic: -8937725997228636978
[03/24/2023-12:57:19] [V] [TRT] Tactic: -8937725997228636978 Time: 0.552832
[03/24/2023-12:57:19] [V] [TRT] Conv_67 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize128x256x8_stage3_warpsize2x4x1_g1_ffma_t1r3s3 Tactic: -8833858409138163072
[03/24/2023-12:57:19] [V] [TRT] Tactic: -8833858409138163072 Time: 0.815232
[03/24/2023-12:57:19] [V] [TRT] Conv_67 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize64x64x8_stage3_warpsize1x4x1_g1_ffma_t1r3s3 Tactic: -7989138351613022500
[03/24/2023-12:57:19] [V] [TRT] Tactic: -7989138351613022500 Time: 0.181376
[03/24/2023-12:57:19] [V] [TRT] Conv_67 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize256x128x8_stage3_warpsize2x4x1_g1_ffma Tactic: -7872883691240863058
[03/24/2023-12:57:19] [V] [TRT] Tactic: -7872883691240863058 Time: 0.572416
[03/24/2023-12:57:19] [V] [TRT] Conv_67 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x256x32_stage3_warpsize2x4x1_g1_tensor16x8x8 Tactic: -7382359095196034537
[03/24/2023-12:57:19] [V] [TRT] Tactic: -7382359095196034537 Time: 0.138752
[03/24/2023-12:57:19] [V] [TRT] Conv_67 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x128x16_stage4_warpsize2x2x1_g1_tensor16x8x8_t1r3s3 Tactic: -7377458734869418330
[03/24/2023-12:57:19] [V] [TRT] Tactic: -7377458734869418330 Time: 0.068736
[03/24/2023-12:57:19] [V] [TRT] Conv_67 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize128x128x8_stage3_warpsize2x4x1_g1_ffma Tactic: -6729618519651721910
[03/24/2023-12:57:19] [V] [TRT] Tactic: -6729618519651721910 Time: 0.349056
[03/24/2023-12:57:19] [V] [TRT] Conv_67 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize256x64x32_stage3_warpsize4x2x1_g1_tensor16x8x8_t1r3s3 Tactic: -6223854811627385844
[03/24/2023-12:57:19] [V] [TRT] Tactic: -6223854811627385844 Time: 0.05184
[03/24/2023-12:57:19] [V] [TRT] Conv_67 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize256x64x8_stage3_warpsize1x4x1_g1_ffma Tactic: -5893833996418445881
[03/24/2023-12:57:19] [V] [TRT] Tactic: -5893833996418445881 Time: 0.26176
[03/24/2023-12:57:19] [V] [TRT] Conv_67 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize128x256x8_stage3_warpsize2x4x1_g1_ffma Tactic: -5701562095007058349
[03/24/2023-12:57:19] [V] [TRT] Tactic: -5701562095007058349 Time: 0.679552
[03/24/2023-12:57:19] [V] [TRT] Conv_67 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize128x64x8_stage3_warpsize1x4x1_g1_ffma Tactic: -5685503422376017600
[03/24/2023-12:57:19] [V] [TRT] Tactic: -5685503422376017600 Time: 0.235392
[03/24/2023-12:57:19] [V] [TRT] Conv_67 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize64x64x8_stage3_warpsize1x4x1_g1_ffma Tactic: -5521125187060117489
[03/24/2023-12:57:19] [V] [TRT] Tactic: -5521125187060117489 Time: 0.163712
[03/24/2023-12:57:19] [V] [TRT] Conv_67 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x128x16_stage4_warpsize2x2x1_g1_tensor16x8x8 Tactic: -5457304872213719461
[03/24/2023-12:57:19] [V] [TRT] Tactic: -5457304872213719461 Time: 0.070656
[03/24/2023-12:57:19] [V] [TRT] Conv_67 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x64x64_stage3_warpsize2x2x1_g1_tensor16x8x8 Tactic: -5441054706931585554
[03/24/2023-12:57:19] [V] [TRT] Tactic: -5441054706931585554 Time: 0.05312
[03/24/2023-12:57:19] [V] [TRT] Conv_67 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize256x64x32_stage3_warpsize4x2x1_g1_tensor16x8x8 Tactic: -5043603702497465467
[03/24/2023-12:57:19] [V] [TRT] Tactic: -5043603702497465467 Time: 0.060032
[03/24/2023-12:57:19] [V] [TRT] Conv_67 Set Tactic Name: ampere_scudnn_128x64_sliced1x2_ldg4_relu_exp_large_nhwc_tn_v1 Tactic: -4756382386362004279
[03/24/2023-12:57:19] [V] [TRT] Tactic: -4756382386362004279 Time: 0.178304
[03/24/2023-12:57:19] [V] [TRT] Conv_67 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize64x64x8_stage3_warpsize1x4x1_g1_ffma Tactic: -4615000974950361663
[03/24/2023-12:57:19] [V] [TRT] Tactic: -4615000974950361663 Time: 0.156672
[03/24/2023-12:57:19] [V] [TRT] Conv_67 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x64x64_stage3_warpsize2x2x1_g1_tensor16x8x8 Tactic: -4564655677311401797
[03/24/2023-12:57:19] [V] [TRT] Tactic: -4564655677311401797 Time: 0.053888
[03/24/2023-12:57:19] [V] [TRT] Conv_67 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize256x64x8_stage3_warpsize1x4x1_g1_ffma_t1r3s3 Tactic: -4314913710375142296
[03/24/2023-12:57:19] [V] [TRT] Tactic: -4314913710375142296 Time: 0.251008
[03/24/2023-12:57:19] [V] [TRT] Conv_67 Set Tactic Name: ampere_scudnn_128x128_relu_exp_large_nhwc_tn_v1 Tactic: -3855385237722507464
[03/24/2023-12:57:19] [V] [TRT] Tactic: -3855385237722507464 Time: 0.34176
[03/24/2023-12:57:19] [V] [TRT] Conv_67 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize128x64x8_stage3_warpsize1x4x1_g1_ffma_t1r3s3 Tactic: -3697587361057948972
[03/24/2023-12:57:19] [V] [TRT] Tactic: -3697587361057948972 Time: 0.23552
[03/24/2023-12:57:19] [V] [TRT] Conv_67 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize256x64x32_stage3_warpsize4x2x1_g1_tensor16x8x8 Tactic: -3540975627865078064
[03/24/2023-12:57:19] [V] [TRT] Tactic: -3540975627865078064 Time: 0.054656
[03/24/2023-12:57:19] [V] [TRT] Conv_67 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize64x128x32_stage5_warpsize2x2x1_g1_tensor16x8x8_t1r3s3 Tactic: -3151804561246216835
[03/24/2023-12:57:19] [V] [TRT] Tactic: -3151804561246216835 Time: 0.076672
[03/24/2023-12:57:19] [V] [TRT] Conv_67 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize64x32x64_stage5_warpsize2x2x1_g1_tensor16x8x8 Tactic: -2885165284206163001
[03/24/2023-12:57:19] [V] [TRT] Tactic: -2885165284206163001 Time: 0.049408
[03/24/2023-12:57:19] [V] [TRT] Conv_67 Set Tactic Name: ampere_scudnn_128x128_relu_exp_medium_nhwc_tn_v1 Tactic: -2809379259463049391
[03/24/2023-12:57:19] [V] [TRT] Tactic: -2809379259463049391 Time: 0.34112
[03/24/2023-12:57:19] [V] [TRT] Conv_67 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x128x32_stage4_warpsize2x2x1_g1_tensor16x8x8_t1r3s3 Tactic: -2801041895330778813
[03/24/2023-12:57:19] [V] [TRT] Tactic: -2801041895330778813 Time: 0.0768
[03/24/2023-12:57:19] [V] [TRT] Conv_67 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize64x256x8_stage3_warpsize1x4x1_g1_ffma_t1r3s3 Tactic: -2747929399988666512
[03/24/2023-12:57:19] [V] [TRT] Tactic: -2747929399988666512 Time: 0.673536
[03/24/2023-12:57:19] [V] [TRT] Conv_67 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize256x128x32_stage3_warpsize4x2x1_g1_tensor16x8x8 Tactic: -1758690179295738332
[03/24/2023-12:57:19] [V] [TRT] Tactic: -1758690179295738332 Time: 0.086016
[03/24/2023-12:57:19] [V] [TRT] Conv_67 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x64x64_stage3_warpsize2x2x1_g1_tensor16x8x8_t1r3s3 Tactic: -1484546572846226796
[03/24/2023-12:57:19] [V] [TRT] Tactic: -1484546572846226796 Time: 0.051072
[03/24/2023-12:57:19] [V] [TRT] Conv_67 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize64x256x8_stage3_warpsize1x4x1_g1_ffma Tactic: -1472061967969061456
[03/24/2023-12:57:19] [V] [TRT] Tactic: -1472061967969061456 Time: 0.690688
[03/24/2023-12:57:19] [V] [TRT] Conv_67 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x128x32_stage4_warpsize2x2x1_g1_tensor16x8x8 Tactic: -858667497925695276
[03/24/2023-12:57:19] [V] [TRT] Tactic: -858667497925695276 Time: 0.108032
[03/24/2023-12:57:19] [V] [TRT] Conv_67 Set Tactic Name: ampere_scudnn_128x128_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: -504296718212024303
[03/24/2023-12:57:19] [V] [TRT] Tactic: -504296718212024303 Time: 0.338688
[03/24/2023-12:57:19] [V] [TRT] Conv_67 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize64x128x8_stage3_warpsize1x4x1_g1_ffma Tactic: -444093195553988951
[03/24/2023-12:57:19] [V] [TRT] Tactic: -444093195553988951 Time: 0.300416
[03/24/2023-12:57:19] [V] [TRT] Fastest Tactic: -2885165284206163001 Time: 0.049408
[03/24/2023-12:57:19] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: -2885165284206163001
[03/24/2023-12:57:19] [V] [TRT] *************** Autotuning format combination: Half(16588800,32400,180,1) -> Half(32400,32400,180,1) ***************
[03/24/2023-12:57:19] [V] [TRT] --------------- Timing Runner: Conv_67 (CudnnConvolution)
[03/24/2023-12:57:19] [V] [TRT] Tactic: 0 Time: 0.368256
[03/24/2023-12:57:20] [V] [TRT] Tactic: 1 Time: 0.148736
[03/24/2023-12:57:20] [V] [TRT] Tactic: 2 Time: 0.440192
[03/24/2023-12:57:20] [V] [TRT] Tactic: 4 Time: 0.259328
[03/24/2023-12:57:20] [V] [TRT] Tactic: 5 Time: 0.422144
[03/24/2023-12:57:20] [V] [TRT] Tactic: 6 Time: 0.398208
[03/24/2023-12:57:20] [V] [TRT] Tactic: 56 Time: 0.368128
[03/24/2023-12:57:20] [V] [TRT] Tactic: 58 Time: 0.440064
[03/24/2023-12:57:20] [V] [TRT] Tactic: 60 Time: 0.260736
[03/24/2023-12:57:20] [V] [TRT] Tactic: 61 Time: 0.42368
[03/24/2023-12:57:20] [V] [TRT] Tactic: 62 Time: 0.400256
[03/24/2023-12:57:20] [V] [TRT] Fastest Tactic: 1 Time: 0.148736
[03/24/2023-12:57:20] [V] [TRT] --------------- Timing Runner: Conv_67 (CaskConvolution)
[03/24/2023-12:57:20] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[03/24/2023-12:57:20] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CudnnConvolution Tactic: 1
[03/24/2023-12:57:20] [V] [TRT] *************** Autotuning format combination: Half(8294400,32400:2,180,1) -> Half(32400,32400:2,180,1) ***************
[03/24/2023-12:57:20] [V] [TRT] --------------- Timing Runner: Conv_67 (FusedConvActConvolution)
[03/24/2023-12:57:20] [V] [TRT] Tactic: 524287 Time: 0.051072
[03/24/2023-12:57:20] [V] [TRT] Tactic: 1048575 Time: 0.047104
[03/24/2023-12:57:20] [V] [TRT] Tactic: 1703935 Time: 0.045312
[03/24/2023-12:57:20] [V] [TRT] Tactic: 2228223 Time: 0.062336
[03/24/2023-12:57:20] [V] [TRT] Tactic: 2424831 Time: 0.064128
[03/24/2023-12:57:20] [V] [TRT] Tactic: 2621439 Time: 0.046976
[03/24/2023-12:57:20] [V] [TRT] Tactic: 3014655 Time: 0.047104
[03/24/2023-12:57:20] [V] [TRT] Tactic: 3604479 Time: 0.046976
[03/24/2023-12:57:20] [V] [TRT] Tactic: 5046271 Time: 0.047616
[03/24/2023-12:57:20] [V] [TRT] Tactic: 6160383 Time: 0.050048
[03/24/2023-12:57:20] [V] [TRT] Tactic: 6488063 Time: 0.05504
[03/24/2023-12:57:20] [V] [TRT] Tactic: 7864319 Time: 0.050304
[03/24/2023-12:57:20] [V] [TRT] Tactic: 8585215 Time: 0.058496
[03/24/2023-12:57:20] [V] [TRT] Tactic: 8847359 Time: 0.050944
[03/24/2023-12:57:20] [V] [TRT] Tactic: 9043967 Time: 0.047616
[03/24/2023-12:57:20] [V] [TRT] Tactic: 9175039 Time: 0.046976
[03/24/2023-12:57:20] [V] [TRT] Tactic: 9961471 Time: 0.06144
[03/24/2023-12:57:20] [V] [TRT] Tactic: 10027007 Time: 0.047744
[03/24/2023-12:57:20] [V] [TRT] Tactic: 10485759 Time: 0.04416
[03/24/2023-12:57:20] [V] [TRT] Tactic: 10682367 Time: 0.049024
[03/24/2023-12:57:20] [V] [TRT] Fastest Tactic: 10485759 Time: 0.04416
[03/24/2023-12:57:20] [V] [TRT] --------------- Timing Runner: Conv_67 (CudnnConvolution)
[03/24/2023-12:57:20] [V] [TRT] CudnnConvolution has no valid tactics for this config, skipping
[03/24/2023-12:57:20] [V] [TRT] --------------- Timing Runner: Conv_67 (CaskConvolution)
[03/24/2023-12:57:20] [V] [TRT] Conv_67 Set Tactic Name: ampere_fp16x2_hcudnn_fp16x2_128x32_relu_medium_nn_v1 Tactic: 2195670545862694453
[03/24/2023-12:57:20] [V] [TRT] Tactic: 2195670545862694453 Time: 0.073728
[03/24/2023-12:57:20] [V] [TRT] Conv_67 Set Tactic Name: ampere_fp16x2_hcudnn_fp16x2_128x64_relu_large_nn_v1 Tactic: 3419182076704469245
[03/24/2023-12:57:20] [V] [TRT] Tactic: 3419182076704469245 Time: 0.101376
[03/24/2023-12:57:20] [V] [TRT] Conv_67 Set Tactic Name: ampere_fp16x2_hcudnn_fp16x2_128x128_relu_medium_nn_v1 Tactic: 3891805945559659536
[03/24/2023-12:57:20] [V] [TRT] Tactic: 3891805945559659536 Time: 0.1824
[03/24/2023-12:57:20] [V] [TRT] Conv_67 Set Tactic Name: ampere_fp16x2_hcudnn_fp16x2_128x64_relu_medium_nn_v1 Tactic: 5548126322150286555
[03/24/2023-12:57:20] [V] [TRT] Tactic: 5548126322150286555 Time: 0.099968
[03/24/2023-12:57:20] [V] [TRT] Conv_67 Set Tactic Name: ampere_fp16x2_hcudnn_fp16x2_128x64_relu_small_nn_v1 Tactic: 6057304366605292508
[03/24/2023-12:57:20] [V] [TRT] Tactic: 6057304366605292508 Time: 0.097664
[03/24/2023-12:57:20] [V] [TRT] Conv_67 Set Tactic Name: ampere_fp16x2_hcudnn_fp16x2_128x128_relu_large_nn_v1 Tactic: -7928611605886347652
[03/24/2023-12:57:20] [V] [TRT] Tactic: -7928611605886347652 Time: 0.18816
[03/24/2023-12:57:20] [V] [TRT] Conv_67 Set Tactic Name: ampere_fp16x2_hcudnn_fp16x2_128x32_relu_large_nn_v1 Tactic: -5172391392092686714
[03/24/2023-12:57:20] [V] [TRT] Tactic: -5172391392092686714 Time: 0.074368
[03/24/2023-12:57:20] [V] [TRT] Conv_67 Set Tactic Name: ampere_fp16x2_hcudnn_fp16x2_128x32_relu_small_nn_v1 Tactic: -4374269919094467161
[03/24/2023-12:57:20] [V] [TRT] Tactic: -4374269919094467161 Time: 0.07168
[03/24/2023-12:57:20] [V] [TRT] Conv_67 Set Tactic Name: ampere_fp16x2_hcudnn_winograd_fp16x2_128x128_ldg1_ldg4_relu_tile148t_nt_v1 Tactic: -4083394051665370953
[03/24/2023-12:57:20] [V] [TRT] Tactic: -4083394051665370953 Time: 0.03264
[03/24/2023-12:57:20] [V] [TRT] Conv_67 Set Tactic Name: ampere_fp16x2_hcudnn_fp16x2_128x128_relu_small_nn_v1 Tactic: -1546027692247304867
[03/24/2023-12:57:20] [V] [TRT] Tactic: -1546027692247304867 Time: 0.18304
[03/24/2023-12:57:20] [V] [TRT] Fastest Tactic: -4083394051665370953 Time: 0.03264
[03/24/2023-12:57:20] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: -4083394051665370953
[03/24/2023-12:57:20] [V] [TRT] *************** Autotuning format combination: Half(2073600,1:8,11520,64) -> Float(32400,32400,180,1) ***************
[03/24/2023-12:57:20] [V] [TRT] --------------- Timing Runner: Conv_67 (CudnnConvolution)
[03/24/2023-12:57:20] [V] [TRT] CudnnConvolution has no valid tactics for this config, skipping
[03/24/2023-12:57:20] [V] [TRT] --------------- Timing Runner: Conv_67 (CaskConvolution)
[03/24/2023-12:57:20] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[03/24/2023-12:57:20] [V] [TRT] *************** Autotuning format combination: Half(2073600,1:8,11520,64) -> Half(32400,1:8,180,1) ***************
[03/24/2023-12:57:20] [V] [TRT] --------------- Timing Runner: Conv_67 (CudaDepthwiseConvolution)
[03/24/2023-12:57:20] [V] [TRT] CudaDepthwiseConvolution has no valid tactics for this config, skipping
[03/24/2023-12:57:20] [V] [TRT] --------------- Timing Runner: Conv_67 (CudnnConvolution)
[03/24/2023-12:57:20] [V] [TRT] CudnnConvolution has no valid tactics for this config, skipping
[03/24/2023-12:57:20] [V] [TRT] --------------- Timing Runner: Conv_67 (CaskConvolution)
[03/24/2023-12:57:20] [V] [TRT] Conv_67 Set Tactic Name: ampere_h16816cudnn_256x128_ldg8_relu_exp_medium_nhwc_tn_v1 Tactic: 254850674756030979
[03/24/2023-12:57:20] [V] [TRT] Tactic: 254850674756030979 Time: 0.045056
[03/24/2023-12:57:20] [V] [TRT] Conv_67 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x128x32_stage3_warpsize4x2x1_g1_tensor16x8x16_t1r3s3 Tactic: 328038211831149625
[03/24/2023-12:57:20] [V] [TRT] Tactic: 328038211831149625 Time: 0.043904
[03/24/2023-12:57:20] [V] [TRT] Conv_67 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x64x64_stage3_warpsize2x2x1_g1_tensor16x8x16_t1r3s3 Tactic: 411553864378931917
[03/24/2023-12:57:20] [V] [TRT] Tactic: 411553864378931917 Time: 0.024576
[03/24/2023-12:57:20] [V] [TRT] Conv_67 Set Tactic Name: sm75_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x128x32_stage1_warpsize4x2x1_g1_tensor16x8x8_t1r3s3 Tactic: 864841579020773074
[03/24/2023-12:57:20] [V] [TRT] Tactic: 864841579020773074 Time: 0.050176
[03/24/2023-12:57:20] [V] [TRT] Conv_67 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x128x32_stage4_warpsize2x2x1_g1_tensor16x8x16 Tactic: 1011057357468998345
[03/24/2023-12:57:20] [V] [TRT] Tactic: 1011057357468998345 Time: 0.037376
[03/24/2023-12:57:20] [V] [TRT] Conv_67 Set Tactic Name: sm75_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x64x32_stage1_warpsize4x1x1_g1_tensor16x8x8 Tactic: 1013168150133367738
[03/24/2023-12:57:20] [V] [TRT] Tactic: 1013168150133367738 Time: 0.033792
[03/24/2023-12:57:20] [V] [TRT] Conv_67 Set Tactic Name: ampere_h16816cudnn_256x128_ldg8_relu_exp_stages_64x3_small_nhwc_tn_v1 Tactic: 1016009564074305832
[03/24/2023-12:57:20] [V] [TRT] Tactic: 1016009564074305832 Time: 0.045312
[03/24/2023-12:57:20] [V] [TRT] Conv_67 Set Tactic Name: sm75_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x128x32_stage1_warpsize2x2x1_g1_tensor16x8x8 Tactic: 1067227531433278814
[03/24/2023-12:57:20] [V] [TRT] Tactic: 1067227531433278814 Time: 0.041344
[03/24/2023-12:57:20] [V] [TRT] Conv_67 Set Tactic Name: ampere_h1688cudnn_128x128_ldg8_relu_exp_medium_nhwc_tn_v1 Tactic: 1156328698016730421
[03/24/2023-12:57:20] [V] [TRT] Tactic: 1156328698016730421 Time: 0.048896
[03/24/2023-12:57:20] [V] [TRT] Conv_67 Set Tactic Name: sm75_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x128x32_stage1_warpsize2x2x1_g1_tensor16x8x8 Tactic: 1579845938601132607
[03/24/2023-12:57:20] [V] [TRT] Tactic: 1579845938601132607 Time: 0.04096
[03/24/2023-12:57:20] [V] [TRT] Conv_67 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x128x32_stage5_warpsize2x2x1_g1_tensor16x8x16_t1r3s3 Tactic: 1723736032573714698
[03/24/2023-12:57:20] [V] [TRT] Tactic: 1723736032573714698 Time: 0.0352
[03/24/2023-12:57:20] [V] [TRT] Conv_67 Set Tactic Name: sm75_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x32x32_stage1_warpsize4x1x1_g1_tensor16x8x8 Tactic: 1796821236841789338
[03/24/2023-12:57:20] [V] [TRT] Tactic: 1796821236841789338 Time: 0.025472
[03/24/2023-12:57:20] [V] [TRT] Conv_67 Set Tactic Name: ampere_h16816cudnn_128x64_ldg8_relu_exp_stages_64x4_medium_nhwc_tn_v1 Tactic: 1832046141070096030
[03/24/2023-12:57:20] [V] [TRT] Tactic: 1832046141070096030 Time: 0.030976
[03/24/2023-12:57:20] [V] [TRT] Conv_67 Set Tactic Name: ampere_h16816cudnn_128x64_sliced1x2_ldg8_relu_exp_stages_64x3_small_nhwc_tn_v1 Tactic: 1838082074606840426
[03/24/2023-12:57:20] [V] [TRT] Tactic: 1838082074606840426 Time: 0.02624
[03/24/2023-12:57:20] [V] [TRT] Conv_67 Set Tactic Name: ampere_h16816cudnn_64x64_sliced1x2_ldg8_relu_exp_stages_64x5_small_nhwc_tn_v1 Tactic: 1899296423087490472
[03/24/2023-12:57:20] [V] [TRT] Tactic: 1899296423087490472 Time: 0.031872
[03/24/2023-12:57:20] [V] [TRT] Conv_67 Set Tactic Name: sm75_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x32x32_stage1_warpsize4x1x1_g1_tensor16x8x8 Tactic: 1948263663414159978
[03/24/2023-12:57:20] [V] [TRT] Tactic: 1948263663414159978 Time: 0.028288
[03/24/2023-12:57:20] [V] [TRT] Conv_67 Set Tactic Name: sm75_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x256x64_stage1_warpsize1x4x2_g1_tensor16x8x8 Tactic: 2027733232253711640
[03/24/2023-12:57:20] [V] [TRT] Tactic: 2027733232253711640 Time: 0.070528
[03/24/2023-12:57:20] [V] [TRT] Conv_67 Set Tactic Name: sm75_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x64x32_stage1_warpsize2x2x1_g1_tensor16x8x8_t1r3s3 Tactic: 2154731107061273008
[03/24/2023-12:57:20] [V] [TRT] Tactic: 2154731107061273008 Time: 0.029184
[03/24/2023-12:57:20] [V] [TRT] Conv_67 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x64x64_stage3_warpsize2x2x1_g1_tensor16x8x16 Tactic: 2428167804343994714
[03/24/2023-12:57:20] [V] [TRT] Tactic: 2428167804343994714 Time: 0.025728
[03/24/2023-12:57:20] [V] [TRT] Conv_67 Set Tactic Name: ampere_h16816cudnn_128x128_ldg8_relu_exp_medium_nhwc_tn_v1 Tactic: 2541579301352125276
[03/24/2023-12:57:20] [V] [TRT] Tactic: 2541579301352125276 Time: 0.0352
[03/24/2023-12:57:20] [V] [TRT] Conv_67 Set Tactic Name: ampere_h16816cudnn_64x64_sliced1x2_ldg8_relu_exp_stages_64x6_small_nhwc_tn_v1 Tactic: 2657157263811141609
[03/24/2023-12:57:20] [V] [TRT] Tactic: 2657157263811141609 Time: 0.036864
[03/24/2023-12:57:20] [V] [TRT] Conv_67 Set Tactic Name: ampere_h16816cudnn_64x128_sliced1x2_ldg8_relu_exp_stages_64x4_large_nhwc_tn_v1 Tactic: 2819719497590964443
[03/24/2023-12:57:20] [V] [TRT] Tactic: 2819719497590964443 Time: 0.048896
[03/24/2023-12:57:20] [V] [TRT] Conv_67 Set Tactic Name: ampere_h16816cudnn_128x64_sliced1x2_ldg8_relu_exp_stages_64x3_medium_nhwc_tn_v1 Tactic: 2968605903460894194
[03/24/2023-12:57:20] [V] [TRT] Tactic: 2968605903460894194 Time: 0.026496
[03/24/2023-12:57:20] [V] [TRT] Conv_67 Set Tactic Name: ampere_h16816cudnn_128x128_ldg8_relu_exp_large_nhwc_tn_v1 Tactic: 2986078304285316765
[03/24/2023-12:57:20] [V] [TRT] Tactic: 2986078304285316765 Time: 0.035584
[03/24/2023-12:57:20] [V] [TRT] Conv_67 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x256x64_stage3_warpsize1x4x1_g1_tensor16x8x16 Tactic: 3016308193087082166
[03/24/2023-12:57:20] [V] [TRT] Tactic: 3016308193087082166 Time: 0.065664
[03/24/2023-12:57:20] [V] [TRT] Conv_67 Set Tactic Name: ampere_h16816cudnn_256x64_ldg8_relu_exp_stages_64x3_large_nhwc_tn_v1 Tactic: 3221382575080507859
[03/24/2023-12:57:20] [V] [TRT] Tactic: 3221382575080507859 Time: 0.030592
[03/24/2023-12:57:20] [V] [TRT] Conv_67 Set Tactic Name: ampere_h16816cudnn_128x128_ldg8_relu_exp_stages_64x3_medium_nhwc_tn_v1 Tactic: 3362537467505018070
[03/24/2023-12:57:20] [V] [TRT] Tactic: 3362537467505018070 Time: 0.040832
[03/24/2023-12:57:20] [V] [TRT] Conv_67 Set Tactic Name: sm75_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x64x32_stage1_warpsize4x1x1_g1_tensor16x8x8_t1r3s3 Tactic: 3464689803495983377
[03/24/2023-12:57:20] [V] [TRT] Tactic: 3464689803495983377 Time: 0.032512
[03/24/2023-12:57:20] [V] [TRT] Conv_67 Set Tactic Name: ampere_h1688cudnn_256x128_ldg8_relu_exp_medium_nhwc_tn_v1 Tactic: 3513075359009385578
[03/24/2023-12:57:20] [V] [TRT] Tactic: 3513075359009385578 Time: 0.05312
[03/24/2023-12:57:20] [V] [TRT] Conv_67 Set Tactic Name: ampere_h16816cudnn_128x64_ldg8_relu_exp_stages_64x4_large_nhwc_tn_v1 Tactic: 3573559043797674382
[03/24/2023-12:57:20] [V] [TRT] Tactic: 3573559043797674382 Time: 0.031488
[03/24/2023-12:57:20] [V] [TRT] Conv_67 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x64x64_stage4_warpsize2x2x1_g1_tensor16x8x16_t1r3s3 Tactic: 3591970081995419777
[03/24/2023-12:57:20] [V] [TRT] Tactic: 3591970081995419777 Time: 0.028416
[03/24/2023-12:57:20] [V] [TRT] Conv_67 Set Tactic Name: sm75_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x128x32_stage1_warpsize2x2x1_g1_tensor16x8x8_t1r3s3 Tactic: 3636831327753843771
[03/24/2023-12:57:20] [V] [TRT] Tactic: 3636831327753843771 Time: 0.038272
[03/24/2023-12:57:20] [V] [TRT] Conv_67 Set Tactic Name: ampere_h1688cudnn_128x128_ldg8_relu_exp_small_nhwc_tn_v1 Tactic: 3704534001553878387
[03/24/2023-12:57:20] [V] [TRT] Tactic: 3704534001553878387 Time: 0.04608
[03/24/2023-12:57:20] [V] [TRT] Conv_67 Set Tactic Name: ampere_h16816cudnn_64x128_ldg8_relu_exp_stages_64x4_small_nhwc_tn_v1 Tactic: 4278315135102886928
[03/24/2023-12:57:20] [V] [TRT] Tactic: 4278315135102886928 Time: 0.043008
[03/24/2023-12:57:20] [V] [TRT] Conv_67 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x32x32_stage4_warpsize4x1x1_g1_tensor16x8x16_t1r3s3 Tactic: 4503233883285355107
[03/24/2023-12:57:20] [V] [TRT] Tactic: 4503233883285355107 Time: 0.020224
[03/24/2023-12:57:20] [V] [TRT] Conv_67 Set Tactic Name: ampere_h16816cudnn_256x64_ldg8_relu_exp_stages_64x3_medium_nhwc_tn_v1 Tactic: 4540505769798915372
[03/24/2023-12:57:20] [V] [TRT] Tactic: 4540505769798915372 Time: 0.030592
[03/24/2023-12:57:20] [V] [TRT] Conv_67 Set Tactic Name: ampere_h16816cudnn_256x64_sliced1x2_ldg8_relu_exp_small_nhwc_tn_v1 Tactic: 4802447371470387646
[03/24/2023-12:57:20] [V] [TRT] Tactic: 4802447371470387646 Time: 0.032768
[03/24/2023-12:57:20] [V] [TRT] Conv_67 Set Tactic Name: ampere_h16816cudnn_256x128_ldg8_relu_exp_small_nhwc_tn_v1 Tactic: 5059676457552313631
[03/24/2023-12:57:20] [V] [TRT] Tactic: 5059676457552313631 Time: 0.044416
[03/24/2023-12:57:20] [V] [TRT] Conv_67 Set Tactic Name: sm75_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x128x64_stage1_warpsize2x2x1_g1_tensor16x8x8_t1r3s3 Tactic: 5263029549013613567
[03/24/2023-12:57:20] [V] [TRT] Tactic: 5263029549013613567 Time: 0.038656
[03/24/2023-12:57:20] [V] [TRT] Conv_67 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x64x64_stage4_warpsize2x2x1_g1_tensor16x8x16 Tactic: 5368829646735632944
[03/24/2023-12:57:20] [V] [TRT] Tactic: 5368829646735632944 Time: 0.03008
[03/24/2023-12:57:20] [V] [TRT] Conv_67 Set Tactic Name: ampere_h1688cudnn_256x64_sliced1x2_ldg8_relu_exp_small_nhwc_tn_v1 Tactic: 5398999388616959893
[03/24/2023-12:57:20] [V] [TRT] Tactic: 5398999388616959893 Time: 0.035584
[03/24/2023-12:57:20] [V] [TRT] Conv_67 Set Tactic Name: sm75_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x256x32_stage1_warpsize2x4x1_g1_tensor16x8x8_t1r3s3 Tactic: 5506334059535811602
[03/24/2023-12:57:20] [V] [TRT] Tactic: 5506334059535811602 Time: 0.068736
[03/24/2023-12:57:20] [V] [TRT] Conv_67 Set Tactic Name: ampere_h16816cudnn_64x128_sliced1x2_ldg8_relu_exp_stages_64x3_large_nhwc_tn_v1 Tactic: 5746691132547383910
[03/24/2023-12:57:20] [V] [TRT] Tactic: 5746691132547383910 Time: 0.036736
[03/24/2023-12:57:20] [V] [TRT] Conv_67 Set Tactic Name: ampere_h16816cudnn_256x64_ldg8_relu_exp_large_nhwc_tn_v1 Tactic: 5770170567977052602
[03/24/2023-12:57:20] [V] [TRT] Tactic: 5770170567977052602 Time: 0.031744
[03/24/2023-12:57:20] [V] [TRT] Conv_67 Set Tactic Name: sm75_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x32x64_stage1_warpsize2x1x2_g1_tensor16x8x8_t1r3s3 Tactic: 5932046018238429951
[03/24/2023-12:57:20] [V] [TRT] Tactic: 5932046018238429951 Time: 0.022272
[03/24/2023-12:57:20] [V] [TRT] Conv_67 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x64x32_stage3_warpsize4x1x1_g1_tensor16x8x16_t1r3s3 Tactic: 5953552212833506549
[03/24/2023-12:57:20] [V] [TRT] Tactic: 5953552212833506549 Time: 0.026752
[03/24/2023-12:57:20] [V] [TRT] Conv_67 Set Tactic Name: ampere_h16816cudnn_64x128_ldg8_relu_exp_stages_64x3_small_nhwc_tn_v1 Tactic: 6034364043891107501
[03/24/2023-12:57:20] [V] [TRT] Tactic: 6034364043891107501 Time: 0.037632
[03/24/2023-12:57:20] [V] [TRT] Conv_67 Set Tactic Name: ampere_h16816cudnn_64x64_ldg8_relu_exp_stages_64x5_large_nhwc_tn_v1 Tactic: 6074229447555668232
[03/24/2023-12:57:20] [V] [TRT] Tactic: 6074229447555668232 Time: 0.033536
[03/24/2023-12:57:20] [V] [TRT] Conv_67 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x64x64_stage3_warpsize2x2x1_g1_tensor16x8x16 Tactic: 6154447660803990543
[03/24/2023-12:57:20] [V] [TRT] Tactic: 6154447660803990543 Time: 0.025472
[03/24/2023-12:57:20] [V] [TRT] Conv_67 Set Tactic Name: sm75_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x32x64_stage1_warpsize2x1x2_g1_tensor16x8x8 Tactic: 6195603576432354734
[03/24/2023-12:57:20] [V] [TRT] Tactic: 6195603576432354734 Time: 0.024448
[03/24/2023-12:57:20] [V] [TRT] Conv_67 Set Tactic Name: sm75_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x32x32_stage1_warpsize4x1x1_g1_tensor16x8x8_t1r3s3 Tactic: 6252808259936499253
[03/24/2023-12:57:20] [V] [TRT] Tactic: 6252808259936499253 Time: 0.027904
[03/24/2023-12:57:20] [V] [TRT] Conv_67 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x128x64_stage3_warpsize2x2x1_g1_tensor16x8x16 Tactic: 6325769668000961702
[03/24/2023-12:57:20] [V] [TRT] Tactic: 6325769668000961702 Time: 0.042496
[03/24/2023-12:57:20] [V] [TRT] Conv_67 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x32x64_stage5_warpsize2x2x1_g1_tensor16x8x16 Tactic: 6350273239113254096
[03/24/2023-12:57:20] [V] [TRT] Tactic: 6350273239113254096 Time: 0.026368
[03/24/2023-12:57:20] [V] [TRT] Conv_67 Set Tactic Name: ampere_h16816cudnn_128x128_ldg8_relu_exp_stages_64x3_small_nhwc_tn_v1 Tactic: 6377497238381488891
[03/24/2023-12:57:20] [V] [TRT] Tactic: 6377497238381488891 Time: 0.040448
[03/24/2023-12:57:20] [V] [TRT] Conv_67 Set Tactic Name: sm75_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x64x64_stage1_warpsize2x2x1_g1_tensor16x8x8 Tactic: 6408235920257988861
[03/24/2023-12:57:20] [V] [TRT] Tactic: 6408235920257988861 Time: 0.028672
[03/24/2023-12:57:20] [V] [TRT] Conv_67 Set Tactic Name: ampere_h16816cudnn_128x64_ldg8_relu_exp_stages_64x3_large_nhwc_tn_v1 Tactic: 6446388116965632819
[03/24/2023-12:57:20] [V] [TRT] Tactic: 6446388116965632819 Time: 0.028288
[03/24/2023-12:57:20] [V] [TRT] Conv_67 Set Tactic Name: ampere_h16816cudnn_128x64_sliced1x2_ldg8_relu_exp_stages_64x4_medium_nhwc_tn_v1 Tactic: 6468794451065529747
[03/24/2023-12:57:20] [V] [TRT] Tactic: 6468794451065529747 Time: 0.031744
[03/24/2023-12:57:20] [V] [TRT] Conv_67 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x128x64_stage3_warpsize4x2x1_g1_tensor16x8x16 Tactic: 6509152032538119080
[03/24/2023-12:57:20] [V] [TRT] Tactic: 6509152032538119080 Time: 0.046336
[03/24/2023-12:57:20] [V] [TRT] Conv_67 Set Tactic Name: ampere_h1688cudnn_256x128_ldg8_relu_exp_large_nhwc_tn_v1 Tactic: 6642277870194067185
[03/24/2023-12:57:20] [V] [TRT] Tactic: 6642277870194067185 Time: 0.05376
[03/24/2023-12:57:20] [V] [TRT] Conv_67 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x256x64_stage3_warpsize1x4x1_g1_tensor16x8x16 Tactic: 6703181542003057635
[03/24/2023-12:57:20] [V] [TRT] Tactic: 6703181542003057635 Time: 0.064512
[03/24/2023-12:57:20] [V] [TRT] Conv_67 Set Tactic Name: ampere_h16816cudnn_64x64_ldg8_relu_exp_stages_64x5_medium_nhwc_tn_v1 Tactic: 6859477213531075460
[03/24/2023-12:57:20] [V] [TRT] Tactic: 6859477213531075460 Time: 0.032896
[03/24/2023-12:57:20] [V] [TRT] Conv_67 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x128x32_stage4_warpsize2x2x1_g1_tensor16x8x16_t1r3s3 Tactic: 6972489290272968208
[03/24/2023-12:57:20] [V] [TRT] Tactic: 6972489290272968208 Time: 0.033792
[03/24/2023-12:57:20] [V] [TRT] Conv_67 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x128x32_stage3_warpsize4x2x1_g1_tensor16x8x16 Tactic: 6979044990896381511
[03/24/2023-12:57:20] [V] [TRT] Tactic: 6979044990896381511 Time: 0.04416
[03/24/2023-12:57:20] [V] [TRT] Conv_67 Set Tactic Name: ampere_h1688cudnn_256x64_ldg8_relu_exp_medium_nhwc_tn_v1 Tactic: 7216571380637776659
[03/24/2023-12:57:20] [V] [TRT] Tactic: 7216571380637776659 Time: 0.035712
[03/24/2023-12:57:20] [V] [TRT] Conv_67 Set Tactic Name: ampere_h16816cudnn_128x64_ldg8_relu_exp_stages_64x3_medium_nhwc_tn_v1 Tactic: 7609923741161019135
[03/24/2023-12:57:20] [V] [TRT] Tactic: 7609923741161019135 Time: 0.02816
[03/24/2023-12:57:20] [V] [TRT] Conv_67 Set Tactic Name: sm75_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x64x32_stage1_warpsize2x2x1_g1_tensor16x8x8 Tactic: 7612687199567064086
[03/24/2023-12:57:20] [V] [TRT] Tactic: 7612687199567064086 Time: 0.03072
[03/24/2023-12:57:20] [V] [TRT] Conv_67 Set Tactic Name: ampere_h16816cudnn_64x64_ldg8_relu_exp_stages_64x6_large_nhwc_tn_v1 Tactic: 7705739241028240201
[03/24/2023-12:57:20] [V] [TRT] Tactic: 7705739241028240201 Time: 0.038912
[03/24/2023-12:57:20] [V] [TRT] Conv_67 Set Tactic Name: sm75_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x128x32_stage1_warpsize2x2x1_g1_tensor16x8x8 Tactic: 7729555994715864793
[03/24/2023-12:57:20] [V] [TRT] Tactic: 7729555994715864793 Time: 0.040832
[03/24/2023-12:57:20] [V] [TRT] Conv_67 Set Tactic Name: sm75_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x64x64_stage1_warpsize2x2x1_g1_tensor16x8x8_t1r3s3 Tactic: 7849296535223586261
[03/24/2023-12:57:20] [V] [TRT] Tactic: 7849296535223586261 Time: 0.028288
[03/24/2023-12:57:20] [V] [TRT] Conv_67 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x256x32_stage3_warpsize2x4x1_g1_tensor16x8x16 Tactic: 8072087735545283117
[03/24/2023-12:57:21] [V] [TRT] Tactic: 8072087735545283117 Time: 0.061312
[03/24/2023-12:57:21] [V] [TRT] Conv_67 Set Tactic Name: ampere_h16816cudnn_64x64_sliced1x2_ldg8_relu_exp_stages_64x5_medium_nhwc_tn_v1 Tactic: 8101703987960976805
[03/24/2023-12:57:21] [V] [TRT] Tactic: 8101703987960976805 Time: 0.03136
[03/24/2023-12:57:21] [V] [TRT] Conv_67 Set Tactic Name: ampere_h16816cudnn_128x64_sliced1x2_ldg8_relu_exp_stages_64x4_small_nhwc_tn_v1 Tactic: 8170606396342855895
[03/24/2023-12:57:21] [V] [TRT] Tactic: 8170606396342855895 Time: 0.03072
[03/24/2023-12:57:21] [V] [TRT] Conv_67 Set Tactic Name: sm75_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x32x64_stage1_warpsize2x1x2_g1_tensor16x8x8 Tactic: 8455608235315878803
[03/24/2023-12:57:21] [V] [TRT] Tactic: 8455608235315878803 Time: 0.025216
[03/24/2023-12:57:21] [V] [TRT] Conv_67 Set Tactic Name: sm75_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x64x64_stage1_warpsize2x2x1_g1_tensor16x8x8 Tactic: 8668812313058150080
[03/24/2023-12:57:21] [V] [TRT] Tactic: 8668812313058150080 Time: 0.02944
[03/24/2023-12:57:21] [V] [TRT] Conv_67 Set Tactic Name: ampere_h1688cudnn_256x64_ldg8_relu_exp_small_nhwc_tn_v1 Tactic: 8839784824303350101
[03/24/2023-12:57:21] [V] [TRT] Tactic: 8839784824303350101 Time: 0.033664
[03/24/2023-12:57:21] [V] [TRT] Conv_67 Set Tactic Name: ampere_h16816cudnn_64x64_sliced1x2_ldg8_relu_exp_stages_64x5_large_nhwc_tn_v1 Tactic: -9217371357561775773
[03/24/2023-12:57:21] [V] [TRT] Tactic: -9217371357561775773 Time: 0.030592
[03/24/2023-12:57:21] [V] [TRT] Conv_67 Set Tactic Name: ampere_h16816cudnn_256x64_sliced1x2_ldg8_relu_exp_medium_nhwc_tn_v1 Tactic: -9009272790678027912
[03/24/2023-12:57:21] [V] [TRT] Tactic: -9009272790678027912 Time: 0.035584
[03/24/2023-12:57:21] [V] [TRT] Conv_67 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x32x32_stage4_warpsize4x1x1_g1_tensor16x8x16 Tactic: -8985224497679592364
[03/24/2023-12:57:21] [V] [TRT] Tactic: -8985224497679592364 Time: 0.02048
[03/24/2023-12:57:21] [V] [TRT] Conv_67 Set Tactic Name: ampere_h16816cudnn_128x64_sliced1x2_ldg8_relu_exp_stages_64x3_large_nhwc_tn_v1 Tactic: -8949544755481315679
[03/24/2023-12:57:21] [V] [TRT] Tactic: -8949544755481315679 Time: 0.026496
[03/24/2023-12:57:21] [V] [TRT] Conv_67 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x64x64_stage3_warpsize4x1x1_g1_tensor16x8x16_t1r3s3 Tactic: -8867999442759527766
[03/24/2023-12:57:21] [V] [TRT] Tactic: -8867999442759527766 Time: 0.03264
[03/24/2023-12:57:21] [V] [TRT] Conv_67 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x128x64_stage3_warpsize2x2x1_g1_tensor16x8x16 Tactic: -8759929675070720385
[03/24/2023-12:57:21] [V] [TRT] Tactic: -8759929675070720385 Time: 0.040832
[03/24/2023-12:57:21] [V] [TRT] Conv_67 Set Tactic Name: ampere_h16816cudnn_64x64_ldg8_relu_exp_stages_64x6_medium_nhwc_tn_v1 Tactic: -8604374562669615024
[03/24/2023-12:57:21] [V] [TRT] Tactic: -8604374562669615024 Time: 0.038016
[03/24/2023-12:57:21] [V] [TRT] Conv_67 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x128x64_stage3_warpsize4x2x1_g1_tensor16x8x16 Tactic: -8362347876645295759
[03/24/2023-12:57:21] [V] [TRT] Tactic: -8362347876645295759 Time: 0.0448
[03/24/2023-12:57:21] [V] [TRT] Conv_67 Set Tactic Name: sm75_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x128x32_stage1_warpsize4x2x1_g1_tensor16x8x8 Tactic: -8254009616492665198
[03/24/2023-12:57:21] [V] [TRT] Tactic: -8254009616492665198 Time: 0.050176
[03/24/2023-12:57:21] [V] [TRT] Conv_67 Set Tactic Name: ampere_h16816cudnn_256x128_ldg8_relu_exp_stages_64x3_large_nhwc_tn_v1 Tactic: -7757610000269494813
[03/24/2023-12:57:21] [V] [TRT] Tactic: -7757610000269494813 Time: 0.04608
[03/24/2023-12:57:21] [V] [TRT] Conv_67 Set Tactic Name: sm75_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x128x32_stage1_warpsize4x2x1_g1_tensor16x8x8 Tactic: -7615325597099025933
[03/24/2023-12:57:21] [V] [TRT] Tactic: -7615325597099025933 Time: 0.0512
[03/24/2023-12:57:21] [V] [TRT] Conv_67 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x64x64_stage3_warpsize4x1x1_g1_tensor16x8x16 Tactic: -6917689122519989488
[03/24/2023-12:57:21] [V] [TRT] Tactic: -6917689122519989488 Time: 0.031616
[03/24/2023-12:57:21] [V] [TRT] Conv_67 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x32x64_stage5_warpsize2x2x1_g1_tensor16x8x16_t1r3s3 Tactic: -6902925267326201166
[03/24/2023-12:57:21] [V] [TRT] Tactic: -6902925267326201166 Time: 0.025472
[03/24/2023-12:57:21] [V] [TRT] Conv_67 Set Tactic Name: ampere_h16816cudnn_64x128_ldg8_relu_exp_stages_64x4_large_nhwc_tn_v1 Tactic: -6840588038605932325
[03/24/2023-12:57:21] [V] [TRT] Tactic: -6840588038605932325 Time: 0.044416
[03/24/2023-12:57:21] [V] [TRT] Conv_67 Set Tactic Name: sm75_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x32x32_stage1_warpsize4x1x1_g1_tensor16x8x8 Tactic: -6828337260021572283
[03/24/2023-12:57:21] [V] [TRT] Tactic: -6828337260021572283 Time: 0.026624
[03/24/2023-12:57:21] [V] [TRT] Conv_67 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x256x32_stage3_warpsize2x4x1_g1_tensor16x8x16 Tactic: -6799856376604253964
[03/24/2023-12:57:21] [V] [TRT] Tactic: -6799856376604253964 Time: 0.061568
[03/24/2023-12:57:21] [V] [TRT] Conv_67 Set Tactic Name: sm75_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x32x32_stage1_warpsize4x1x1_g1_tensor16x8x8 Tactic: -6711815420995272523
[03/24/2023-12:57:21] [V] [TRT] Tactic: -6711815420995272523 Time: 0.030464
[03/24/2023-12:57:21] [V] [TRT] Conv_67 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x32x32_stage4_warpsize4x1x1_g1_tensor16x8x16_t1r3s3 Tactic: -6625722781282978136
[03/24/2023-12:57:21] [V] [TRT] Tactic: -6625722781282978136 Time: 0.021376
[03/24/2023-12:57:21] [V] [TRT] Conv_67 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x64x32_stage3_warpsize4x1x1_g1_tensor16x8x16 Tactic: -6525498856028268801
[03/24/2023-12:57:21] [V] [TRT] Tactic: -6525498856028268801 Time: 0.028416
[03/24/2023-12:57:21] [V] [TRT] Conv_67 Set Tactic Name: sm75_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x256x64_stage1_warpsize1x4x2_g1_tensor16x8x8 Tactic: -6489479581011009593
[03/24/2023-12:57:21] [V] [TRT] Tactic: -6489479581011009593 Time: 0.070528
[03/24/2023-12:57:21] [V] [TRT] Conv_67 Set Tactic Name: ampere_h16816cudnn_64x64_sliced1x2_ldg8_relu_exp_stages_64x6_medium_nhwc_tn_v1 Tactic: -6356316196810535311
[03/24/2023-12:57:21] [V] [TRT] Tactic: -6356316196810535311 Time: 0.039808
[03/24/2023-12:57:21] [V] [TRT] Conv_67 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x32x32_stage4_warpsize4x1x1_g1_tensor16x8x16 Tactic: -6324345858751792783
[03/24/2023-12:57:21] [V] [TRT] Tactic: -6324345858751792783 Time: 0.0224
[03/24/2023-12:57:21] [V] [TRT] Conv_67 Set Tactic Name: sm75_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x256x64_stage1_warpsize1x4x2_g1_tensor16x8x8_t1r3s3 Tactic: -6320761427625651496
[03/24/2023-12:57:21] [V] [TRT] Tactic: -6320761427625651496 Time: 0.069376
[03/24/2023-12:57:21] [V] [TRT] Conv_67 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x256x32_stage3_warpsize2x4x1_g1_tensor16x8x16_t1r3s3 Tactic: -6262400699544994312
[03/24/2023-12:57:21] [V] [TRT] Tactic: -6262400699544994312 Time: 0.060288
[03/24/2023-12:57:21] [V] [TRT] Conv_67 Set Tactic Name: ampere_h1688cudnn_128x128_ldg8_relu_exp_large_nhwc_tn_v1 Tactic: -6257787336162086472
[03/24/2023-12:57:21] [V] [TRT] Tactic: -6257787336162086472 Time: 0.051968
[03/24/2023-12:57:21] [V] [TRT] Conv_67 Set Tactic Name: sm75_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x128x64_stage1_warpsize2x2x1_g1_tensor16x8x8 Tactic: -6080892721161662420
[03/24/2023-12:57:21] [V] [TRT] Tactic: -6080892721161662420 Time: 0.040064
[03/24/2023-12:57:21] [V] [TRT] Conv_67 Set Tactic Name: ampere_h16816cudnn_128x64_ldg8_relu_exp_stages_64x4_small_nhwc_tn_v1 Tactic: -6063766379489217211
[03/24/2023-12:57:21] [V] [TRT] Tactic: -6063766379489217211 Time: 0.030592
[03/24/2023-12:57:21] [V] [TRT] Conv_67 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x128x32_stage5_warpsize2x2x1_g1_tensor16x8x16 Tactic: -5777580938094193096
[03/24/2023-12:57:21] [V] [TRT] Tactic: -5777580938094193096 Time: 0.035584
[03/24/2023-12:57:21] [V] [TRT] Conv_67 Set Tactic Name: sm75_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x128x64_stage1_warpsize2x2x1_g1_tensor16x8x8 Tactic: -5710735840878760115
[03/24/2023-12:57:21] [V] [TRT] Tactic: -5710735840878760115 Time: 0.040832
[03/24/2023-12:57:21] [V] [TRT] Conv_67 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x128x32_stage3_warpsize4x2x1_g1_tensor16x8x16 Tactic: -5657273398217409378
[03/24/2023-12:57:21] [V] [TRT] Tactic: -5657273398217409378 Time: 0.044032
[03/24/2023-12:57:21] [V] [TRT] Conv_67 Set Tactic Name: sm75_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x128x32_stage1_warpsize2x2x1_g1_tensor16x8x8_t1r3s3 Tactic: -5546257196173962281
[03/24/2023-12:57:21] [V] [TRT] Tactic: -5546257196173962281 Time: 0.039552
[03/24/2023-12:57:21] [V] [TRT] Conv_67 Set Tactic Name: ampere_h16816cudnn_128x128_ldg8_relu_exp_small_nhwc_tn_v1 Tactic: -5530886555766748586
[03/24/2023-12:57:21] [V] [TRT] Tactic: -5530886555766748586 Time: 0.034432
[03/24/2023-12:57:21] [V] [TRT] Conv_67 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x64x32_stage5_warpsize2x2x1_g1_tensor16x8x16_t1r3s3 Tactic: -5422685219138380548
[03/24/2023-12:57:21] [V] [TRT] Tactic: -5422685219138380548 Time: 0.02496
[03/24/2023-12:57:21] [V] [TRT] Conv_67 Set Tactic Name: ampere_h16816cudnn_256x64_ldg8_relu_exp_stages_64x3_small_nhwc_tn_v1 Tactic: -5261787675443473128
[03/24/2023-12:57:21] [V] [TRT] Tactic: -5261787675443473128 Time: 0.030336
[03/24/2023-12:57:21] [V] [TRT] Conv_67 Set Tactic Name: sm75_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x64x32_stage1_warpsize4x1x1_g1_tensor16x8x8 Tactic: -5198219374380660379
[03/24/2023-12:57:21] [V] [TRT] Tactic: -5198219374380660379 Time: 0.033152
[03/24/2023-12:57:21] [V] [TRT] Conv_67 Set Tactic Name: ampere_h16816cudnn_64x128_sliced1x2_ldg8_relu_exp_stages_64x3_medium_nhwc_tn_v1 Tactic: -5161596964442251102
[03/24/2023-12:57:21] [V] [TRT] Tactic: -5161596964442251102 Time: 0.036224
[03/24/2023-12:57:21] [V] [TRT] Conv_67 Set Tactic Name: ampere_h16816cudnn_64x128_ldg8_relu_exp_stages_64x3_medium_nhwc_tn_v1 Tactic: -5127240325355316006
[03/24/2023-12:57:21] [V] [TRT] Tactic: -5127240325355316006 Time: 0.038016
[03/24/2023-12:57:21] [V] [TRT] Conv_67 Set Tactic Name: ampere_h16816cudnn_256x128_ldg8_relu_exp_stages_64x3_medium_nhwc_tn_v1 Tactic: -5109582882231362997
[03/24/2023-12:57:21] [V] [TRT] Tactic: -5109582882231362997 Time: 0.045824
[03/24/2023-12:57:21] [V] [TRT] Conv_67 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x64x32_stage5_warpsize2x2x1_g1_tensor16x8x16 Tactic: -4825567853927730435
[03/24/2023-12:57:21] [V] [TRT] Tactic: -4825567853927730435 Time: 0.029696
[03/24/2023-12:57:21] [V] [TRT] Conv_67 Set Tactic Name: ampere_h16816cudnn_64x128_sliced1x2_ldg8_relu_exp_stages_64x4_small_nhwc_tn_v1 Tactic: -4796511246675321840
[03/24/2023-12:57:21] [V] [TRT] Tactic: -4796511246675321840 Time: 0.046976
[03/24/2023-12:57:21] [V] [TRT] Conv_67 Set Tactic Name: ampere_h16816cudnn_64x64_sliced1x2_ldg8_relu_exp_stages_64x6_large_nhwc_tn_v1 Tactic: -4706569565442112734
[03/24/2023-12:57:21] [V] [TRT] Tactic: -4706569565442112734 Time: 0.040192
[03/24/2023-12:57:21] [V] [TRT] Conv_67 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x128x64_stage3_warpsize2x2x1_g1_tensor16x8x16_t1r3s3 Tactic: -4566599693570369588
[03/24/2023-12:57:21] [V] [TRT] Tactic: -4566599693570369588 Time: 0.040832
[03/24/2023-12:57:21] [V] [TRT] Conv_67 Set Tactic Name: ampere_h16816cudnn_128x128_ldg8_relu_exp_stages_64x3_large_nhwc_tn_v1 Tactic: -4409144516525410768
[03/24/2023-12:57:21] [V] [TRT] Tactic: -4409144516525410768 Time: 0.040832
[03/24/2023-12:57:21] [V] [TRT] Conv_67 Set Tactic Name: ampere_h16816cudnn_128x64_ldg8_relu_exp_stages_64x3_small_nhwc_tn_v1 Tactic: -4379519430184503304
[03/24/2023-12:57:21] [V] [TRT] Tactic: -4379519430184503304 Time: 0.028416
[03/24/2023-12:57:21] [V] [TRT] Conv_67 Set Tactic Name: ampere_h1688cudnn_256x128_ldg8_relu_exp_small_nhwc_tn_v1 Tactic: -4152066959007262150
[03/24/2023-12:57:21] [V] [TRT] Tactic: -4152066959007262150 Time: 0.050304
[03/24/2023-12:57:21] [V] [TRT] Conv_67 Set Tactic Name: ampere_h16816cudnn_64x128_ldg8_relu_exp_stages_64x4_medium_nhwc_tn_v1 Tactic: -4021926646879732549
[03/24/2023-12:57:21] [V] [TRT] Tactic: -4021926646879732549 Time: 0.043776
[03/24/2023-12:57:21] [V] [TRT] Conv_67 Set Tactic Name: ampere_h16816cudnn_64x128_sliced1x2_ldg8_relu_exp_stages_64x4_medium_nhwc_tn_v1 Tactic: -3987638434926559037
[03/24/2023-12:57:21] [V] [TRT] Tactic: -3987638434926559037 Time: 0.047104
[03/24/2023-12:57:21] [V] [TRT] Conv_67 Set Tactic Name: ampere_h1688cudnn_256x64_sliced1x2_ldg8_relu_exp_medium_nhwc_tn_v1 Tactic: -3905653247016903130
[03/24/2023-12:57:21] [V] [TRT] Tactic: -3905653247016903130 Time: 0.038144
[03/24/2023-12:57:21] [V] [TRT] Conv_67 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x64x32_stage5_warpsize2x2x1_g1_tensor16x8x16 Tactic: -3903974568488493144
[03/24/2023-12:57:21] [V] [TRT] Tactic: -3903974568488493144 Time: 0.028544
[03/24/2023-12:57:21] [V] [TRT] Conv_67 Set Tactic Name: ampere_h16816cudnn_64x128_ldg8_relu_exp_stages_64x3_large_nhwc_tn_v1 Tactic: -3895429239811098010
[03/24/2023-12:57:21] [V] [TRT] Tactic: -3895429239811098010 Time: 0.038272
[03/24/2023-12:57:21] [V] [TRT] Conv_67 Set Tactic Name: ampere_h16816cudnn_256x64_ldg8_relu_exp_small_nhwc_tn_v1 Tactic: -3864869056275745423
[03/24/2023-12:57:21] [V] [TRT] Tactic: -3864869056275745423 Time: 0.03072
[03/24/2023-12:57:21] [V] [TRT] Conv_67 Set Tactic Name: sm75_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x32x32_stage1_warpsize4x1x1_g1_tensor16x8x8_t1r3s3 Tactic: -3784342055748695733
[03/24/2023-12:57:21] [V] [TRT] Tactic: -3784342055748695733 Time: 0.024704
[03/24/2023-12:57:21] [V] [TRT] Conv_67 Set Tactic Name: ampere_h16816cudnn_64x64_ldg8_relu_exp_stages_64x5_small_nhwc_tn_v1 Tactic: -3601464762214218301
[03/24/2023-12:57:21] [V] [TRT] Tactic: -3601464762214218301 Time: 0.032768
[03/24/2023-12:57:21] [V] [TRT] Conv_67 Set Tactic Name: sm75_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x64x32_stage1_warpsize2x2x1_g1_tensor16x8x8 Tactic: -3425274793298557239
[03/24/2023-12:57:21] [V] [TRT] Tactic: -3425274793298557239 Time: 0.030336
[03/24/2023-12:57:21] [V] [TRT] Conv_67 Set Tactic Name: ampere_h1688cudnn_256x64_sliced1x2_ldg8_relu_exp_large_nhwc_tn_v1 Tactic: -3412636942650049698
[03/24/2023-12:57:21] [V] [TRT] Tactic: -3412636942650049698 Time: 0.038528
[03/24/2023-12:57:21] [V] [TRT] Conv_67 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x64x32_stage3_warpsize4x1x1_g1_tensor16x8x16 Tactic: -3338665856053412950
[03/24/2023-12:57:21] [V] [TRT] Tactic: -3338665856053412950 Time: 0.027008
[03/24/2023-12:57:21] [V] [TRT] Conv_67 Set Tactic Name: sm75_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x128x32_stage1_warpsize2x2x1_g1_tensor16x8x8 Tactic: -3271955096576257018
[03/24/2023-12:57:21] [V] [TRT] Tactic: -3271955096576257018 Time: 0.039808
[03/24/2023-12:57:21] [V] [TRT] Conv_67 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x128x64_stage3_warpsize4x2x1_g1_tensor16x8x16_t1r3s3 Tactic: -3243541398692466074
[03/24/2023-12:57:21] [V] [TRT] Tactic: -3243541398692466074 Time: 0.045952
[03/24/2023-12:57:21] [V] [TRT] Conv_67 Set Tactic Name: ampere_h16816cudnn_64x128_sliced1x2_ldg8_relu_exp_stages_64x3_small_nhwc_tn_v1 Tactic: -3058330359340425555
[03/24/2023-12:57:21] [V] [TRT] Tactic: -3058330359340425555 Time: 0.036224
[03/24/2023-12:57:21] [V] [TRT] Conv_67 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x256x64_stage3_warpsize1x4x1_g1_tensor16x8x16_t1r3s3 Tactic: -2899647483672319239
[03/24/2023-12:57:21] [V] [TRT] Tactic: -2899647483672319239 Time: 0.063232
[03/24/2023-12:57:21] [V] [TRT] Conv_67 Set Tactic Name: ampere_h16816cudnn_256x64_sliced1x2_ldg8_relu_exp_large_nhwc_tn_v1 Tactic: -2816084650627734155
[03/24/2023-12:57:21] [V] [TRT] Tactic: -2816084650627734155 Time: 0.03584
[03/24/2023-12:57:21] [V] [TRT] Conv_67 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x128x32_stage5_warpsize2x2x1_g1_tensor16x8x16 Tactic: -2662892962457732243
[03/24/2023-12:57:21] [V] [TRT] Tactic: -2662892962457732243 Time: 0.03456
[03/24/2023-12:57:21] [V] [TRT] Conv_67 Set Tactic Name: ampere_h16816cudnn_256x128_ldg8_relu_exp_large_nhwc_tn_v1 Tactic: -2559894581585337900
[03/24/2023-12:57:21] [V] [TRT] Tactic: -2559894581585337900 Time: 0.045184
[03/24/2023-12:57:21] [V] [TRT] Conv_67 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x32x32_stage4_warpsize4x1x1_g1_tensor16x8x16 Tactic: -2530740716768816092
[03/24/2023-12:57:21] [V] [TRT] Tactic: -2530740716768816092 Time: 0.023552
[03/24/2023-12:57:21] [V] [TRT] Conv_67 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x128x32_stage4_warpsize2x2x1_g1_tensor16x8x16 Tactic: -2332828394978346992
[03/24/2023-12:57:21] [V] [TRT] Tactic: -2332828394978346992 Time: 0.034688
[03/24/2023-12:57:21] [V] [TRT] Conv_67 Set Tactic Name: ampere_h1688cudnn_256x64_ldg8_relu_exp_large_nhwc_tn_v1 Tactic: -2241736083352441442
[03/24/2023-12:57:21] [V] [TRT] Tactic: -2241736083352441442 Time: 0.034816
[03/24/2023-12:57:21] [V] [TRT] Conv_67 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x32x64_stage5_warpsize2x2x1_g1_tensor16x8x16 Tactic: -2161909437867201546
[03/24/2023-12:57:21] [V] [TRT] Tactic: -2161909437867201546 Time: 0.026496
[03/24/2023-12:57:21] [V] [TRT] Conv_67 Set Tactic Name: ampere_h16816cudnn_256x64_ldg8_relu_exp_medium_nhwc_tn_v1 Tactic: -1985778916402815946
[03/24/2023-12:57:21] [V] [TRT] Tactic: -1985778916402815946 Time: 0.03072
[03/24/2023-12:57:21] [V] [TRT] Conv_67 Set Tactic Name: sm75_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x256x32_stage1_warpsize2x4x1_g1_tensor16x8x8 Tactic: -1708101578041178688
[03/24/2023-12:57:21] [V] [TRT] Tactic: -1708101578041178688 Time: 0.070528
[03/24/2023-12:57:21] [V] [TRT] Conv_67 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x64x64_stage3_warpsize4x1x1_g1_tensor16x8x16 Tactic: -1502788097503482299
[03/24/2023-12:57:21] [V] [TRT] Tactic: -1502788097503482299 Time: 0.032896
[03/24/2023-12:57:21] [V] [TRT] Conv_67 Set Tactic Name: ampere_h16816cudnn_128x64_sliced1x2_ldg8_relu_exp_stages_64x4_large_nhwc_tn_v1 Tactic: -1500496213132463076
[03/24/2023-12:57:21] [V] [TRT] Tactic: -1500496213132463076 Time: 0.03264
[03/24/2023-12:57:21] [V] [TRT] Conv_67 Set Tactic Name: ampere_h16816cudnn_64x64_ldg8_relu_exp_stages_64x6_small_nhwc_tn_v1 Tactic: -1099247066487349374
[03/24/2023-12:57:21] [V] [TRT] Tactic: -1099247066487349374 Time: 0.036608
[03/24/2023-12:57:21] [V] [TRT] Conv_67 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x64x64_stage4_warpsize2x2x1_g1_tensor16x8x16 Tactic: -910286698936744682
[03/24/2023-12:57:21] [V] [TRT] Tactic: -910286698936744682 Time: 0.029952
[03/24/2023-12:57:21] [V] [TRT] Conv_67 Set Tactic Name: sm75_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x256x32_stage1_warpsize2x4x1_g1_tensor16x8x8 Tactic: -907287437357565279
[03/24/2023-12:57:21] [V] [TRT] Tactic: -907287437357565279 Time: 0.069632
[03/24/2023-12:57:21] [V] [TRT] Conv_67 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x32x32_stage4_warpsize4x1x1_g1_tensor16x8x16 Tactic: -606726295133751039
[03/24/2023-12:57:21] [V] [TRT] Tactic: -606726295133751039 Time: 0.021376
[03/24/2023-12:57:21] [V] [TRT] Fastest Tactic: 4503233883285355107 Time: 0.020224
[03/24/2023-12:57:21] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: 4503233883285355107
[03/24/2023-12:57:21] [V] [TRT] *************** Autotuning format combination: Half(1036800,1:16,5760,32) -> Half(32400,1:16,180,1) ***************
[03/24/2023-12:57:21] [V] [TRT] --------------- Timing Runner: Conv_67 (CudnnConvolution)
[03/24/2023-12:57:21] [V] [TRT] CudnnConvolution has no valid tactics for this config, skipping
[03/24/2023-12:57:21] [V] [TRT] --------------- Timing Runner: Conv_67 (CaskConvolution)
[03/24/2023-12:57:21] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[03/24/2023-12:57:21] [V] [TRT] =============== Computing costs for 
[03/24/2023-12:57:21] [V] [TRT] *************** Autotuning format combination: Float(16588800,32400,180,1) -> Float(97200,32400,180,1) ***************
[03/24/2023-12:57:21] [V] [TRT] --------------- Timing Runner: Conv_70 (CudaDepthwiseConvolution)
[03/24/2023-12:57:21] [V] [TRT] CudaDepthwiseConvolution has no valid tactics for this config, skipping
[03/24/2023-12:57:21] [V] [TRT] --------------- Timing Runner: Conv_70 (FusedConvActConvolution)
[03/24/2023-12:57:21] [V] [TRT] Tactic: 524287 Time: 0.0992
[03/24/2023-12:57:21] [V] [TRT] Tactic: 1048575 Time: 0.091008
[03/24/2023-12:57:21] [V] [TRT] Tactic: 1703935 Time: 0.08704
[03/24/2023-12:57:21] [V] [TRT] Tactic: 2228223 Time: 0.102272
[03/24/2023-12:57:21] [V] [TRT] Tactic: 2424831 Time: 0.103936
[03/24/2023-12:57:21] [V] [TRT] Tactic: 2621439 Time: 0.087168
[03/24/2023-12:57:21] [V] [TRT] Tactic: 3014655 Time: 0.090112
[03/24/2023-12:57:21] [V] [TRT] Tactic: 3604479 Time: 0.089088
[03/24/2023-12:57:21] [V] [TRT] Tactic: 5046271 Time: 0.093824
[03/24/2023-12:57:21] [V] [TRT] Tactic: 6160383 Time: 0.09536
[03/24/2023-12:57:21] [V] [TRT] Tactic: 6488063 Time: 0.105472
[03/24/2023-12:57:21] [V] [TRT] Tactic: 7864319 Time: 0.091776
[03/24/2023-12:57:21] [V] [TRT] Tactic: 8585215 Time: 0.117504
[03/24/2023-12:57:21] [V] [TRT] Tactic: 8847359 Time: 0.09088
[03/24/2023-12:57:21] [V] [TRT] Tactic: 9043967 Time: 0.091136
[03/24/2023-12:57:21] [V] [TRT] Tactic: 9175039 Time: 0.089088
[03/24/2023-12:57:21] [V] [TRT] Tactic: 9961471 Time: 0.097152
[03/24/2023-12:57:21] [V] [TRT] Tactic: 10027007 Time: 0.095232
[03/24/2023-12:57:21] [V] [TRT] Tactic: 10485759 Time: 0.084992
[03/24/2023-12:57:21] [V] [TRT] Tactic: 10682367 Time: 0.086912
[03/24/2023-12:57:21] [V] [TRT] Fastest Tactic: 10485759 Time: 0.084992
[03/24/2023-12:57:21] [V] [TRT] --------------- Timing Runner: Conv_70 (CudnnConvolution)
[03/24/2023-12:57:21] [V] [TRT] Tactic: 0 Time: 0.18752
[03/24/2023-12:57:21] [V] [TRT] Tactic: 1 Time: 0.104704
[03/24/2023-12:57:21] [V] [TRT] Tactic: 2 Time: 0.259584
[03/24/2023-12:57:21] [V] [TRT] Tactic: 4 Time: 0.46848
[03/24/2023-12:57:21] [V] [TRT] Tactic: 5 Time: 0.533248
[03/24/2023-12:57:22] [V] [TRT] Tactic: 6 Time: 0.079488
[03/24/2023-12:57:22] [V] [TRT] Tactic: 56 Time: 0.187776
[03/24/2023-12:57:22] [V] [TRT] Tactic: 57 Time: 0.104192
[03/24/2023-12:57:22] [V] [TRT] Tactic: 58 Time: 0.259072
[03/24/2023-12:57:22] [V] [TRT] Tactic: 60 Time: 0.466048
[03/24/2023-12:57:22] [V] [TRT] Tactic: 61 Time: 0.535424
[03/24/2023-12:57:22] [V] [TRT] Tactic: 62 Time: 0.079616
[03/24/2023-12:57:22] [V] [TRT] Tactic: 112 Time: 0.187648
[03/24/2023-12:57:22] [V] [TRT] Tactic: 113 Time: 0.25024
[03/24/2023-12:57:22] [V] [TRT] Tactic: 114 Time: 0.259456
[03/24/2023-12:57:22] [V] [TRT] Tactic: 116 Time: 0.465536
[03/24/2023-12:57:22] [V] [TRT] Tactic: 117 Time: 0.555904
[03/24/2023-12:57:22] [V] [TRT] Tactic: 118 Time: 0.079616
[03/24/2023-12:57:22] [V] [TRT] Fastest Tactic: 6 Time: 0.079488
[03/24/2023-12:57:22] [V] [TRT] --------------- Timing Runner: Conv_70 (CaskConvolution)
[03/24/2023-12:57:22] [V] [TRT] Conv_70 Set Tactic Name: ampere_scudnn_128x64_relu_small_nn_v1 Tactic: 4549827808004681195
[03/24/2023-12:57:22] [V] [TRT] Tactic: 4549827808004681195 Time: 0.238592
[03/24/2023-12:57:22] [V] [TRT] Conv_70 Set Tactic Name: ampere_scudnn_128x128_relu_small_nn_v1 Tactic: 5779835512569528575
[03/24/2023-12:57:22] [V] [TRT] Tactic: 5779835512569528575 Time: 0.437376
[03/24/2023-12:57:22] [V] [TRT] Conv_70 Set Tactic Name: ampere_scudnn_128x128_relu_xregs_large_nn_v1 Tactic: 6053873026024413720
[03/24/2023-12:57:22] [V] [TRT] Tactic: 6053873026024413720 Time: 0.395904
[03/24/2023-12:57:22] [V] [TRT] Conv_70 Set Tactic Name: ampere_scudnn_128x64_relu_xregs_large_nn_v1 Tactic: 6767548733843469815
[03/24/2023-12:57:22] [V] [TRT] Tactic: 6767548733843469815 Time: 0.194432
[03/24/2023-12:57:22] [V] [TRT] Conv_70 Set Tactic Name: ampere_scudnn_128x32_relu_small_nn_v1 Tactic: -6313876406580483184
[03/24/2023-12:57:22] [V] [TRT] Tactic: -6313876406580483184 Time: 0.14528
[03/24/2023-12:57:22] [V] [TRT] Conv_70 Set Tactic Name: ampere_scudnn_128x128_relu_medium_nn_v1 Tactic: -1123676555321336786
[03/24/2023-12:57:22] [V] [TRT] Tactic: -1123676555321336786 Time: 0.354048
[03/24/2023-12:57:22] [V] [TRT] Conv_70 Set Tactic Name: ampere_scudnn_128x64_relu_medium_nn_v1 Tactic: -701551393537224327
[03/24/2023-12:57:22] [V] [TRT] Tactic: -701551393537224327 Time: 0.196992
[03/24/2023-12:57:22] [V] [TRT] Fastest Tactic: -6313876406580483184 Time: 0.14528
[03/24/2023-12:57:22] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CudnnConvolution Tactic: 6
[03/24/2023-12:57:22] [V] [TRT] *************** Autotuning format combination: Float(16588800,1,92160,512) -> Float(97200,1,540,3) ***************
[03/24/2023-12:57:22] [V] [TRT] --------------- Timing Runner: Conv_70 (CudnnConvolution)
[03/24/2023-12:57:22] [V] [TRT] CudnnConvolution has no valid tactics for this config, skipping
[03/24/2023-12:57:22] [V] [TRT] --------------- Timing Runner: Conv_70 (CaskConvolution)
[03/24/2023-12:57:22] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[03/24/2023-12:57:22] [V] [TRT] *************** Autotuning format combination: Float(4147200,1:4,23040,128) -> Float(32400,1:4,180,1) ***************
[03/24/2023-12:57:22] [V] [TRT] --------------- Timing Runner: Conv_70 (CudnnConvolution)
[03/24/2023-12:57:22] [V] [TRT] CudnnConvolution has no valid tactics for this config, skipping
[03/24/2023-12:57:22] [V] [TRT] --------------- Timing Runner: Conv_70 (CaskConvolution)
[03/24/2023-12:57:22] [V] [TRT] Conv_70 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize64x128x32_stage5_warpsize2x2x1_g1_tensor16x8x8 Tactic: 1237784342446422381
[03/24/2023-12:57:22] [V] [TRT] Tactic: 1237784342446422381 Time: 0.084992
[03/24/2023-12:57:22] [V] [TRT] Conv_70 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x64x32_stage5_warpsize2x2x1_g1_tensor16x8x8 Tactic: 1426562292875733922
[03/24/2023-12:57:22] [V] [TRT] Tactic: 1426562292875733922 Time: 0.05632
[03/24/2023-12:57:22] [V] [TRT] Conv_70 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize64x128x8_stage3_warpsize1x4x1_g1_ffma_t1r3s3 Tactic: 2086609538387166260
[03/24/2023-12:57:22] [V] [TRT] Tactic: 2086609538387166260 Time: 0.294144
[03/24/2023-12:57:22] [V] [TRT] Conv_70 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize256x128x32_stage3_warpsize4x2x1_g1_tensor16x8x8_t1r3s3 Tactic: 2388153022056233219
[03/24/2023-12:57:22] [V] [TRT] Tactic: 2388153022056233219 Time: 0.084736
[03/24/2023-12:57:22] [V] [TRT] Conv_70 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x128x32_stage4_warpsize2x2x1_g1_tensor16x8x8 Tactic: 2716437853123234317
[03/24/2023-12:57:22] [V] [TRT] Tactic: 2716437853123234317 Time: 0.0768
[03/24/2023-12:57:22] [V] [TRT] Conv_70 Set Tactic Name: ampere_scudnn_128x64_sliced1x2_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: 2860655430572478466
[03/24/2023-12:57:22] [V] [TRT] Tactic: 2860655430572478466 Time: 0.186112
[03/24/2023-12:57:22] [V] [TRT] Conv_70 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize64x128x8_stage3_warpsize1x4x1_g1_ffma Tactic: 3239733199291090177
[03/24/2023-12:57:22] [V] [TRT] Tactic: 3239733199291090177 Time: 0.2944
[03/24/2023-12:57:22] [V] [TRT] Conv_70 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize64x64x64_stage4_warpsize2x2x1_g1_tensor16x8x8_t1r3s3 Tactic: 3278852197192504305
[03/24/2023-12:57:22] [V] [TRT] Tactic: 3278852197192504305 Time: 0.056192
[03/24/2023-12:57:22] [V] [TRT] Conv_70 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize256x128x32_stage3_warpsize4x2x1_g1_tensor16x8x8 Tactic: 3904690393614050557
[03/24/2023-12:57:22] [V] [TRT] Tactic: 3904690393614050557 Time: 0.10368
[03/24/2023-12:57:22] [V] [TRT] Conv_70 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize64x64x64_stage4_warpsize2x2x1_g1_tensor16x8x8 Tactic: 4061115162338989075
[03/24/2023-12:57:22] [V] [TRT] Tactic: 4061115162338989075 Time: 0.061696
[03/24/2023-12:57:22] [V] [TRT] Conv_70 Set Tactic Name: ampere_scudnn_128x32_sliced1x4_ldg4_relu_exp_medium_nhwc_tn_v1 Tactic: 4474630279712975759
[03/24/2023-12:57:22] [V] [TRT] Tactic: 4474630279712975759 Time: 0.100736
[03/24/2023-12:57:22] [V] [TRT] Conv_70 Set Tactic Name: ampere_scudnn_128x32_sliced1x4_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: 4479823862704990365
[03/24/2023-12:57:22] [V] [TRT] Tactic: 4479823862704990365 Time: 0.10048
[03/24/2023-12:57:22] [V] [TRT] Conv_70 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize64x256x8_stage3_warpsize1x4x1_g1_ffma Tactic: 4517590677127196184
[03/24/2023-12:57:22] [V] [TRT] Tactic: 4517590677127196184 Time: 0.699648
[03/24/2023-12:57:22] [V] [TRT] Conv_70 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize128x128x8_stage3_warpsize2x4x1_g1_ffma_t1r3s3 Tactic: 4634080872644479428
[03/24/2023-12:57:22] [V] [TRT] Tactic: 4634080872644479428 Time: 0.356608
[03/24/2023-12:57:22] [V] [TRT] Conv_70 Set Tactic Name: ampere_scudnn_128x64_sliced1x2_ldg4_relu_exp_medium_nhwc_tn_v1 Tactic: 4696204239951173149
[03/24/2023-12:57:22] [V] [TRT] Tactic: 4696204239951173149 Time: 0.186368
[03/24/2023-12:57:22] [V] [TRT] Conv_70 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x256x32_stage3_warpsize2x4x1_g1_tensor16x8x8 Tactic: 5200329514761435342
[03/24/2023-12:57:22] [V] [TRT] Tactic: 5200329514761435342 Time: 0.116736
[03/24/2023-12:57:22] [V] [TRT] Conv_70 Set Tactic Name: ampere_scudnn_128x128_relu_exp_small_nhwc_tn_v1 Tactic: 5778138195697110003
[03/24/2023-12:57:22] [V] [TRT] Tactic: 5778138195697110003 Time: 0.350848
[03/24/2023-12:57:22] [V] [TRT] Conv_70 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize256x128x8_stage3_warpsize2x4x1_g1_ffma Tactic: 6310198979346901507
[03/24/2023-12:57:22] [V] [TRT] Tactic: 6310198979346901507 Time: 0.489216
[03/24/2023-12:57:22] [V] [TRT] Conv_70 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x256x32_stage3_warpsize2x4x1_g1_tensor16x8x8_t1r3s3 Tactic: 7011693366046809027
[03/24/2023-12:57:22] [V] [TRT] Tactic: 7011693366046809027 Time: 0.114304
[03/24/2023-12:57:22] [V] [TRT] Conv_70 Set Tactic Name: ampere_scudnn_128x128_ldg4_relu_exp_large_nhwc_tn_v1 Tactic: 7155825427510256858
[03/24/2023-12:57:22] [V] [TRT] Tactic: 7155825427510256858 Time: 0.352768
[03/24/2023-12:57:22] [V] [TRT] Conv_70 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize128x64x8_stage3_warpsize1x4x1_g1_ffma Tactic: 7222247112373541608
[03/24/2023-12:57:22] [V] [TRT] Tactic: 7222247112373541608 Time: 0.249856
[03/24/2023-12:57:22] [V] [TRT] Conv_70 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x128x16_stage4_warpsize2x2x1_g1_tensor16x8x8 Tactic: 7342025736444949634
[03/24/2023-12:57:22] [V] [TRT] Tactic: 7342025736444949634 Time: 0.077952
[03/24/2023-12:57:22] [V] [TRT] Conv_70 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize64x128x32_stage5_warpsize2x2x1_g1_tensor16x8x8 Tactic: 7347365539922924600
[03/24/2023-12:57:22] [V] [TRT] Tactic: 7347365539922924600 Time: 0.082688
[03/24/2023-12:57:22] [V] [TRT] Conv_70 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x64x32_stage5_warpsize2x2x1_g1_tensor16x8x8 Tactic: 7428197830878119671
[03/24/2023-12:57:22] [V] [TRT] Tactic: 7428197830878119671 Time: 0.053632
[03/24/2023-12:57:22] [V] [TRT] Conv_70 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize64x32x64_stage5_warpsize2x2x1_g1_tensor16x8x8_t1r3s3 Tactic: 7465323447915168822
[03/24/2023-12:57:22] [V] [TRT] Tactic: 7465323447915168822 Time: 0.045824
[03/24/2023-12:57:22] [V] [TRT] Conv_70 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize128x128x8_stage3_warpsize2x4x1_g1_ffma Tactic: 7472640475524677095
[03/24/2023-12:57:22] [V] [TRT] Tactic: 7472640475524677095 Time: 0.363392
[03/24/2023-12:57:22] [V] [TRT] Conv_70 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize64x32x64_stage5_warpsize2x2x1_g1_tensor16x8x8 Tactic: 7938223790021272801
[03/24/2023-12:57:22] [V] [TRT] Tactic: 7938223790021272801 Time: 0.04928
[03/24/2023-12:57:22] [V] [TRT] Conv_70 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize128x256x8_stage3_warpsize2x4x1_g1_ffma Tactic: 8498373915030836990
[03/24/2023-12:57:22] [V] [TRT] Tactic: 8498373915030836990 Time: 0.710272
[03/24/2023-12:57:22] [V] [TRT] Conv_70 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x64x32_stage5_warpsize2x2x1_g1_tensor16x8x8_t1r3s3 Tactic: 8836645772682419994
[03/24/2023-12:57:22] [V] [TRT] Tactic: 8836645772682419994 Time: 0.051712
[03/24/2023-12:57:22] [V] [TRT] Conv_70 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize256x64x8_stage3_warpsize1x4x1_g1_ffma Tactic: 8869697132622550639
[03/24/2023-12:57:22] [V] [TRT] Tactic: 8869697132622550639 Time: 0.276736
[03/24/2023-12:57:22] [V] [TRT] Conv_70 Set Tactic Name: ampere_scudnn_128x128_ldg4_relu_exp_medium_nhwc_tn_v1 Tactic: 8918020581761223752
[03/24/2023-12:57:22] [V] [TRT] Tactic: 8918020581761223752 Time: 0.349568
[03/24/2023-12:57:22] [V] [TRT] Conv_70 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize64x64x64_stage4_warpsize2x2x1_g1_tensor16x8x8 Tactic: -9114138070928278731
[03/24/2023-12:57:22] [V] [TRT] Tactic: -9114138070928278731 Time: 0.060928
[03/24/2023-12:57:22] [V] [TRT] Conv_70 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize256x128x8_stage3_warpsize2x4x1_g1_ffma_t1r3s3 Tactic: -8937725997228636978
[03/24/2023-12:57:22] [V] [TRT] Tactic: -8937725997228636978 Time: 0.471552
[03/24/2023-12:57:22] [V] [TRT] Conv_70 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize128x256x8_stage3_warpsize2x4x1_g1_ffma_t1r3s3 Tactic: -8833858409138163072
[03/24/2023-12:57:22] [V] [TRT] Tactic: -8833858409138163072 Time: 0.69952
[03/24/2023-12:57:22] [V] [TRT] Conv_70 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize64x64x8_stage3_warpsize1x4x1_g1_ffma_t1r3s3 Tactic: -7989138351613022500
[03/24/2023-12:57:22] [V] [TRT] Tactic: -7989138351613022500 Time: 0.155008
[03/24/2023-12:57:22] [V] [TRT] Conv_70 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize256x128x8_stage3_warpsize2x4x1_g1_ffma Tactic: -7872883691240863058
[03/24/2023-12:57:22] [V] [TRT] Tactic: -7872883691240863058 Time: 0.48896
[03/24/2023-12:57:22] [V] [TRT] Conv_70 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x256x32_stage3_warpsize2x4x1_g1_tensor16x8x8 Tactic: -7382359095196034537
[03/24/2023-12:57:22] [V] [TRT] Tactic: -7382359095196034537 Time: 0.118528
[03/24/2023-12:57:22] [V] [TRT] Conv_70 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x128x16_stage4_warpsize2x2x1_g1_tensor16x8x8_t1r3s3 Tactic: -7377458734869418330
[03/24/2023-12:57:22] [V] [TRT] Tactic: -7377458734869418330 Time: 0.070528
[03/24/2023-12:57:22] [V] [TRT] Conv_70 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize128x128x8_stage3_warpsize2x4x1_g1_ffma Tactic: -6729618519651721910
[03/24/2023-12:57:22] [V] [TRT] Tactic: -6729618519651721910 Time: 0.341504
[03/24/2023-12:57:22] [V] [TRT] Conv_70 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize256x64x32_stage3_warpsize4x2x1_g1_tensor16x8x8_t1r3s3 Tactic: -6223854811627385844
[03/24/2023-12:57:22] [V] [TRT] Tactic: -6223854811627385844 Time: 0.050688
[03/24/2023-12:57:22] [V] [TRT] Conv_70 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize256x64x8_stage3_warpsize1x4x1_g1_ffma Tactic: -5893833996418445881
[03/24/2023-12:57:22] [V] [TRT] Tactic: -5893833996418445881 Time: 0.256768
[03/24/2023-12:57:22] [V] [TRT] Conv_70 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize128x256x8_stage3_warpsize2x4x1_g1_ffma Tactic: -5701562095007058349
[03/24/2023-12:57:22] [V] [TRT] Tactic: -5701562095007058349 Time: 0.66624
[03/24/2023-12:57:22] [V] [TRT] Conv_70 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize128x64x8_stage3_warpsize1x4x1_g1_ffma Tactic: -5685503422376017600
[03/24/2023-12:57:22] [V] [TRT] Tactic: -5685503422376017600 Time: 0.2304
[03/24/2023-12:57:22] [V] [TRT] Conv_70 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize64x64x8_stage3_warpsize1x4x1_g1_ffma Tactic: -5521125187060117489
[03/24/2023-12:57:22] [V] [TRT] Tactic: -5521125187060117489 Time: 0.16064
[03/24/2023-12:57:22] [V] [TRT] Conv_70 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x128x16_stage4_warpsize2x2x1_g1_tensor16x8x8 Tactic: -5457304872213719461
[03/24/2023-12:57:22] [V] [TRT] Tactic: -5457304872213719461 Time: 0.069632
[03/24/2023-12:57:22] [V] [TRT] Conv_70 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x64x64_stage3_warpsize2x2x1_g1_tensor16x8x8 Tactic: -5441054706931585554
[03/24/2023-12:57:22] [V] [TRT] Tactic: -5441054706931585554 Time: 0.051968
[03/24/2023-12:57:22] [V] [TRT] Conv_70 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize256x64x32_stage3_warpsize4x2x1_g1_tensor16x8x8 Tactic: -5043603702497465467
[03/24/2023-12:57:22] [V] [TRT] Tactic: -5043603702497465467 Time: 0.059136
[03/24/2023-12:57:22] [V] [TRT] Conv_70 Set Tactic Name: ampere_scudnn_128x64_sliced1x2_ldg4_relu_exp_large_nhwc_tn_v1 Tactic: -4756382386362004279
[03/24/2023-12:57:22] [V] [TRT] Tactic: -4756382386362004279 Time: 0.175104
[03/24/2023-12:57:22] [V] [TRT] Conv_70 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize64x64x8_stage3_warpsize1x4x1_g1_ffma Tactic: -4615000974950361663
[03/24/2023-12:57:22] [V] [TRT] Tactic: -4615000974950361663 Time: 0.153472
[03/24/2023-12:57:22] [V] [TRT] Conv_70 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x64x64_stage3_warpsize2x2x1_g1_tensor16x8x8 Tactic: -4564655677311401797
[03/24/2023-12:57:22] [V] [TRT] Tactic: -4564655677311401797 Time: 0.05312
[03/24/2023-12:57:22] [V] [TRT] Conv_70 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize256x64x8_stage3_warpsize1x4x1_g1_ffma_t1r3s3 Tactic: -4314913710375142296
[03/24/2023-12:57:22] [V] [TRT] Tactic: -4314913710375142296 Time: 0.246912
[03/24/2023-12:57:22] [V] [TRT] Conv_70 Set Tactic Name: ampere_scudnn_128x128_relu_exp_large_nhwc_tn_v1 Tactic: -3855385237722507464
[03/24/2023-12:57:22] [V] [TRT] Tactic: -3855385237722507464 Time: 0.334848
[03/24/2023-12:57:22] [V] [TRT] Conv_70 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize128x64x8_stage3_warpsize1x4x1_g1_ffma_t1r3s3 Tactic: -3697587361057948972
[03/24/2023-12:57:22] [V] [TRT] Tactic: -3697587361057948972 Time: 0.231424
[03/24/2023-12:57:22] [V] [TRT] Conv_70 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize256x64x32_stage3_warpsize4x2x1_g1_tensor16x8x8 Tactic: -3540975627865078064
[03/24/2023-12:57:22] [V] [TRT] Tactic: -3540975627865078064 Time: 0.053888
[03/24/2023-12:57:22] [V] [TRT] Conv_70 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize64x128x32_stage5_warpsize2x2x1_g1_tensor16x8x8_t1r3s3 Tactic: -3151804561246216835
[03/24/2023-12:57:22] [V] [TRT] Tactic: -3151804561246216835 Time: 0.074752
[03/24/2023-12:57:22] [V] [TRT] Conv_70 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize64x32x64_stage5_warpsize2x2x1_g1_tensor16x8x8 Tactic: -2885165284206163001
[03/24/2023-12:57:22] [V] [TRT] Tactic: -2885165284206163001 Time: 0.048768
[03/24/2023-12:57:22] [V] [TRT] Conv_70 Set Tactic Name: ampere_scudnn_128x128_relu_exp_medium_nhwc_tn_v1 Tactic: -2809379259463049391
[03/24/2023-12:57:22] [V] [TRT] Tactic: -2809379259463049391 Time: 0.334208
[03/24/2023-12:57:22] [V] [TRT] Conv_70 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x128x32_stage4_warpsize2x2x1_g1_tensor16x8x8_t1r3s3 Tactic: -2801041895330778813
[03/24/2023-12:57:22] [V] [TRT] Tactic: -2801041895330778813 Time: 0.074496
[03/24/2023-12:57:22] [V] [TRT] Conv_70 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize64x256x8_stage3_warpsize1x4x1_g1_ffma_t1r3s3 Tactic: -2747929399988666512
[03/24/2023-12:57:22] [V] [TRT] Tactic: -2747929399988666512 Time: 0.659456
[03/24/2023-12:57:22] [V] [TRT] Conv_70 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize256x128x32_stage3_warpsize4x2x1_g1_tensor16x8x8 Tactic: -1758690179295738332
[03/24/2023-12:57:22] [V] [TRT] Tactic: -1758690179295738332 Time: 0.083968
[03/24/2023-12:57:22] [V] [TRT] Conv_70 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x64x64_stage3_warpsize2x2x1_g1_tensor16x8x8_t1r3s3 Tactic: -1484546572846226796
[03/24/2023-12:57:22] [V] [TRT] Tactic: -1484546572846226796 Time: 0.050176
[03/24/2023-12:57:22] [V] [TRT] Conv_70 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize64x256x8_stage3_warpsize1x4x1_g1_ffma Tactic: -1472061967969061456
[03/24/2023-12:57:22] [V] [TRT] Tactic: -1472061967969061456 Time: 0.676096
[03/24/2023-12:57:22] [V] [TRT] Conv_70 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x128x32_stage4_warpsize2x2x1_g1_tensor16x8x8 Tactic: -858667497925695276
[03/24/2023-12:57:22] [V] [TRT] Tactic: -858667497925695276 Time: 0.105472
[03/24/2023-12:57:22] [V] [TRT] Conv_70 Set Tactic Name: ampere_scudnn_128x128_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: -504296718212024303
[03/24/2023-12:57:22] [V] [TRT] Tactic: -504296718212024303 Time: 0.331776
[03/24/2023-12:57:22] [V] [TRT] Conv_70 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize64x128x8_stage3_warpsize1x4x1_g1_ffma Tactic: -444093195553988951
[03/24/2023-12:57:22] [V] [TRT] Tactic: -444093195553988951 Time: 0.294144
[03/24/2023-12:57:22] [V] [TRT] Fastest Tactic: 7465323447915168822 Time: 0.045824
[03/24/2023-12:57:22] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: 7465323447915168822
[03/24/2023-12:57:22] [V] [TRT] *************** Autotuning format combination: Half(16588800,32400,180,1) -> Half(97200,32400,180,1) ***************
[03/24/2023-12:57:22] [V] [TRT] --------------- Timing Runner: Conv_70 (CudnnConvolution)
[03/24/2023-12:57:22] [V] [TRT] Tactic: 0 Time: 0.361344
[03/24/2023-12:57:22] [V] [TRT] Tactic: 1 Time: 0.150656
[03/24/2023-12:57:22] [V] [TRT] Tactic: 2 Time: 0.431872
[03/24/2023-12:57:22] [V] [TRT] Tactic: 4 Time: 0.415488
[03/24/2023-12:57:22] [V] [TRT] Tactic: 5 Time: 0.434176
[03/24/2023-12:57:22] [V] [TRT] Tactic: 6 Time: 0.3936
[03/24/2023-12:57:22] [V] [TRT] Tactic: 56 Time: 0.361728
[03/24/2023-12:57:22] [V] [TRT] Tactic: 58 Time: 0.432
[03/24/2023-12:57:22] [V] [TRT] Tactic: 60 Time: 0.416384
[03/24/2023-12:57:22] [V] [TRT] Tactic: 61 Time: 0.44352
[03/24/2023-12:57:22] [V] [TRT] Tactic: 62 Time: 0.393856
[03/24/2023-12:57:22] [V] [TRT] Fastest Tactic: 1 Time: 0.150656
[03/24/2023-12:57:22] [V] [TRT] --------------- Timing Runner: Conv_70 (CaskConvolution)
[03/24/2023-12:57:22] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[03/24/2023-12:57:22] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CudnnConvolution Tactic: 1
[03/24/2023-12:57:22] [V] [TRT] *************** Autotuning format combination: Half(8294400,32400:2,180,1) -> Half(64800,32400:2,180,1) ***************
[03/24/2023-12:57:22] [V] [TRT] --------------- Timing Runner: Conv_70 (FusedConvActConvolution)
[03/24/2023-12:57:22] [V] [TRT] Tactic: 524287 Time: 0.04992
[03/24/2023-12:57:22] [V] [TRT] Tactic: 1048575 Time: 0.04608
[03/24/2023-12:57:22] [V] [TRT] Tactic: 1703935 Time: 0.045312
[03/24/2023-12:57:22] [V] [TRT] Tactic: 2228223 Time: 0.062208
[03/24/2023-12:57:22] [V] [TRT] Tactic: 2424831 Time: 0.064384
[03/24/2023-12:57:22] [V] [TRT] Tactic: 2621439 Time: 0.046848
[03/24/2023-12:57:23] [V] [TRT] Tactic: 3014655 Time: 0.04736
[03/24/2023-12:57:23] [V] [TRT] Tactic: 3604479 Time: 0.047104
[03/24/2023-12:57:23] [V] [TRT] Tactic: 5046271 Time: 0.047744
[03/24/2023-12:57:23] [V] [TRT] Tactic: 6160383 Time: 0.050048
[03/24/2023-12:57:23] [V] [TRT] Tactic: 6488063 Time: 0.055168
[03/24/2023-12:57:23] [V] [TRT] Tactic: 7864319 Time: 0.050688
[03/24/2023-12:57:23] [V] [TRT] Tactic: 8585215 Time: 0.058624
[03/24/2023-12:57:23] [V] [TRT] Tactic: 8847359 Time: 0.050944
[03/24/2023-12:57:23] [V] [TRT] Tactic: 9043967 Time: 0.047232
[03/24/2023-12:57:23] [V] [TRT] Tactic: 9175039 Time: 0.046976
[03/24/2023-12:57:23] [V] [TRT] Tactic: 9961471 Time: 0.06144
[03/24/2023-12:57:23] [V] [TRT] Tactic: 10027007 Time: 0.048
[03/24/2023-12:57:23] [V] [TRT] Tactic: 10485759 Time: 0.044032
[03/24/2023-12:57:23] [V] [TRT] Tactic: 10682367 Time: 0.049152
[03/24/2023-12:57:23] [V] [TRT] Fastest Tactic: 10485759 Time: 0.044032
[03/24/2023-12:57:23] [V] [TRT] --------------- Timing Runner: Conv_70 (CudnnConvolution)
[03/24/2023-12:57:23] [V] [TRT] CudnnConvolution has no valid tactics for this config, skipping
[03/24/2023-12:57:23] [V] [TRT] --------------- Timing Runner: Conv_70 (CaskConvolution)
[03/24/2023-12:57:23] [V] [TRT] Conv_70 Set Tactic Name: ampere_fp16x2_hcudnn_fp16x2_128x32_relu_medium_nn_v1 Tactic: 2195670545862694453
[03/24/2023-12:57:23] [V] [TRT] Tactic: 2195670545862694453 Time: 0.073472
[03/24/2023-12:57:23] [V] [TRT] Conv_70 Set Tactic Name: ampere_fp16x2_hcudnn_fp16x2_128x64_relu_large_nn_v1 Tactic: 3419182076704469245
[03/24/2023-12:57:23] [V] [TRT] Tactic: 3419182076704469245 Time: 0.101376
[03/24/2023-12:57:23] [V] [TRT] Conv_70 Set Tactic Name: ampere_fp16x2_hcudnn_fp16x2_128x128_relu_medium_nn_v1 Tactic: 3891805945559659536
[03/24/2023-12:57:23] [V] [TRT] Tactic: 3891805945559659536 Time: 0.182656
[03/24/2023-12:57:23] [V] [TRT] Conv_70 Set Tactic Name: ampere_fp16x2_hcudnn_fp16x2_128x64_relu_medium_nn_v1 Tactic: 5548126322150286555
[03/24/2023-12:57:23] [V] [TRT] Tactic: 5548126322150286555 Time: 0.10048
[03/24/2023-12:57:23] [V] [TRT] Conv_70 Set Tactic Name: ampere_fp16x2_hcudnn_fp16x2_128x64_relu_small_nn_v1 Tactic: 6057304366605292508
[03/24/2023-12:57:23] [V] [TRT] Tactic: 6057304366605292508 Time: 0.098432
[03/24/2023-12:57:23] [V] [TRT] Conv_70 Set Tactic Name: ampere_fp16x2_hcudnn_fp16x2_128x128_relu_large_nn_v1 Tactic: -7928611605886347652
[03/24/2023-12:57:23] [V] [TRT] Tactic: -7928611605886347652 Time: 0.188032
[03/24/2023-12:57:23] [V] [TRT] Conv_70 Set Tactic Name: ampere_fp16x2_hcudnn_fp16x2_128x32_relu_large_nn_v1 Tactic: -5172391392092686714
[03/24/2023-12:57:23] [V] [TRT] Tactic: -5172391392092686714 Time: 0.07424
[03/24/2023-12:57:23] [V] [TRT] Conv_70 Set Tactic Name: ampere_fp16x2_hcudnn_fp16x2_128x32_relu_small_nn_v1 Tactic: -4374269919094467161
[03/24/2023-12:57:23] [V] [TRT] Tactic: -4374269919094467161 Time: 0.07168
[03/24/2023-12:57:23] [V] [TRT] Conv_70 Set Tactic Name: ampere_fp16x2_hcudnn_winograd_fp16x2_128x128_ldg1_ldg4_relu_tile148t_nt_v1 Tactic: -4083394051665370953
[03/24/2023-12:57:23] [V] [TRT] Tactic: -4083394051665370953 Time: 0.032384
[03/24/2023-12:57:23] [V] [TRT] Conv_70 Set Tactic Name: ampere_fp16x2_hcudnn_fp16x2_128x128_relu_small_nn_v1 Tactic: -1546027692247304867
[03/24/2023-12:57:23] [V] [TRT] Tactic: -1546027692247304867 Time: 0.183296
[03/24/2023-12:57:23] [V] [TRT] Fastest Tactic: -4083394051665370953 Time: 0.032384
[03/24/2023-12:57:23] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: -4083394051665370953
[03/24/2023-12:57:23] [V] [TRT] *************** Autotuning format combination: Half(2073600,1:8,11520,64) -> Float(97200,32400,180,1) ***************
[03/24/2023-12:57:23] [V] [TRT] --------------- Timing Runner: Conv_70 (CudnnConvolution)
[03/24/2023-12:57:23] [V] [TRT] CudnnConvolution has no valid tactics for this config, skipping
[03/24/2023-12:57:23] [V] [TRT] --------------- Timing Runner: Conv_70 (CaskConvolution)
[03/24/2023-12:57:23] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[03/24/2023-12:57:23] [V] [TRT] *************** Autotuning format combination: Half(2073600,1:8,11520,64) -> Half(32400,1:8,180,1) ***************
[03/24/2023-12:57:23] [V] [TRT] --------------- Timing Runner: Conv_70 (CudaDepthwiseConvolution)
[03/24/2023-12:57:23] [V] [TRT] CudaDepthwiseConvolution has no valid tactics for this config, skipping
[03/24/2023-12:57:23] [V] [TRT] --------------- Timing Runner: Conv_70 (CudnnConvolution)
[03/24/2023-12:57:23] [V] [TRT] CudnnConvolution has no valid tactics for this config, skipping
[03/24/2023-12:57:23] [V] [TRT] --------------- Timing Runner: Conv_70 (CaskConvolution)
[03/24/2023-12:57:23] [V] [TRT] Conv_70 Set Tactic Name: ampere_h16816cudnn_256x128_ldg8_relu_exp_medium_nhwc_tn_v1 Tactic: 254850674756030979
[03/24/2023-12:57:23] [V] [TRT] Tactic: 254850674756030979 Time: 0.045184
[03/24/2023-12:57:23] [V] [TRT] Conv_70 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x128x32_stage3_warpsize4x2x1_g1_tensor16x8x16_t1r3s3 Tactic: 328038211831149625
[03/24/2023-12:57:23] [V] [TRT] Tactic: 328038211831149625 Time: 0.043776
[03/24/2023-12:57:23] [V] [TRT] Conv_70 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x64x64_stage3_warpsize2x2x1_g1_tensor16x8x16_t1r3s3 Tactic: 411553864378931917
[03/24/2023-12:57:23] [V] [TRT] Tactic: 411553864378931917 Time: 0.024448
[03/24/2023-12:57:23] [V] [TRT] Conv_70 Set Tactic Name: sm75_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x128x32_stage1_warpsize4x2x1_g1_tensor16x8x8_t1r3s3 Tactic: 864841579020773074
[03/24/2023-12:57:23] [V] [TRT] Tactic: 864841579020773074 Time: 0.050048
[03/24/2023-12:57:23] [V] [TRT] Conv_70 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x128x32_stage4_warpsize2x2x1_g1_tensor16x8x16 Tactic: 1011057357468998345
[03/24/2023-12:57:23] [V] [TRT] Tactic: 1011057357468998345 Time: 0.037376
[03/24/2023-12:57:23] [V] [TRT] Conv_70 Set Tactic Name: sm75_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x64x32_stage1_warpsize4x1x1_g1_tensor16x8x8 Tactic: 1013168150133367738
[03/24/2023-12:57:23] [V] [TRT] Tactic: 1013168150133367738 Time: 0.033792
[03/24/2023-12:57:23] [V] [TRT] Conv_70 Set Tactic Name: ampere_h16816cudnn_256x128_ldg8_relu_exp_stages_64x3_small_nhwc_tn_v1 Tactic: 1016009564074305832
[03/24/2023-12:57:23] [V] [TRT] Tactic: 1016009564074305832 Time: 0.045184
[03/24/2023-12:57:23] [V] [TRT] Conv_70 Set Tactic Name: sm75_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x128x32_stage1_warpsize2x2x1_g1_tensor16x8x8 Tactic: 1067227531433278814
[03/24/2023-12:57:23] [V] [TRT] Tactic: 1067227531433278814 Time: 0.041472
[03/24/2023-12:57:23] [V] [TRT] Conv_70 Set Tactic Name: ampere_h1688cudnn_128x128_ldg8_relu_exp_medium_nhwc_tn_v1 Tactic: 1156328698016730421
[03/24/2023-12:57:23] [V] [TRT] Tactic: 1156328698016730421 Time: 0.050048
[03/24/2023-12:57:23] [V] [TRT] Conv_70 Set Tactic Name: sm75_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x128x32_stage1_warpsize2x2x1_g1_tensor16x8x8 Tactic: 1579845938601132607
[03/24/2023-12:57:23] [V] [TRT] Tactic: 1579845938601132607 Time: 0.04096
[03/24/2023-12:57:23] [V] [TRT] Conv_70 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x128x32_stage5_warpsize2x2x1_g1_tensor16x8x16_t1r3s3 Tactic: 1723736032573714698
[03/24/2023-12:57:23] [V] [TRT] Tactic: 1723736032573714698 Time: 0.036224
[03/24/2023-12:57:23] [V] [TRT] Conv_70 Set Tactic Name: sm75_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x32x32_stage1_warpsize4x1x1_g1_tensor16x8x8 Tactic: 1796821236841789338
[03/24/2023-12:57:23] [V] [TRT] Tactic: 1796821236841789338 Time: 0.0256
[03/24/2023-12:57:23] [V] [TRT] Conv_70 Set Tactic Name: ampere_h16816cudnn_128x64_ldg8_relu_exp_stages_64x4_medium_nhwc_tn_v1 Tactic: 1832046141070096030
[03/24/2023-12:57:23] [V] [TRT] Tactic: 1832046141070096030 Time: 0.030848
[03/24/2023-12:57:23] [V] [TRT] Conv_70 Set Tactic Name: ampere_h16816cudnn_128x64_sliced1x2_ldg8_relu_exp_stages_64x3_small_nhwc_tn_v1 Tactic: 1838082074606840426
[03/24/2023-12:57:23] [V] [TRT] Tactic: 1838082074606840426 Time: 0.026496
[03/24/2023-12:57:23] [V] [TRT] Conv_70 Set Tactic Name: ampere_h16816cudnn_64x64_sliced1x2_ldg8_relu_exp_stages_64x5_small_nhwc_tn_v1 Tactic: 1899296423087490472
[03/24/2023-12:57:23] [V] [TRT] Tactic: 1899296423087490472 Time: 0.031872
[03/24/2023-12:57:23] [V] [TRT] Conv_70 Set Tactic Name: sm75_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x32x32_stage1_warpsize4x1x1_g1_tensor16x8x8 Tactic: 1948263663414159978
[03/24/2023-12:57:23] [V] [TRT] Tactic: 1948263663414159978 Time: 0.028416
[03/24/2023-12:57:23] [V] [TRT] Conv_70 Set Tactic Name: sm75_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x256x64_stage1_warpsize1x4x2_g1_tensor16x8x8 Tactic: 2027733232253711640
[03/24/2023-12:57:23] [V] [TRT] Tactic: 2027733232253711640 Time: 0.070656
[03/24/2023-12:57:23] [V] [TRT] Conv_70 Set Tactic Name: sm75_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x64x32_stage1_warpsize2x2x1_g1_tensor16x8x8_t1r3s3 Tactic: 2154731107061273008
[03/24/2023-12:57:23] [V] [TRT] Tactic: 2154731107061273008 Time: 0.02944
[03/24/2023-12:57:23] [V] [TRT] Conv_70 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x64x64_stage3_warpsize2x2x1_g1_tensor16x8x16 Tactic: 2428167804343994714
[03/24/2023-12:57:23] [V] [TRT] Tactic: 2428167804343994714 Time: 0.025856
[03/24/2023-12:57:23] [V] [TRT] Conv_70 Set Tactic Name: ampere_h16816cudnn_128x128_ldg8_relu_exp_medium_nhwc_tn_v1 Tactic: 2541579301352125276
[03/24/2023-12:57:23] [V] [TRT] Tactic: 2541579301352125276 Time: 0.0352
[03/24/2023-12:57:23] [V] [TRT] Conv_70 Set Tactic Name: ampere_h16816cudnn_64x64_sliced1x2_ldg8_relu_exp_stages_64x6_small_nhwc_tn_v1 Tactic: 2657157263811141609
[03/24/2023-12:57:23] [V] [TRT] Tactic: 2657157263811141609 Time: 0.036864
[03/24/2023-12:57:23] [V] [TRT] Conv_70 Set Tactic Name: ampere_h16816cudnn_64x128_sliced1x2_ldg8_relu_exp_stages_64x4_large_nhwc_tn_v1 Tactic: 2819719497590964443
[03/24/2023-12:57:23] [V] [TRT] Tactic: 2819719497590964443 Time: 0.048896
[03/24/2023-12:57:23] [V] [TRT] Conv_70 Set Tactic Name: ampere_h16816cudnn_128x64_sliced1x2_ldg8_relu_exp_stages_64x3_medium_nhwc_tn_v1 Tactic: 2968605903460894194
[03/24/2023-12:57:23] [V] [TRT] Tactic: 2968605903460894194 Time: 0.026496
[03/24/2023-12:57:23] [V] [TRT] Conv_70 Set Tactic Name: ampere_h16816cudnn_128x128_ldg8_relu_exp_large_nhwc_tn_v1 Tactic: 2986078304285316765
[03/24/2023-12:57:23] [V] [TRT] Tactic: 2986078304285316765 Time: 0.035328
[03/24/2023-12:57:23] [V] [TRT] Conv_70 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x256x64_stage3_warpsize1x4x1_g1_tensor16x8x16 Tactic: 3016308193087082166
[03/24/2023-12:57:23] [V] [TRT] Tactic: 3016308193087082166 Time: 0.065536
[03/24/2023-12:57:23] [V] [TRT] Conv_70 Set Tactic Name: ampere_h16816cudnn_256x64_ldg8_relu_exp_stages_64x3_large_nhwc_tn_v1 Tactic: 3221382575080507859
[03/24/2023-12:57:23] [V] [TRT] Tactic: 3221382575080507859 Time: 0.03072
[03/24/2023-12:57:23] [V] [TRT] Conv_70 Set Tactic Name: ampere_h16816cudnn_128x128_ldg8_relu_exp_stages_64x3_medium_nhwc_tn_v1 Tactic: 3362537467505018070
[03/24/2023-12:57:23] [V] [TRT] Tactic: 3362537467505018070 Time: 0.040832
[03/24/2023-12:57:23] [V] [TRT] Conv_70 Set Tactic Name: sm75_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x64x32_stage1_warpsize4x1x1_g1_tensor16x8x8_t1r3s3 Tactic: 3464689803495983377
[03/24/2023-12:57:23] [V] [TRT] Tactic: 3464689803495983377 Time: 0.032512
[03/24/2023-12:57:23] [V] [TRT] Conv_70 Set Tactic Name: ampere_h1688cudnn_256x128_ldg8_relu_exp_medium_nhwc_tn_v1 Tactic: 3513075359009385578
[03/24/2023-12:57:23] [V] [TRT] Tactic: 3513075359009385578 Time: 0.053248
[03/24/2023-12:57:23] [V] [TRT] Conv_70 Set Tactic Name: ampere_h16816cudnn_128x64_ldg8_relu_exp_stages_64x4_large_nhwc_tn_v1 Tactic: 3573559043797674382
[03/24/2023-12:57:23] [V] [TRT] Tactic: 3573559043797674382 Time: 0.031744
[03/24/2023-12:57:23] [V] [TRT] Conv_70 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x64x64_stage4_warpsize2x2x1_g1_tensor16x8x16_t1r3s3 Tactic: 3591970081995419777
[03/24/2023-12:57:23] [V] [TRT] Tactic: 3591970081995419777 Time: 0.028544
[03/24/2023-12:57:23] [V] [TRT] Conv_70 Set Tactic Name: sm75_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x128x32_stage1_warpsize2x2x1_g1_tensor16x8x8_t1r3s3 Tactic: 3636831327753843771
[03/24/2023-12:57:23] [V] [TRT] Tactic: 3636831327753843771 Time: 0.038144
[03/24/2023-12:57:23] [V] [TRT] Conv_70 Set Tactic Name: ampere_h1688cudnn_128x128_ldg8_relu_exp_small_nhwc_tn_v1 Tactic: 3704534001553878387
[03/24/2023-12:57:23] [V] [TRT] Tactic: 3704534001553878387 Time: 0.045952
[03/24/2023-12:57:23] [V] [TRT] Conv_70 Set Tactic Name: ampere_h16816cudnn_64x128_ldg8_relu_exp_stages_64x4_small_nhwc_tn_v1 Tactic: 4278315135102886928
[03/24/2023-12:57:23] [V] [TRT] Tactic: 4278315135102886928 Time: 0.043008
[03/24/2023-12:57:23] [V] [TRT] Conv_70 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x32x32_stage4_warpsize4x1x1_g1_tensor16x8x16_t1r3s3 Tactic: 4503233883285355107
[03/24/2023-12:57:23] [V] [TRT] Tactic: 4503233883285355107 Time: 0.020224
[03/24/2023-12:57:23] [V] [TRT] Conv_70 Set Tactic Name: ampere_h16816cudnn_256x64_ldg8_relu_exp_stages_64x3_medium_nhwc_tn_v1 Tactic: 4540505769798915372
[03/24/2023-12:57:23] [V] [TRT] Tactic: 4540505769798915372 Time: 0.03072
[03/24/2023-12:57:23] [V] [TRT] Conv_70 Set Tactic Name: ampere_h16816cudnn_256x64_sliced1x2_ldg8_relu_exp_small_nhwc_tn_v1 Tactic: 4802447371470387646
[03/24/2023-12:57:23] [V] [TRT] Tactic: 4802447371470387646 Time: 0.03264
[03/24/2023-12:57:23] [V] [TRT] Conv_70 Set Tactic Name: ampere_h16816cudnn_256x128_ldg8_relu_exp_small_nhwc_tn_v1 Tactic: 5059676457552313631
[03/24/2023-12:57:23] [V] [TRT] Tactic: 5059676457552313631 Time: 0.0448
[03/24/2023-12:57:23] [V] [TRT] Conv_70 Set Tactic Name: sm75_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x128x64_stage1_warpsize2x2x1_g1_tensor16x8x8_t1r3s3 Tactic: 5263029549013613567
[03/24/2023-12:57:23] [V] [TRT] Tactic: 5263029549013613567 Time: 0.038784
[03/24/2023-12:57:23] [V] [TRT] Conv_70 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x64x64_stage4_warpsize2x2x1_g1_tensor16x8x16 Tactic: 5368829646735632944
[03/24/2023-12:57:23] [V] [TRT] Tactic: 5368829646735632944 Time: 0.030208
[03/24/2023-12:57:23] [V] [TRT] Conv_70 Set Tactic Name: ampere_h1688cudnn_256x64_sliced1x2_ldg8_relu_exp_small_nhwc_tn_v1 Tactic: 5398999388616959893
[03/24/2023-12:57:23] [V] [TRT] Tactic: 5398999388616959893 Time: 0.035712
[03/24/2023-12:57:23] [V] [TRT] Conv_70 Set Tactic Name: sm75_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x256x32_stage1_warpsize2x4x1_g1_tensor16x8x8_t1r3s3 Tactic: 5506334059535811602
[03/24/2023-12:57:23] [V] [TRT] Tactic: 5506334059535811602 Time: 0.068864
[03/24/2023-12:57:23] [V] [TRT] Conv_70 Set Tactic Name: ampere_h16816cudnn_64x128_sliced1x2_ldg8_relu_exp_stages_64x3_large_nhwc_tn_v1 Tactic: 5746691132547383910
[03/24/2023-12:57:23] [V] [TRT] Tactic: 5746691132547383910 Time: 0.036736
[03/24/2023-12:57:23] [V] [TRT] Conv_70 Set Tactic Name: ampere_h16816cudnn_256x64_ldg8_relu_exp_large_nhwc_tn_v1 Tactic: 5770170567977052602
[03/24/2023-12:57:23] [V] [TRT] Tactic: 5770170567977052602 Time: 0.031744
[03/24/2023-12:57:23] [V] [TRT] Conv_70 Set Tactic Name: sm75_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x32x64_stage1_warpsize2x1x2_g1_tensor16x8x8_t1r3s3 Tactic: 5932046018238429951
[03/24/2023-12:57:23] [V] [TRT] Tactic: 5932046018238429951 Time: 0.022016
[03/24/2023-12:57:23] [V] [TRT] Conv_70 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x64x32_stage3_warpsize4x1x1_g1_tensor16x8x16_t1r3s3 Tactic: 5953552212833506549
[03/24/2023-12:57:23] [V] [TRT] Tactic: 5953552212833506549 Time: 0.027008
[03/24/2023-12:57:23] [V] [TRT] Conv_70 Set Tactic Name: ampere_h16816cudnn_64x128_ldg8_relu_exp_stages_64x3_small_nhwc_tn_v1 Tactic: 6034364043891107501
[03/24/2023-12:57:23] [V] [TRT] Tactic: 6034364043891107501 Time: 0.037888
[03/24/2023-12:57:23] [V] [TRT] Conv_70 Set Tactic Name: ampere_h16816cudnn_64x64_ldg8_relu_exp_stages_64x5_large_nhwc_tn_v1 Tactic: 6074229447555668232
[03/24/2023-12:57:23] [V] [TRT] Tactic: 6074229447555668232 Time: 0.033792
[03/24/2023-12:57:23] [V] [TRT] Conv_70 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x64x64_stage3_warpsize2x2x1_g1_tensor16x8x16 Tactic: 6154447660803990543
[03/24/2023-12:57:23] [V] [TRT] Tactic: 6154447660803990543 Time: 0.025472
[03/24/2023-12:57:23] [V] [TRT] Conv_70 Set Tactic Name: sm75_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x32x64_stage1_warpsize2x1x2_g1_tensor16x8x8 Tactic: 6195603576432354734
[03/24/2023-12:57:23] [V] [TRT] Tactic: 6195603576432354734 Time: 0.024448
[03/24/2023-12:57:23] [V] [TRT] Conv_70 Set Tactic Name: sm75_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x32x32_stage1_warpsize4x1x1_g1_tensor16x8x8_t1r3s3 Tactic: 6252808259936499253
[03/24/2023-12:57:23] [V] [TRT] Tactic: 6252808259936499253 Time: 0.027904
[03/24/2023-12:57:23] [V] [TRT] Conv_70 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x128x64_stage3_warpsize2x2x1_g1_tensor16x8x16 Tactic: 6325769668000961702
[03/24/2023-12:57:23] [V] [TRT] Tactic: 6325769668000961702 Time: 0.04224
[03/24/2023-12:57:23] [V] [TRT] Conv_70 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x32x64_stage5_warpsize2x2x1_g1_tensor16x8x16 Tactic: 6350273239113254096
[03/24/2023-12:57:23] [V] [TRT] Tactic: 6350273239113254096 Time: 0.026496
[03/24/2023-12:57:23] [V] [TRT] Conv_70 Set Tactic Name: ampere_h16816cudnn_128x128_ldg8_relu_exp_stages_64x3_small_nhwc_tn_v1 Tactic: 6377497238381488891
[03/24/2023-12:57:23] [V] [TRT] Tactic: 6377497238381488891 Time: 0.040192
[03/24/2023-12:57:23] [V] [TRT] Conv_70 Set Tactic Name: sm75_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x64x64_stage1_warpsize2x2x1_g1_tensor16x8x8 Tactic: 6408235920257988861
[03/24/2023-12:57:23] [V] [TRT] Tactic: 6408235920257988861 Time: 0.028416
[03/24/2023-12:57:23] [V] [TRT] Conv_70 Set Tactic Name: ampere_h16816cudnn_128x64_ldg8_relu_exp_stages_64x3_large_nhwc_tn_v1 Tactic: 6446388116965632819
[03/24/2023-12:57:23] [V] [TRT] Tactic: 6446388116965632819 Time: 0.028544
[03/24/2023-12:57:23] [V] [TRT] Conv_70 Set Tactic Name: ampere_h16816cudnn_128x64_sliced1x2_ldg8_relu_exp_stages_64x4_medium_nhwc_tn_v1 Tactic: 6468794451065529747
[03/24/2023-12:57:23] [V] [TRT] Tactic: 6468794451065529747 Time: 0.031744
[03/24/2023-12:57:23] [V] [TRT] Conv_70 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x128x64_stage3_warpsize4x2x1_g1_tensor16x8x16 Tactic: 6509152032538119080
[03/24/2023-12:57:23] [V] [TRT] Tactic: 6509152032538119080 Time: 0.046336
[03/24/2023-12:57:23] [V] [TRT] Conv_70 Set Tactic Name: ampere_h1688cudnn_256x128_ldg8_relu_exp_large_nhwc_tn_v1 Tactic: 6642277870194067185
[03/24/2023-12:57:23] [V] [TRT] Tactic: 6642277870194067185 Time: 0.053888
[03/24/2023-12:57:23] [V] [TRT] Conv_70 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x256x64_stage3_warpsize1x4x1_g1_tensor16x8x16 Tactic: 6703181542003057635
[03/24/2023-12:57:23] [V] [TRT] Tactic: 6703181542003057635 Time: 0.064512
[03/24/2023-12:57:23] [V] [TRT] Conv_70 Set Tactic Name: ampere_h16816cudnn_64x64_ldg8_relu_exp_stages_64x5_medium_nhwc_tn_v1 Tactic: 6859477213531075460
[03/24/2023-12:57:23] [V] [TRT] Tactic: 6859477213531075460 Time: 0.033024
[03/24/2023-12:57:23] [V] [TRT] Conv_70 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x128x32_stage4_warpsize2x2x1_g1_tensor16x8x16_t1r3s3 Tactic: 6972489290272968208
[03/24/2023-12:57:23] [V] [TRT] Tactic: 6972489290272968208 Time: 0.033664
[03/24/2023-12:57:23] [V] [TRT] Conv_70 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x128x32_stage3_warpsize4x2x1_g1_tensor16x8x16 Tactic: 6979044990896381511
[03/24/2023-12:57:23] [V] [TRT] Tactic: 6979044990896381511 Time: 0.044032
[03/24/2023-12:57:23] [V] [TRT] Conv_70 Set Tactic Name: ampere_h1688cudnn_256x64_ldg8_relu_exp_medium_nhwc_tn_v1 Tactic: 7216571380637776659
[03/24/2023-12:57:23] [V] [TRT] Tactic: 7216571380637776659 Time: 0.035584
[03/24/2023-12:57:23] [V] [TRT] Conv_70 Set Tactic Name: ampere_h16816cudnn_128x64_ldg8_relu_exp_stages_64x3_medium_nhwc_tn_v1 Tactic: 7609923741161019135
[03/24/2023-12:57:23] [V] [TRT] Tactic: 7609923741161019135 Time: 0.028416
[03/24/2023-12:57:23] [V] [TRT] Conv_70 Set Tactic Name: sm75_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x64x32_stage1_warpsize2x2x1_g1_tensor16x8x8 Tactic: 7612687199567064086
[03/24/2023-12:57:23] [V] [TRT] Tactic: 7612687199567064086 Time: 0.030976
[03/24/2023-12:57:23] [V] [TRT] Conv_70 Set Tactic Name: ampere_h16816cudnn_64x64_ldg8_relu_exp_stages_64x6_large_nhwc_tn_v1 Tactic: 7705739241028240201
[03/24/2023-12:57:23] [V] [TRT] Tactic: 7705739241028240201 Time: 0.03904
[03/24/2023-12:57:23] [V] [TRT] Conv_70 Set Tactic Name: sm75_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x128x32_stage1_warpsize2x2x1_g1_tensor16x8x8 Tactic: 7729555994715864793
[03/24/2023-12:57:23] [V] [TRT] Tactic: 7729555994715864793 Time: 0.040832
[03/24/2023-12:57:23] [V] [TRT] Conv_70 Set Tactic Name: sm75_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x64x64_stage1_warpsize2x2x1_g1_tensor16x8x8_t1r3s3 Tactic: 7849296535223586261
[03/24/2023-12:57:23] [V] [TRT] Tactic: 7849296535223586261 Time: 0.028288
[03/24/2023-12:57:23] [V] [TRT] Conv_70 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x256x32_stage3_warpsize2x4x1_g1_tensor16x8x16 Tactic: 8072087735545283117
[03/24/2023-12:57:23] [V] [TRT] Tactic: 8072087735545283117 Time: 0.061184
[03/24/2023-12:57:23] [V] [TRT] Conv_70 Set Tactic Name: ampere_h16816cudnn_64x64_sliced1x2_ldg8_relu_exp_stages_64x5_medium_nhwc_tn_v1 Tactic: 8101703987960976805
[03/24/2023-12:57:23] [V] [TRT] Tactic: 8101703987960976805 Time: 0.031104
[03/24/2023-12:57:23] [V] [TRT] Conv_70 Set Tactic Name: ampere_h16816cudnn_128x64_sliced1x2_ldg8_relu_exp_stages_64x4_small_nhwc_tn_v1 Tactic: 8170606396342855895
[03/24/2023-12:57:23] [V] [TRT] Tactic: 8170606396342855895 Time: 0.03072
[03/24/2023-12:57:23] [V] [TRT] Conv_70 Set Tactic Name: sm75_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x32x64_stage1_warpsize2x1x2_g1_tensor16x8x8 Tactic: 8455608235315878803
[03/24/2023-12:57:23] [V] [TRT] Tactic: 8455608235315878803 Time: 0.025472
[03/24/2023-12:57:23] [V] [TRT] Conv_70 Set Tactic Name: sm75_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x64x64_stage1_warpsize2x2x1_g1_tensor16x8x8 Tactic: 8668812313058150080
[03/24/2023-12:57:23] [V] [TRT] Tactic: 8668812313058150080 Time: 0.029696
[03/24/2023-12:57:23] [V] [TRT] Conv_70 Set Tactic Name: ampere_h1688cudnn_256x64_ldg8_relu_exp_small_nhwc_tn_v1 Tactic: 8839784824303350101
[03/24/2023-12:57:23] [V] [TRT] Tactic: 8839784824303350101 Time: 0.033664
[03/24/2023-12:57:23] [V] [TRT] Conv_70 Set Tactic Name: ampere_h16816cudnn_64x64_sliced1x2_ldg8_relu_exp_stages_64x5_large_nhwc_tn_v1 Tactic: -9217371357561775773
[03/24/2023-12:57:23] [V] [TRT] Tactic: -9217371357561775773 Time: 0.030592
[03/24/2023-12:57:23] [V] [TRT] Conv_70 Set Tactic Name: ampere_h16816cudnn_256x64_sliced1x2_ldg8_relu_exp_medium_nhwc_tn_v1 Tactic: -9009272790678027912
[03/24/2023-12:57:23] [V] [TRT] Tactic: -9009272790678027912 Time: 0.035712
[03/24/2023-12:57:23] [V] [TRT] Conv_70 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x32x32_stage4_warpsize4x1x1_g1_tensor16x8x16 Tactic: -8985224497679592364
[03/24/2023-12:57:23] [V] [TRT] Tactic: -8985224497679592364 Time: 0.020352
[03/24/2023-12:57:23] [V] [TRT] Conv_70 Set Tactic Name: ampere_h16816cudnn_128x64_sliced1x2_ldg8_relu_exp_stages_64x3_large_nhwc_tn_v1 Tactic: -8949544755481315679
[03/24/2023-12:57:23] [V] [TRT] Tactic: -8949544755481315679 Time: 0.026624
[03/24/2023-12:57:23] [V] [TRT] Conv_70 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x64x64_stage3_warpsize4x1x1_g1_tensor16x8x16_t1r3s3 Tactic: -8867999442759527766
[03/24/2023-12:57:23] [V] [TRT] Tactic: -8867999442759527766 Time: 0.03264
[03/24/2023-12:57:23] [V] [TRT] Conv_70 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x128x64_stage3_warpsize2x2x1_g1_tensor16x8x16 Tactic: -8759929675070720385
[03/24/2023-12:57:23] [V] [TRT] Tactic: -8759929675070720385 Time: 0.040832
[03/24/2023-12:57:23] [V] [TRT] Conv_70 Set Tactic Name: ampere_h16816cudnn_64x64_ldg8_relu_exp_stages_64x6_medium_nhwc_tn_v1 Tactic: -8604374562669615024
[03/24/2023-12:57:23] [V] [TRT] Tactic: -8604374562669615024 Time: 0.038272
[03/24/2023-12:57:23] [V] [TRT] Conv_70 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x128x64_stage3_warpsize4x2x1_g1_tensor16x8x16 Tactic: -8362347876645295759
[03/24/2023-12:57:23] [V] [TRT] Tactic: -8362347876645295759 Time: 0.044928
[03/24/2023-12:57:23] [V] [TRT] Conv_70 Set Tactic Name: sm75_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x128x32_stage1_warpsize4x2x1_g1_tensor16x8x8 Tactic: -8254009616492665198
[03/24/2023-12:57:23] [V] [TRT] Tactic: -8254009616492665198 Time: 0.050048
[03/24/2023-12:57:23] [V] [TRT] Conv_70 Set Tactic Name: ampere_h16816cudnn_256x128_ldg8_relu_exp_stages_64x3_large_nhwc_tn_v1 Tactic: -7757610000269494813
[03/24/2023-12:57:23] [V] [TRT] Tactic: -7757610000269494813 Time: 0.045952
[03/24/2023-12:57:23] [V] [TRT] Conv_70 Set Tactic Name: sm75_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x128x32_stage1_warpsize4x2x1_g1_tensor16x8x8 Tactic: -7615325597099025933
[03/24/2023-12:57:23] [V] [TRT] Tactic: -7615325597099025933 Time: 0.0512
[03/24/2023-12:57:23] [V] [TRT] Conv_70 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x64x64_stage3_warpsize4x1x1_g1_tensor16x8x16 Tactic: -6917689122519989488
[03/24/2023-12:57:23] [V] [TRT] Tactic: -6917689122519989488 Time: 0.031488
[03/24/2023-12:57:23] [V] [TRT] Conv_70 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x32x64_stage5_warpsize2x2x1_g1_tensor16x8x16_t1r3s3 Tactic: -6902925267326201166
[03/24/2023-12:57:23] [V] [TRT] Tactic: -6902925267326201166 Time: 0.025472
[03/24/2023-12:57:23] [V] [TRT] Conv_70 Set Tactic Name: ampere_h16816cudnn_64x128_ldg8_relu_exp_stages_64x4_large_nhwc_tn_v1 Tactic: -6840588038605932325
[03/24/2023-12:57:23] [V] [TRT] Tactic: -6840588038605932325 Time: 0.044416
[03/24/2023-12:57:23] [V] [TRT] Conv_70 Set Tactic Name: sm75_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x32x32_stage1_warpsize4x1x1_g1_tensor16x8x8 Tactic: -6828337260021572283
[03/24/2023-12:57:23] [V] [TRT] Tactic: -6828337260021572283 Time: 0.026496
[03/24/2023-12:57:23] [V] [TRT] Conv_70 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x256x32_stage3_warpsize2x4x1_g1_tensor16x8x16 Tactic: -6799856376604253964
[03/24/2023-12:57:23] [V] [TRT] Tactic: -6799856376604253964 Time: 0.06144
[03/24/2023-12:57:23] [V] [TRT] Conv_70 Set Tactic Name: sm75_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x32x32_stage1_warpsize4x1x1_g1_tensor16x8x8 Tactic: -6711815420995272523
[03/24/2023-12:57:23] [V] [TRT] Tactic: -6711815420995272523 Time: 0.030464
[03/24/2023-12:57:23] [V] [TRT] Conv_70 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x32x32_stage4_warpsize4x1x1_g1_tensor16x8x16_t1r3s3 Tactic: -6625722781282978136
[03/24/2023-12:57:24] [V] [TRT] Tactic: -6625722781282978136 Time: 0.021376
[03/24/2023-12:57:24] [V] [TRT] Conv_70 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x64x32_stage3_warpsize4x1x1_g1_tensor16x8x16 Tactic: -6525498856028268801
[03/24/2023-12:57:24] [V] [TRT] Tactic: -6525498856028268801 Time: 0.028032
[03/24/2023-12:57:24] [V] [TRT] Conv_70 Set Tactic Name: sm75_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x256x64_stage1_warpsize1x4x2_g1_tensor16x8x8 Tactic: -6489479581011009593
[03/24/2023-12:57:24] [V] [TRT] Tactic: -6489479581011009593 Time: 0.070656
[03/24/2023-12:57:24] [V] [TRT] Conv_70 Set Tactic Name: ampere_h16816cudnn_64x64_sliced1x2_ldg8_relu_exp_stages_64x6_medium_nhwc_tn_v1 Tactic: -6356316196810535311
[03/24/2023-12:57:24] [V] [TRT] Tactic: -6356316196810535311 Time: 0.039936
[03/24/2023-12:57:24] [V] [TRT] Conv_70 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x32x32_stage4_warpsize4x1x1_g1_tensor16x8x16 Tactic: -6324345858751792783
[03/24/2023-12:57:24] [V] [TRT] Tactic: -6324345858751792783 Time: 0.022272
[03/24/2023-12:57:24] [V] [TRT] Conv_70 Set Tactic Name: sm75_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x256x64_stage1_warpsize1x4x2_g1_tensor16x8x8_t1r3s3 Tactic: -6320761427625651496
[03/24/2023-12:57:24] [V] [TRT] Tactic: -6320761427625651496 Time: 0.069632
[03/24/2023-12:57:24] [V] [TRT] Conv_70 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x256x32_stage3_warpsize2x4x1_g1_tensor16x8x16_t1r3s3 Tactic: -6262400699544994312
[03/24/2023-12:57:24] [V] [TRT] Tactic: -6262400699544994312 Time: 0.060416
[03/24/2023-12:57:24] [V] [TRT] Conv_70 Set Tactic Name: ampere_h1688cudnn_128x128_ldg8_relu_exp_large_nhwc_tn_v1 Tactic: -6257787336162086472
[03/24/2023-12:57:24] [V] [TRT] Tactic: -6257787336162086472 Time: 0.051968
[03/24/2023-12:57:24] [V] [TRT] Conv_70 Set Tactic Name: sm75_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x128x64_stage1_warpsize2x2x1_g1_tensor16x8x8 Tactic: -6080892721161662420
[03/24/2023-12:57:24] [V] [TRT] Tactic: -6080892721161662420 Time: 0.040192
[03/24/2023-12:57:24] [V] [TRT] Conv_70 Set Tactic Name: ampere_h16816cudnn_128x64_ldg8_relu_exp_stages_64x4_small_nhwc_tn_v1 Tactic: -6063766379489217211
[03/24/2023-12:57:24] [V] [TRT] Tactic: -6063766379489217211 Time: 0.030592
[03/24/2023-12:57:24] [V] [TRT] Conv_70 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x128x32_stage5_warpsize2x2x1_g1_tensor16x8x16 Tactic: -5777580938094193096
[03/24/2023-12:57:24] [V] [TRT] Tactic: -5777580938094193096 Time: 0.035584
[03/24/2023-12:57:24] [V] [TRT] Conv_70 Set Tactic Name: sm75_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x128x64_stage1_warpsize2x2x1_g1_tensor16x8x8 Tactic: -5710735840878760115
[03/24/2023-12:57:24] [V] [TRT] Tactic: -5710735840878760115 Time: 0.040704
[03/24/2023-12:57:24] [V] [TRT] Conv_70 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x128x32_stage3_warpsize4x2x1_g1_tensor16x8x16 Tactic: -5657273398217409378
[03/24/2023-12:57:24] [V] [TRT] Tactic: -5657273398217409378 Time: 0.043904
[03/24/2023-12:57:24] [V] [TRT] Conv_70 Set Tactic Name: sm75_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x128x32_stage1_warpsize2x2x1_g1_tensor16x8x8_t1r3s3 Tactic: -5546257196173962281
[03/24/2023-12:57:24] [V] [TRT] Tactic: -5546257196173962281 Time: 0.03968
[03/24/2023-12:57:24] [V] [TRT] Conv_70 Set Tactic Name: ampere_h16816cudnn_128x128_ldg8_relu_exp_small_nhwc_tn_v1 Tactic: -5530886555766748586
[03/24/2023-12:57:24] [V] [TRT] Tactic: -5530886555766748586 Time: 0.03456
[03/24/2023-12:57:24] [V] [TRT] Conv_70 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x64x32_stage5_warpsize2x2x1_g1_tensor16x8x16_t1r3s3 Tactic: -5422685219138380548
[03/24/2023-12:57:24] [V] [TRT] Tactic: -5422685219138380548 Time: 0.025216
[03/24/2023-12:57:24] [V] [TRT] Conv_70 Set Tactic Name: ampere_h16816cudnn_256x64_ldg8_relu_exp_stages_64x3_small_nhwc_tn_v1 Tactic: -5261787675443473128
[03/24/2023-12:57:24] [V] [TRT] Tactic: -5261787675443473128 Time: 0.030464
[03/24/2023-12:57:24] [V] [TRT] Conv_70 Set Tactic Name: sm75_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x64x32_stage1_warpsize4x1x1_g1_tensor16x8x8 Tactic: -5198219374380660379
[03/24/2023-12:57:24] [V] [TRT] Tactic: -5198219374380660379 Time: 0.033152
[03/24/2023-12:57:24] [V] [TRT] Conv_70 Set Tactic Name: ampere_h16816cudnn_64x128_sliced1x2_ldg8_relu_exp_stages_64x3_medium_nhwc_tn_v1 Tactic: -5161596964442251102
[03/24/2023-12:57:24] [V] [TRT] Tactic: -5161596964442251102 Time: 0.03584
[03/24/2023-12:57:24] [V] [TRT] Conv_70 Set Tactic Name: ampere_h16816cudnn_64x128_ldg8_relu_exp_stages_64x3_medium_nhwc_tn_v1 Tactic: -5127240325355316006
[03/24/2023-12:57:24] [V] [TRT] Tactic: -5127240325355316006 Time: 0.03776
[03/24/2023-12:57:24] [V] [TRT] Conv_70 Set Tactic Name: ampere_h16816cudnn_256x128_ldg8_relu_exp_stages_64x3_medium_nhwc_tn_v1 Tactic: -5109582882231362997
[03/24/2023-12:57:24] [V] [TRT] Tactic: -5109582882231362997 Time: 0.045824
[03/24/2023-12:57:24] [V] [TRT] Conv_70 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x64x32_stage5_warpsize2x2x1_g1_tensor16x8x16 Tactic: -4825567853927730435
[03/24/2023-12:57:24] [V] [TRT] Tactic: -4825567853927730435 Time: 0.029696
[03/24/2023-12:57:24] [V] [TRT] Conv_70 Set Tactic Name: ampere_h16816cudnn_64x128_sliced1x2_ldg8_relu_exp_stages_64x4_small_nhwc_tn_v1 Tactic: -4796511246675321840
[03/24/2023-12:57:24] [V] [TRT] Tactic: -4796511246675321840 Time: 0.046848
[03/24/2023-12:57:24] [V] [TRT] Conv_70 Set Tactic Name: ampere_h16816cudnn_64x64_sliced1x2_ldg8_relu_exp_stages_64x6_large_nhwc_tn_v1 Tactic: -4706569565442112734
[03/24/2023-12:57:24] [V] [TRT] Tactic: -4706569565442112734 Time: 0.040192
[03/24/2023-12:57:24] [V] [TRT] Conv_70 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x128x64_stage3_warpsize2x2x1_g1_tensor16x8x16_t1r3s3 Tactic: -4566599693570369588
[03/24/2023-12:57:24] [V] [TRT] Tactic: -4566599693570369588 Time: 0.041088
[03/24/2023-12:57:24] [V] [TRT] Conv_70 Set Tactic Name: ampere_h16816cudnn_128x128_ldg8_relu_exp_stages_64x3_large_nhwc_tn_v1 Tactic: -4409144516525410768
[03/24/2023-12:57:24] [V] [TRT] Tactic: -4409144516525410768 Time: 0.040576
[03/24/2023-12:57:24] [V] [TRT] Conv_70 Set Tactic Name: ampere_h16816cudnn_128x64_ldg8_relu_exp_stages_64x3_small_nhwc_tn_v1 Tactic: -4379519430184503304
[03/24/2023-12:57:24] [V] [TRT] Tactic: -4379519430184503304 Time: 0.02816
[03/24/2023-12:57:24] [V] [TRT] Conv_70 Set Tactic Name: ampere_h1688cudnn_256x128_ldg8_relu_exp_small_nhwc_tn_v1 Tactic: -4152066959007262150
[03/24/2023-12:57:24] [V] [TRT] Tactic: -4152066959007262150 Time: 0.04992
[03/24/2023-12:57:24] [V] [TRT] Conv_70 Set Tactic Name: ampere_h16816cudnn_64x128_ldg8_relu_exp_stages_64x4_medium_nhwc_tn_v1 Tactic: -4021926646879732549
[03/24/2023-12:57:24] [V] [TRT] Tactic: -4021926646879732549 Time: 0.044032
[03/24/2023-12:57:24] [V] [TRT] Conv_70 Set Tactic Name: ampere_h16816cudnn_64x128_sliced1x2_ldg8_relu_exp_stages_64x4_medium_nhwc_tn_v1 Tactic: -3987638434926559037
[03/24/2023-12:57:24] [V] [TRT] Tactic: -3987638434926559037 Time: 0.046976
[03/24/2023-12:57:24] [V] [TRT] Conv_70 Set Tactic Name: ampere_h1688cudnn_256x64_sliced1x2_ldg8_relu_exp_medium_nhwc_tn_v1 Tactic: -3905653247016903130
[03/24/2023-12:57:24] [V] [TRT] Tactic: -3905653247016903130 Time: 0.037888
[03/24/2023-12:57:24] [V] [TRT] Conv_70 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x64x32_stage5_warpsize2x2x1_g1_tensor16x8x16 Tactic: -3903974568488493144
[03/24/2023-12:57:24] [V] [TRT] Tactic: -3903974568488493144 Time: 0.028288
[03/24/2023-12:57:24] [V] [TRT] Conv_70 Set Tactic Name: ampere_h16816cudnn_64x128_ldg8_relu_exp_stages_64x3_large_nhwc_tn_v1 Tactic: -3895429239811098010
[03/24/2023-12:57:24] [V] [TRT] Tactic: -3895429239811098010 Time: 0.03776
[03/24/2023-12:57:24] [V] [TRT] Conv_70 Set Tactic Name: ampere_h16816cudnn_256x64_ldg8_relu_exp_small_nhwc_tn_v1 Tactic: -3864869056275745423
[03/24/2023-12:57:24] [V] [TRT] Tactic: -3864869056275745423 Time: 0.030592
[03/24/2023-12:57:24] [V] [TRT] Conv_70 Set Tactic Name: sm75_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x32x32_stage1_warpsize4x1x1_g1_tensor16x8x8_t1r3s3 Tactic: -3784342055748695733
[03/24/2023-12:57:24] [V] [TRT] Tactic: -3784342055748695733 Time: 0.02496
[03/24/2023-12:57:24] [V] [TRT] Conv_70 Set Tactic Name: ampere_h16816cudnn_64x64_ldg8_relu_exp_stages_64x5_small_nhwc_tn_v1 Tactic: -3601464762214218301
[03/24/2023-12:57:24] [V] [TRT] Tactic: -3601464762214218301 Time: 0.032768
[03/24/2023-12:57:24] [V] [TRT] Conv_70 Set Tactic Name: sm75_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x64x32_stage1_warpsize2x2x1_g1_tensor16x8x8 Tactic: -3425274793298557239
[03/24/2023-12:57:24] [V] [TRT] Tactic: -3425274793298557239 Time: 0.030464
[03/24/2023-12:57:24] [V] [TRT] Conv_70 Set Tactic Name: ampere_h1688cudnn_256x64_sliced1x2_ldg8_relu_exp_large_nhwc_tn_v1 Tactic: -3412636942650049698
[03/24/2023-12:57:24] [V] [TRT] Tactic: -3412636942650049698 Time: 0.038528
[03/24/2023-12:57:24] [V] [TRT] Conv_70 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x64x32_stage3_warpsize4x1x1_g1_tensor16x8x16 Tactic: -3338665856053412950
[03/24/2023-12:57:24] [V] [TRT] Tactic: -3338665856053412950 Time: 0.027008
[03/24/2023-12:57:24] [V] [TRT] Conv_70 Set Tactic Name: sm75_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x128x32_stage1_warpsize2x2x1_g1_tensor16x8x8 Tactic: -3271955096576257018
[03/24/2023-12:57:24] [V] [TRT] Tactic: -3271955096576257018 Time: 0.039808
[03/24/2023-12:57:24] [V] [TRT] Conv_70 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x128x64_stage3_warpsize4x2x1_g1_tensor16x8x16_t1r3s3 Tactic: -3243541398692466074
[03/24/2023-12:57:24] [V] [TRT] Tactic: -3243541398692466074 Time: 0.045824
[03/24/2023-12:57:24] [V] [TRT] Conv_70 Set Tactic Name: ampere_h16816cudnn_64x128_sliced1x2_ldg8_relu_exp_stages_64x3_small_nhwc_tn_v1 Tactic: -3058330359340425555
[03/24/2023-12:57:24] [V] [TRT] Tactic: -3058330359340425555 Time: 0.036352
[03/24/2023-12:57:24] [V] [TRT] Conv_70 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x256x64_stage3_warpsize1x4x1_g1_tensor16x8x16_t1r3s3 Tactic: -2899647483672319239
[03/24/2023-12:57:24] [V] [TRT] Tactic: -2899647483672319239 Time: 0.06336
[03/24/2023-12:57:24] [V] [TRT] Conv_70 Set Tactic Name: ampere_h16816cudnn_256x64_sliced1x2_ldg8_relu_exp_large_nhwc_tn_v1 Tactic: -2816084650627734155
[03/24/2023-12:57:24] [V] [TRT] Tactic: -2816084650627734155 Time: 0.03584
[03/24/2023-12:57:24] [V] [TRT] Conv_70 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x128x32_stage5_warpsize2x2x1_g1_tensor16x8x16 Tactic: -2662892962457732243
[03/24/2023-12:57:24] [V] [TRT] Tactic: -2662892962457732243 Time: 0.03456
[03/24/2023-12:57:24] [V] [TRT] Conv_70 Set Tactic Name: ampere_h16816cudnn_256x128_ldg8_relu_exp_large_nhwc_tn_v1 Tactic: -2559894581585337900
[03/24/2023-12:57:24] [V] [TRT] Tactic: -2559894581585337900 Time: 0.045312
[03/24/2023-12:57:24] [V] [TRT] Conv_70 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x32x32_stage4_warpsize4x1x1_g1_tensor16x8x16 Tactic: -2530740716768816092
[03/24/2023-12:57:24] [V] [TRT] Tactic: -2530740716768816092 Time: 0.023296
[03/24/2023-12:57:24] [V] [TRT] Conv_70 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x128x32_stage4_warpsize2x2x1_g1_tensor16x8x16 Tactic: -2332828394978346992
[03/24/2023-12:57:24] [V] [TRT] Tactic: -2332828394978346992 Time: 0.034688
[03/24/2023-12:57:24] [V] [TRT] Conv_70 Set Tactic Name: ampere_h1688cudnn_256x64_ldg8_relu_exp_large_nhwc_tn_v1 Tactic: -2241736083352441442
[03/24/2023-12:57:24] [V] [TRT] Tactic: -2241736083352441442 Time: 0.034816
[03/24/2023-12:57:24] [V] [TRT] Conv_70 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x32x64_stage5_warpsize2x2x1_g1_tensor16x8x16 Tactic: -2161909437867201546
[03/24/2023-12:57:24] [V] [TRT] Tactic: -2161909437867201546 Time: 0.026496
[03/24/2023-12:57:24] [V] [TRT] Conv_70 Set Tactic Name: ampere_h16816cudnn_256x64_ldg8_relu_exp_medium_nhwc_tn_v1 Tactic: -1985778916402815946
[03/24/2023-12:57:24] [V] [TRT] Tactic: -1985778916402815946 Time: 0.030848
[03/24/2023-12:57:24] [V] [TRT] Conv_70 Set Tactic Name: sm75_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x256x32_stage1_warpsize2x4x1_g1_tensor16x8x8 Tactic: -1708101578041178688
[03/24/2023-12:57:24] [V] [TRT] Tactic: -1708101578041178688 Time: 0.070656
[03/24/2023-12:57:24] [V] [TRT] Conv_70 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x64x64_stage3_warpsize4x1x1_g1_tensor16x8x16 Tactic: -1502788097503482299
[03/24/2023-12:57:24] [V] [TRT] Tactic: -1502788097503482299 Time: 0.033024
[03/24/2023-12:57:24] [V] [TRT] Conv_70 Set Tactic Name: ampere_h16816cudnn_128x64_sliced1x2_ldg8_relu_exp_stages_64x4_large_nhwc_tn_v1 Tactic: -1500496213132463076
[03/24/2023-12:57:24] [V] [TRT] Tactic: -1500496213132463076 Time: 0.03264
[03/24/2023-12:57:24] [V] [TRT] Conv_70 Set Tactic Name: ampere_h16816cudnn_64x64_ldg8_relu_exp_stages_64x6_small_nhwc_tn_v1 Tactic: -1099247066487349374
[03/24/2023-12:57:24] [V] [TRT] Tactic: -1099247066487349374 Time: 0.036224
[03/24/2023-12:57:24] [V] [TRT] Conv_70 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x64x64_stage4_warpsize2x2x1_g1_tensor16x8x16 Tactic: -910286698936744682
[03/24/2023-12:57:24] [V] [TRT] Tactic: -910286698936744682 Time: 0.029824
[03/24/2023-12:57:24] [V] [TRT] Conv_70 Set Tactic Name: sm75_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x256x32_stage1_warpsize2x4x1_g1_tensor16x8x8 Tactic: -907287437357565279
[03/24/2023-12:57:24] [V] [TRT] Tactic: -907287437357565279 Time: 0.069504
[03/24/2023-12:57:24] [V] [TRT] Conv_70 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x32x32_stage4_warpsize4x1x1_g1_tensor16x8x16 Tactic: -606726295133751039
[03/24/2023-12:57:24] [V] [TRT] Tactic: -606726295133751039 Time: 0.021376
[03/24/2023-12:57:24] [V] [TRT] Fastest Tactic: 4503233883285355107 Time: 0.020224
[03/24/2023-12:57:24] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: 4503233883285355107
[03/24/2023-12:57:24] [V] [TRT] *************** Autotuning format combination: Half(1036800,1:16,5760,32) -> Half(32400,1:16,180,1) ***************
[03/24/2023-12:57:24] [V] [TRT] --------------- Timing Runner: Conv_70 (CudnnConvolution)
[03/24/2023-12:57:24] [V] [TRT] CudnnConvolution has no valid tactics for this config, skipping
[03/24/2023-12:57:24] [V] [TRT] --------------- Timing Runner: Conv_70 (CaskConvolution)
[03/24/2023-12:57:24] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[03/24/2023-12:57:24] [V] [TRT] =============== Computing costs for 
[03/24/2023-12:57:24] [V] [TRT] *************** Autotuning format combination: Float(16588800,32400,180,1) -> Float(64800,32400,180,1) ***************
[03/24/2023-12:57:24] [V] [TRT] *************** Autotuning format combination: Float(16588800,1,92160,512) -> Float(64800,1,360,2) ***************
[03/24/2023-12:57:24] [V] [TRT] *************** Autotuning format combination: Float(4147200,1:4,23040,128) -> Float(32400,1:4,180,1) ***************
[03/24/2023-12:57:24] [V] [TRT] *************** Autotuning format combination: Half(16588800,32400,180,1) -> Half(64800,32400,180,1) ***************
[03/24/2023-12:57:24] [V] [TRT] *************** Autotuning format combination: Half(8294400,32400:2,180,1) -> Half(32400,32400:2,180,1) ***************
[03/24/2023-12:57:24] [V] [TRT] *************** Autotuning format combination: Half(2073600,1:8,11520,64) -> Float(64800,32400,180,1) ***************
[03/24/2023-12:57:24] [V] [TRT] *************** Autotuning format combination: Half(2073600,1:8,11520,64) -> Half(32400,1:8,180,1) ***************
[03/24/2023-12:57:24] [V] [TRT] *************** Autotuning format combination: Half(1036800,1:16,5760,32) -> Half(32400,1:16,180,1) ***************
[03/24/2023-12:57:24] [V] [TRT] =============== Computing costs for 
[03/24/2023-12:57:24] [V] [TRT] *************** Autotuning format combination: Float(16588800,32400,180,1) -> Float(64800,32400,180,1) ***************
[03/24/2023-12:57:24] [V] [TRT] *************** Autotuning format combination: Float(16588800,1,92160,512) -> Float(64800,1,360,2) ***************
[03/24/2023-12:57:24] [V] [TRT] *************** Autotuning format combination: Float(4147200,1:4,23040,128) -> Float(32400,1:4,180,1) ***************
[03/24/2023-12:57:24] [V] [TRT] *************** Autotuning format combination: Half(16588800,32400,180,1) -> Half(64800,32400,180,1) ***************
[03/24/2023-12:57:24] [V] [TRT] *************** Autotuning format combination: Half(8294400,32400:2,180,1) -> Half(32400,32400:2,180,1) ***************
[03/24/2023-12:57:24] [V] [TRT] *************** Autotuning format combination: Half(2073600,1:8,11520,64) -> Float(64800,32400,180,1) ***************
[03/24/2023-12:57:24] [V] [TRT] *************** Autotuning format combination: Half(2073600,1:8,11520,64) -> Half(32400,1:8,180,1) ***************
[03/24/2023-12:57:24] [V] [TRT] *************** Autotuning format combination: Half(1036800,1:16,5760,32) -> Half(32400,1:16,180,1) ***************
[03/24/2023-12:57:24] [V] [TRT] =============== Computing costs for 
[03/24/2023-12:57:24] [V] [TRT] *************** Autotuning format combination: Float(16588800,32400,180,1) -> Float(32400,32400,180,1) ***************
[03/24/2023-12:57:24] [V] [TRT] *************** Autotuning format combination: Float(16588800,1,92160,512) -> Float(32400,1,180,1) ***************
[03/24/2023-12:57:24] [V] [TRT] *************** Autotuning format combination: Float(4147200,1:4,23040,128) -> Float(32400,1:4,180,1) ***************
[03/24/2023-12:57:24] [V] [TRT] *************** Autotuning format combination: Half(16588800,32400,180,1) -> Half(32400,32400,180,1) ***************
[03/24/2023-12:57:24] [V] [TRT] *************** Autotuning format combination: Half(8294400,32400:2,180,1) -> Half(32400,32400:2,180,1) ***************
[03/24/2023-12:57:24] [V] [TRT] *************** Autotuning format combination: Half(2073600,1:8,11520,64) -> Float(32400,32400,180,1) ***************
[03/24/2023-12:57:24] [V] [TRT] *************** Autotuning format combination: Half(2073600,1:8,11520,64) -> Half(32400,1:8,180,1) ***************
[03/24/2023-12:57:24] [V] [TRT] *************** Autotuning format combination: Half(1036800,1:16,5760,32) -> Half(32400,1:16,180,1) ***************
[03/24/2023-12:57:24] [V] [TRT] =============== Computing costs for 
[03/24/2023-12:57:24] [V] [TRT] *************** Autotuning format combination: Float(16588800,32400,180,1) -> Float(64800,32400,180,1) ***************
[03/24/2023-12:57:24] [V] [TRT] *************** Autotuning format combination: Float(16588800,1,92160,512) -> Float(64800,1,360,2) ***************
[03/24/2023-12:57:24] [V] [TRT] *************** Autotuning format combination: Float(4147200,1:4,23040,128) -> Float(32400,1:4,180,1) ***************
[03/24/2023-12:57:24] [V] [TRT] *************** Autotuning format combination: Half(16588800,32400,180,1) -> Half(64800,32400,180,1) ***************
[03/24/2023-12:57:24] [V] [TRT] *************** Autotuning format combination: Half(8294400,32400:2,180,1) -> Half(32400,32400:2,180,1) ***************
[03/24/2023-12:57:24] [V] [TRT] *************** Autotuning format combination: Half(2073600,1:8,11520,64) -> Float(64800,32400,180,1) ***************
[03/24/2023-12:57:24] [V] [TRT] *************** Autotuning format combination: Half(2073600,1:8,11520,64) -> Half(32400,1:8,180,1) ***************
[03/24/2023-12:57:24] [V] [TRT] *************** Autotuning format combination: Half(1036800,1:16,5760,32) -> Half(32400,1:16,180,1) ***************
[03/24/2023-12:57:24] [V] [TRT] =============== Computing costs for 
[03/24/2023-12:57:24] [V] [TRT] *************** Autotuning format combination: Float(16588800,32400,180,1) -> Float(32400,32400,180,1) ***************
[03/24/2023-12:57:24] [V] [TRT] *************** Autotuning format combination: Float(16588800,1,92160,512) -> Float(32400,1,180,1) ***************
[03/24/2023-12:57:24] [V] [TRT] *************** Autotuning format combination: Float(4147200,1:4,23040,128) -> Float(32400,1:4,180,1) ***************
[03/24/2023-12:57:24] [V] [TRT] *************** Autotuning format combination: Half(16588800,32400,180,1) -> Half(32400,32400,180,1) ***************
[03/24/2023-12:57:24] [V] [TRT] *************** Autotuning format combination: Half(8294400,32400:2,180,1) -> Half(32400,32400:2,180,1) ***************
[03/24/2023-12:57:24] [V] [TRT] *************** Autotuning format combination: Half(2073600,1:8,11520,64) -> Float(32400,32400,180,1) ***************
[03/24/2023-12:57:24] [V] [TRT] *************** Autotuning format combination: Half(2073600,1:8,11520,64) -> Half(32400,1:8,180,1) ***************
[03/24/2023-12:57:24] [V] [TRT] *************** Autotuning format combination: Half(1036800,1:16,5760,32) -> Half(32400,1:16,180,1) ***************
[03/24/2023-12:57:24] [V] [TRT] =============== Computing costs for 
[03/24/2023-12:57:24] [V] [TRT] *************** Autotuning format combination: Float(2073600,32400,180,1) -> Float(16588800,32400,180,1) ***************
[03/24/2023-12:57:24] [V] [TRT] *************** Autotuning format combination: Float(2073600,1,11520,64) -> Float(16588800,1,92160,512) ***************
[03/24/2023-12:57:24] [V] [TRT] *************** Autotuning format combination: Float(518400,1:4,2880,16) -> Float(4147200,1:4,23040,128) ***************
[03/24/2023-12:57:24] [V] [TRT] *************** Autotuning format combination: Half(2073600,32400,180,1) -> Half(16588800,32400,180,1) ***************
[03/24/2023-12:57:24] [V] [TRT] *************** Autotuning format combination: Half(1036800,32400:2,180,1) -> Half(8294400,32400:2,180,1) ***************
[03/24/2023-12:57:24] [V] [TRT] *************** Autotuning format combination: Half(259200,1:8,1440,8) -> Float(16588800,32400,180,1) ***************
[03/24/2023-12:57:24] [V] [TRT] *************** Autotuning format combination: Half(259200,1:8,1440,8) -> Half(2073600,1:8,11520,64) ***************
[03/24/2023-12:57:24] [V] [TRT] *************** Autotuning format combination: Half(129600,1:16,720,4) -> Half(1036800,1:16,5760,32) ***************
[03/24/2023-12:57:24] [V] [TRT] =============== Computing costs for 
[03/24/2023-12:57:24] [V] [TRT] *************** Autotuning format combination: Float(16588800,32400,180,1) -> Float(97200,32400,180,1) ***************
[03/24/2023-12:57:24] [V] [TRT] *************** Autotuning format combination: Float(16588800,1,92160,512) -> Float(97200,1,540,3) ***************
[03/24/2023-12:57:24] [V] [TRT] *************** Autotuning format combination: Float(4147200,1:4,23040,128) -> Float(32400,1:4,180,1) ***************
[03/24/2023-12:57:24] [V] [TRT] *************** Autotuning format combination: Half(16588800,32400,180,1) -> Half(97200,32400,180,1) ***************
[03/24/2023-12:57:24] [V] [TRT] *************** Autotuning format combination: Half(8294400,32400:2,180,1) -> Half(64800,32400:2,180,1) ***************
[03/24/2023-12:57:24] [V] [TRT] *************** Autotuning format combination: Half(2073600,1:8,11520,64) -> Float(97200,32400,180,1) ***************
[03/24/2023-12:57:24] [V] [TRT] *************** Autotuning format combination: Half(2073600,1:8,11520,64) -> Half(32400,1:8,180,1) ***************
[03/24/2023-12:57:24] [V] [TRT] *************** Autotuning format combination: Half(1036800,1:16,5760,32) -> Half(32400,1:16,180,1) ***************
[03/24/2023-12:57:24] [V] [TRT] =============== Computing costs for 
[03/24/2023-12:57:24] [V] [TRT] *************** Autotuning format combination: Float(16588800,32400,180,1) -> Float(64800,32400,180,1) ***************
[03/24/2023-12:57:24] [V] [TRT] *************** Autotuning format combination: Float(16588800,1,92160,512) -> Float(64800,1,360,2) ***************
[03/24/2023-12:57:24] [V] [TRT] *************** Autotuning format combination: Float(4147200,1:4,23040,128) -> Float(32400,1:4,180,1) ***************
[03/24/2023-12:57:24] [V] [TRT] *************** Autotuning format combination: Half(16588800,32400,180,1) -> Half(64800,32400,180,1) ***************
[03/24/2023-12:57:24] [V] [TRT] *************** Autotuning format combination: Half(8294400,32400:2,180,1) -> Half(32400,32400:2,180,1) ***************
[03/24/2023-12:57:24] [V] [TRT] *************** Autotuning format combination: Half(2073600,1:8,11520,64) -> Float(64800,32400,180,1) ***************
[03/24/2023-12:57:24] [V] [TRT] *************** Autotuning format combination: Half(2073600,1:8,11520,64) -> Half(32400,1:8,180,1) ***************
[03/24/2023-12:57:24] [V] [TRT] *************** Autotuning format combination: Half(1036800,1:16,5760,32) -> Half(32400,1:16,180,1) ***************
[03/24/2023-12:57:24] [V] [TRT] =============== Computing costs for 
[03/24/2023-12:57:24] [V] [TRT] *************** Autotuning format combination: Float(16588800,32400,180,1) -> Float(64800,32400,180,1) ***************
[03/24/2023-12:57:24] [V] [TRT] *************** Autotuning format combination: Float(16588800,1,92160,512) -> Float(64800,1,360,2) ***************
[03/24/2023-12:57:24] [V] [TRT] *************** Autotuning format combination: Float(4147200,1:4,23040,128) -> Float(32400,1:4,180,1) ***************
[03/24/2023-12:57:24] [V] [TRT] *************** Autotuning format combination: Half(16588800,32400,180,1) -> Half(64800,32400,180,1) ***************
[03/24/2023-12:57:24] [V] [TRT] *************** Autotuning format combination: Half(8294400,32400:2,180,1) -> Half(32400,32400:2,180,1) ***************
[03/24/2023-12:57:24] [V] [TRT] *************** Autotuning format combination: Half(2073600,1:8,11520,64) -> Float(64800,32400,180,1) ***************
[03/24/2023-12:57:24] [V] [TRT] *************** Autotuning format combination: Half(2073600,1:8,11520,64) -> Half(32400,1:8,180,1) ***************
[03/24/2023-12:57:24] [V] [TRT] *************** Autotuning format combination: Half(1036800,1:16,5760,32) -> Half(32400,1:16,180,1) ***************
[03/24/2023-12:57:24] [V] [TRT] =============== Computing costs for 
[03/24/2023-12:57:24] [V] [TRT] *************** Autotuning format combination: Float(16588800,32400,180,1) -> Float(64800,32400,180,1) ***************
[03/24/2023-12:57:24] [V] [TRT] *************** Autotuning format combination: Float(16588800,1,92160,512) -> Float(64800,1,360,2) ***************
[03/24/2023-12:57:24] [V] [TRT] *************** Autotuning format combination: Float(4147200,1:4,23040,128) -> Float(32400,1:4,180,1) ***************
[03/24/2023-12:57:24] [V] [TRT] *************** Autotuning format combination: Half(16588800,32400,180,1) -> Half(64800,32400,180,1) ***************
[03/24/2023-12:57:24] [V] [TRT] *************** Autotuning format combination: Half(8294400,32400:2,180,1) -> Half(32400,32400:2,180,1) ***************
[03/24/2023-12:57:24] [V] [TRT] *************** Autotuning format combination: Half(2073600,1:8,11520,64) -> Float(64800,32400,180,1) ***************
[03/24/2023-12:57:24] [V] [TRT] *************** Autotuning format combination: Half(2073600,1:8,11520,64) -> Half(32400,1:8,180,1) ***************
[03/24/2023-12:57:24] [V] [TRT] *************** Autotuning format combination: Half(1036800,1:16,5760,32) -> Half(32400,1:16,180,1) ***************
[03/24/2023-12:57:24] [V] [TRT] =============== Computing costs for 
[03/24/2023-12:57:24] [V] [TRT] *************** Autotuning format combination: Float(16588800,32400,180,1) -> Float(64800,32400,180,1) ***************
[03/24/2023-12:57:24] [V] [TRT] *************** Autotuning format combination: Float(16588800,1,92160,512) -> Float(64800,1,360,2) ***************
[03/24/2023-12:57:24] [V] [TRT] *************** Autotuning format combination: Float(4147200,1:4,23040,128) -> Float(32400,1:4,180,1) ***************
[03/24/2023-12:57:24] [V] [TRT] *************** Autotuning format combination: Half(16588800,32400,180,1) -> Half(64800,32400,180,1) ***************
[03/24/2023-12:57:24] [V] [TRT] *************** Autotuning format combination: Half(8294400,32400:2,180,1) -> Half(32400,32400:2,180,1) ***************
[03/24/2023-12:57:24] [V] [TRT] *************** Autotuning format combination: Half(2073600,1:8,11520,64) -> Float(64800,32400,180,1) ***************
[03/24/2023-12:57:24] [V] [TRT] *************** Autotuning format combination: Half(2073600,1:8,11520,64) -> Half(32400,1:8,180,1) ***************
[03/24/2023-12:57:25] [V] [TRT] *************** Autotuning format combination: Half(1036800,1:16,5760,32) -> Half(32400,1:16,180,1) ***************
[03/24/2023-12:57:25] [V] [TRT] =============== Computing costs for 
[03/24/2023-12:57:25] [V] [TRT] *************** Autotuning format combination: Float(16588800,32400,180,1) -> Float(32400,32400,180,1) ***************
[03/24/2023-12:57:25] [V] [TRT] *************** Autotuning format combination: Float(16588800,1,92160,512) -> Float(32400,1,180,1) ***************
[03/24/2023-12:57:25] [V] [TRT] *************** Autotuning format combination: Float(4147200,1:4,23040,128) -> Float(32400,1:4,180,1) ***************
[03/24/2023-12:57:25] [V] [TRT] *************** Autotuning format combination: Half(16588800,32400,180,1) -> Half(32400,32400,180,1) ***************
[03/24/2023-12:57:25] [V] [TRT] *************** Autotuning format combination: Half(8294400,32400:2,180,1) -> Half(32400,32400:2,180,1) ***************
[03/24/2023-12:57:25] [V] [TRT] *************** Autotuning format combination: Half(2073600,1:8,11520,64) -> Float(32400,32400,180,1) ***************
[03/24/2023-12:57:25] [V] [TRT] *************** Autotuning format combination: Half(2073600,1:8,11520,64) -> Half(32400,1:8,180,1) ***************
[03/24/2023-12:57:25] [V] [TRT] *************** Autotuning format combination: Half(1036800,1:16,5760,32) -> Half(32400,1:16,180,1) ***************
[03/24/2023-12:57:25] [V] [TRT] =============== Computing costs for 
[03/24/2023-12:57:25] [V] [TRT] *************** Autotuning format combination: Float(16588800,32400,180,1) -> Float(97200,32400,180,1) ***************
[03/24/2023-12:57:25] [V] [TRT] *************** Autotuning format combination: Float(16588800,1,92160,512) -> Float(97200,1,540,3) ***************
[03/24/2023-12:57:25] [V] [TRT] *************** Autotuning format combination: Float(4147200,1:4,23040,128) -> Float(32400,1:4,180,1) ***************
[03/24/2023-12:57:25] [V] [TRT] *************** Autotuning format combination: Half(16588800,32400,180,1) -> Half(97200,32400,180,1) ***************
[03/24/2023-12:57:25] [V] [TRT] *************** Autotuning format combination: Half(8294400,32400:2,180,1) -> Half(64800,32400:2,180,1) ***************
[03/24/2023-12:57:25] [V] [TRT] *************** Autotuning format combination: Half(2073600,1:8,11520,64) -> Float(97200,32400,180,1) ***************
[03/24/2023-12:57:25] [V] [TRT] *************** Autotuning format combination: Half(2073600,1:8,11520,64) -> Half(32400,1:8,180,1) ***************
[03/24/2023-12:57:25] [V] [TRT] *************** Autotuning format combination: Half(1036800,1:16,5760,32) -> Half(32400,1:16,180,1) ***************
[03/24/2023-12:57:25] [V] [TRT] =============== Computing costs for 
[03/24/2023-12:57:25] [V] [TRT] *************** Autotuning format combination: Float(16588800,32400,180,1) -> Float(64800,32400,180,1) ***************
[03/24/2023-12:57:25] [V] [TRT] *************** Autotuning format combination: Float(16588800,1,92160,512) -> Float(64800,1,360,2) ***************
[03/24/2023-12:57:25] [V] [TRT] *************** Autotuning format combination: Float(4147200,1:4,23040,128) -> Float(32400,1:4,180,1) ***************
[03/24/2023-12:57:25] [V] [TRT] *************** Autotuning format combination: Half(16588800,32400,180,1) -> Half(64800,32400,180,1) ***************
[03/24/2023-12:57:25] [V] [TRT] *************** Autotuning format combination: Half(8294400,32400:2,180,1) -> Half(32400,32400:2,180,1) ***************
[03/24/2023-12:57:25] [V] [TRT] *************** Autotuning format combination: Half(2073600,1:8,11520,64) -> Float(64800,32400,180,1) ***************
[03/24/2023-12:57:25] [V] [TRT] *************** Autotuning format combination: Half(2073600,1:8,11520,64) -> Half(32400,1:8,180,1) ***************
[03/24/2023-12:57:25] [V] [TRT] *************** Autotuning format combination: Half(1036800,1:16,5760,32) -> Half(32400,1:16,180,1) ***************
[03/24/2023-12:57:25] [V] [TRT] =============== Computing costs for 
[03/24/2023-12:57:25] [V] [TRT] *************** Autotuning format combination: Float(2073600,32400,180,1) -> Float(16588800,32400,180,1) ***************
[03/24/2023-12:57:25] [V] [TRT] *************** Autotuning format combination: Float(2073600,1,11520,64) -> Float(16588800,1,92160,512) ***************
[03/24/2023-12:57:25] [V] [TRT] *************** Autotuning format combination: Float(518400,1:4,2880,16) -> Float(4147200,1:4,23040,128) ***************
[03/24/2023-12:57:25] [V] [TRT] *************** Autotuning format combination: Half(2073600,32400,180,1) -> Half(16588800,32400,180,1) ***************
[03/24/2023-12:57:25] [V] [TRT] *************** Autotuning format combination: Half(1036800,32400:2,180,1) -> Half(8294400,32400:2,180,1) ***************
[03/24/2023-12:57:25] [V] [TRT] *************** Autotuning format combination: Half(259200,1:8,1440,8) -> Float(16588800,32400,180,1) ***************
[03/24/2023-12:57:25] [V] [TRT] *************** Autotuning format combination: Half(259200,1:8,1440,8) -> Half(2073600,1:8,11520,64) ***************
[03/24/2023-12:57:25] [V] [TRT] *************** Autotuning format combination: Half(129600,1:16,720,4) -> Half(1036800,1:16,5760,32) ***************
[03/24/2023-12:57:25] [V] [TRT] =============== Computing costs for 
[03/24/2023-12:57:25] [V] [TRT] *************** Autotuning format combination: Float(16588800,32400,180,1) -> Float(64800,32400,180,1) ***************
[03/24/2023-12:57:25] [V] [TRT] *************** Autotuning format combination: Float(16588800,1,92160,512) -> Float(64800,1,360,2) ***************
[03/24/2023-12:57:25] [V] [TRT] *************** Autotuning format combination: Float(4147200,1:4,23040,128) -> Float(32400,1:4,180,1) ***************
[03/24/2023-12:57:25] [V] [TRT] *************** Autotuning format combination: Half(16588800,32400,180,1) -> Half(64800,32400,180,1) ***************
[03/24/2023-12:57:25] [V] [TRT] *************** Autotuning format combination: Half(8294400,32400:2,180,1) -> Half(32400,32400:2,180,1) ***************
[03/24/2023-12:57:25] [V] [TRT] *************** Autotuning format combination: Half(2073600,1:8,11520,64) -> Float(64800,32400,180,1) ***************
[03/24/2023-12:57:25] [V] [TRT] *************** Autotuning format combination: Half(2073600,1:8,11520,64) -> Half(32400,1:8,180,1) ***************
[03/24/2023-12:57:25] [V] [TRT] *************** Autotuning format combination: Half(1036800,1:16,5760,32) -> Half(32400,1:16,180,1) ***************
[03/24/2023-12:57:25] [V] [TRT] =============== Computing costs for 
[03/24/2023-12:57:25] [V] [TRT] *************** Autotuning format combination: Float(16588800,32400,180,1) -> Float(64800,32400,180,1) ***************
[03/24/2023-12:57:25] [V] [TRT] *************** Autotuning format combination: Float(16588800,1,92160,512) -> Float(64800,1,360,2) ***************
[03/24/2023-12:57:25] [V] [TRT] *************** Autotuning format combination: Float(4147200,1:4,23040,128) -> Float(32400,1:4,180,1) ***************
[03/24/2023-12:57:25] [V] [TRT] *************** Autotuning format combination: Half(16588800,32400,180,1) -> Half(64800,32400,180,1) ***************
[03/24/2023-12:57:25] [V] [TRT] *************** Autotuning format combination: Half(8294400,32400:2,180,1) -> Half(32400,32400:2,180,1) ***************
[03/24/2023-12:57:25] [V] [TRT] *************** Autotuning format combination: Half(2073600,1:8,11520,64) -> Float(64800,32400,180,1) ***************
[03/24/2023-12:57:25] [V] [TRT] *************** Autotuning format combination: Half(2073600,1:8,11520,64) -> Half(32400,1:8,180,1) ***************
[03/24/2023-12:57:25] [V] [TRT] *************** Autotuning format combination: Half(1036800,1:16,5760,32) -> Half(32400,1:16,180,1) ***************
[03/24/2023-12:57:25] [V] [TRT] =============== Computing costs for 
[03/24/2023-12:57:25] [V] [TRT] *************** Autotuning format combination: Float(16588800,32400,180,1) -> Float(64800,32400,180,1) ***************
[03/24/2023-12:57:25] [V] [TRT] *************** Autotuning format combination: Float(16588800,1,92160,512) -> Float(64800,1,360,2) ***************
[03/24/2023-12:57:25] [V] [TRT] *************** Autotuning format combination: Float(4147200,1:4,23040,128) -> Float(32400,1:4,180,1) ***************
[03/24/2023-12:57:25] [V] [TRT] *************** Autotuning format combination: Half(16588800,32400,180,1) -> Half(64800,32400,180,1) ***************
[03/24/2023-12:57:25] [V] [TRT] *************** Autotuning format combination: Half(8294400,32400:2,180,1) -> Half(32400,32400:2,180,1) ***************
[03/24/2023-12:57:25] [V] [TRT] *************** Autotuning format combination: Half(2073600,1:8,11520,64) -> Float(64800,32400,180,1) ***************
[03/24/2023-12:57:25] [V] [TRT] *************** Autotuning format combination: Half(2073600,1:8,11520,64) -> Half(32400,1:8,180,1) ***************
[03/24/2023-12:57:25] [V] [TRT] *************** Autotuning format combination: Half(1036800,1:16,5760,32) -> Half(32400,1:16,180,1) ***************
[03/24/2023-12:57:25] [V] [TRT] =============== Computing costs for 
[03/24/2023-12:57:25] [V] [TRT] *************** Autotuning format combination: Float(16588800,32400,180,1) -> Float(32400,32400,180,1) ***************
[03/24/2023-12:57:25] [V] [TRT] *************** Autotuning format combination: Float(16588800,1,92160,512) -> Float(32400,1,180,1) ***************
[03/24/2023-12:57:25] [V] [TRT] *************** Autotuning format combination: Float(4147200,1:4,23040,128) -> Float(32400,1:4,180,1) ***************
[03/24/2023-12:57:25] [V] [TRT] *************** Autotuning format combination: Half(16588800,32400,180,1) -> Half(32400,32400,180,1) ***************
[03/24/2023-12:57:25] [V] [TRT] *************** Autotuning format combination: Half(8294400,32400:2,180,1) -> Half(32400,32400:2,180,1) ***************
[03/24/2023-12:57:25] [V] [TRT] *************** Autotuning format combination: Half(2073600,1:8,11520,64) -> Float(32400,32400,180,1) ***************
[03/24/2023-12:57:25] [V] [TRT] *************** Autotuning format combination: Half(2073600,1:8,11520,64) -> Half(32400,1:8,180,1) ***************
[03/24/2023-12:57:25] [V] [TRT] *************** Autotuning format combination: Half(1036800,1:16,5760,32) -> Half(32400,1:16,180,1) ***************
[03/24/2023-12:57:25] [V] [TRT] =============== Computing costs for 
[03/24/2023-12:57:25] [V] [TRT] *************** Autotuning format combination: Float(16588800,32400,180,1) -> Float(97200,32400,180,1) ***************
[03/24/2023-12:57:25] [V] [TRT] *************** Autotuning format combination: Float(16588800,1,92160,512) -> Float(97200,1,540,3) ***************
[03/24/2023-12:57:25] [V] [TRT] *************** Autotuning format combination: Float(4147200,1:4,23040,128) -> Float(32400,1:4,180,1) ***************
[03/24/2023-12:57:25] [V] [TRT] *************** Autotuning format combination: Half(16588800,32400,180,1) -> Half(97200,32400,180,1) ***************
[03/24/2023-12:57:25] [V] [TRT] *************** Autotuning format combination: Half(8294400,32400:2,180,1) -> Half(64800,32400:2,180,1) ***************
[03/24/2023-12:57:25] [V] [TRT] *************** Autotuning format combination: Half(2073600,1:8,11520,64) -> Float(97200,32400,180,1) ***************
[03/24/2023-12:57:25] [V] [TRT] *************** Autotuning format combination: Half(2073600,1:8,11520,64) -> Half(32400,1:8,180,1) ***************
[03/24/2023-12:57:25] [V] [TRT] *************** Autotuning format combination: Half(1036800,1:16,5760,32) -> Half(32400,1:16,180,1) ***************
[03/24/2023-12:57:25] [V] [TRT] =============== Computing costs for 
[03/24/2023-12:57:25] [V] [TRT] *************** Autotuning format combination: Float(16588800,32400,180,1) -> Float(64800,32400,180,1) ***************
[03/24/2023-12:57:25] [V] [TRT] *************** Autotuning format combination: Float(16588800,1,92160,512) -> Float(64800,1,360,2) ***************
[03/24/2023-12:57:25] [V] [TRT] *************** Autotuning format combination: Float(4147200,1:4,23040,128) -> Float(32400,1:4,180,1) ***************
[03/24/2023-12:57:25] [V] [TRT] *************** Autotuning format combination: Half(16588800,32400,180,1) -> Half(64800,32400,180,1) ***************
[03/24/2023-12:57:25] [V] [TRT] *************** Autotuning format combination: Half(8294400,32400:2,180,1) -> Half(32400,32400:2,180,1) ***************
[03/24/2023-12:57:25] [V] [TRT] *************** Autotuning format combination: Half(2073600,1:8,11520,64) -> Float(64800,32400,180,1) ***************
[03/24/2023-12:57:25] [V] [TRT] *************** Autotuning format combination: Half(2073600,1:8,11520,64) -> Half(32400,1:8,180,1) ***************
[03/24/2023-12:57:25] [V] [TRT] *************** Autotuning format combination: Half(1036800,1:16,5760,32) -> Half(32400,1:16,180,1) ***************
[03/24/2023-12:57:25] [V] [TRT] =============== Computing costs for 
[03/24/2023-12:57:25] [V] [TRT] *************** Autotuning format combination: Float(16588800,32400,180,1) -> Float(64800,32400,180,1) ***************
[03/24/2023-12:57:25] [V] [TRT] *************** Autotuning format combination: Float(16588800,1,92160,512) -> Float(64800,1,360,2) ***************
[03/24/2023-12:57:25] [V] [TRT] *************** Autotuning format combination: Float(4147200,1:4,23040,128) -> Float(32400,1:4,180,1) ***************
[03/24/2023-12:57:25] [V] [TRT] *************** Autotuning format combination: Half(16588800,32400,180,1) -> Half(64800,32400,180,1) ***************
[03/24/2023-12:57:25] [V] [TRT] *************** Autotuning format combination: Half(8294400,32400:2,180,1) -> Half(32400,32400:2,180,1) ***************
[03/24/2023-12:57:25] [V] [TRT] *************** Autotuning format combination: Half(2073600,1:8,11520,64) -> Float(64800,32400,180,1) ***************
[03/24/2023-12:57:25] [V] [TRT] *************** Autotuning format combination: Half(2073600,1:8,11520,64) -> Half(32400,1:8,180,1) ***************
[03/24/2023-12:57:25] [V] [TRT] *************** Autotuning format combination: Half(1036800,1:16,5760,32) -> Half(32400,1:16,180,1) ***************
[03/24/2023-12:57:25] [V] [TRT] =============== Computing costs for 
[03/24/2023-12:57:25] [V] [TRT] *************** Autotuning format combination: Float(16588800,32400,180,1) -> Float(32400,32400,180,1) ***************
[03/24/2023-12:57:25] [V] [TRT] *************** Autotuning format combination: Float(16588800,1,92160,512) -> Float(32400,1,180,1) ***************
[03/24/2023-12:57:25] [V] [TRT] *************** Autotuning format combination: Float(4147200,1:4,23040,128) -> Float(32400,1:4,180,1) ***************
[03/24/2023-12:57:25] [V] [TRT] *************** Autotuning format combination: Half(16588800,32400,180,1) -> Half(32400,32400,180,1) ***************
[03/24/2023-12:57:25] [V] [TRT] *************** Autotuning format combination: Half(8294400,32400:2,180,1) -> Half(32400,32400:2,180,1) ***************
[03/24/2023-12:57:25] [V] [TRT] *************** Autotuning format combination: Half(2073600,1:8,11520,64) -> Float(32400,32400,180,1) ***************
[03/24/2023-12:57:25] [V] [TRT] *************** Autotuning format combination: Half(2073600,1:8,11520,64) -> Half(32400,1:8,180,1) ***************
[03/24/2023-12:57:25] [V] [TRT] *************** Autotuning format combination: Half(1036800,1:16,5760,32) -> Half(32400,1:16,180,1) ***************
[03/24/2023-12:57:25] [V] [TRT] =============== Computing costs for 
[03/24/2023-12:57:25] [V] [TRT] *************** Autotuning format combination: Float(2073600,32400,180,1) -> Float(16588800,32400,180,1) ***************
[03/24/2023-12:57:25] [V] [TRT] *************** Autotuning format combination: Float(2073600,1,11520,64) -> Float(16588800,1,92160,512) ***************
[03/24/2023-12:57:25] [V] [TRT] *************** Autotuning format combination: Float(518400,1:4,2880,16) -> Float(4147200,1:4,23040,128) ***************
[03/24/2023-12:57:25] [V] [TRT] *************** Autotuning format combination: Half(2073600,32400,180,1) -> Half(16588800,32400,180,1) ***************
[03/24/2023-12:57:25] [V] [TRT] *************** Autotuning format combination: Half(1036800,32400:2,180,1) -> Half(8294400,32400:2,180,1) ***************
[03/24/2023-12:57:25] [V] [TRT] *************** Autotuning format combination: Half(259200,1:8,1440,8) -> Float(16588800,32400,180,1) ***************
[03/24/2023-12:57:25] [V] [TRT] *************** Autotuning format combination: Half(259200,1:8,1440,8) -> Half(2073600,1:8,11520,64) ***************
[03/24/2023-12:57:25] [V] [TRT] *************** Autotuning format combination: Half(129600,1:16,720,4) -> Half(1036800,1:16,5760,32) ***************
[03/24/2023-12:57:25] [V] [TRT] =============== Computing costs for 
[03/24/2023-12:57:25] [V] [TRT] *************** Autotuning format combination: Float(16588800,32400,180,1) -> Float(64800,32400,180,1) ***************
[03/24/2023-12:57:25] [V] [TRT] *************** Autotuning format combination: Float(16588800,1,92160,512) -> Float(64800,1,360,2) ***************
[03/24/2023-12:57:25] [V] [TRT] *************** Autotuning format combination: Float(4147200,1:4,23040,128) -> Float(32400,1:4,180,1) ***************
[03/24/2023-12:57:25] [V] [TRT] *************** Autotuning format combination: Half(16588800,32400,180,1) -> Half(64800,32400,180,1) ***************
[03/24/2023-12:57:25] [V] [TRT] *************** Autotuning format combination: Half(8294400,32400:2,180,1) -> Half(32400,32400:2,180,1) ***************
[03/24/2023-12:57:25] [V] [TRT] *************** Autotuning format combination: Half(2073600,1:8,11520,64) -> Float(64800,32400,180,1) ***************
[03/24/2023-12:57:25] [V] [TRT] *************** Autotuning format combination: Half(2073600,1:8,11520,64) -> Half(32400,1:8,180,1) ***************
[03/24/2023-12:57:25] [V] [TRT] *************** Autotuning format combination: Half(1036800,1:16,5760,32) -> Half(32400,1:16,180,1) ***************
[03/24/2023-12:57:25] [V] [TRT] =============== Computing costs for 
[03/24/2023-12:57:25] [V] [TRT] *************** Autotuning format combination: Float(16588800,32400,180,1) -> Float(32400,32400,180,1) ***************
[03/24/2023-12:57:25] [V] [TRT] *************** Autotuning format combination: Float(16588800,1,92160,512) -> Float(32400,1,180,1) ***************
[03/24/2023-12:57:25] [V] [TRT] *************** Autotuning format combination: Float(4147200,1:4,23040,128) -> Float(32400,1:4,180,1) ***************
[03/24/2023-12:57:25] [V] [TRT] *************** Autotuning format combination: Half(16588800,32400,180,1) -> Half(32400,32400,180,1) ***************
[03/24/2023-12:57:25] [V] [TRT] *************** Autotuning format combination: Half(8294400,32400:2,180,1) -> Half(32400,32400:2,180,1) ***************
[03/24/2023-12:57:25] [V] [TRT] *************** Autotuning format combination: Half(2073600,1:8,11520,64) -> Float(32400,32400,180,1) ***************
[03/24/2023-12:57:25] [V] [TRT] *************** Autotuning format combination: Half(2073600,1:8,11520,64) -> Half(32400,1:8,180,1) ***************
[03/24/2023-12:57:25] [V] [TRT] *************** Autotuning format combination: Half(1036800,1:16,5760,32) -> Half(32400,1:16,180,1) ***************
[03/24/2023-12:57:25] [V] [TRT] =============== Computing costs for 
[03/24/2023-12:57:25] [V] [TRT] *************** Autotuning format combination: Float(16588800,32400,180,1) -> Float(97200,32400,180,1) ***************
[03/24/2023-12:57:25] [V] [TRT] *************** Autotuning format combination: Float(16588800,1,92160,512) -> Float(97200,1,540,3) ***************
[03/24/2023-12:57:25] [V] [TRT] *************** Autotuning format combination: Float(4147200,1:4,23040,128) -> Float(32400,1:4,180,1) ***************
[03/24/2023-12:57:25] [V] [TRT] *************** Autotuning format combination: Half(16588800,32400,180,1) -> Half(97200,32400,180,1) ***************
[03/24/2023-12:57:25] [V] [TRT] *************** Autotuning format combination: Half(8294400,32400:2,180,1) -> Half(64800,32400:2,180,1) ***************
[03/24/2023-12:57:25] [V] [TRT] *************** Autotuning format combination: Half(2073600,1:8,11520,64) -> Float(97200,32400,180,1) ***************
[03/24/2023-12:57:25] [V] [TRT] *************** Autotuning format combination: Half(2073600,1:8,11520,64) -> Half(32400,1:8,180,1) ***************
[03/24/2023-12:57:25] [V] [TRT] *************** Autotuning format combination: Half(1036800,1:16,5760,32) -> Half(32400,1:16,180,1) ***************
[03/24/2023-12:57:25] [V] [TRT] =============== Computing costs for 
[03/24/2023-12:57:25] [V] [TRT] *************** Autotuning format combination: Float(16588800,32400,180,1) -> Float(64800,32400,180,1) ***************
[03/24/2023-12:57:25] [V] [TRT] *************** Autotuning format combination: Float(16588800,1,92160,512) -> Float(64800,1,360,2) ***************
[03/24/2023-12:57:25] [V] [TRT] *************** Autotuning format combination: Float(4147200,1:4,23040,128) -> Float(32400,1:4,180,1) ***************
[03/24/2023-12:57:25] [V] [TRT] *************** Autotuning format combination: Half(16588800,32400,180,1) -> Half(64800,32400,180,1) ***************
[03/24/2023-12:57:25] [V] [TRT] *************** Autotuning format combination: Half(8294400,32400:2,180,1) -> Half(32400,32400:2,180,1) ***************
[03/24/2023-12:57:25] [V] [TRT] *************** Autotuning format combination: Half(2073600,1:8,11520,64) -> Float(64800,32400,180,1) ***************
[03/24/2023-12:57:25] [V] [TRT] *************** Autotuning format combination: Half(2073600,1:8,11520,64) -> Half(32400,1:8,180,1) ***************
[03/24/2023-12:57:25] [V] [TRT] *************** Autotuning format combination: Half(1036800,1:16,5760,32) -> Half(32400,1:16,180,1) ***************
[03/24/2023-12:57:25] [V] [TRT] =============== Computing costs for 
[03/24/2023-12:57:25] [V] [TRT] *************** Autotuning format combination: Float(16588800,32400,180,1) -> Float(64800,32400,180,1) ***************
[03/24/2023-12:57:25] [V] [TRT] *************** Autotuning format combination: Float(16588800,1,92160,512) -> Float(64800,1,360,2) ***************
[03/24/2023-12:57:25] [V] [TRT] *************** Autotuning format combination: Float(4147200,1:4,23040,128) -> Float(32400,1:4,180,1) ***************
[03/24/2023-12:57:25] [V] [TRT] *************** Autotuning format combination: Half(16588800,32400,180,1) -> Half(64800,32400,180,1) ***************
[03/24/2023-12:57:25] [V] [TRT] *************** Autotuning format combination: Half(8294400,32400:2,180,1) -> Half(32400,32400:2,180,1) ***************
[03/24/2023-12:57:25] [V] [TRT] *************** Autotuning format combination: Half(2073600,1:8,11520,64) -> Float(64800,32400,180,1) ***************
[03/24/2023-12:57:25] [V] [TRT] *************** Autotuning format combination: Half(2073600,1:8,11520,64) -> Half(32400,1:8,180,1) ***************
[03/24/2023-12:57:25] [V] [TRT] *************** Autotuning format combination: Half(1036800,1:16,5760,32) -> Half(32400,1:16,180,1) ***************
[03/24/2023-12:57:25] [V] [TRT] =============== Computing costs for 
[03/24/2023-12:57:25] [V] [TRT] *************** Autotuning format combination: Float(16588800,32400,180,1) -> Float(64800,32400,180,1) ***************
[03/24/2023-12:57:25] [V] [TRT] *************** Autotuning format combination: Float(16588800,1,92160,512) -> Float(64800,1,360,2) ***************
[03/24/2023-12:57:25] [V] [TRT] *************** Autotuning format combination: Float(4147200,1:4,23040,128) -> Float(32400,1:4,180,1) ***************
[03/24/2023-12:57:25] [V] [TRT] *************** Autotuning format combination: Half(16588800,32400,180,1) -> Half(64800,32400,180,1) ***************
[03/24/2023-12:57:25] [V] [TRT] *************** Autotuning format combination: Half(8294400,32400:2,180,1) -> Half(32400,32400:2,180,1) ***************
[03/24/2023-12:57:25] [V] [TRT] *************** Autotuning format combination: Half(2073600,1:8,11520,64) -> Float(64800,32400,180,1) ***************
[03/24/2023-12:57:25] [V] [TRT] *************** Autotuning format combination: Half(2073600,1:8,11520,64) -> Half(32400,1:8,180,1) ***************
[03/24/2023-12:57:25] [V] [TRT] *************** Autotuning format combination: Half(1036800,1:16,5760,32) -> Half(32400,1:16,180,1) ***************
[03/24/2023-12:57:25] [V] [TRT] =============== Computing costs for 
[03/24/2023-12:57:25] [V] [TRT] *************** Autotuning format combination: Float(16588800,32400,180,1) -> Float(64800,32400,180,1) ***************
[03/24/2023-12:57:25] [V] [TRT] *************** Autotuning format combination: Float(16588800,1,92160,512) -> Float(64800,1,360,2) ***************
[03/24/2023-12:57:25] [V] [TRT] *************** Autotuning format combination: Float(4147200,1:4,23040,128) -> Float(32400,1:4,180,1) ***************
[03/24/2023-12:57:25] [V] [TRT] *************** Autotuning format combination: Half(16588800,32400,180,1) -> Half(64800,32400,180,1) ***************
[03/24/2023-12:57:25] [V] [TRT] *************** Autotuning format combination: Half(8294400,32400:2,180,1) -> Half(32400,32400:2,180,1) ***************
[03/24/2023-12:57:25] [V] [TRT] *************** Autotuning format combination: Half(2073600,1:8,11520,64) -> Float(64800,32400,180,1) ***************
[03/24/2023-12:57:25] [V] [TRT] *************** Autotuning format combination: Half(2073600,1:8,11520,64) -> Half(32400,1:8,180,1) ***************
[03/24/2023-12:57:25] [V] [TRT] *************** Autotuning format combination: Half(1036800,1:16,5760,32) -> Half(32400,1:16,180,1) ***************
[03/24/2023-12:57:25] [V] [TRT] =============== Computing costs for 
[03/24/2023-12:57:25] [V] [TRT] *************** Autotuning format combination: Float(16588800,32400,180,1) -> Float(32400,32400,180,1) ***************
[03/24/2023-12:57:25] [V] [TRT] *************** Autotuning format combination: Float(16588800,1,92160,512) -> Float(32400,1,180,1) ***************
[03/24/2023-12:57:25] [V] [TRT] *************** Autotuning format combination: Float(4147200,1:4,23040,128) -> Float(32400,1:4,180,1) ***************
[03/24/2023-12:57:25] [V] [TRT] *************** Autotuning format combination: Half(16588800,32400,180,1) -> Half(32400,32400,180,1) ***************
[03/24/2023-12:57:25] [V] [TRT] *************** Autotuning format combination: Half(8294400,32400:2,180,1) -> Half(32400,32400:2,180,1) ***************
[03/24/2023-12:57:25] [V] [TRT] *************** Autotuning format combination: Half(2073600,1:8,11520,64) -> Float(32400,32400,180,1) ***************
[03/24/2023-12:57:25] [V] [TRT] *************** Autotuning format combination: Half(2073600,1:8,11520,64) -> Half(32400,1:8,180,1) ***************
[03/24/2023-12:57:25] [V] [TRT] *************** Autotuning format combination: Half(1036800,1:16,5760,32) -> Half(32400,1:16,180,1) ***************
[03/24/2023-12:57:25] [V] [TRT] =============== Computing costs for 
[03/24/2023-12:57:25] [V] [TRT] *************** Autotuning format combination: Float(2073600,32400,180,1) -> Float(8294400,32400,180,1) ***************
[03/24/2023-12:57:25] [V] [TRT] --------------- Timing Runner: Conv_158 + Relu_159 || Conv_161 + Relu_162 || Conv_164 + Relu_165 || Conv_167 + Relu_168 (CudaDepthwiseConvolution)
[03/24/2023-12:57:25] [V] [TRT] CudaDepthwiseConvolution has no valid tactics for this config, skipping
[03/24/2023-12:57:25] [V] [TRT] --------------- Timing Runner: Conv_158 + Relu_159 || Conv_161 + Relu_162 || Conv_164 + Relu_165 || Conv_167 + Relu_168 (FusedConvActConvolution)
[03/24/2023-12:57:25] [V] [TRT] Tactic: 524287 Time: 1.1113
[03/24/2023-12:57:25] [V] [TRT] Tactic: 720895 Time: 1.09184
[03/24/2023-12:57:26] [V] [TRT] Tactic: 983039 Time: 1.05843
[03/24/2023-12:57:26] [V] [TRT] Tactic: 1048575 Time: 1.13562
[03/24/2023-12:57:26] [V] [TRT] Tactic: 1703935 Time: 1.12934
[03/24/2023-12:57:26] [V] [TRT] Tactic: 1769471 Time: 0.82176
[03/24/2023-12:57:26] [V] [TRT] Tactic: 1966079 Time: 0.68864
[03/24/2023-12:57:26] [V] [TRT] Tactic: 2031615 Time: 0.6496
[03/24/2023-12:57:26] [V] [TRT] Tactic: 2228223 Time: 0.63936
[03/24/2023-12:57:26] [V] [TRT] Tactic: 2424831 Time: 0.81408
[03/24/2023-12:57:26] [V] [TRT] Tactic: 2621439 Time: 0.6432
[03/24/2023-12:57:26] [V] [TRT] Tactic: 2752511 Time: 0.637568
[03/24/2023-12:57:26] [V] [TRT] Tactic: 2818047 Time: 0.651392
[03/24/2023-12:57:26] [V] [TRT] Tactic: 2883583 Time: 0.707584
[03/24/2023-12:57:26] [V] [TRT] Tactic: 3014655 Time: 0.632064
[03/24/2023-12:57:26] [V] [TRT] Tactic: 3145727 Time: 0.60736
[03/24/2023-12:57:26] [V] [TRT] Tactic: 3473407 Time: 0.636032
[03/24/2023-12:57:26] [V] [TRT] Tactic: 3604479 Time: 0.621696
[03/24/2023-12:57:26] [V] [TRT] Tactic: 3735551 Time: 0.646016
[03/24/2023-12:57:26] [V] [TRT] Tactic: 4390911 Time: 0.70336
[03/24/2023-12:57:26] [V] [TRT] Tactic: 5046271 Time: 0.604416
[03/24/2023-12:57:26] [V] [TRT] Tactic: 5963775 Time: 0.652288
[03/24/2023-12:57:26] [V] [TRT] Tactic: 6160383 Time: 0.642176
[03/24/2023-12:57:26] [V] [TRT] Tactic: 6488063 Time: 0.620416
[03/24/2023-12:57:27] [V] [TRT] Tactic: 6881279 Time: 0.665728
[03/24/2023-12:57:27] [V] [TRT] Tactic: 7274495 Time: 0.6912
[03/24/2023-12:57:27] [V] [TRT] Tactic: 7864319 Time: 0.640256
[03/24/2023-12:57:27] [V] [TRT] Tactic: 7995391 Time: 0.61312
[03/24/2023-12:57:27] [V] [TRT] Tactic: 8585215 Time: 0.645504
[03/24/2023-12:57:27] [V] [TRT] Tactic: 8847359 Time: 0.655488
[03/24/2023-12:57:27] [V] [TRT] Tactic: 8978431 Time: 0.659456
[03/24/2023-12:57:27] [V] [TRT] Tactic: 9043967 Time: 0.60352
[03/24/2023-12:57:27] [V] [TRT] Tactic: 9175039 Time: 0.621696
[03/24/2023-12:57:27] [V] [TRT] Tactic: 9502719 Time: 0.705792
[03/24/2023-12:57:27] [V] [TRT] Tactic: 9830399 Time: 0.64128
[03/24/2023-12:57:27] [V] [TRT] Tactic: 9961471 Time: 0.778368
[03/24/2023-12:57:27] [V] [TRT] Tactic: 10027007 Time: 0.6016
[03/24/2023-12:57:27] [V] [TRT] Tactic: 10092543 Time: 0.705664
[03/24/2023-12:57:27] [V] [TRT] Tactic: 10289151 Time: 0.673152
[03/24/2023-12:57:27] [V] [TRT] Tactic: 10485759 Time: 0.592768
[03/24/2023-12:57:27] [V] [TRT] Tactic: 10682367 Time: 0.633344
[03/24/2023-12:57:27] [V] [TRT] Tactic: 10813439 Time: 0.58816
[03/24/2023-12:57:27] [V] [TRT] Fastest Tactic: 10813439 Time: 0.58816
[03/24/2023-12:57:27] [V] [TRT] --------------- Timing Runner: Conv_158 + Relu_159 || Conv_161 + Relu_162 || Conv_164 + Relu_165 || Conv_167 + Relu_168 (CudnnConvolution)
[03/24/2023-12:57:27] [V] [TRT] Tactic: 0 Time: 0.859648
[03/24/2023-12:57:27] [V] [TRT] Tactic: 1 Time: 0.276736
[03/24/2023-12:57:27] [V] [TRT] Tactic: 2 Time: 0.913792
[03/24/2023-12:57:27] [V] [TRT] Tactic: 4 skipped. Scratch requested: 8691449856, available: 4294967296
[03/24/2023-12:57:27] [V] [TRT] Tactic: 5 Time: 2.60096
[03/24/2023-12:57:27] [V] [TRT] Tactic: 6 Time: 0.428288
[03/24/2023-12:57:27] [V] [TRT] Tactic: 56 Time: 0.859904
[03/24/2023-12:57:27] [V] [TRT] Tactic: 57 Time: 0.277248
[03/24/2023-12:57:27] [V] [TRT] Tactic: 58 Time: 0.91264
[03/24/2023-12:57:27] [V] [TRT] Tactic: 60 skipped. Scratch requested: 8691449856, available: 4294967296
[03/24/2023-12:57:28] [V] [TRT] Tactic: 61 Time: 2.59891
[03/24/2023-12:57:28] [V] [TRT] Tactic: 62 Time: 0.427904
[03/24/2023-12:57:28] [V] [TRT] Tactic: 112 Time: 0.859392
[03/24/2023-12:57:28] [V] [TRT] Tactic: 113 Time: 0.678016
[03/24/2023-12:57:28] [V] [TRT] Tactic: 114 Time: 0.914944
[03/24/2023-12:57:28] [V] [TRT] Tactic: 116 skipped. Scratch requested: 8691449856, available: 4294967296
[03/24/2023-12:57:28] [V] [TRT] Tactic: 117 Time: 2.59917
[03/24/2023-12:57:28] [V] [TRT] Tactic: 118 Time: 0.42816
[03/24/2023-12:57:28] [V] [TRT] Fastest Tactic: 1 Time: 0.276736
[03/24/2023-12:57:28] [V] [TRT] Setting workspace to 8691449856enables more tactics for profiling
[03/24/2023-12:57:28] [V] [TRT] --------------- Timing Runner: Conv_158 + Relu_159 || Conv_161 + Relu_162 || Conv_164 + Relu_165 || Conv_167 + Relu_168 (CaskConvolution)
[03/24/2023-12:57:28] [V] [TRT] Conv_158 + Relu_159 || Conv_161 + Relu_162 || Conv_164 + Relu_165 || Conv_167 + Relu_168 Set Tactic Name: ampere_scudnn_128x64_relu_small_nn_v1 Tactic: 4549827808004681195
[03/24/2023-12:57:28] [V] [TRT] Tactic: 4549827808004681195 Time: 0.570496
[03/24/2023-12:57:28] [V] [TRT] Conv_158 + Relu_159 || Conv_161 + Relu_162 || Conv_164 + Relu_165 || Conv_167 + Relu_168 Set Tactic Name: ampere_scudnn_128x128_relu_small_nn_v1 Tactic: 5779835512569528575
[03/24/2023-12:57:28] [V] [TRT] Tactic: 5779835512569528575 Time: 0.552448
[03/24/2023-12:57:28] [V] [TRT] Conv_158 + Relu_159 || Conv_161 + Relu_162 || Conv_164 + Relu_165 || Conv_167 + Relu_168 Set Tactic Name: ampere_scudnn_128x128_relu_xregs_large_nn_v1 Tactic: 6053873026024413720
[03/24/2023-12:57:28] [V] [TRT] Tactic: 6053873026024413720 Time: 0.591232
[03/24/2023-12:57:28] [V] [TRT] Conv_158 + Relu_159 || Conv_161 + Relu_162 || Conv_164 + Relu_165 || Conv_167 + Relu_168 Set Tactic Name: ampere_scudnn_128x64_relu_xregs_large_nn_v1 Tactic: 6767548733843469815
[03/24/2023-12:57:28] [V] [TRT] Tactic: 6767548733843469815 Time: 0.564352
[03/24/2023-12:57:28] [V] [TRT] Conv_158 + Relu_159 || Conv_161 + Relu_162 || Conv_164 + Relu_165 || Conv_167 + Relu_168 Set Tactic Name: ampere_scudnn_128x32_relu_small_nn_v1 Tactic: -6313876406580483184
[03/24/2023-12:57:28] [V] [TRT] Tactic: -6313876406580483184 Time: 0.612096
[03/24/2023-12:57:28] [V] [TRT] Conv_158 + Relu_159 || Conv_161 + Relu_162 || Conv_164 + Relu_165 || Conv_167 + Relu_168 Set Tactic Name: ampere_scudnn_128x128_relu_medium_nn_v1 Tactic: -1123676555321336786
[03/24/2023-12:57:28] [V] [TRT] Tactic: -1123676555321336786 Time: 0.553216
[03/24/2023-12:57:28] [V] [TRT] Conv_158 + Relu_159 || Conv_161 + Relu_162 || Conv_164 + Relu_165 || Conv_167 + Relu_168 Set Tactic Name: ampere_scudnn_128x64_relu_medium_nn_v1 Tactic: -701551393537224327
[03/24/2023-12:57:28] [V] [TRT] Tactic: -701551393537224327 Time: 0.575104
[03/24/2023-12:57:28] [V] [TRT] Fastest Tactic: 5779835512569528575 Time: 0.552448
[03/24/2023-12:57:28] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CudnnConvolution Tactic: 1
[03/24/2023-12:57:28] [V] [TRT] *************** Autotuning format combination: Float(2073600,1,11520,64) -> Float(8294400,1,46080,256) ***************
[03/24/2023-12:57:28] [V] [TRT] --------------- Timing Runner: Conv_158 + Relu_159 || Conv_161 + Relu_162 || Conv_164 + Relu_165 || Conv_167 + Relu_168 (CudnnConvolution)
[03/24/2023-12:57:28] [V] [TRT] CudnnConvolution has no valid tactics for this config, skipping
[03/24/2023-12:57:28] [V] [TRT] --------------- Timing Runner: Conv_158 + Relu_159 || Conv_161 + Relu_162 || Conv_164 + Relu_165 || Conv_167 + Relu_168 (CaskConvolution)
[03/24/2023-12:57:28] [V] [TRT] Conv_158 + Relu_159 || Conv_161 + Relu_162 || Conv_164 + Relu_165 || Conv_167 + Relu_168 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize64x128x8_stage3_warpsize1x4x1_g1_ffma_t1r3s3 Tactic: 2086609538387166260
[03/24/2023-12:57:28] [V] [TRT] Tactic: 2086609538387166260 Time: 0.553728
[03/24/2023-12:57:28] [V] [TRT] Conv_158 + Relu_159 || Conv_161 + Relu_162 || Conv_164 + Relu_165 || Conv_167 + Relu_168 Set Tactic Name: ampere_scudnn_128x64_sliced1x2_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: 2860655430572478466
[03/24/2023-12:57:28] [V] [TRT] Tactic: 2860655430572478466 Time: 0.566272
[03/24/2023-12:57:28] [V] [TRT] Conv_158 + Relu_159 || Conv_161 + Relu_162 || Conv_164 + Relu_165 || Conv_167 + Relu_168 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize64x128x8_stage3_warpsize1x4x1_g1_ffma Tactic: 3239733199291090177
[03/24/2023-12:57:28] [V] [TRT] Tactic: 3239733199291090177 Time: 0.552064
[03/24/2023-12:57:28] [V] [TRT] Conv_158 + Relu_159 || Conv_161 + Relu_162 || Conv_164 + Relu_165 || Conv_167 + Relu_168 Set Tactic Name: ampere_scudnn_128x32_sliced1x4_ldg4_relu_exp_medium_nhwc_tn_v1 Tactic: 4474630279712975759
[03/24/2023-12:57:28] [V] [TRT] Tactic: 4474630279712975759 Time: 0.553088
[03/24/2023-12:57:28] [V] [TRT] Conv_158 + Relu_159 || Conv_161 + Relu_162 || Conv_164 + Relu_165 || Conv_167 + Relu_168 Set Tactic Name: ampere_scudnn_128x32_sliced1x4_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: 4479823862704990365
[03/24/2023-12:57:28] [V] [TRT] Tactic: 4479823862704990365 Time: 0.549376
[03/24/2023-12:57:28] [V] [TRT] Conv_158 + Relu_159 || Conv_161 + Relu_162 || Conv_164 + Relu_165 || Conv_167 + Relu_168 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize64x256x8_stage3_warpsize1x4x1_g1_ffma Tactic: 4517590677127196184
[03/24/2023-12:57:28] [V] [TRT] Tactic: 4517590677127196184 Time: 0.688768
[03/24/2023-12:57:28] [V] [TRT] Conv_158 + Relu_159 || Conv_161 + Relu_162 || Conv_164 + Relu_165 || Conv_167 + Relu_168 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize128x128x8_stage3_warpsize2x4x1_g1_ffma_t1r3s3 Tactic: 4634080872644479428
[03/24/2023-12:57:28] [V] [TRT] Tactic: 4634080872644479428 Time: 0.568704
[03/24/2023-12:57:28] [V] [TRT] Conv_158 + Relu_159 || Conv_161 + Relu_162 || Conv_164 + Relu_165 || Conv_167 + Relu_168 Set Tactic Name: ampere_scudnn_128x64_sliced1x2_ldg4_relu_exp_medium_nhwc_tn_v1 Tactic: 4696204239951173149
[03/24/2023-12:57:28] [V] [TRT] Tactic: 4696204239951173149 Time: 0.566272
[03/24/2023-12:57:28] [V] [TRT] Conv_158 + Relu_159 || Conv_161 + Relu_162 || Conv_164 + Relu_165 || Conv_167 + Relu_168 Set Tactic Name: ampere_scudnn_128x128_relu_exp_small_nhwc_tn_v1 Tactic: 5778138195697110003
[03/24/2023-12:57:28] [V] [TRT] Tactic: 5778138195697110003 Time: 0.550272
[03/24/2023-12:57:28] [V] [TRT] Conv_158 + Relu_159 || Conv_161 + Relu_162 || Conv_164 + Relu_165 || Conv_167 + Relu_168 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize256x128x8_stage3_warpsize2x4x1_g1_ffma Tactic: 6310198979346901507
[03/24/2023-12:57:28] [V] [TRT] Tactic: 6310198979346901507 Time: 0.704768
[03/24/2023-12:57:28] [V] [TRT] Conv_158 + Relu_159 || Conv_161 + Relu_162 || Conv_164 + Relu_165 || Conv_167 + Relu_168 Set Tactic Name: ampere_scudnn_128x128_ldg4_relu_exp_large_nhwc_tn_v1 Tactic: 7155825427510256858
[03/24/2023-12:57:28] [V] [TRT] Tactic: 7155825427510256858 Time: 0.551936
[03/24/2023-12:57:28] [V] [TRT] Conv_158 + Relu_159 || Conv_161 + Relu_162 || Conv_164 + Relu_165 || Conv_167 + Relu_168 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize128x64x8_stage3_warpsize1x4x1_g1_ffma Tactic: 7222247112373541608
[03/24/2023-12:57:28] [V] [TRT] Tactic: 7222247112373541608 Time: 0.591616
[03/24/2023-12:57:28] [V] [TRT] Conv_158 + Relu_159 || Conv_161 + Relu_162 || Conv_164 + Relu_165 || Conv_167 + Relu_168 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize128x128x8_stage3_warpsize2x4x1_g1_ffma Tactic: 7472640475524677095
[03/24/2023-12:57:28] [V] [TRT] Tactic: 7472640475524677095 Time: 0.5792
[03/24/2023-12:57:28] [V] [TRT] Conv_158 + Relu_159 || Conv_161 + Relu_162 || Conv_164 + Relu_165 || Conv_167 + Relu_168 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize128x256x8_stage3_warpsize2x4x1_g1_ffma Tactic: 8498373915030836990
[03/24/2023-12:57:28] [V] [TRT] Tactic: 8498373915030836990 Time: 0.68672
[03/24/2023-12:57:28] [V] [TRT] Conv_158 + Relu_159 || Conv_161 + Relu_162 || Conv_164 + Relu_165 || Conv_167 + Relu_168 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize256x64x8_stage3_warpsize1x4x1_g1_ffma Tactic: 8869697132622550639
[03/24/2023-12:57:28] [V] [TRT] Tactic: 8869697132622550639 Time: 0.776448
[03/24/2023-12:57:28] [V] [TRT] Conv_158 + Relu_159 || Conv_161 + Relu_162 || Conv_164 + Relu_165 || Conv_167 + Relu_168 Set Tactic Name: ampere_scudnn_128x128_ldg4_relu_exp_medium_nhwc_tn_v1 Tactic: 8918020581761223752
[03/24/2023-12:57:28] [V] [TRT] Tactic: 8918020581761223752 Time: 0.546944
[03/24/2023-12:57:28] [V] [TRT] Conv_158 + Relu_159 || Conv_161 + Relu_162 || Conv_164 + Relu_165 || Conv_167 + Relu_168 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize256x128x8_stage3_warpsize2x4x1_g1_ffma_t1r3s3 Tactic: -8937725997228636978
[03/24/2023-12:57:28] [V] [TRT] Tactic: -8937725997228636978 Time: 0.680576
[03/24/2023-12:57:28] [V] [TRT] Conv_158 + Relu_159 || Conv_161 + Relu_162 || Conv_164 + Relu_165 || Conv_167 + Relu_168 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize128x256x8_stage3_warpsize2x4x1_g1_ffma_t1r3s3 Tactic: -8833858409138163072
[03/24/2023-12:57:28] [V] [TRT] Tactic: -8833858409138163072 Time: 0.676096
[03/24/2023-12:57:28] [V] [TRT] Conv_158 + Relu_159 || Conv_161 + Relu_162 || Conv_164 + Relu_165 || Conv_167 + Relu_168 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize64x64x8_stage3_warpsize1x4x1_g1_ffma_t1r3s3 Tactic: -7989138351613022500
[03/24/2023-12:57:28] [V] [TRT] Tactic: -7989138351613022500 Time: 0.532608
[03/24/2023-12:57:28] [V] [TRT] Conv_158 + Relu_159 || Conv_161 + Relu_162 || Conv_164 + Relu_165 || Conv_167 + Relu_168 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize256x128x8_stage3_warpsize2x4x1_g1_ffma Tactic: -7872883691240863058
[03/24/2023-12:57:28] [V] [TRT] Tactic: -7872883691240863058 Time: 0.70592
[03/24/2023-12:57:28] [V] [TRT] Conv_158 + Relu_159 || Conv_161 + Relu_162 || Conv_164 + Relu_165 || Conv_167 + Relu_168 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize128x128x8_stage3_warpsize2x4x1_g1_ffma Tactic: -6729618519651721910
[03/24/2023-12:57:28] [V] [TRT] Tactic: -6729618519651721910 Time: 0.5728
[03/24/2023-12:57:28] [V] [TRT] Conv_158 + Relu_159 || Conv_161 + Relu_162 || Conv_164 + Relu_165 || Conv_167 + Relu_168 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize256x64x8_stage3_warpsize1x4x1_g1_ffma Tactic: -5893833996418445881
[03/24/2023-12:57:28] [V] [TRT] Tactic: -5893833996418445881 Time: 0.758784
[03/24/2023-12:57:28] [V] [TRT] Conv_158 + Relu_159 || Conv_161 + Relu_162 || Conv_164 + Relu_165 || Conv_167 + Relu_168 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize128x256x8_stage3_warpsize2x4x1_g1_ffma Tactic: -5701562095007058349
[03/24/2023-12:57:28] [V] [TRT] Tactic: -5701562095007058349 Time: 0.678144
[03/24/2023-12:57:28] [V] [TRT] Conv_158 + Relu_159 || Conv_161 + Relu_162 || Conv_164 + Relu_165 || Conv_167 + Relu_168 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize128x64x8_stage3_warpsize1x4x1_g1_ffma Tactic: -5685503422376017600
[03/24/2023-12:57:28] [V] [TRT] Tactic: -5685503422376017600 Time: 0.573312
[03/24/2023-12:57:28] [V] [TRT] Conv_158 + Relu_159 || Conv_161 + Relu_162 || Conv_164 + Relu_165 || Conv_167 + Relu_168 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize64x64x8_stage3_warpsize1x4x1_g1_ffma Tactic: -5521125187060117489
[03/24/2023-12:57:28] [V] [TRT] Tactic: -5521125187060117489 Time: 0.577536
[03/24/2023-12:57:28] [V] [TRT] Conv_158 + Relu_159 || Conv_161 + Relu_162 || Conv_164 + Relu_165 || Conv_167 + Relu_168 Set Tactic Name: ampere_scudnn_128x64_sliced1x2_ldg4_relu_exp_large_nhwc_tn_v1 Tactic: -4756382386362004279
[03/24/2023-12:57:28] [V] [TRT] Tactic: -4756382386362004279 Time: 0.558976
[03/24/2023-12:57:28] [V] [TRT] Conv_158 + Relu_159 || Conv_161 + Relu_162 || Conv_164 + Relu_165 || Conv_167 + Relu_168 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize64x64x8_stage3_warpsize1x4x1_g1_ffma Tactic: -4615000974950361663
[03/24/2023-12:57:28] [V] [TRT] Tactic: -4615000974950361663 Time: 0.552576
[03/24/2023-12:57:28] [V] [TRT] Conv_158 + Relu_159 || Conv_161 + Relu_162 || Conv_164 + Relu_165 || Conv_167 + Relu_168 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize256x64x8_stage3_warpsize1x4x1_g1_ffma_t1r3s3 Tactic: -4314913710375142296
[03/24/2023-12:57:28] [V] [TRT] Tactic: -4314913710375142296 Time: 0.729856
[03/24/2023-12:57:28] [V] [TRT] Conv_158 + Relu_159 || Conv_161 + Relu_162 || Conv_164 + Relu_165 || Conv_167 + Relu_168 Set Tactic Name: ampere_scudnn_128x128_relu_exp_large_nhwc_tn_v1 Tactic: -3855385237722507464
[03/24/2023-12:57:28] [V] [TRT] Tactic: -3855385237722507464 Time: 0.553088
[03/24/2023-12:57:28] [V] [TRT] Conv_158 + Relu_159 || Conv_161 + Relu_162 || Conv_164 + Relu_165 || Conv_167 + Relu_168 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize128x64x8_stage3_warpsize1x4x1_g1_ffma_t1r3s3 Tactic: -3697587361057948972
[03/24/2023-12:57:28] [V] [TRT] Tactic: -3697587361057948972 Time: 0.57472
[03/24/2023-12:57:28] [V] [TRT] Conv_158 + Relu_159 || Conv_161 + Relu_162 || Conv_164 + Relu_165 || Conv_167 + Relu_168 Set Tactic Name: ampere_scudnn_128x128_relu_exp_medium_nhwc_tn_v1 Tactic: -2809379259463049391
[03/24/2023-12:57:28] [V] [TRT] Tactic: -2809379259463049391 Time: 0.552576
[03/24/2023-12:57:28] [V] [TRT] Conv_158 + Relu_159 || Conv_161 + Relu_162 || Conv_164 + Relu_165 || Conv_167 + Relu_168 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize64x256x8_stage3_warpsize1x4x1_g1_ffma_t1r3s3 Tactic: -2747929399988666512
[03/24/2023-12:57:28] [V] [TRT] Tactic: -2747929399988666512 Time: 0.674048
[03/24/2023-12:57:28] [V] [TRT] Conv_158 + Relu_159 || Conv_161 + Relu_162 || Conv_164 + Relu_165 || Conv_167 + Relu_168 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize64x256x8_stage3_warpsize1x4x1_g1_ffma Tactic: -1472061967969061456
[03/24/2023-12:57:28] [V] [TRT] Tactic: -1472061967969061456 Time: 0.675456
[03/24/2023-12:57:28] [V] [TRT] Conv_158 + Relu_159 || Conv_161 + Relu_162 || Conv_164 + Relu_165 || Conv_167 + Relu_168 Set Tactic Name: ampere_scudnn_128x128_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: -504296718212024303
[03/24/2023-12:57:28] [V] [TRT] Tactic: -504296718212024303 Time: 0.547072
[03/24/2023-12:57:28] [V] [TRT] Conv_158 + Relu_159 || Conv_161 + Relu_162 || Conv_164 + Relu_165 || Conv_167 + Relu_168 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize64x128x8_stage3_warpsize1x4x1_g1_ffma Tactic: -444093195553988951
[03/24/2023-12:57:28] [V] [TRT] Tactic: -444093195553988951 Time: 0.58048
[03/24/2023-12:57:28] [V] [TRT] Fastest Tactic: -7989138351613022500 Time: 0.532608
[03/24/2023-12:57:28] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: -7989138351613022500
[03/24/2023-12:57:28] [V] [TRT] *************** Autotuning format combination: Float(518400,1:4,2880,16) -> Float(2073600,1:4,11520,64) ***************
[03/24/2023-12:57:28] [V] [TRT] --------------- Timing Runner: Conv_158 + Relu_159 || Conv_161 + Relu_162 || Conv_164 + Relu_165 || Conv_167 + Relu_168 (CudnnConvolution)
[03/24/2023-12:57:28] [V] [TRT] CudnnConvolution has no valid tactics for this config, skipping
[03/24/2023-12:57:28] [V] [TRT] --------------- Timing Runner: Conv_158 + Relu_159 || Conv_161 + Relu_162 || Conv_164 + Relu_165 || Conv_167 + Relu_168 (CaskConvolution)
[03/24/2023-12:57:28] [V] [TRT] Conv_158 + Relu_159 || Conv_161 + Relu_162 || Conv_164 + Relu_165 || Conv_167 + Relu_168 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize64x128x32_stage5_warpsize2x2x1_g1_tensor16x8x8 Tactic: 1237784342446422381
[03/24/2023-12:57:28] [V] [TRT] Tactic: 1237784342446422381 Time: 0.156032
[03/24/2023-12:57:28] [V] [TRT] Conv_158 + Relu_159 || Conv_161 + Relu_162 || Conv_164 + Relu_165 || Conv_167 + Relu_168 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x64x32_stage5_warpsize2x2x1_g1_tensor16x8x8 Tactic: 1426562292875733922
[03/24/2023-12:57:28] [V] [TRT] Tactic: 1426562292875733922 Time: 0.166144
[03/24/2023-12:57:28] [V] [TRT] Conv_158 + Relu_159 || Conv_161 + Relu_162 || Conv_164 + Relu_165 || Conv_167 + Relu_168 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize64x128x8_stage3_warpsize1x4x1_g1_ffma_t1r3s3 Tactic: 2086609538387166260
[03/24/2023-12:57:28] [V] [TRT] Tactic: 2086609538387166260 Time: 0.553728
[03/24/2023-12:57:28] [V] [TRT] Conv_158 + Relu_159 || Conv_161 + Relu_162 || Conv_164 + Relu_165 || Conv_167 + Relu_168 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize256x128x32_stage3_warpsize4x2x1_g1_tensor16x8x8_t1r3s3 Tactic: 2388153022056233219
[03/24/2023-12:57:28] [V] [TRT] Tactic: 2388153022056233219 Time: 0.126336
[03/24/2023-12:57:28] [V] [TRT] Conv_158 + Relu_159 || Conv_161 + Relu_162 || Conv_164 + Relu_165 || Conv_167 + Relu_168 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x128x32_stage4_warpsize2x2x1_g1_tensor16x8x8 Tactic: 2716437853123234317
[03/24/2023-12:57:28] [V] [TRT] Tactic: 2716437853123234317 Time: 0.118784
[03/24/2023-12:57:28] [V] [TRT] Conv_158 + Relu_159 || Conv_161 + Relu_162 || Conv_164 + Relu_165 || Conv_167 + Relu_168 Set Tactic Name: ampere_scudnn_128x64_sliced1x2_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: 2860655430572478466
[03/24/2023-12:57:28] [V] [TRT] Tactic: 2860655430572478466 Time: 0.5664
[03/24/2023-12:57:28] [V] [TRT] Conv_158 + Relu_159 || Conv_161 + Relu_162 || Conv_164 + Relu_165 || Conv_167 + Relu_168 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize64x128x8_stage3_warpsize1x4x1_g1_ffma Tactic: 3239733199291090177
[03/24/2023-12:57:28] [V] [TRT] Tactic: 3239733199291090177 Time: 0.552448
[03/24/2023-12:57:28] [V] [TRT] Conv_158 + Relu_159 || Conv_161 + Relu_162 || Conv_164 + Relu_165 || Conv_167 + Relu_168 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize64x64x64_stage4_warpsize2x2x1_g1_tensor16x8x8_t1r3s3 Tactic: 3278852197192504305
[03/24/2023-12:57:28] [V] [TRT] Tactic: 3278852197192504305 Time: 0.201344
[03/24/2023-12:57:28] [V] [TRT] Conv_158 + Relu_159 || Conv_161 + Relu_162 || Conv_164 + Relu_165 || Conv_167 + Relu_168 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize256x128x32_stage3_warpsize4x2x1_g1_tensor16x8x8 Tactic: 3904690393614050557
[03/24/2023-12:57:28] [V] [TRT] Tactic: 3904690393614050557 Time: 0.153728
[03/24/2023-12:57:28] [V] [TRT] Conv_158 + Relu_159 || Conv_161 + Relu_162 || Conv_164 + Relu_165 || Conv_167 + Relu_168 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize64x64x64_stage4_warpsize2x2x1_g1_tensor16x8x8 Tactic: 4061115162338989075
[03/24/2023-12:57:28] [V] [TRT] Tactic: 4061115162338989075 Time: 0.20544
[03/24/2023-12:57:28] [V] [TRT] Conv_158 + Relu_159 || Conv_161 + Relu_162 || Conv_164 + Relu_165 || Conv_167 + Relu_168 Set Tactic Name: ampere_scudnn_128x32_sliced1x4_ldg4_relu_exp_medium_nhwc_tn_v1 Tactic: 4474630279712975759
[03/24/2023-12:57:29] [V] [TRT] Tactic: 4474630279712975759 Time: 0.553088
[03/24/2023-12:57:29] [V] [TRT] Conv_158 + Relu_159 || Conv_161 + Relu_162 || Conv_164 + Relu_165 || Conv_167 + Relu_168 Set Tactic Name: ampere_scudnn_128x32_sliced1x4_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: 4479823862704990365
[03/24/2023-12:57:29] [V] [TRT] Tactic: 4479823862704990365 Time: 0.54976
[03/24/2023-12:57:29] [V] [TRT] Conv_158 + Relu_159 || Conv_161 + Relu_162 || Conv_164 + Relu_165 || Conv_167 + Relu_168 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize64x256x8_stage3_warpsize1x4x1_g1_ffma Tactic: 4517590677127196184
[03/24/2023-12:57:29] [V] [TRT] Tactic: 4517590677127196184 Time: 0.689152
[03/24/2023-12:57:29] [V] [TRT] Conv_158 + Relu_159 || Conv_161 + Relu_162 || Conv_164 + Relu_165 || Conv_167 + Relu_168 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize128x128x8_stage3_warpsize2x4x1_g1_ffma_t1r3s3 Tactic: 4634080872644479428
[03/24/2023-12:57:29] [V] [TRT] Tactic: 4634080872644479428 Time: 0.568704
[03/24/2023-12:57:29] [V] [TRT] Conv_158 + Relu_159 || Conv_161 + Relu_162 || Conv_164 + Relu_165 || Conv_167 + Relu_168 Set Tactic Name: ampere_scudnn_128x64_sliced1x2_ldg4_relu_exp_medium_nhwc_tn_v1 Tactic: 4696204239951173149
[03/24/2023-12:57:29] [V] [TRT] Tactic: 4696204239951173149 Time: 0.566656
[03/24/2023-12:57:29] [V] [TRT] Conv_158 + Relu_159 || Conv_161 + Relu_162 || Conv_164 + Relu_165 || Conv_167 + Relu_168 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x256x32_stage3_warpsize2x4x1_g1_tensor16x8x8 Tactic: 5200329514761435342
[03/24/2023-12:57:29] [V] [TRT] Tactic: 5200329514761435342 Time: 0.121856
[03/24/2023-12:57:29] [V] [TRT] Conv_158 + Relu_159 || Conv_161 + Relu_162 || Conv_164 + Relu_165 || Conv_167 + Relu_168 Set Tactic Name: ampere_scudnn_128x128_relu_exp_small_nhwc_tn_v1 Tactic: 5778138195697110003
[03/24/2023-12:57:29] [V] [TRT] Tactic: 5778138195697110003 Time: 0.550144
[03/24/2023-12:57:29] [V] [TRT] Conv_158 + Relu_159 || Conv_161 + Relu_162 || Conv_164 + Relu_165 || Conv_167 + Relu_168 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize256x128x8_stage3_warpsize2x4x1_g1_ffma Tactic: 6310198979346901507
[03/24/2023-12:57:29] [V] [TRT] Tactic: 6310198979346901507 Time: 0.704896
[03/24/2023-12:57:29] [V] [TRT] Conv_158 + Relu_159 || Conv_161 + Relu_162 || Conv_164 + Relu_165 || Conv_167 + Relu_168 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x256x32_stage3_warpsize2x4x1_g1_tensor16x8x8_t1r3s3 Tactic: 7011693366046809027
[03/24/2023-12:57:29] [V] [TRT] Tactic: 7011693366046809027 Time: 0.120064
[03/24/2023-12:57:29] [V] [TRT] Conv_158 + Relu_159 || Conv_161 + Relu_162 || Conv_164 + Relu_165 || Conv_167 + Relu_168 Set Tactic Name: ampere_scudnn_128x128_ldg4_relu_exp_large_nhwc_tn_v1 Tactic: 7155825427510256858
[03/24/2023-12:57:29] [V] [TRT] Tactic: 7155825427510256858 Time: 0.552192
[03/24/2023-12:57:29] [V] [TRT] Conv_158 + Relu_159 || Conv_161 + Relu_162 || Conv_164 + Relu_165 || Conv_167 + Relu_168 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize128x64x8_stage3_warpsize1x4x1_g1_ffma Tactic: 7222247112373541608
[03/24/2023-12:57:29] [V] [TRT] Tactic: 7222247112373541608 Time: 0.591744
[03/24/2023-12:57:29] [V] [TRT] Conv_158 + Relu_159 || Conv_161 + Relu_162 || Conv_164 + Relu_165 || Conv_167 + Relu_168 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x128x16_stage4_warpsize2x2x1_g1_tensor16x8x8 Tactic: 7342025736444949634
[03/24/2023-12:57:29] [V] [TRT] Tactic: 7342025736444949634 Time: 0.121472
[03/24/2023-12:57:29] [V] [TRT] Conv_158 + Relu_159 || Conv_161 + Relu_162 || Conv_164 + Relu_165 || Conv_167 + Relu_168 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize64x128x32_stage5_warpsize2x2x1_g1_tensor16x8x8 Tactic: 7347365539922924600
[03/24/2023-12:57:29] [V] [TRT] Tactic: 7347365539922924600 Time: 0.148096
[03/24/2023-12:57:29] [V] [TRT] Conv_158 + Relu_159 || Conv_161 + Relu_162 || Conv_164 + Relu_165 || Conv_167 + Relu_168 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x64x32_stage5_warpsize2x2x1_g1_tensor16x8x8 Tactic: 7428197830878119671
[03/24/2023-12:57:29] [V] [TRT] Tactic: 7428197830878119671 Time: 0.158592
[03/24/2023-12:57:29] [V] [TRT] Conv_158 + Relu_159 || Conv_161 + Relu_162 || Conv_164 + Relu_165 || Conv_167 + Relu_168 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize64x32x64_stage5_warpsize2x2x1_g1_tensor16x8x8_t1r3s3 Tactic: 7465323447915168822
[03/24/2023-12:57:29] [V] [TRT] Tactic: 7465323447915168822 Time: 0.306816
[03/24/2023-12:57:29] [V] [TRT] Conv_158 + Relu_159 || Conv_161 + Relu_162 || Conv_164 + Relu_165 || Conv_167 + Relu_168 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize128x128x8_stage3_warpsize2x4x1_g1_ffma Tactic: 7472640475524677095
[03/24/2023-12:57:29] [V] [TRT] Tactic: 7472640475524677095 Time: 0.578944
[03/24/2023-12:57:29] [V] [TRT] Conv_158 + Relu_159 || Conv_161 + Relu_162 || Conv_164 + Relu_165 || Conv_167 + Relu_168 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize64x32x64_stage5_warpsize2x2x1_g1_tensor16x8x8 Tactic: 7938223790021272801
[03/24/2023-12:57:29] [V] [TRT] Tactic: 7938223790021272801 Time: 0.3264
[03/24/2023-12:57:29] [V] [TRT] Conv_158 + Relu_159 || Conv_161 + Relu_162 || Conv_164 + Relu_165 || Conv_167 + Relu_168 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize128x256x8_stage3_warpsize2x4x1_g1_ffma Tactic: 8498373915030836990
[03/24/2023-12:57:29] [V] [TRT] Tactic: 8498373915030836990 Time: 0.686464
[03/24/2023-12:57:29] [V] [TRT] Conv_158 + Relu_159 || Conv_161 + Relu_162 || Conv_164 + Relu_165 || Conv_167 + Relu_168 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x64x32_stage5_warpsize2x2x1_g1_tensor16x8x8_t1r3s3 Tactic: 8836645772682419994
[03/24/2023-12:57:29] [V] [TRT] Tactic: 8836645772682419994 Time: 0.151936
[03/24/2023-12:57:29] [V] [TRT] Conv_158 + Relu_159 || Conv_161 + Relu_162 || Conv_164 + Relu_165 || Conv_167 + Relu_168 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize256x64x8_stage3_warpsize1x4x1_g1_ffma Tactic: 8869697132622550639
[03/24/2023-12:57:29] [V] [TRT] Tactic: 8869697132622550639 Time: 0.777472
[03/24/2023-12:57:29] [V] [TRT] Conv_158 + Relu_159 || Conv_161 + Relu_162 || Conv_164 + Relu_165 || Conv_167 + Relu_168 Set Tactic Name: ampere_scudnn_128x128_ldg4_relu_exp_medium_nhwc_tn_v1 Tactic: 8918020581761223752
[03/24/2023-12:57:29] [V] [TRT] Tactic: 8918020581761223752 Time: 0.547072
[03/24/2023-12:57:29] [V] [TRT] Conv_158 + Relu_159 || Conv_161 + Relu_162 || Conv_164 + Relu_165 || Conv_167 + Relu_168 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize64x64x64_stage4_warpsize2x2x1_g1_tensor16x8x8 Tactic: -9114138070928278731
[03/24/2023-12:57:29] [V] [TRT] Tactic: -9114138070928278731 Time: 0.214272
[03/24/2023-12:57:29] [V] [TRT] Conv_158 + Relu_159 || Conv_161 + Relu_162 || Conv_164 + Relu_165 || Conv_167 + Relu_168 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize256x128x8_stage3_warpsize2x4x1_g1_ffma_t1r3s3 Tactic: -8937725997228636978
[03/24/2023-12:57:29] [V] [TRT] Tactic: -8937725997228636978 Time: 0.678784
[03/24/2023-12:57:29] [V] [TRT] Conv_158 + Relu_159 || Conv_161 + Relu_162 || Conv_164 + Relu_165 || Conv_167 + Relu_168 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize128x256x8_stage3_warpsize2x4x1_g1_ffma_t1r3s3 Tactic: -8833858409138163072
[03/24/2023-12:57:29] [V] [TRT] Tactic: -8833858409138163072 Time: 0.674432
[03/24/2023-12:57:29] [V] [TRT] Conv_158 + Relu_159 || Conv_161 + Relu_162 || Conv_164 + Relu_165 || Conv_167 + Relu_168 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize64x64x8_stage3_warpsize1x4x1_g1_ffma_t1r3s3 Tactic: -7989138351613022500
[03/24/2023-12:57:29] [V] [TRT] Tactic: -7989138351613022500 Time: 0.532096
[03/24/2023-12:57:29] [V] [TRT] Conv_158 + Relu_159 || Conv_161 + Relu_162 || Conv_164 + Relu_165 || Conv_167 + Relu_168 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize256x128x8_stage3_warpsize2x4x1_g1_ffma Tactic: -7872883691240863058
[03/24/2023-12:57:29] [V] [TRT] Tactic: -7872883691240863058 Time: 0.704768
[03/24/2023-12:57:29] [V] [TRT] Conv_158 + Relu_159 || Conv_161 + Relu_162 || Conv_164 + Relu_165 || Conv_167 + Relu_168 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x256x32_stage3_warpsize2x4x1_g1_tensor16x8x8 Tactic: -7382359095196034537
[03/24/2023-12:57:29] [V] [TRT] Tactic: -7382359095196034537 Time: 0.123008
[03/24/2023-12:57:29] [V] [TRT] Conv_158 + Relu_159 || Conv_161 + Relu_162 || Conv_164 + Relu_165 || Conv_167 + Relu_168 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x128x16_stage4_warpsize2x2x1_g1_tensor16x8x8_t1r3s3 Tactic: -7377458734869418330
[03/24/2023-12:57:29] [V] [TRT] Tactic: -7377458734869418330 Time: 0.111872
[03/24/2023-12:57:29] [V] [TRT] Conv_158 + Relu_159 || Conv_161 + Relu_162 || Conv_164 + Relu_165 || Conv_167 + Relu_168 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize128x128x8_stage3_warpsize2x4x1_g1_ffma Tactic: -6729618519651721910
[03/24/2023-12:57:29] [V] [TRT] Tactic: -6729618519651721910 Time: 0.572928
[03/24/2023-12:57:29] [V] [TRT] Conv_158 + Relu_159 || Conv_161 + Relu_162 || Conv_164 + Relu_165 || Conv_167 + Relu_168 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize256x64x32_stage3_warpsize4x2x1_g1_tensor16x8x8_t1r3s3 Tactic: -6223854811627385844
[03/24/2023-12:57:29] [V] [TRT] Tactic: -6223854811627385844 Time: 0.124416
[03/24/2023-12:57:29] [V] [TRT] Conv_158 + Relu_159 || Conv_161 + Relu_162 || Conv_164 + Relu_165 || Conv_167 + Relu_168 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize256x64x8_stage3_warpsize1x4x1_g1_ffma Tactic: -5893833996418445881
[03/24/2023-12:57:29] [V] [TRT] Tactic: -5893833996418445881 Time: 0.757632
[03/24/2023-12:57:29] [V] [TRT] Conv_158 + Relu_159 || Conv_161 + Relu_162 || Conv_164 + Relu_165 || Conv_167 + Relu_168 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize128x256x8_stage3_warpsize2x4x1_g1_ffma Tactic: -5701562095007058349
[03/24/2023-12:57:29] [V] [TRT] Tactic: -5701562095007058349 Time: 0.67776
[03/24/2023-12:57:29] [V] [TRT] Conv_158 + Relu_159 || Conv_161 + Relu_162 || Conv_164 + Relu_165 || Conv_167 + Relu_168 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize128x64x8_stage3_warpsize1x4x1_g1_ffma Tactic: -5685503422376017600
[03/24/2023-12:57:29] [V] [TRT] Tactic: -5685503422376017600 Time: 0.572928
[03/24/2023-12:57:29] [V] [TRT] Conv_158 + Relu_159 || Conv_161 + Relu_162 || Conv_164 + Relu_165 || Conv_167 + Relu_168 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize64x64x8_stage3_warpsize1x4x1_g1_ffma Tactic: -5521125187060117489
[03/24/2023-12:57:29] [V] [TRT] Tactic: -5521125187060117489 Time: 0.57728
[03/24/2023-12:57:29] [V] [TRT] Conv_158 + Relu_159 || Conv_161 + Relu_162 || Conv_164 + Relu_165 || Conv_167 + Relu_168 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x128x16_stage4_warpsize2x2x1_g1_tensor16x8x8 Tactic: -5457304872213719461
[03/24/2023-12:57:29] [V] [TRT] Tactic: -5457304872213719461 Time: 0.114816
[03/24/2023-12:57:29] [V] [TRT] Conv_158 + Relu_159 || Conv_161 + Relu_162 || Conv_164 + Relu_165 || Conv_167 + Relu_168 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x64x64_stage3_warpsize2x2x1_g1_tensor16x8x8 Tactic: -5441054706931585554
[03/24/2023-12:57:29] [V] [TRT] Tactic: -5441054706931585554 Time: 0.16512
[03/24/2023-12:57:29] [V] [TRT] Conv_158 + Relu_159 || Conv_161 + Relu_162 || Conv_164 + Relu_165 || Conv_167 + Relu_168 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize256x64x32_stage3_warpsize4x2x1_g1_tensor16x8x8 Tactic: -5043603702497465467
[03/24/2023-12:57:29] [V] [TRT] Tactic: -5043603702497465467 Time: 0.142208
[03/24/2023-12:57:29] [V] [TRT] Conv_158 + Relu_159 || Conv_161 + Relu_162 || Conv_164 + Relu_165 || Conv_167 + Relu_168 Set Tactic Name: ampere_scudnn_128x64_sliced1x2_ldg4_relu_exp_large_nhwc_tn_v1 Tactic: -4756382386362004279
[03/24/2023-12:57:29] [V] [TRT] Tactic: -4756382386362004279 Time: 0.558848
[03/24/2023-12:57:29] [V] [TRT] Conv_158 + Relu_159 || Conv_161 + Relu_162 || Conv_164 + Relu_165 || Conv_167 + Relu_168 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize64x64x8_stage3_warpsize1x4x1_g1_ffma Tactic: -4615000974950361663
[03/24/2023-12:57:29] [V] [TRT] Tactic: -4615000974950361663 Time: 0.55232
[03/24/2023-12:57:29] [V] [TRT] Conv_158 + Relu_159 || Conv_161 + Relu_162 || Conv_164 + Relu_165 || Conv_167 + Relu_168 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x64x64_stage3_warpsize2x2x1_g1_tensor16x8x8 Tactic: -4564655677311401797
[03/24/2023-12:57:29] [V] [TRT] Tactic: -4564655677311401797 Time: 0.171776
[03/24/2023-12:57:29] [V] [TRT] Conv_158 + Relu_159 || Conv_161 + Relu_162 || Conv_164 + Relu_165 || Conv_167 + Relu_168 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize256x64x8_stage3_warpsize1x4x1_g1_ffma_t1r3s3 Tactic: -4314913710375142296
[03/24/2023-12:57:29] [V] [TRT] Tactic: -4314913710375142296 Time: 0.729472
[03/24/2023-12:57:29] [V] [TRT] Conv_158 + Relu_159 || Conv_161 + Relu_162 || Conv_164 + Relu_165 || Conv_167 + Relu_168 Set Tactic Name: ampere_scudnn_128x128_relu_exp_large_nhwc_tn_v1 Tactic: -3855385237722507464
[03/24/2023-12:57:29] [V] [TRT] Tactic: -3855385237722507464 Time: 0.552832
[03/24/2023-12:57:29] [V] [TRT] Conv_158 + Relu_159 || Conv_161 + Relu_162 || Conv_164 + Relu_165 || Conv_167 + Relu_168 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize128x64x8_stage3_warpsize1x4x1_g1_ffma_t1r3s3 Tactic: -3697587361057948972
[03/24/2023-12:57:29] [V] [TRT] Tactic: -3697587361057948972 Time: 0.57472
[03/24/2023-12:57:29] [V] [TRT] Conv_158 + Relu_159 || Conv_161 + Relu_162 || Conv_164 + Relu_165 || Conv_167 + Relu_168 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize256x64x32_stage3_warpsize4x2x1_g1_tensor16x8x8 Tactic: -3540975627865078064
[03/24/2023-12:57:29] [V] [TRT] Tactic: -3540975627865078064 Time: 0.13056
[03/24/2023-12:57:29] [V] [TRT] Conv_158 + Relu_159 || Conv_161 + Relu_162 || Conv_164 + Relu_165 || Conv_167 + Relu_168 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize64x128x32_stage5_warpsize2x2x1_g1_tensor16x8x8_t1r3s3 Tactic: -3151804561246216835
[03/24/2023-12:57:29] [V] [TRT] Tactic: -3151804561246216835 Time: 0.14528
[03/24/2023-12:57:29] [V] [TRT] Conv_158 + Relu_159 || Conv_161 + Relu_162 || Conv_164 + Relu_165 || Conv_167 + Relu_168 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize64x32x64_stage5_warpsize2x2x1_g1_tensor16x8x8 Tactic: -2885165284206163001
[03/24/2023-12:57:29] [V] [TRT] Tactic: -2885165284206163001 Time: 0.317696
[03/24/2023-12:57:29] [V] [TRT] Conv_158 + Relu_159 || Conv_161 + Relu_162 || Conv_164 + Relu_165 || Conv_167 + Relu_168 Set Tactic Name: ampere_scudnn_128x128_relu_exp_medium_nhwc_tn_v1 Tactic: -2809379259463049391
[03/24/2023-12:57:29] [V] [TRT] Tactic: -2809379259463049391 Time: 0.552576
[03/24/2023-12:57:29] [V] [TRT] Conv_158 + Relu_159 || Conv_161 + Relu_162 || Conv_164 + Relu_165 || Conv_167 + Relu_168 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x128x32_stage4_warpsize2x2x1_g1_tensor16x8x8_t1r3s3 Tactic: -2801041895330778813
[03/24/2023-12:57:29] [V] [TRT] Tactic: -2801041895330778813 Time: 0.12672
[03/24/2023-12:57:29] [V] [TRT] Conv_158 + Relu_159 || Conv_161 + Relu_162 || Conv_164 + Relu_165 || Conv_167 + Relu_168 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize64x256x8_stage3_warpsize1x4x1_g1_ffma_t1r3s3 Tactic: -2747929399988666512
[03/24/2023-12:57:29] [V] [TRT] Tactic: -2747929399988666512 Time: 0.672896
[03/24/2023-12:57:29] [V] [TRT] Conv_158 + Relu_159 || Conv_161 + Relu_162 || Conv_164 + Relu_165 || Conv_167 + Relu_168 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize256x128x32_stage3_warpsize4x2x1_g1_tensor16x8x8 Tactic: -1758690179295738332
[03/24/2023-12:57:29] [V] [TRT] Tactic: -1758690179295738332 Time: 0.131712
[03/24/2023-12:57:29] [V] [TRT] Conv_158 + Relu_159 || Conv_161 + Relu_162 || Conv_164 + Relu_165 || Conv_167 + Relu_168 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x64x64_stage3_warpsize2x2x1_g1_tensor16x8x8_t1r3s3 Tactic: -1484546572846226796
[03/24/2023-12:57:29] [V] [TRT] Tactic: -1484546572846226796 Time: 0.165632
[03/24/2023-12:57:29] [V] [TRT] Conv_158 + Relu_159 || Conv_161 + Relu_162 || Conv_164 + Relu_165 || Conv_167 + Relu_168 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize64x256x8_stage3_warpsize1x4x1_g1_ffma Tactic: -1472061967969061456
[03/24/2023-12:57:29] [V] [TRT] Tactic: -1472061967969061456 Time: 0.675968
[03/24/2023-12:57:29] [V] [TRT] Conv_158 + Relu_159 || Conv_161 + Relu_162 || Conv_164 + Relu_165 || Conv_167 + Relu_168 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x128x32_stage4_warpsize2x2x1_g1_tensor16x8x8 Tactic: -858667497925695276
[03/24/2023-12:57:29] [V] [TRT] Tactic: -858667497925695276 Time: 0.173312
[03/24/2023-12:57:29] [V] [TRT] Conv_158 + Relu_159 || Conv_161 + Relu_162 || Conv_164 + Relu_165 || Conv_167 + Relu_168 Set Tactic Name: ampere_scudnn_128x128_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: -504296718212024303
[03/24/2023-12:57:29] [V] [TRT] Tactic: -504296718212024303 Time: 0.546944
[03/24/2023-12:57:29] [V] [TRT] Conv_158 + Relu_159 || Conv_161 + Relu_162 || Conv_164 + Relu_165 || Conv_167 + Relu_168 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize64x128x8_stage3_warpsize1x4x1_g1_ffma Tactic: -444093195553988951
[03/24/2023-12:57:29] [V] [TRT] Tactic: -444093195553988951 Time: 0.57984
[03/24/2023-12:57:29] [V] [TRT] Fastest Tactic: -7377458734869418330 Time: 0.111872
[03/24/2023-12:57:29] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: -7377458734869418330
[03/24/2023-12:57:29] [V] [TRT] *************** Autotuning format combination: Half(2073600,32400,180,1) -> Half(8294400,32400,180,1) ***************
[03/24/2023-12:57:29] [V] [TRT] --------------- Timing Runner: Conv_158 + Relu_159 || Conv_161 + Relu_162 || Conv_164 + Relu_165 || Conv_167 + Relu_168 (CudnnConvolution)
[03/24/2023-12:57:29] [V] [TRT] Tactic: 0 Time: 0.78272
[03/24/2023-12:57:29] [V] [TRT] Tactic: 1 Time: 0.690944
[03/24/2023-12:57:29] [V] [TRT] Tactic: 2 Time: 0.857856
[03/24/2023-12:57:29] [V] [TRT] Tactic: 4 skipped. Scratch requested: 8691449856, available: 4294967296
[03/24/2023-12:57:29] [V] [TRT] Tactic: 5 Time: 2.54234
[03/24/2023-12:57:29] [V] [TRT] Tactic: 6 Time: 0.45056
[03/24/2023-12:57:29] [V] [TRT] Tactic: 56 Time: 0.782208
[03/24/2023-12:57:29] [V] [TRT] Tactic: 58 Time: 0.857984
[03/24/2023-12:57:29] [V] [TRT] Tactic: 60 skipped. Scratch requested: 8691449856, available: 4294967296
[03/24/2023-12:57:29] [V] [TRT] Tactic: 61 Time: 2.5431
[03/24/2023-12:57:29] [V] [TRT] Tactic: 62 Time: 0.44992
[03/24/2023-12:57:29] [V] [TRT] Fastest Tactic: 62 Time: 0.44992
[03/24/2023-12:57:29] [V] [TRT] Setting workspace to 8691449856enables more tactics for profiling
[03/24/2023-12:57:29] [V] [TRT] --------------- Timing Runner: Conv_158 + Relu_159 || Conv_161 + Relu_162 || Conv_164 + Relu_165 || Conv_167 + Relu_168 (CaskConvolution)
[03/24/2023-12:57:29] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[03/24/2023-12:57:29] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CudnnConvolution Tactic: 62
[03/24/2023-12:57:29] [V] [TRT] *************** Autotuning format combination: Half(1036800,32400:2,180,1) -> Half(4147200,32400:2,180,1) ***************
[03/24/2023-12:57:29] [V] [TRT] --------------- Timing Runner: Conv_158 + Relu_159 || Conv_161 + Relu_162 || Conv_164 + Relu_165 || Conv_167 + Relu_168 (FusedConvActConvolution)
[03/24/2023-12:57:29] [V] [TRT] Tactic: 524287 Time: 0.27456
[03/24/2023-12:57:29] [V] [TRT] Tactic: 720895 Time: 0.243072
[03/24/2023-12:57:29] [V] [TRT] Tactic: 983039 Time: 0.273152
[03/24/2023-12:57:30] [V] [TRT] Tactic: 1048575 Time: 0.274304
[03/24/2023-12:57:30] [V] [TRT] Tactic: 1703935 Time: 0.27136
[03/24/2023-12:57:30] [V] [TRT] Tactic: 1769471 Time: 0.348544
[03/24/2023-12:57:30] [V] [TRT] Tactic: 1966079 Time: 0.296064
[03/24/2023-12:57:30] [V] [TRT] Tactic: 2031615 Time: 0.249472
[03/24/2023-12:57:30] [V] [TRT] Tactic: 2228223 Time: 0.283776
[03/24/2023-12:57:30] [V] [TRT] Tactic: 2424831 Time: 0.442496
[03/24/2023-12:57:30] [V] [TRT] Tactic: 2621439 Time: 0.29184
[03/24/2023-12:57:30] [V] [TRT] Tactic: 2752511 Time: 0.270208
[03/24/2023-12:57:30] [V] [TRT] Tactic: 2818047 Time: 0.315264
[03/24/2023-12:57:30] [V] [TRT] Tactic: 2883583 Time: 0.295936
[03/24/2023-12:57:30] [V] [TRT] Tactic: 3014655 Time: 0.269056
[03/24/2023-12:57:30] [V] [TRT] Tactic: 3145727 Time: 0.268928
[03/24/2023-12:57:30] [V] [TRT] Tactic: 3473407 Time: 0.269056
[03/24/2023-12:57:30] [V] [TRT] Tactic: 3604479 Time: 0.28224
[03/24/2023-12:57:30] [V] [TRT] Tactic: 3735551 Time: 0.265216
[03/24/2023-12:57:30] [V] [TRT] Tactic: 4390911 Time: 0.269184
[03/24/2023-12:57:30] [V] [TRT] Tactic: 5046271 Time: 0.267904
[03/24/2023-12:57:30] [V] [TRT] Tactic: 5963775 Time: 0.261376
[03/24/2023-12:57:30] [V] [TRT] Tactic: 6160383 Time: 0.280192
[03/24/2023-12:57:30] [V] [TRT] Tactic: 6488063 Time: 0.271872
[03/24/2023-12:57:30] [V] [TRT] Tactic: 6881279 Time: 0.268544
[03/24/2023-12:57:30] [V] [TRT] Tactic: 7274495 Time: 0.317056
[03/24/2023-12:57:30] [V] [TRT] Tactic: 7864319 Time: 0.312704
[03/24/2023-12:57:30] [V] [TRT] Tactic: 7995391 Time: 0.283904
[03/24/2023-12:57:30] [V] [TRT] Tactic: 8585215 Time: 0.27328
[03/24/2023-12:57:30] [V] [TRT] Tactic: 8847359 Time: 0.3072
[03/24/2023-12:57:30] [V] [TRT] Tactic: 8978431 Time: 0.254976
[03/24/2023-12:57:30] [V] [TRT] Tactic: 9043967 Time: 0.269696
[03/24/2023-12:57:30] [V] [TRT] Tactic: 9175039 Time: 0.28224
[03/24/2023-12:57:30] [V] [TRT] Tactic: 9502719 Time: 0.275712
[03/24/2023-12:57:30] [V] [TRT] Tactic: 9830399 Time: 0.268928
[03/24/2023-12:57:30] [V] [TRT] Tactic: 9961471 Time: 0.434432
[03/24/2023-12:57:30] [V] [TRT] Tactic: 10027007 Time: 0.264704
[03/24/2023-12:57:30] [V] [TRT] Tactic: 10092543 Time: 0.269568
[03/24/2023-12:57:30] [V] [TRT] Tactic: 10289151 Time: 0.294784
[03/24/2023-12:57:30] [V] [TRT] Tactic: 10485759 Time: 0.268032
[03/24/2023-12:57:30] [V] [TRT] Tactic: 10682367 Time: 0.323968
[03/24/2023-12:57:30] [V] [TRT] Tactic: 10813439 Time: 0.301184
[03/24/2023-12:57:30] [V] [TRT] Fastest Tactic: 720895 Time: 0.243072
[03/24/2023-12:57:30] [V] [TRT] --------------- Timing Runner: Conv_158 + Relu_159 || Conv_161 + Relu_162 || Conv_164 + Relu_165 || Conv_167 + Relu_168 (CudnnConvolution)
[03/24/2023-12:57:30] [V] [TRT] CudnnConvolution has no valid tactics for this config, skipping
[03/24/2023-12:57:30] [V] [TRT] --------------- Timing Runner: Conv_158 + Relu_159 || Conv_161 + Relu_162 || Conv_164 + Relu_165 || Conv_167 + Relu_168 (CaskConvolution)
[03/24/2023-12:57:30] [V] [TRT] Conv_158 + Relu_159 || Conv_161 + Relu_162 || Conv_164 + Relu_165 || Conv_167 + Relu_168 Set Tactic Name: ampere_fp16x2_hcudnn_fp16x2_128x32_relu_medium_nn_v1 Tactic: 2195670545862694453
[03/24/2023-12:57:30] [V] [TRT] Tactic: 2195670545862694453 Time: 0.311168
[03/24/2023-12:57:30] [V] [TRT] Conv_158 + Relu_159 || Conv_161 + Relu_162 || Conv_164 + Relu_165 || Conv_167 + Relu_168 Set Tactic Name: ampere_fp16x2_hcudnn_fp16x2_128x64_relu_large_nn_v1 Tactic: 3419182076704469245
[03/24/2023-12:57:30] [V] [TRT] Tactic: 3419182076704469245 Time: 0.301312
[03/24/2023-12:57:30] [V] [TRT] Conv_158 + Relu_159 || Conv_161 + Relu_162 || Conv_164 + Relu_165 || Conv_167 + Relu_168 Set Tactic Name: ampere_fp16x2_hcudnn_fp16x2_128x128_relu_medium_nn_v1 Tactic: 3891805945559659536
[03/24/2023-12:57:30] [V] [TRT] Tactic: 3891805945559659536 Time: 0.300928
[03/24/2023-12:57:30] [V] [TRT] Conv_158 + Relu_159 || Conv_161 + Relu_162 || Conv_164 + Relu_165 || Conv_167 + Relu_168 Set Tactic Name: ampere_fp16x2_hcudnn_fp16x2_128x64_relu_medium_nn_v1 Tactic: 5548126322150286555
[03/24/2023-12:57:30] [V] [TRT] Tactic: 5548126322150286555 Time: 0.298496
[03/24/2023-12:57:30] [V] [TRT] Conv_158 + Relu_159 || Conv_161 + Relu_162 || Conv_164 + Relu_165 || Conv_167 + Relu_168 Set Tactic Name: ampere_fp16x2_hcudnn_fp16x2_128x64_relu_small_nn_v1 Tactic: 6057304366605292508
[03/24/2023-12:57:30] [V] [TRT] Tactic: 6057304366605292508 Time: 0.294016
[03/24/2023-12:57:30] [V] [TRT] Conv_158 + Relu_159 || Conv_161 + Relu_162 || Conv_164 + Relu_165 || Conv_167 + Relu_168 Set Tactic Name: ampere_fp16x2_hcudnn_fp16x2_128x128_relu_large_nn_v1 Tactic: -7928611605886347652
[03/24/2023-12:57:30] [V] [TRT] Tactic: -7928611605886347652 Time: 0.310272
[03/24/2023-12:57:30] [V] [TRT] Conv_158 + Relu_159 || Conv_161 + Relu_162 || Conv_164 + Relu_165 || Conv_167 + Relu_168 Set Tactic Name: ampere_fp16x2_hcudnn_fp16x2_128x32_relu_large_nn_v1 Tactic: -5172391392092686714
[03/24/2023-12:57:30] [V] [TRT] Tactic: -5172391392092686714 Time: 0.314368
[03/24/2023-12:57:30] [V] [TRT] Conv_158 + Relu_159 || Conv_161 + Relu_162 || Conv_164 + Relu_165 || Conv_167 + Relu_168 Set Tactic Name: ampere_fp16x2_hcudnn_fp16x2_128x32_relu_small_nn_v1 Tactic: -4374269919094467161
[03/24/2023-12:57:30] [V] [TRT] Tactic: -4374269919094467161 Time: 0.306304
[03/24/2023-12:57:30] [V] [TRT] Conv_158 + Relu_159 || Conv_161 + Relu_162 || Conv_164 + Relu_165 || Conv_167 + Relu_168 Set Tactic Name: ampere_fp16x2_hcudnn_winograd_fp16x2_128x128_ldg1_ldg4_relu_tile148t_nt_v1 Tactic: -4083394051665370953
[03/24/2023-12:57:30] [V] [TRT] Tactic: -4083394051665370953 Time: 0.172928
[03/24/2023-12:57:30] [V] [TRT] Conv_158 + Relu_159 || Conv_161 + Relu_162 || Conv_164 + Relu_165 || Conv_167 + Relu_168 Set Tactic Name: ampere_fp16x2_hcudnn_fp16x2_128x128_relu_small_nn_v1 Tactic: -1546027692247304867
[03/24/2023-12:57:31] [V] [TRT] Tactic: -1546027692247304867 Time: 0.303744
[03/24/2023-12:57:31] [V] [TRT] Fastest Tactic: -4083394051665370953 Time: 0.172928
[03/24/2023-12:57:31] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: -4083394051665370953
[03/24/2023-12:57:31] [V] [TRT] *************** Autotuning format combination: Half(259200,1:8,1440,8) -> Float(8294400,32400,180,1) ***************
[03/24/2023-12:57:31] [V] [TRT] --------------- Timing Runner: Conv_158 + Relu_159 || Conv_161 + Relu_162 || Conv_164 + Relu_165 || Conv_167 + Relu_168 (CudnnConvolution)
[03/24/2023-12:57:31] [V] [TRT] CudnnConvolution has no valid tactics for this config, skipping
[03/24/2023-12:57:31] [V] [TRT] --------------- Timing Runner: Conv_158 + Relu_159 || Conv_161 + Relu_162 || Conv_164 + Relu_165 || Conv_167 + Relu_168 (CaskConvolution)
[03/24/2023-12:57:31] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[03/24/2023-12:57:31] [V] [TRT] *************** Autotuning format combination: Half(259200,1:8,1440,8) -> Half(1036800,1:8,5760,32) ***************
[03/24/2023-12:57:31] [V] [TRT] --------------- Timing Runner: Conv_158 + Relu_159 || Conv_161 + Relu_162 || Conv_164 + Relu_165 || Conv_167 + Relu_168 (CudaDepthwiseConvolution)
[03/24/2023-12:57:31] [V] [TRT] CudaDepthwiseConvolution has no valid tactics for this config, skipping
[03/24/2023-12:57:31] [V] [TRT] --------------- Timing Runner: Conv_158 + Relu_159 || Conv_161 + Relu_162 || Conv_164 + Relu_165 || Conv_167 + Relu_168 (CudnnConvolution)
[03/24/2023-12:57:31] [V] [TRT] Tactic: 0 Time: 0.915456
[03/24/2023-12:57:31] [V] [TRT] Tactic: 1 Time: 1.71366
[03/24/2023-12:57:31] [V] [TRT] Tactic: 2 Time: 1.01811
[03/24/2023-12:57:31] [V] [TRT] Tactic: 6 Time: 0.44416
[03/24/2023-12:57:31] [V] [TRT] Tactic: 56 Time: 0.915584
[03/24/2023-12:57:31] [V] [TRT] Tactic: 58 Time: 1.01824
[03/24/2023-12:57:31] [V] [TRT] Tactic: 62 Time: 0.444288
[03/24/2023-12:57:31] [V] [TRT] Fastest Tactic: 6 Time: 0.44416
[03/24/2023-12:57:31] [V] [TRT] --------------- Timing Runner: Conv_158 + Relu_159 || Conv_161 + Relu_162 || Conv_164 + Relu_165 || Conv_167 + Relu_168 (CaskConvolution)
[03/24/2023-12:57:31] [V] [TRT] Conv_158 + Relu_159 || Conv_161 + Relu_162 || Conv_164 + Relu_165 || Conv_167 + Relu_168 Set Tactic Name: ampere_h16816cudnn_256x128_ldg8_relu_exp_medium_nhwc_tn_v1 Tactic: 254850674756030979
[03/24/2023-12:57:31] [V] [TRT] Tactic: 254850674756030979 Time: 0.068096
[03/24/2023-12:57:31] [V] [TRT] Conv_158 + Relu_159 || Conv_161 + Relu_162 || Conv_164 + Relu_165 || Conv_167 + Relu_168 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x128x32_stage3_warpsize4x2x1_g1_tensor16x8x16_t1r3s3 Tactic: 328038211831149625
[03/24/2023-12:57:31] [V] [TRT] Tactic: 328038211831149625 Time: 0.064256
[03/24/2023-12:57:31] [V] [TRT] Conv_158 + Relu_159 || Conv_161 + Relu_162 || Conv_164 + Relu_165 || Conv_167 + Relu_168 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x64x64_stage3_warpsize2x2x1_g1_tensor16x8x16_t1r3s3 Tactic: 411553864378931917
[03/24/2023-12:57:31] [V] [TRT] Tactic: 411553864378931917 Time: 0.073088
[03/24/2023-12:57:31] [V] [TRT] Conv_158 + Relu_159 || Conv_161 + Relu_162 || Conv_164 + Relu_165 || Conv_167 + Relu_168 Set Tactic Name: sm75_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x128x32_stage1_warpsize4x2x1_g1_tensor16x8x8_t1r3s3 Tactic: 864841579020773074
[03/24/2023-12:57:31] [V] [TRT] Tactic: 864841579020773074 Time: 0.073856
[03/24/2023-12:57:31] [V] [TRT] Conv_158 + Relu_159 || Conv_161 + Relu_162 || Conv_164 + Relu_165 || Conv_167 + Relu_168 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x128x32_stage4_warpsize2x2x1_g1_tensor16x8x16 Tactic: 1011057357468998345
[03/24/2023-12:57:31] [V] [TRT] Tactic: 1011057357468998345 Time: 0.057216
[03/24/2023-12:57:31] [V] [TRT] Conv_158 + Relu_159 || Conv_161 + Relu_162 || Conv_164 + Relu_165 || Conv_167 + Relu_168 Set Tactic Name: sm75_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x64x32_stage1_warpsize4x1x1_g1_tensor16x8x8 Tactic: 1013168150133367738
[03/24/2023-12:57:31] [V] [TRT] Tactic: 1013168150133367738 Time: 0.075776
[03/24/2023-12:57:31] [V] [TRT] Conv_158 + Relu_159 || Conv_161 + Relu_162 || Conv_164 + Relu_165 || Conv_167 + Relu_168 Set Tactic Name: ampere_h16816cudnn_256x128_ldg8_relu_exp_stages_64x3_small_nhwc_tn_v1 Tactic: 1016009564074305832
[03/24/2023-12:57:31] [V] [TRT] Tactic: 1016009564074305832 Time: 0.06848
[03/24/2023-12:57:31] [V] [TRT] Conv_158 + Relu_159 || Conv_161 + Relu_162 || Conv_164 + Relu_165 || Conv_167 + Relu_168 Set Tactic Name: sm75_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x128x32_stage1_warpsize2x2x1_g1_tensor16x8x8 Tactic: 1067227531433278814
[03/24/2023-12:57:31] [V] [TRT] Tactic: 1067227531433278814 Time: 0.067968
[03/24/2023-12:57:31] [V] [TRT] Conv_158 + Relu_159 || Conv_161 + Relu_162 || Conv_164 + Relu_165 || Conv_167 + Relu_168 Set Tactic Name: ampere_h1688cudnn_128x128_ldg8_relu_exp_medium_nhwc_tn_v1 Tactic: 1156328698016730421
[03/24/2023-12:57:31] [V] [TRT] Tactic: 1156328698016730421 Time: 0.077952
[03/24/2023-12:57:31] [V] [TRT] Conv_158 + Relu_159 || Conv_161 + Relu_162 || Conv_164 + Relu_165 || Conv_167 + Relu_168 Set Tactic Name: sm75_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x128x32_stage1_warpsize2x2x1_g1_tensor16x8x8 Tactic: 1579845938601132607
[03/24/2023-12:57:31] [V] [TRT] Tactic: 1579845938601132607 Time: 0.068224
[03/24/2023-12:57:31] [V] [TRT] Conv_158 + Relu_159 || Conv_161 + Relu_162 || Conv_164 + Relu_165 || Conv_167 + Relu_168 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x128x32_stage5_warpsize2x2x1_g1_tensor16x8x16_t1r3s3 Tactic: 1723736032573714698
[03/24/2023-12:57:31] [V] [TRT] Tactic: 1723736032573714698 Time: 0.068736
[03/24/2023-12:57:31] [V] [TRT] Conv_158 + Relu_159 || Conv_161 + Relu_162 || Conv_164 + Relu_165 || Conv_167 + Relu_168 Set Tactic Name: sm75_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x32x32_stage1_warpsize4x1x1_g1_tensor16x8x8 Tactic: 1796821236841789338
[03/24/2023-12:57:31] [V] [TRT] Tactic: 1796821236841789338 Time: 0.114432
[03/24/2023-12:57:31] [V] [TRT] Conv_158 + Relu_159 || Conv_161 + Relu_162 || Conv_164 + Relu_165 || Conv_167 + Relu_168 Set Tactic Name: ampere_h16816cudnn_128x64_ldg8_relu_exp_stages_64x4_medium_nhwc_tn_v1 Tactic: 1832046141070096030
[03/24/2023-12:57:31] [V] [TRT] Tactic: 1832046141070096030 Time: 0.088064
[03/24/2023-12:57:31] [V] [TRT] Conv_158 + Relu_159 || Conv_161 + Relu_162 || Conv_164 + Relu_165 || Conv_167 + Relu_168 Set Tactic Name: ampere_h16816cudnn_128x64_sliced1x2_ldg8_relu_exp_stages_64x3_small_nhwc_tn_v1 Tactic: 1838082074606840426
[03/24/2023-12:57:31] [V] [TRT] Tactic: 1838082074606840426 Time: 0.068992
[03/24/2023-12:57:31] [V] [TRT] Conv_158 + Relu_159 || Conv_161 + Relu_162 || Conv_164 + Relu_165 || Conv_167 + Relu_168 Set Tactic Name: ampere_h16816cudnn_64x64_sliced1x2_ldg8_relu_exp_stages_64x5_small_nhwc_tn_v1 Tactic: 1899296423087490472
[03/24/2023-12:57:31] [V] [TRT] Tactic: 1899296423087490472 Time: 0.101504
[03/24/2023-12:57:31] [V] [TRT] Conv_158 + Relu_159 || Conv_161 + Relu_162 || Conv_164 + Relu_165 || Conv_167 + Relu_168 Set Tactic Name: sm75_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x32x32_stage1_warpsize4x1x1_g1_tensor16x8x8 Tactic: 1948263663414159978
[03/24/2023-12:57:31] [V] [TRT] Tactic: 1948263663414159978 Time: 0.105088
[03/24/2023-12:57:31] [V] [TRT] Conv_158 + Relu_159 || Conv_161 + Relu_162 || Conv_164 + Relu_165 || Conv_167 + Relu_168 Set Tactic Name: sm75_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x256x64_stage1_warpsize1x4x2_g1_tensor16x8x8 Tactic: 2027733232253711640
[03/24/2023-12:57:31] [V] [TRT] Tactic: 2027733232253711640 Time: 0.079104
[03/24/2023-12:57:31] [V] [TRT] Conv_158 + Relu_159 || Conv_161 + Relu_162 || Conv_164 + Relu_165 || Conv_167 + Relu_168 Set Tactic Name: sm75_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x64x32_stage1_warpsize2x2x1_g1_tensor16x8x8_t1r3s3 Tactic: 2154731107061273008
[03/24/2023-12:57:31] [V] [TRT] Tactic: 2154731107061273008 Time: 0.08128
[03/24/2023-12:57:31] [V] [TRT] Conv_158 + Relu_159 || Conv_161 + Relu_162 || Conv_164 + Relu_165 || Conv_167 + Relu_168 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x64x64_stage3_warpsize2x2x1_g1_tensor16x8x16 Tactic: 2428167804343994714
[03/24/2023-12:57:31] [V] [TRT] Tactic: 2428167804343994714 Time: 0.06976
[03/24/2023-12:57:31] [V] [TRT] Conv_158 + Relu_159 || Conv_161 + Relu_162 || Conv_164 + Relu_165 || Conv_167 + Relu_168 Set Tactic Name: ampere_h16816cudnn_128x128_ldg8_relu_exp_medium_nhwc_tn_v1 Tactic: 2541579301352125276
[03/24/2023-12:57:31] [V] [TRT] Tactic: 2541579301352125276 Time: 0.056832
[03/24/2023-12:57:31] [V] [TRT] Conv_158 + Relu_159 || Conv_161 + Relu_162 || Conv_164 + Relu_165 || Conv_167 + Relu_168 Set Tactic Name: ampere_h16816cudnn_64x64_sliced1x2_ldg8_relu_exp_stages_64x6_small_nhwc_tn_v1 Tactic: 2657157263811141609
[03/24/2023-12:57:31] [V] [TRT] Tactic: 2657157263811141609 Time: 0.12416
[03/24/2023-12:57:31] [V] [TRT] Conv_158 + Relu_159 || Conv_161 + Relu_162 || Conv_164 + Relu_165 || Conv_167 + Relu_168 Set Tactic Name: ampere_h16816cudnn_64x128_sliced1x2_ldg8_relu_exp_stages_64x4_large_nhwc_tn_v1 Tactic: 2819719497590964443
[03/24/2023-12:57:31] [V] [TRT] Tactic: 2819719497590964443 Time: 0.090624
[03/24/2023-12:57:31] [V] [TRT] Conv_158 + Relu_159 || Conv_161 + Relu_162 || Conv_164 + Relu_165 || Conv_167 + Relu_168 Set Tactic Name: ampere_h16816cudnn_128x64_sliced1x2_ldg8_relu_exp_stages_64x3_medium_nhwc_tn_v1 Tactic: 2968605903460894194
[03/24/2023-12:57:31] [V] [TRT] Tactic: 2968605903460894194 Time: 0.0704
[03/24/2023-12:57:31] [V] [TRT] Conv_158 + Relu_159 || Conv_161 + Relu_162 || Conv_164 + Relu_165 || Conv_167 + Relu_168 Set Tactic Name: ampere_h16816cudnn_128x128_ldg8_relu_exp_large_nhwc_tn_v1 Tactic: 2986078304285316765
[03/24/2023-12:57:31] [V] [TRT] Tactic: 2986078304285316765 Time: 0.057344
[03/24/2023-12:57:31] [V] [TRT] Conv_158 + Relu_159 || Conv_161 + Relu_162 || Conv_164 + Relu_165 || Conv_167 + Relu_168 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x256x64_stage3_warpsize1x4x1_g1_tensor16x8x16 Tactic: 3016308193087082166
[03/24/2023-12:57:31] [V] [TRT] Tactic: 3016308193087082166 Time: 0.075776
[03/24/2023-12:57:31] [V] [TRT] Conv_158 + Relu_159 || Conv_161 + Relu_162 || Conv_164 + Relu_165 || Conv_167 + Relu_168 Set Tactic Name: ampere_h16816cudnn_256x64_ldg8_relu_exp_stages_64x3_large_nhwc_tn_v1 Tactic: 3221382575080507859
[03/24/2023-12:57:31] [V] [TRT] Tactic: 3221382575080507859 Time: 0.069376
[03/24/2023-12:57:31] [V] [TRT] Conv_158 + Relu_159 || Conv_161 + Relu_162 || Conv_164 + Relu_165 || Conv_167 + Relu_168 Set Tactic Name: ampere_h16816cudnn_128x128_ldg8_relu_exp_stages_64x3_medium_nhwc_tn_v1 Tactic: 3362537467505018070
[03/24/2023-12:57:31] [V] [TRT] Tactic: 3362537467505018070 Time: 0.065408
[03/24/2023-12:57:31] [V] [TRT] Conv_158 + Relu_159 || Conv_161 + Relu_162 || Conv_164 + Relu_165 || Conv_167 + Relu_168 Set Tactic Name: sm75_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x64x32_stage1_warpsize4x1x1_g1_tensor16x8x8_t1r3s3 Tactic: 3464689803495983377
[03/24/2023-12:57:31] [V] [TRT] Tactic: 3464689803495983377 Time: 0.07168
[03/24/2023-12:57:31] [V] [TRT] Conv_158 + Relu_159 || Conv_161 + Relu_162 || Conv_164 + Relu_165 || Conv_167 + Relu_168 Set Tactic Name: ampere_h1688cudnn_256x128_ldg8_relu_exp_medium_nhwc_tn_v1 Tactic: 3513075359009385578
[03/24/2023-12:57:31] [V] [TRT] Tactic: 3513075359009385578 Time: 0.079872
[03/24/2023-12:57:31] [V] [TRT] Conv_158 + Relu_159 || Conv_161 + Relu_162 || Conv_164 + Relu_165 || Conv_167 + Relu_168 Set Tactic Name: ampere_h16816cudnn_128x64_ldg8_relu_exp_stages_64x4_large_nhwc_tn_v1 Tactic: 3573559043797674382
[03/24/2023-12:57:31] [V] [TRT] Tactic: 3573559043797674382 Time: 0.089856
[03/24/2023-12:57:31] [V] [TRT] Conv_158 + Relu_159 || Conv_161 + Relu_162 || Conv_164 + Relu_165 || Conv_167 + Relu_168 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x64x64_stage4_warpsize2x2x1_g1_tensor16x8x16_t1r3s3 Tactic: 3591970081995419777
[03/24/2023-12:57:31] [V] [TRT] Tactic: 3591970081995419777 Time: 0.0928
[03/24/2023-12:57:31] [V] [TRT] Conv_158 + Relu_159 || Conv_161 + Relu_162 || Conv_164 + Relu_165 || Conv_167 + Relu_168 Set Tactic Name: sm75_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x128x32_stage1_warpsize2x2x1_g1_tensor16x8x8_t1r3s3 Tactic: 3636831327753843771
[03/24/2023-12:57:31] [V] [TRT] Tactic: 3636831327753843771 Time: 0.061312
[03/24/2023-12:57:31] [V] [TRT] Conv_158 + Relu_159 || Conv_161 + Relu_162 || Conv_164 + Relu_165 || Conv_167 + Relu_168 Set Tactic Name: ampere_h1688cudnn_128x128_ldg8_relu_exp_small_nhwc_tn_v1 Tactic: 3704534001553878387
[03/24/2023-12:57:31] [V] [TRT] Tactic: 3704534001553878387 Time: 0.074752
[03/24/2023-12:57:31] [V] [TRT] Conv_158 + Relu_159 || Conv_161 + Relu_162 || Conv_164 + Relu_165 || Conv_167 + Relu_168 Set Tactic Name: ampere_h16816cudnn_64x128_ldg8_relu_exp_stages_64x4_small_nhwc_tn_v1 Tactic: 4278315135102886928
[03/24/2023-12:57:31] [V] [TRT] Tactic: 4278315135102886928 Time: 0.082048
[03/24/2023-12:57:31] [V] [TRT] Conv_158 + Relu_159 || Conv_161 + Relu_162 || Conv_164 + Relu_165 || Conv_167 + Relu_168 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x32x32_stage4_warpsize4x1x1_g1_tensor16x8x16_t1r3s3 Tactic: 4503233883285355107
[03/24/2023-12:57:31] [V] [TRT] Tactic: 4503233883285355107 Time: 0.08768
[03/24/2023-12:57:31] [V] [TRT] Conv_158 + Relu_159 || Conv_161 + Relu_162 || Conv_164 + Relu_165 || Conv_167 + Relu_168 Set Tactic Name: ampere_h16816cudnn_256x64_ldg8_relu_exp_stages_64x3_medium_nhwc_tn_v1 Tactic: 4540505769798915372
[03/24/2023-12:57:31] [V] [TRT] Tactic: 4540505769798915372 Time: 0.068608
[03/24/2023-12:57:31] [V] [TRT] Conv_158 + Relu_159 || Conv_161 + Relu_162 || Conv_164 + Relu_165 || Conv_167 + Relu_168 Set Tactic Name: ampere_h16816cudnn_256x64_sliced1x2_ldg8_relu_exp_small_nhwc_tn_v1 Tactic: 4802447371470387646
[03/24/2023-12:57:31] [V] [TRT] Tactic: 4802447371470387646 Time: 0.07744
[03/24/2023-12:57:31] [V] [TRT] Conv_158 + Relu_159 || Conv_161 + Relu_162 || Conv_164 + Relu_165 || Conv_167 + Relu_168 Set Tactic Name: ampere_h16816cudnn_256x128_ldg8_relu_exp_small_nhwc_tn_v1 Tactic: 5059676457552313631
[03/24/2023-12:57:31] [V] [TRT] Tactic: 5059676457552313631 Time: 0.067072
[03/24/2023-12:57:31] [V] [TRT] Conv_158 + Relu_159 || Conv_161 + Relu_162 || Conv_164 + Relu_165 || Conv_167 + Relu_168 Set Tactic Name: sm75_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x128x64_stage1_warpsize2x2x1_g1_tensor16x8x8_t1r3s3 Tactic: 5263029549013613567
[03/24/2023-12:57:31] [V] [TRT] Tactic: 5263029549013613567 Time: 0.06144
[03/24/2023-12:57:31] [V] [TRT] Conv_158 + Relu_159 || Conv_161 + Relu_162 || Conv_164 + Relu_165 || Conv_167 + Relu_168 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x64x64_stage4_warpsize2x2x1_g1_tensor16x8x16 Tactic: 5368829646735632944
[03/24/2023-12:57:31] [V] [TRT] Tactic: 5368829646735632944 Time: 0.092672
[03/24/2023-12:57:31] [V] [TRT] Conv_158 + Relu_159 || Conv_161 + Relu_162 || Conv_164 + Relu_165 || Conv_167 + Relu_168 Set Tactic Name: ampere_h1688cudnn_256x64_sliced1x2_ldg8_relu_exp_small_nhwc_tn_v1 Tactic: 5398999388616959893
[03/24/2023-12:57:31] [V] [TRT] Tactic: 5398999388616959893 Time: 0.081664
[03/24/2023-12:57:31] [V] [TRT] Conv_158 + Relu_159 || Conv_161 + Relu_162 || Conv_164 + Relu_165 || Conv_167 + Relu_168 Set Tactic Name: sm75_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x256x32_stage1_warpsize2x4x1_g1_tensor16x8x8_t1r3s3 Tactic: 5506334059535811602
[03/24/2023-12:57:31] [V] [TRT] Tactic: 5506334059535811602 Time: 0.072576
[03/24/2023-12:57:31] [V] [TRT] Conv_158 + Relu_159 || Conv_161 + Relu_162 || Conv_164 + Relu_165 || Conv_167 + Relu_168 Set Tactic Name: ampere_h16816cudnn_64x128_sliced1x2_ldg8_relu_exp_stages_64x3_large_nhwc_tn_v1 Tactic: 5746691132547383910
[03/24/2023-12:57:31] [V] [TRT] Tactic: 5746691132547383910 Time: 0.07168
[03/24/2023-12:57:31] [V] [TRT] Conv_158 + Relu_159 || Conv_161 + Relu_162 || Conv_164 + Relu_165 || Conv_167 + Relu_168 Set Tactic Name: ampere_h16816cudnn_256x64_ldg8_relu_exp_large_nhwc_tn_v1 Tactic: 5770170567977052602
[03/24/2023-12:57:31] [V] [TRT] Tactic: 5770170567977052602 Time: 0.068864
[03/24/2023-12:57:31] [V] [TRT] Conv_158 + Relu_159 || Conv_161 + Relu_162 || Conv_164 + Relu_165 || Conv_167 + Relu_168 Set Tactic Name: sm75_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x32x64_stage1_warpsize2x1x2_g1_tensor16x8x8_t1r3s3 Tactic: 5932046018238429951
[03/24/2023-12:57:31] [V] [TRT] Tactic: 5932046018238429951 Time: 0.109952
[03/24/2023-12:57:31] [V] [TRT] Conv_158 + Relu_159 || Conv_161 + Relu_162 || Conv_164 + Relu_165 || Conv_167 + Relu_168 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x64x32_stage3_warpsize4x1x1_g1_tensor16x8x16_t1r3s3 Tactic: 5953552212833506549
[03/24/2023-12:57:31] [V] [TRT] Tactic: 5953552212833506549 Time: 0.058496
[03/24/2023-12:57:31] [V] [TRT] Conv_158 + Relu_159 || Conv_161 + Relu_162 || Conv_164 + Relu_165 || Conv_167 + Relu_168 Set Tactic Name: ampere_h16816cudnn_64x128_ldg8_relu_exp_stages_64x3_small_nhwc_tn_v1 Tactic: 6034364043891107501
[03/24/2023-12:57:31] [V] [TRT] Tactic: 6034364043891107501 Time: 0.073344
[03/24/2023-12:57:31] [V] [TRT] Conv_158 + Relu_159 || Conv_161 + Relu_162 || Conv_164 + Relu_165 || Conv_167 + Relu_168 Set Tactic Name: ampere_h16816cudnn_64x64_ldg8_relu_exp_stages_64x5_large_nhwc_tn_v1 Tactic: 6074229447555668232
[03/24/2023-12:57:31] [V] [TRT] Tactic: 6074229447555668232 Time: 0.108416
[03/24/2023-12:57:31] [V] [TRT] Conv_158 + Relu_159 || Conv_161 + Relu_162 || Conv_164 + Relu_165 || Conv_167 + Relu_168 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x64x64_stage3_warpsize2x2x1_g1_tensor16x8x16 Tactic: 6154447660803990543
[03/24/2023-12:57:31] [V] [TRT] Tactic: 6154447660803990543 Time: 0.075264
[03/24/2023-12:57:31] [V] [TRT] Conv_158 + Relu_159 || Conv_161 + Relu_162 || Conv_164 + Relu_165 || Conv_167 + Relu_168 Set Tactic Name: sm75_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x32x64_stage1_warpsize2x1x2_g1_tensor16x8x8 Tactic: 6195603576432354734
[03/24/2023-12:57:31] [V] [TRT] Tactic: 6195603576432354734 Time: 0.113664
[03/24/2023-12:57:31] [V] [TRT] Conv_158 + Relu_159 || Conv_161 + Relu_162 || Conv_164 + Relu_165 || Conv_167 + Relu_168 Set Tactic Name: sm75_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x32x32_stage1_warpsize4x1x1_g1_tensor16x8x8_t1r3s3 Tactic: 6252808259936499253
[03/24/2023-12:57:31] [V] [TRT] Tactic: 6252808259936499253 Time: 0.10432
[03/24/2023-12:57:31] [V] [TRT] Conv_158 + Relu_159 || Conv_161 + Relu_162 || Conv_164 + Relu_165 || Conv_167 + Relu_168 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x128x64_stage3_warpsize2x2x1_g1_tensor16x8x16 Tactic: 6325769668000961702
[03/24/2023-12:57:31] [V] [TRT] Tactic: 6325769668000961702 Time: 0.070144
[03/24/2023-12:57:31] [V] [TRT] Conv_158 + Relu_159 || Conv_161 + Relu_162 || Conv_164 + Relu_165 || Conv_167 + Relu_168 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x32x64_stage5_warpsize2x2x1_g1_tensor16x8x16 Tactic: 6350273239113254096
[03/24/2023-12:57:31] [V] [TRT] Tactic: 6350273239113254096 Time: 0.150656
[03/24/2023-12:57:31] [V] [TRT] Conv_158 + Relu_159 || Conv_161 + Relu_162 || Conv_164 + Relu_165 || Conv_167 + Relu_168 Set Tactic Name: ampere_h16816cudnn_128x128_ldg8_relu_exp_stages_64x3_small_nhwc_tn_v1 Tactic: 6377497238381488891
[03/24/2023-12:57:31] [V] [TRT] Tactic: 6377497238381488891 Time: 0.065408
[03/24/2023-12:57:31] [V] [TRT] Conv_158 + Relu_159 || Conv_161 + Relu_162 || Conv_164 + Relu_165 || Conv_167 + Relu_168 Set Tactic Name: sm75_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x64x64_stage1_warpsize2x2x1_g1_tensor16x8x8 Tactic: 6408235920257988861
[03/24/2023-12:57:31] [V] [TRT] Tactic: 6408235920257988861 Time: 0.086784
[03/24/2023-12:57:31] [V] [TRT] Conv_158 + Relu_159 || Conv_161 + Relu_162 || Conv_164 + Relu_165 || Conv_167 + Relu_168 Set Tactic Name: ampere_h16816cudnn_128x64_ldg8_relu_exp_stages_64x3_large_nhwc_tn_v1 Tactic: 6446388116965632819
[03/24/2023-12:57:31] [V] [TRT] Tactic: 6446388116965632819 Time: 0.0736
[03/24/2023-12:57:31] [V] [TRT] Conv_158 + Relu_159 || Conv_161 + Relu_162 || Conv_164 + Relu_165 || Conv_167 + Relu_168 Set Tactic Name: ampere_h16816cudnn_128x64_sliced1x2_ldg8_relu_exp_stages_64x4_medium_nhwc_tn_v1 Tactic: 6468794451065529747
[03/24/2023-12:57:31] [V] [TRT] Tactic: 6468794451065529747 Time: 0.089856
[03/24/2023-12:57:31] [V] [TRT] Conv_158 + Relu_159 || Conv_161 + Relu_162 || Conv_164 + Relu_165 || Conv_167 + Relu_168 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x128x64_stage3_warpsize4x2x1_g1_tensor16x8x16 Tactic: 6509152032538119080
[03/24/2023-12:57:31] [V] [TRT] Tactic: 6509152032538119080 Time: 0.06976
[03/24/2023-12:57:31] [V] [TRT] Conv_158 + Relu_159 || Conv_161 + Relu_162 || Conv_164 + Relu_165 || Conv_167 + Relu_168 Set Tactic Name: ampere_h1688cudnn_256x128_ldg8_relu_exp_large_nhwc_tn_v1 Tactic: 6642277870194067185
[03/24/2023-12:57:31] [V] [TRT] Tactic: 6642277870194067185 Time: 0.08064
[03/24/2023-12:57:31] [V] [TRT] Conv_158 + Relu_159 || Conv_161 + Relu_162 || Conv_164 + Relu_165 || Conv_167 + Relu_168 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x256x64_stage3_warpsize1x4x1_g1_tensor16x8x16 Tactic: 6703181542003057635
[03/24/2023-12:57:31] [V] [TRT] Tactic: 6703181542003057635 Time: 0.073472
[03/24/2023-12:57:31] [V] [TRT] Conv_158 + Relu_159 || Conv_161 + Relu_162 || Conv_164 + Relu_165 || Conv_167 + Relu_168 Set Tactic Name: ampere_h16816cudnn_64x64_ldg8_relu_exp_stages_64x5_medium_nhwc_tn_v1 Tactic: 6859477213531075460
[03/24/2023-12:57:31] [V] [TRT] Tactic: 6859477213531075460 Time: 0.107008
[03/24/2023-12:57:31] [V] [TRT] Conv_158 + Relu_159 || Conv_161 + Relu_162 || Conv_164 + Relu_165 || Conv_167 + Relu_168 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x128x32_stage4_warpsize2x2x1_g1_tensor16x8x16_t1r3s3 Tactic: 6972489290272968208
[03/24/2023-12:57:31] [V] [TRT] Tactic: 6972489290272968208 Time: 0.05312
[03/24/2023-12:57:31] [V] [TRT] Conv_158 + Relu_159 || Conv_161 + Relu_162 || Conv_164 + Relu_165 || Conv_167 + Relu_168 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x128x32_stage3_warpsize4x2x1_g1_tensor16x8x16 Tactic: 6979044990896381511
[03/24/2023-12:57:31] [V] [TRT] Tactic: 6979044990896381511 Time: 0.065536
[03/24/2023-12:57:31] [V] [TRT] Conv_158 + Relu_159 || Conv_161 + Relu_162 || Conv_164 + Relu_165 || Conv_167 + Relu_168 Set Tactic Name: ampere_h1688cudnn_256x64_ldg8_relu_exp_medium_nhwc_tn_v1 Tactic: 7216571380637776659
[03/24/2023-12:57:31] [V] [TRT] Tactic: 7216571380637776659 Time: 0.089984
[03/24/2023-12:57:31] [V] [TRT] Conv_158 + Relu_159 || Conv_161 + Relu_162 || Conv_164 + Relu_165 || Conv_167 + Relu_168 Set Tactic Name: ampere_h16816cudnn_128x64_ldg8_relu_exp_stages_64x3_medium_nhwc_tn_v1 Tactic: 7609923741161019135
[03/24/2023-12:57:31] [V] [TRT] Tactic: 7609923741161019135 Time: 0.073728
[03/24/2023-12:57:31] [V] [TRT] Conv_158 + Relu_159 || Conv_161 + Relu_162 || Conv_164 + Relu_165 || Conv_167 + Relu_168 Set Tactic Name: sm75_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x64x32_stage1_warpsize2x2x1_g1_tensor16x8x8 Tactic: 7612687199567064086
[03/24/2023-12:57:31] [V] [TRT] Tactic: 7612687199567064086 Time: 0.086016
[03/24/2023-12:57:31] [V] [TRT] Conv_158 + Relu_159 || Conv_161 + Relu_162 || Conv_164 + Relu_165 || Conv_167 + Relu_168 Set Tactic Name: ampere_h16816cudnn_64x64_ldg8_relu_exp_stages_64x6_large_nhwc_tn_v1 Tactic: 7705739241028240201
[03/24/2023-12:57:31] [V] [TRT] Tactic: 7705739241028240201 Time: 0.130176
[03/24/2023-12:57:31] [V] [TRT] Conv_158 + Relu_159 || Conv_161 + Relu_162 || Conv_164 + Relu_165 || Conv_167 + Relu_168 Set Tactic Name: sm75_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x128x32_stage1_warpsize2x2x1_g1_tensor16x8x8 Tactic: 7729555994715864793
[03/24/2023-12:57:31] [V] [TRT] Tactic: 7729555994715864793 Time: 0.083456
[03/24/2023-12:57:31] [V] [TRT] Conv_158 + Relu_159 || Conv_161 + Relu_162 || Conv_164 + Relu_165 || Conv_167 + Relu_168 Set Tactic Name: sm75_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x64x64_stage1_warpsize2x2x1_g1_tensor16x8x8_t1r3s3 Tactic: 7849296535223586261
[03/24/2023-12:57:31] [V] [TRT] Tactic: 7849296535223586261 Time: 0.086016
[03/24/2023-12:57:31] [V] [TRT] Conv_158 + Relu_159 || Conv_161 + Relu_162 || Conv_164 + Relu_165 || Conv_167 + Relu_168 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x256x32_stage3_warpsize2x4x1_g1_tensor16x8x16 Tactic: 8072087735545283117
[03/24/2023-12:57:31] [V] [TRT] Tactic: 8072087735545283117 Time: 0.063744
[03/24/2023-12:57:31] [V] [TRT] Conv_158 + Relu_159 || Conv_161 + Relu_162 || Conv_164 + Relu_165 || Conv_167 + Relu_168 Set Tactic Name: ampere_h16816cudnn_64x64_sliced1x2_ldg8_relu_exp_stages_64x5_medium_nhwc_tn_v1 Tactic: 8101703987960976805
[03/24/2023-12:57:31] [V] [TRT] Tactic: 8101703987960976805 Time: 0.10304
[03/24/2023-12:57:31] [V] [TRT] Conv_158 + Relu_159 || Conv_161 + Relu_162 || Conv_164 + Relu_165 || Conv_167 + Relu_168 Set Tactic Name: ampere_h16816cudnn_128x64_sliced1x2_ldg8_relu_exp_stages_64x4_small_nhwc_tn_v1 Tactic: 8170606396342855895
[03/24/2023-12:57:31] [V] [TRT] Tactic: 8170606396342855895 Time: 0.086784
[03/24/2023-12:57:31] [V] [TRT] Conv_158 + Relu_159 || Conv_161 + Relu_162 || Conv_164 + Relu_165 || Conv_167 + Relu_168 Set Tactic Name: sm75_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x32x64_stage1_warpsize2x1x2_g1_tensor16x8x8 Tactic: 8455608235315878803
[03/24/2023-12:57:31] [V] [TRT] Tactic: 8455608235315878803 Time: 0.121728
[03/24/2023-12:57:31] [V] [TRT] Conv_158 + Relu_159 || Conv_161 + Relu_162 || Conv_164 + Relu_165 || Conv_167 + Relu_168 Set Tactic Name: sm75_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x64x64_stage1_warpsize2x2x1_g1_tensor16x8x8 Tactic: 8668812313058150080
[03/24/2023-12:57:31] [V] [TRT] Tactic: 8668812313058150080 Time: 0.091008
[03/24/2023-12:57:31] [V] [TRT] Conv_158 + Relu_159 || Conv_161 + Relu_162 || Conv_164 + Relu_165 || Conv_167 + Relu_168 Set Tactic Name: ampere_h1688cudnn_256x64_ldg8_relu_exp_small_nhwc_tn_v1 Tactic: 8839784824303350101
[03/24/2023-12:57:31] [V] [TRT] Tactic: 8839784824303350101 Time: 0.080896
[03/24/2023-12:57:31] [V] [TRT] Conv_158 + Relu_159 || Conv_161 + Relu_162 || Conv_164 + Relu_165 || Conv_167 + Relu_168 Set Tactic Name: ampere_h16816cudnn_64x64_sliced1x2_ldg8_relu_exp_stages_64x5_large_nhwc_tn_v1 Tactic: -9217371357561775773
[03/24/2023-12:57:31] [V] [TRT] Tactic: -9217371357561775773 Time: 0.10304
[03/24/2023-12:57:31] [V] [TRT] Conv_158 + Relu_159 || Conv_161 + Relu_162 || Conv_164 + Relu_165 || Conv_167 + Relu_168 Set Tactic Name: ampere_h16816cudnn_256x64_sliced1x2_ldg8_relu_exp_medium_nhwc_tn_v1 Tactic: -9009272790678027912
[03/24/2023-12:57:31] [V] [TRT] Tactic: -9009272790678027912 Time: 0.08384
[03/24/2023-12:57:31] [V] [TRT] Conv_158 + Relu_159 || Conv_161 + Relu_162 || Conv_164 + Relu_165 || Conv_167 + Relu_168 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x32x32_stage4_warpsize4x1x1_g1_tensor16x8x16 Tactic: -8985224497679592364
[03/24/2023-12:57:31] [V] [TRT] Tactic: -8985224497679592364 Time: 0.088832
[03/24/2023-12:57:31] [V] [TRT] Conv_158 + Relu_159 || Conv_161 + Relu_162 || Conv_164 + Relu_165 || Conv_167 + Relu_168 Set Tactic Name: ampere_h16816cudnn_128x64_sliced1x2_ldg8_relu_exp_stages_64x3_large_nhwc_tn_v1 Tactic: -8949544755481315679
[03/24/2023-12:57:31] [V] [TRT] Tactic: -8949544755481315679 Time: 0.071808
[03/24/2023-12:57:31] [V] [TRT] Conv_158 + Relu_159 || Conv_161 + Relu_162 || Conv_164 + Relu_165 || Conv_167 + Relu_168 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x64x64_stage3_warpsize4x1x1_g1_tensor16x8x16_t1r3s3 Tactic: -8867999442759527766
[03/24/2023-12:57:31] [V] [TRT] Tactic: -8867999442759527766 Time: 0.078464
[03/24/2023-12:57:31] [V] [TRT] Conv_158 + Relu_159 || Conv_161 + Relu_162 || Conv_164 + Relu_165 || Conv_167 + Relu_168 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x128x64_stage3_warpsize2x2x1_g1_tensor16x8x16 Tactic: -8759929675070720385
[03/24/2023-12:57:31] [V] [TRT] Tactic: -8759929675070720385 Time: 0.066176
[03/24/2023-12:57:31] [V] [TRT] Conv_158 + Relu_159 || Conv_161 + Relu_162 || Conv_164 + Relu_165 || Conv_167 + Relu_168 Set Tactic Name: ampere_h16816cudnn_64x64_ldg8_relu_exp_stages_64x6_medium_nhwc_tn_v1 Tactic: -8604374562669615024
[03/24/2023-12:57:31] [V] [TRT] Tactic: -8604374562669615024 Time: 0.126976
[03/24/2023-12:57:31] [V] [TRT] Conv_158 + Relu_159 || Conv_161 + Relu_162 || Conv_164 + Relu_165 || Conv_167 + Relu_168 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x128x64_stage3_warpsize4x2x1_g1_tensor16x8x16 Tactic: -8362347876645295759
[03/24/2023-12:57:31] [V] [TRT] Tactic: -8362347876645295759 Time: 0.066688
[03/24/2023-12:57:31] [V] [TRT] Conv_158 + Relu_159 || Conv_161 + Relu_162 || Conv_164 + Relu_165 || Conv_167 + Relu_168 Set Tactic Name: sm75_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x128x32_stage1_warpsize4x2x1_g1_tensor16x8x8 Tactic: -8254009616492665198
[03/24/2023-12:57:31] [V] [TRT] Tactic: -8254009616492665198 Time: 0.073728
[03/24/2023-12:57:31] [V] [TRT] Conv_158 + Relu_159 || Conv_161 + Relu_162 || Conv_164 + Relu_165 || Conv_167 + Relu_168 Set Tactic Name: ampere_h16816cudnn_256x128_ldg8_relu_exp_stages_64x3_large_nhwc_tn_v1 Tactic: -7757610000269494813
[03/24/2023-12:57:31] [V] [TRT] Tactic: -7757610000269494813 Time: 0.069504
[03/24/2023-12:57:31] [V] [TRT] Conv_158 + Relu_159 || Conv_161 + Relu_162 || Conv_164 + Relu_165 || Conv_167 + Relu_168 Set Tactic Name: sm75_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x128x32_stage1_warpsize4x2x1_g1_tensor16x8x8 Tactic: -7615325597099025933
[03/24/2023-12:57:31] [V] [TRT] Tactic: -7615325597099025933 Time: 0.075776
[03/24/2023-12:57:31] [V] [TRT] Conv_158 + Relu_159 || Conv_161 + Relu_162 || Conv_164 + Relu_165 || Conv_167 + Relu_168 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x64x64_stage3_warpsize4x1x1_g1_tensor16x8x16 Tactic: -6917689122519989488
[03/24/2023-12:57:31] [V] [TRT] Tactic: -6917689122519989488 Time: 0.074624
[03/24/2023-12:57:31] [V] [TRT] Conv_158 + Relu_159 || Conv_161 + Relu_162 || Conv_164 + Relu_165 || Conv_167 + Relu_168 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x32x64_stage5_warpsize2x2x1_g1_tensor16x8x16_t1r3s3 Tactic: -6902925267326201166
[03/24/2023-12:57:31] [V] [TRT] Tactic: -6902925267326201166 Time: 0.143616
[03/24/2023-12:57:31] [V] [TRT] Conv_158 + Relu_159 || Conv_161 + Relu_162 || Conv_164 + Relu_165 || Conv_167 + Relu_168 Set Tactic Name: ampere_h16816cudnn_64x128_ldg8_relu_exp_stages_64x4_large_nhwc_tn_v1 Tactic: -6840588038605932325
[03/24/2023-12:57:31] [V] [TRT] Tactic: -6840588038605932325 Time: 0.084096
[03/24/2023-12:57:31] [V] [TRT] Conv_158 + Relu_159 || Conv_161 + Relu_162 || Conv_164 + Relu_165 || Conv_167 + Relu_168 Set Tactic Name: sm75_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x32x32_stage1_warpsize4x1x1_g1_tensor16x8x8 Tactic: -6828337260021572283
[03/24/2023-12:57:31] [V] [TRT] Tactic: -6828337260021572283 Time: 0.122368
[03/24/2023-12:57:31] [V] [TRT] Conv_158 + Relu_159 || Conv_161 + Relu_162 || Conv_164 + Relu_165 || Conv_167 + Relu_168 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x256x32_stage3_warpsize2x4x1_g1_tensor16x8x16 Tactic: -6799856376604253964
[03/24/2023-12:57:31] [V] [TRT] Tactic: -6799856376604253964 Time: 0.064384
[03/24/2023-12:57:31] [V] [TRT] Conv_158 + Relu_159 || Conv_161 + Relu_162 || Conv_164 + Relu_165 || Conv_167 + Relu_168 Set Tactic Name: sm75_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x32x32_stage1_warpsize4x1x1_g1_tensor16x8x8 Tactic: -6711815420995272523
[03/24/2023-12:57:31] [V] [TRT] Tactic: -6711815420995272523 Time: 0.114432
[03/24/2023-12:57:31] [V] [TRT] Conv_158 + Relu_159 || Conv_161 + Relu_162 || Conv_164 + Relu_165 || Conv_167 + Relu_168 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x32x32_stage4_warpsize4x1x1_g1_tensor16x8x16_t1r3s3 Tactic: -6625722781282978136
[03/24/2023-12:57:31] [V] [TRT] Tactic: -6625722781282978136 Time: 0.092288
[03/24/2023-12:57:31] [V] [TRT] Conv_158 + Relu_159 || Conv_161 + Relu_162 || Conv_164 + Relu_165 || Conv_167 + Relu_168 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x64x32_stage3_warpsize4x1x1_g1_tensor16x8x16 Tactic: -6525498856028268801
[03/24/2023-12:57:31] [V] [TRT] Tactic: -6525498856028268801 Time: 0.059776
[03/24/2023-12:57:31] [V] [TRT] Conv_158 + Relu_159 || Conv_161 + Relu_162 || Conv_164 + Relu_165 || Conv_167 + Relu_168 Set Tactic Name: sm75_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x256x64_stage1_warpsize1x4x2_g1_tensor16x8x8 Tactic: -6489479581011009593
[03/24/2023-12:57:31] [V] [TRT] Tactic: -6489479581011009593 Time: 0.077952
[03/24/2023-12:57:31] [V] [TRT] Conv_158 + Relu_159 || Conv_161 + Relu_162 || Conv_164 + Relu_165 || Conv_167 + Relu_168 Set Tactic Name: ampere_h16816cudnn_64x64_sliced1x2_ldg8_relu_exp_stages_64x6_medium_nhwc_tn_v1 Tactic: -6356316196810535311
[03/24/2023-12:57:31] [V] [TRT] Tactic: -6356316196810535311 Time: 0.132096
[03/24/2023-12:57:31] [V] [TRT] Conv_158 + Relu_159 || Conv_161 + Relu_162 || Conv_164 + Relu_165 || Conv_167 + Relu_168 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x32x32_stage4_warpsize4x1x1_g1_tensor16x8x16 Tactic: -6324345858751792783
[03/24/2023-12:57:31] [V] [TRT] Tactic: -6324345858751792783 Time: 0.094336
[03/24/2023-12:57:31] [V] [TRT] Conv_158 + Relu_159 || Conv_161 + Relu_162 || Conv_164 + Relu_165 || Conv_167 + Relu_168 Set Tactic Name: sm75_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x256x64_stage1_warpsize1x4x2_g1_tensor16x8x8_t1r3s3 Tactic: -6320761427625651496
[03/24/2023-12:57:31] [V] [TRT] Tactic: -6320761427625651496 Time: 0.075776
[03/24/2023-12:57:31] [V] [TRT] Conv_158 + Relu_159 || Conv_161 + Relu_162 || Conv_164 + Relu_165 || Conv_167 + Relu_168 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x256x32_stage3_warpsize2x4x1_g1_tensor16x8x16_t1r3s3 Tactic: -6262400699544994312
[03/24/2023-12:57:31] [V] [TRT] Tactic: -6262400699544994312 Time: 0.063488
[03/24/2023-12:57:31] [V] [TRT] Conv_158 + Relu_159 || Conv_161 + Relu_162 || Conv_164 + Relu_165 || Conv_167 + Relu_168 Set Tactic Name: ampere_h1688cudnn_128x128_ldg8_relu_exp_large_nhwc_tn_v1 Tactic: -6257787336162086472
[03/24/2023-12:57:31] [V] [TRT] Tactic: -6257787336162086472 Time: 0.077952
[03/24/2023-12:57:31] [V] [TRT] Conv_158 + Relu_159 || Conv_161 + Relu_162 || Conv_164 + Relu_165 || Conv_167 + Relu_168 Set Tactic Name: sm75_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x128x64_stage1_warpsize2x2x1_g1_tensor16x8x8 Tactic: -6080892721161662420
[03/24/2023-12:57:31] [V] [TRT] Tactic: -6080892721161662420 Time: 0.063232
[03/24/2023-12:57:31] [V] [TRT] Conv_158 + Relu_159 || Conv_161 + Relu_162 || Conv_164 + Relu_165 || Conv_167 + Relu_168 Set Tactic Name: ampere_h16816cudnn_128x64_ldg8_relu_exp_stages_64x4_small_nhwc_tn_v1 Tactic: -6063766379489217211
[03/24/2023-12:57:31] [V] [TRT] Tactic: -6063766379489217211 Time: 0.086016
[03/24/2023-12:57:31] [V] [TRT] Conv_158 + Relu_159 || Conv_161 + Relu_162 || Conv_164 + Relu_165 || Conv_167 + Relu_168 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x128x32_stage5_warpsize2x2x1_g1_tensor16x8x16 Tactic: -5777580938094193096
[03/24/2023-12:57:31] [V] [TRT] Tactic: -5777580938094193096 Time: 0.067584
[03/24/2023-12:57:31] [V] [TRT] Conv_158 + Relu_159 || Conv_161 + Relu_162 || Conv_164 + Relu_165 || Conv_167 + Relu_168 Set Tactic Name: sm75_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x128x64_stage1_warpsize2x2x1_g1_tensor16x8x8 Tactic: -5710735840878760115
[03/24/2023-12:57:31] [V] [TRT] Tactic: -5710735840878760115 Time: 0.063744
[03/24/2023-12:57:31] [V] [TRT] Conv_158 + Relu_159 || Conv_161 + Relu_162 || Conv_164 + Relu_165 || Conv_167 + Relu_168 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x128x32_stage3_warpsize4x2x1_g1_tensor16x8x16 Tactic: -5657273398217409378
[03/24/2023-12:57:31] [V] [TRT] Tactic: -5657273398217409378 Time: 0.064512
[03/24/2023-12:57:31] [V] [TRT] Conv_158 + Relu_159 || Conv_161 + Relu_162 || Conv_164 + Relu_165 || Conv_167 + Relu_168 Set Tactic Name: sm75_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x128x32_stage1_warpsize2x2x1_g1_tensor16x8x8_t1r3s3 Tactic: -5546257196173962281
[03/24/2023-12:57:31] [V] [TRT] Tactic: -5546257196173962281 Time: 0.081536
[03/24/2023-12:57:31] [V] [TRT] Conv_158 + Relu_159 || Conv_161 + Relu_162 || Conv_164 + Relu_165 || Conv_167 + Relu_168 Set Tactic Name: ampere_h16816cudnn_128x128_ldg8_relu_exp_small_nhwc_tn_v1 Tactic: -5530886555766748586
[03/24/2023-12:57:31] [V] [TRT] Tactic: -5530886555766748586 Time: 0.05632
[03/24/2023-12:57:31] [V] [TRT] Conv_158 + Relu_159 || Conv_161 + Relu_162 || Conv_164 + Relu_165 || Conv_167 + Relu_168 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x64x32_stage5_warpsize2x2x1_g1_tensor16x8x16_t1r3s3 Tactic: -5422685219138380548
[03/24/2023-12:57:31] [V] [TRT] Tactic: -5422685219138380548 Time: 0.068224
[03/24/2023-12:57:31] [V] [TRT] Conv_158 + Relu_159 || Conv_161 + Relu_162 || Conv_164 + Relu_165 || Conv_167 + Relu_168 Set Tactic Name: ampere_h16816cudnn_256x64_ldg8_relu_exp_stages_64x3_small_nhwc_tn_v1 Tactic: -5261787675443473128
[03/24/2023-12:57:31] [V] [TRT] Tactic: -5261787675443473128 Time: 0.067712
[03/24/2023-12:57:31] [V] [TRT] Conv_158 + Relu_159 || Conv_161 + Relu_162 || Conv_164 + Relu_165 || Conv_167 + Relu_168 Set Tactic Name: sm75_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x64x32_stage1_warpsize4x1x1_g1_tensor16x8x8 Tactic: -5198219374380660379
[03/24/2023-12:57:31] [V] [TRT] Tactic: -5198219374380660379 Time: 0.072704
[03/24/2023-12:57:31] [V] [TRT] Conv_158 + Relu_159 || Conv_161 + Relu_162 || Conv_164 + Relu_165 || Conv_167 + Relu_168 Set Tactic Name: ampere_h16816cudnn_64x128_sliced1x2_ldg8_relu_exp_stages_64x3_medium_nhwc_tn_v1 Tactic: -5161596964442251102
[03/24/2023-12:57:31] [V] [TRT] Tactic: -5161596964442251102 Time: 0.070784
[03/24/2023-12:57:31] [V] [TRT] Conv_158 + Relu_159 || Conv_161 + Relu_162 || Conv_164 + Relu_165 || Conv_167 + Relu_168 Set Tactic Name: ampere_h16816cudnn_64x128_ldg8_relu_exp_stages_64x3_medium_nhwc_tn_v1 Tactic: -5127240325355316006
[03/24/2023-12:57:31] [V] [TRT] Tactic: -5127240325355316006 Time: 0.073856
[03/24/2023-12:57:31] [V] [TRT] Conv_158 + Relu_159 || Conv_161 + Relu_162 || Conv_164 + Relu_165 || Conv_167 + Relu_168 Set Tactic Name: ampere_h16816cudnn_256x128_ldg8_relu_exp_stages_64x3_medium_nhwc_tn_v1 Tactic: -5109582882231362997
[03/24/2023-12:57:31] [V] [TRT] Tactic: -5109582882231362997 Time: 0.068864
[03/24/2023-12:57:31] [V] [TRT] Conv_158 + Relu_159 || Conv_161 + Relu_162 || Conv_164 + Relu_165 || Conv_167 + Relu_168 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x64x32_stage5_warpsize2x2x1_g1_tensor16x8x16 Tactic: -4825567853927730435
[03/24/2023-12:57:31] [V] [TRT] Tactic: -4825567853927730435 Time: 0.073984
[03/24/2023-12:57:31] [V] [TRT] Conv_158 + Relu_159 || Conv_161 + Relu_162 || Conv_164 + Relu_165 || Conv_167 + Relu_168 Set Tactic Name: ampere_h16816cudnn_64x128_sliced1x2_ldg8_relu_exp_stages_64x4_small_nhwc_tn_v1 Tactic: -4796511246675321840
[03/24/2023-12:57:31] [V] [TRT] Tactic: -4796511246675321840 Time: 0.087936
[03/24/2023-12:57:31] [V] [TRT] Conv_158 + Relu_159 || Conv_161 + Relu_162 || Conv_164 + Relu_165 || Conv_167 + Relu_168 Set Tactic Name: ampere_h16816cudnn_64x64_sliced1x2_ldg8_relu_exp_stages_64x6_large_nhwc_tn_v1 Tactic: -4706569565442112734
[03/24/2023-12:57:31] [V] [TRT] Tactic: -4706569565442112734 Time: 0.134144
[03/24/2023-12:57:31] [V] [TRT] Conv_158 + Relu_159 || Conv_161 + Relu_162 || Conv_164 + Relu_165 || Conv_167 + Relu_168 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x128x64_stage3_warpsize2x2x1_g1_tensor16x8x16_t1r3s3 Tactic: -4566599693570369588
[03/24/2023-12:57:31] [V] [TRT] Tactic: -4566599693570369588 Time: 0.068736
[03/24/2023-12:57:31] [V] [TRT] Conv_158 + Relu_159 || Conv_161 + Relu_162 || Conv_164 + Relu_165 || Conv_167 + Relu_168 Set Tactic Name: ampere_h16816cudnn_128x128_ldg8_relu_exp_stages_64x3_large_nhwc_tn_v1 Tactic: -4409144516525410768
[03/24/2023-12:57:31] [V] [TRT] Tactic: -4409144516525410768 Time: 0.065536
[03/24/2023-12:57:31] [V] [TRT] Conv_158 + Relu_159 || Conv_161 + Relu_162 || Conv_164 + Relu_165 || Conv_167 + Relu_168 Set Tactic Name: ampere_h16816cudnn_128x64_ldg8_relu_exp_stages_64x3_small_nhwc_tn_v1 Tactic: -4379519430184503304
[03/24/2023-12:57:31] [V] [TRT] Tactic: -4379519430184503304 Time: 0.07296
[03/24/2023-12:57:31] [V] [TRT] Conv_158 + Relu_159 || Conv_161 + Relu_162 || Conv_164 + Relu_165 || Conv_167 + Relu_168 Set Tactic Name: ampere_h1688cudnn_256x128_ldg8_relu_exp_small_nhwc_tn_v1 Tactic: -4152066959007262150
[03/24/2023-12:57:31] [V] [TRT] Tactic: -4152066959007262150 Time: 0.075392
[03/24/2023-12:57:31] [V] [TRT] Conv_158 + Relu_159 || Conv_161 + Relu_162 || Conv_164 + Relu_165 || Conv_167 + Relu_168 Set Tactic Name: ampere_h16816cudnn_64x128_ldg8_relu_exp_stages_64x4_medium_nhwc_tn_v1 Tactic: -4021926646879732549
[03/24/2023-12:57:31] [V] [TRT] Tactic: -4021926646879732549 Time: 0.083072
[03/24/2023-12:57:31] [V] [TRT] Conv_158 + Relu_159 || Conv_161 + Relu_162 || Conv_164 + Relu_165 || Conv_167 + Relu_168 Set Tactic Name: ampere_h16816cudnn_64x128_sliced1x2_ldg8_relu_exp_stages_64x4_medium_nhwc_tn_v1 Tactic: -3987638434926559037
[03/24/2023-12:57:31] [V] [TRT] Tactic: -3987638434926559037 Time: 0.088064
[03/24/2023-12:57:31] [V] [TRT] Conv_158 + Relu_159 || Conv_161 + Relu_162 || Conv_164 + Relu_165 || Conv_167 + Relu_168 Set Tactic Name: ampere_h1688cudnn_256x64_sliced1x2_ldg8_relu_exp_medium_nhwc_tn_v1 Tactic: -3905653247016903130
[03/24/2023-12:57:31] [V] [TRT] Tactic: -3905653247016903130 Time: 0.088064
[03/24/2023-12:57:31] [V] [TRT] Conv_158 + Relu_159 || Conv_161 + Relu_162 || Conv_164 + Relu_165 || Conv_167 + Relu_168 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x64x32_stage5_warpsize2x2x1_g1_tensor16x8x16 Tactic: -3903974568488493144
[03/24/2023-12:57:31] [V] [TRT] Tactic: -3903974568488493144 Time: 0.07168
[03/24/2023-12:57:31] [V] [TRT] Conv_158 + Relu_159 || Conv_161 + Relu_162 || Conv_164 + Relu_165 || Conv_167 + Relu_168 Set Tactic Name: ampere_h16816cudnn_64x128_ldg8_relu_exp_stages_64x3_large_nhwc_tn_v1 Tactic: -3895429239811098010
[03/24/2023-12:57:31] [V] [TRT] Tactic: -3895429239811098010 Time: 0.073856
[03/24/2023-12:57:31] [V] [TRT] Conv_158 + Relu_159 || Conv_161 + Relu_162 || Conv_164 + Relu_165 || Conv_167 + Relu_168 Set Tactic Name: ampere_h16816cudnn_256x64_ldg8_relu_exp_small_nhwc_tn_v1 Tactic: -3864869056275745423
[03/24/2023-12:57:31] [V] [TRT] Tactic: -3864869056275745423 Time: 0.066048
[03/24/2023-12:57:31] [V] [TRT] Conv_158 + Relu_159 || Conv_161 + Relu_162 || Conv_164 + Relu_165 || Conv_167 + Relu_168 Set Tactic Name: sm75_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x32x32_stage1_warpsize4x1x1_g1_tensor16x8x8_t1r3s3 Tactic: -3784342055748695733
[03/24/2023-12:57:31] [V] [TRT] Tactic: -3784342055748695733 Time: 0.11328
[03/24/2023-12:57:31] [V] [TRT] Conv_158 + Relu_159 || Conv_161 + Relu_162 || Conv_164 + Relu_165 || Conv_167 + Relu_168 Set Tactic Name: ampere_h16816cudnn_64x64_ldg8_relu_exp_stages_64x5_small_nhwc_tn_v1 Tactic: -3601464762214218301
[03/24/2023-12:57:31] [V] [TRT] Tactic: -3601464762214218301 Time: 0.106368
[03/24/2023-12:57:31] [V] [TRT] Conv_158 + Relu_159 || Conv_161 + Relu_162 || Conv_164 + Relu_165 || Conv_167 + Relu_168 Set Tactic Name: sm75_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x64x32_stage1_warpsize2x2x1_g1_tensor16x8x8 Tactic: -3425274793298557239
[03/24/2023-12:57:31] [V] [TRT] Tactic: -3425274793298557239 Time: 0.08192
[03/24/2023-12:57:31] [V] [TRT] Conv_158 + Relu_159 || Conv_161 + Relu_162 || Conv_164 + Relu_165 || Conv_167 + Relu_168 Set Tactic Name: ampere_h1688cudnn_256x64_sliced1x2_ldg8_relu_exp_large_nhwc_tn_v1 Tactic: -3412636942650049698
[03/24/2023-12:57:31] [V] [TRT] Tactic: -3412636942650049698 Time: 0.08896
[03/24/2023-12:57:31] [V] [TRT] Conv_158 + Relu_159 || Conv_161 + Relu_162 || Conv_164 + Relu_165 || Conv_167 + Relu_168 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x64x32_stage3_warpsize4x1x1_g1_tensor16x8x16 Tactic: -3338665856053412950
[03/24/2023-12:57:31] [V] [TRT] Tactic: -3338665856053412950 Time: 0.059264
[03/24/2023-12:57:31] [V] [TRT] Conv_158 + Relu_159 || Conv_161 + Relu_162 || Conv_164 + Relu_165 || Conv_167 + Relu_168 Set Tactic Name: sm75_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x128x32_stage1_warpsize2x2x1_g1_tensor16x8x8 Tactic: -3271955096576257018
[03/24/2023-12:57:32] [V] [TRT] Tactic: -3271955096576257018 Time: 0.082048
[03/24/2023-12:57:32] [V] [TRT] Conv_158 + Relu_159 || Conv_161 + Relu_162 || Conv_164 + Relu_165 || Conv_167 + Relu_168 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x128x64_stage3_warpsize4x2x1_g1_tensor16x8x16_t1r3s3 Tactic: -3243541398692466074
[03/24/2023-12:57:32] [V] [TRT] Tactic: -3243541398692466074 Time: 0.069248
[03/24/2023-12:57:32] [V] [TRT] Conv_158 + Relu_159 || Conv_161 + Relu_162 || Conv_164 + Relu_165 || Conv_167 + Relu_168 Set Tactic Name: ampere_h16816cudnn_64x128_sliced1x2_ldg8_relu_exp_stages_64x3_small_nhwc_tn_v1 Tactic: -3058330359340425555
[03/24/2023-12:57:32] [V] [TRT] Tactic: -3058330359340425555 Time: 0.070528
[03/24/2023-12:57:32] [V] [TRT] Conv_158 + Relu_159 || Conv_161 + Relu_162 || Conv_164 + Relu_165 || Conv_167 + Relu_168 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x256x64_stage3_warpsize1x4x1_g1_tensor16x8x16_t1r3s3 Tactic: -2899647483672319239
[03/24/2023-12:57:32] [V] [TRT] Tactic: -2899647483672319239 Time: 0.07488
[03/24/2023-12:57:32] [V] [TRT] Conv_158 + Relu_159 || Conv_161 + Relu_162 || Conv_164 + Relu_165 || Conv_167 + Relu_168 Set Tactic Name: ampere_h16816cudnn_256x64_sliced1x2_ldg8_relu_exp_large_nhwc_tn_v1 Tactic: -2816084650627734155
[03/24/2023-12:57:32] [V] [TRT] Tactic: -2816084650627734155 Time: 0.084608
[03/24/2023-12:57:32] [V] [TRT] Conv_158 + Relu_159 || Conv_161 + Relu_162 || Conv_164 + Relu_165 || Conv_167 + Relu_168 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x128x32_stage5_warpsize2x2x1_g1_tensor16x8x16 Tactic: -2662892962457732243
[03/24/2023-12:57:32] [V] [TRT] Tactic: -2662892962457732243 Time: 0.067584
[03/24/2023-12:57:32] [V] [TRT] Conv_158 + Relu_159 || Conv_161 + Relu_162 || Conv_164 + Relu_165 || Conv_167 + Relu_168 Set Tactic Name: ampere_h16816cudnn_256x128_ldg8_relu_exp_large_nhwc_tn_v1 Tactic: -2559894581585337900
[03/24/2023-12:57:32] [V] [TRT] Tactic: -2559894581585337900 Time: 0.067968
[03/24/2023-12:57:32] [V] [TRT] Conv_158 + Relu_159 || Conv_161 + Relu_162 || Conv_164 + Relu_165 || Conv_167 + Relu_168 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x32x32_stage4_warpsize4x1x1_g1_tensor16x8x16 Tactic: -2530740716768816092
[03/24/2023-12:57:32] [V] [TRT] Tactic: -2530740716768816092 Time: 0.0896
[03/24/2023-12:57:32] [V] [TRT] Conv_158 + Relu_159 || Conv_161 + Relu_162 || Conv_164 + Relu_165 || Conv_167 + Relu_168 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x128x32_stage4_warpsize2x2x1_g1_tensor16x8x16 Tactic: -2332828394978346992
[03/24/2023-12:57:32] [V] [TRT] Tactic: -2332828394978346992 Time: 0.054272
[03/24/2023-12:57:32] [V] [TRT] Conv_158 + Relu_159 || Conv_161 + Relu_162 || Conv_164 + Relu_165 || Conv_167 + Relu_168 Set Tactic Name: ampere_h1688cudnn_256x64_ldg8_relu_exp_large_nhwc_tn_v1 Tactic: -2241736083352441442
[03/24/2023-12:57:32] [V] [TRT] Tactic: -2241736083352441442 Time: 0.09024
[03/24/2023-12:57:32] [V] [TRT] Conv_158 + Relu_159 || Conv_161 + Relu_162 || Conv_164 + Relu_165 || Conv_167 + Relu_168 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x32x64_stage5_warpsize2x2x1_g1_tensor16x8x16 Tactic: -2161909437867201546
[03/24/2023-12:57:32] [V] [TRT] Tactic: -2161909437867201546 Time: 0.143104
[03/24/2023-12:57:32] [V] [TRT] Conv_158 + Relu_159 || Conv_161 + Relu_162 || Conv_164 + Relu_165 || Conv_167 + Relu_168 Set Tactic Name: ampere_h16816cudnn_256x64_ldg8_relu_exp_medium_nhwc_tn_v1 Tactic: -1985778916402815946
[03/24/2023-12:57:32] [V] [TRT] Tactic: -1985778916402815946 Time: 0.06784
[03/24/2023-12:57:32] [V] [TRT] Conv_158 + Relu_159 || Conv_161 + Relu_162 || Conv_164 + Relu_165 || Conv_167 + Relu_168 Set Tactic Name: sm75_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x256x32_stage1_warpsize2x4x1_g1_tensor16x8x8 Tactic: -1708101578041178688
[03/24/2023-12:57:32] [V] [TRT] Tactic: -1708101578041178688 Time: 0.074496
[03/24/2023-12:57:32] [V] [TRT] Conv_158 + Relu_159 || Conv_161 + Relu_162 || Conv_164 + Relu_165 || Conv_167 + Relu_168 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x64x64_stage3_warpsize4x1x1_g1_tensor16x8x16 Tactic: -1502788097503482299
[03/24/2023-12:57:32] [V] [TRT] Tactic: -1502788097503482299 Time: 0.080128
[03/24/2023-12:57:32] [V] [TRT] Conv_158 + Relu_159 || Conv_161 + Relu_162 || Conv_164 + Relu_165 || Conv_167 + Relu_168 Set Tactic Name: ampere_h16816cudnn_128x64_sliced1x2_ldg8_relu_exp_stages_64x4_large_nhwc_tn_v1 Tactic: -1500496213132463076
[03/24/2023-12:57:32] [V] [TRT] Tactic: -1500496213132463076 Time: 0.093056
[03/24/2023-12:57:32] [V] [TRT] Conv_158 + Relu_159 || Conv_161 + Relu_162 || Conv_164 + Relu_165 || Conv_167 + Relu_168 Set Tactic Name: ampere_h16816cudnn_64x64_ldg8_relu_exp_stages_64x6_small_nhwc_tn_v1 Tactic: -1099247066487349374
[03/24/2023-12:57:32] [V] [TRT] Tactic: -1099247066487349374 Time: 0.119808
[03/24/2023-12:57:32] [V] [TRT] Conv_158 + Relu_159 || Conv_161 + Relu_162 || Conv_164 + Relu_165 || Conv_167 + Relu_168 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x64x64_stage4_warpsize2x2x1_g1_tensor16x8x16 Tactic: -910286698936744682
[03/24/2023-12:57:32] [V] [TRT] Tactic: -910286698936744682 Time: 0.09536
[03/24/2023-12:57:32] [V] [TRT] Conv_158 + Relu_159 || Conv_161 + Relu_162 || Conv_164 + Relu_165 || Conv_167 + Relu_168 Set Tactic Name: sm75_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x256x32_stage1_warpsize2x4x1_g1_tensor16x8x8 Tactic: -907287437357565279
[03/24/2023-12:57:32] [V] [TRT] Tactic: -907287437357565279 Time: 0.073472
[03/24/2023-12:57:32] [V] [TRT] Conv_158 + Relu_159 || Conv_161 + Relu_162 || Conv_164 + Relu_165 || Conv_167 + Relu_168 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x32x32_stage4_warpsize4x1x1_g1_tensor16x8x16 Tactic: -606726295133751039
[03/24/2023-12:57:32] [V] [TRT] Tactic: -606726295133751039 Time: 0.097536
[03/24/2023-12:57:32] [V] [TRT] Fastest Tactic: 6972489290272968208 Time: 0.05312
[03/24/2023-12:57:32] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: 6972489290272968208
[03/24/2023-12:57:32] [V] [TRT] *************** Autotuning format combination: Half(129600,1:16,720,4) -> Half(518400,1:16,2880,16) ***************
[03/24/2023-12:57:32] [V] [TRT] --------------- Timing Runner: Conv_158 + Relu_159 || Conv_161 + Relu_162 || Conv_164 + Relu_165 || Conv_167 + Relu_168 (CudnnConvolution)
[03/24/2023-12:57:32] [V] [TRT] CudnnConvolution has no valid tactics for this config, skipping
[03/24/2023-12:57:32] [V] [TRT] --------------- Timing Runner: Conv_158 + Relu_159 || Conv_161 + Relu_162 || Conv_164 + Relu_165 || Conv_167 + Relu_168 (CaskConvolution)
[03/24/2023-12:57:32] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[03/24/2023-12:57:32] [V] [TRT] =============== Computing costs for 
[03/24/2023-12:57:32] [V] [TRT] *************** Autotuning format combination: Float(8294400,32400,180,1) -> Float(97200,32400,180,1) ***************
[03/24/2023-12:57:32] [V] [TRT] --------------- Timing Runner: Conv_160 (CudaDepthwiseConvolution)
[03/24/2023-12:57:32] [V] [TRT] CudaDepthwiseConvolution has no valid tactics for this config, skipping
[03/24/2023-12:57:32] [V] [TRT] --------------- Timing Runner: Conv_160 (FusedConvActConvolution)
[03/24/2023-12:57:32] [V] [TRT] Tactic: 524287 Time: 0.099328
[03/24/2023-12:57:32] [V] [TRT] Tactic: 1048575 Time: 0.091008
[03/24/2023-12:57:32] [V] [TRT] Tactic: 1703935 Time: 0.08704
[03/24/2023-12:57:32] [V] [TRT] Tactic: 2228223 Time: 0.102272
[03/24/2023-12:57:32] [V] [TRT] Tactic: 2424831 Time: 0.103936
[03/24/2023-12:57:32] [V] [TRT] Tactic: 2621439 Time: 0.08704
[03/24/2023-12:57:32] [V] [TRT] Tactic: 3014655 Time: 0.089984
[03/24/2023-12:57:32] [V] [TRT] Tactic: 3604479 Time: 0.08896
[03/24/2023-12:57:32] [V] [TRT] Tactic: 5046271 Time: 0.093824
[03/24/2023-12:57:32] [V] [TRT] Tactic: 6160383 Time: 0.095232
[03/24/2023-12:57:32] [V] [TRT] Tactic: 6488063 Time: 0.105344
[03/24/2023-12:57:32] [V] [TRT] Tactic: 7864319 Time: 0.09152
[03/24/2023-12:57:32] [V] [TRT] Tactic: 8585215 Time: 0.116992
[03/24/2023-12:57:32] [V] [TRT] Tactic: 8847359 Time: 0.09088
[03/24/2023-12:57:32] [V] [TRT] Tactic: 9043967 Time: 0.091008
[03/24/2023-12:57:32] [V] [TRT] Tactic: 9175039 Time: 0.08896
[03/24/2023-12:57:32] [V] [TRT] Tactic: 9961471 Time: 0.09728
[03/24/2023-12:57:32] [V] [TRT] Tactic: 10027007 Time: 0.095104
[03/24/2023-12:57:32] [V] [TRT] Tactic: 10485759 Time: 0.084608
[03/24/2023-12:57:32] [V] [TRT] Tactic: 10682367 Time: 0.08704
[03/24/2023-12:57:32] [V] [TRT] Fastest Tactic: 10485759 Time: 0.084608
[03/24/2023-12:57:32] [V] [TRT] --------------- Timing Runner: Conv_160 (CudnnConvolution)
[03/24/2023-12:57:32] [V] [TRT] Tactic: 0 Time: 0.144384
[03/24/2023-12:57:32] [V] [TRT] Tactic: 1 Time: 0.086272
[03/24/2023-12:57:32] [V] [TRT] Tactic: 2 Time: 0.210048
[03/24/2023-12:57:32] [V] [TRT] Tactic: 4 Time: 0.41216
[03/24/2023-12:57:32] [V] [TRT] Tactic: 5 Time: 0.582656
[03/24/2023-12:57:32] [V] [TRT] Tactic: 6 Time: 0.061312
[03/24/2023-12:57:32] [V] [TRT] Tactic: 56 Time: 0.144384
[03/24/2023-12:57:32] [V] [TRT] Tactic: 57 Time: 0.086528
[03/24/2023-12:57:32] [V] [TRT] Tactic: 58 Time: 0.21056
[03/24/2023-12:57:32] [V] [TRT] Tactic: 60 Time: 0.4096
[03/24/2023-12:57:32] [V] [TRT] Tactic: 61 Time: 0.422016
[03/24/2023-12:57:32] [V] [TRT] Tactic: 62 Time: 0.061312
[03/24/2023-12:57:32] [V] [TRT] Tactic: 112 Time: 0.14464
[03/24/2023-12:57:32] [V] [TRT] Tactic: 113 Time: 0.192512
[03/24/2023-12:57:32] [V] [TRT] Tactic: 114 Time: 0.210432
[03/24/2023-12:57:32] [V] [TRT] Tactic: 116 Time: 0.411008
[03/24/2023-12:57:32] [V] [TRT] Tactic: 117 Time: 0.42624
[03/24/2023-12:57:32] [V] [TRT] Tactic: 118 Time: 0.06144
[03/24/2023-12:57:32] [V] [TRT] Fastest Tactic: 62 Time: 0.061312
[03/24/2023-12:57:32] [V] [TRT] --------------- Timing Runner: Conv_160 (CaskConvolution)
[03/24/2023-12:57:32] [V] [TRT] Conv_160 Set Tactic Name: ampere_scudnn_128x64_relu_small_nn_v1 Tactic: 4549827808004681195
[03/24/2023-12:57:32] [V] [TRT] Tactic: 4549827808004681195 Time: 0.183296
[03/24/2023-12:57:32] [V] [TRT] Conv_160 Set Tactic Name: ampere_scudnn_128x128_relu_small_nn_v1 Tactic: 5779835512569528575
[03/24/2023-12:57:32] [V] [TRT] Tactic: 5779835512569528575 Time: 0.336
[03/24/2023-12:57:32] [V] [TRT] Conv_160 Set Tactic Name: ampere_scudnn_128x128_relu_xregs_large_nn_v1 Tactic: 6053873026024413720
[03/24/2023-12:57:32] [V] [TRT] Tactic: 6053873026024413720 Time: 0.354944
[03/24/2023-12:57:32] [V] [TRT] Conv_160 Set Tactic Name: ampere_scudnn_128x64_relu_xregs_large_nn_v1 Tactic: 6767548733843469815
[03/24/2023-12:57:32] [V] [TRT] Tactic: 6767548733843469815 Time: 0.18496
[03/24/2023-12:57:32] [V] [TRT] Conv_160 Set Tactic Name: ampere_scudnn_128x32_relu_small_nn_v1 Tactic: -6313876406580483184
[03/24/2023-12:57:32] [V] [TRT] Tactic: -6313876406580483184 Time: 0.137728
[03/24/2023-12:57:32] [V] [TRT] Conv_160 Set Tactic Name: ampere_scudnn_128x128_relu_medium_nn_v1 Tactic: -1123676555321336786
[03/24/2023-12:57:32] [V] [TRT] Tactic: -1123676555321336786 Time: 0.336128
[03/24/2023-12:57:32] [V] [TRT] Conv_160 Set Tactic Name: ampere_scudnn_128x64_relu_medium_nn_v1 Tactic: -701551393537224327
[03/24/2023-12:57:32] [V] [TRT] Tactic: -701551393537224327 Time: 0.187392
[03/24/2023-12:57:32] [V] [TRT] Fastest Tactic: -6313876406580483184 Time: 0.137728
[03/24/2023-12:57:32] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CudnnConvolution Tactic: 62
[03/24/2023-12:57:32] [V] [TRT] *************** Autotuning format combination: Float(8294400,1,46080,256) -> Float(97200,1,540,3) ***************
[03/24/2023-12:57:32] [V] [TRT] --------------- Timing Runner: Conv_160 (CudnnConvolution)
[03/24/2023-12:57:32] [V] [TRT] CudnnConvolution has no valid tactics for this config, skipping
[03/24/2023-12:57:32] [V] [TRT] --------------- Timing Runner: Conv_160 (CaskConvolution)
[03/24/2023-12:57:32] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[03/24/2023-12:57:32] [V] [TRT] *************** Autotuning format combination: Float(2073600,1:4,11520,64) -> Float(32400,1:4,180,1) ***************
[03/24/2023-12:57:32] [V] [TRT] --------------- Timing Runner: Conv_160 (CudnnConvolution)
[03/24/2023-12:57:32] [V] [TRT] CudnnConvolution has no valid tactics for this config, skipping
[03/24/2023-12:57:32] [V] [TRT] --------------- Timing Runner: Conv_160 (CaskConvolution)
[03/24/2023-12:57:32] [V] [TRT] Conv_160 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize64x128x32_stage5_warpsize2x2x1_g1_tensor16x8x8 Tactic: 1237784342446422381
[03/24/2023-12:57:32] [V] [TRT] Tactic: 1237784342446422381 Time: 0.080896
[03/24/2023-12:57:32] [V] [TRT] Conv_160 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x64x32_stage5_warpsize2x2x1_g1_tensor16x8x8 Tactic: 1426562292875733922
[03/24/2023-12:57:32] [V] [TRT] Tactic: 1426562292875733922 Time: 0.054272
[03/24/2023-12:57:32] [V] [TRT] Conv_160 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize64x128x8_stage3_warpsize1x4x1_g1_ffma_t1r3s3 Tactic: 2086609538387166260
[03/24/2023-12:57:32] [V] [TRT] Tactic: 2086609538387166260 Time: 0.280064
[03/24/2023-12:57:32] [V] [TRT] Conv_160 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize256x128x32_stage3_warpsize4x2x1_g1_tensor16x8x8_t1r3s3 Tactic: 2388153022056233219
[03/24/2023-12:57:32] [V] [TRT] Tactic: 2388153022056233219 Time: 0.08
[03/24/2023-12:57:32] [V] [TRT] Conv_160 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x128x32_stage4_warpsize2x2x1_g1_tensor16x8x8 Tactic: 2716437853123234317
[03/24/2023-12:57:32] [V] [TRT] Tactic: 2716437853123234317 Time: 0.071296
[03/24/2023-12:57:32] [V] [TRT] Conv_160 Set Tactic Name: ampere_scudnn_128x64_sliced1x2_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: 2860655430572478466
[03/24/2023-12:57:32] [V] [TRT] Tactic: 2860655430572478466 Time: 0.177024
[03/24/2023-12:57:32] [V] [TRT] Conv_160 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize64x128x8_stage3_warpsize1x4x1_g1_ffma Tactic: 3239733199291090177
[03/24/2023-12:57:32] [V] [TRT] Tactic: 3239733199291090177 Time: 0.279808
[03/24/2023-12:57:32] [V] [TRT] Conv_160 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize64x64x64_stage4_warpsize2x2x1_g1_tensor16x8x8_t1r3s3 Tactic: 3278852197192504305
[03/24/2023-12:57:32] [V] [TRT] Tactic: 3278852197192504305 Time: 0.053376
[03/24/2023-12:57:32] [V] [TRT] Conv_160 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize256x128x32_stage3_warpsize4x2x1_g1_tensor16x8x8 Tactic: 3904690393614050557
[03/24/2023-12:57:32] [V] [TRT] Tactic: 3904690393614050557 Time: 0.098176
[03/24/2023-12:57:32] [V] [TRT] Conv_160 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize64x64x64_stage4_warpsize2x2x1_g1_tensor16x8x8 Tactic: 4061115162338989075
[03/24/2023-12:57:32] [V] [TRT] Tactic: 4061115162338989075 Time: 0.058368
[03/24/2023-12:57:32] [V] [TRT] Conv_160 Set Tactic Name: ampere_scudnn_128x32_sliced1x4_ldg4_relu_exp_medium_nhwc_tn_v1 Tactic: 4474630279712975759
[03/24/2023-12:57:32] [V] [TRT] Tactic: 4474630279712975759 Time: 0.096256
[03/24/2023-12:57:32] [V] [TRT] Conv_160 Set Tactic Name: ampere_scudnn_128x32_sliced1x4_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: 4479823862704990365
[03/24/2023-12:57:32] [V] [TRT] Tactic: 4479823862704990365 Time: 0.095872
[03/24/2023-12:57:32] [V] [TRT] Conv_160 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize64x256x8_stage3_warpsize1x4x1_g1_ffma Tactic: 4517590677127196184
[03/24/2023-12:57:32] [V] [TRT] Tactic: 4517590677127196184 Time: 0.663296
[03/24/2023-12:57:32] [V] [TRT] Conv_160 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize128x128x8_stage3_warpsize2x4x1_g1_ffma_t1r3s3 Tactic: 4634080872644479428
[03/24/2023-12:57:32] [V] [TRT] Tactic: 4634080872644479428 Time: 0.338048
[03/24/2023-12:57:32] [V] [TRT] Conv_160 Set Tactic Name: ampere_scudnn_128x64_sliced1x2_ldg4_relu_exp_medium_nhwc_tn_v1 Tactic: 4696204239951173149
[03/24/2023-12:57:32] [V] [TRT] Tactic: 4696204239951173149 Time: 0.177152
[03/24/2023-12:57:32] [V] [TRT] Conv_160 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x256x32_stage3_warpsize2x4x1_g1_tensor16x8x8 Tactic: 5200329514761435342
[03/24/2023-12:57:32] [V] [TRT] Tactic: 5200329514761435342 Time: 0.110592
[03/24/2023-12:57:32] [V] [TRT] Conv_160 Set Tactic Name: ampere_scudnn_128x128_relu_exp_small_nhwc_tn_v1 Tactic: 5778138195697110003
[03/24/2023-12:57:32] [V] [TRT] Tactic: 5778138195697110003 Time: 0.332672
[03/24/2023-12:57:32] [V] [TRT] Conv_160 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize256x128x8_stage3_warpsize2x4x1_g1_ffma Tactic: 6310198979346901507
[03/24/2023-12:57:32] [V] [TRT] Tactic: 6310198979346901507 Time: 0.463744
[03/24/2023-12:57:32] [V] [TRT] Conv_160 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x256x32_stage3_warpsize2x4x1_g1_tensor16x8x8_t1r3s3 Tactic: 7011693366046809027
[03/24/2023-12:57:32] [V] [TRT] Tactic: 7011693366046809027 Time: 0.108928
[03/24/2023-12:57:32] [V] [TRT] Conv_160 Set Tactic Name: ampere_scudnn_128x128_ldg4_relu_exp_large_nhwc_tn_v1 Tactic: 7155825427510256858
[03/24/2023-12:57:32] [V] [TRT] Tactic: 7155825427510256858 Time: 0.33472
[03/24/2023-12:57:32] [V] [TRT] Conv_160 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize128x64x8_stage3_warpsize1x4x1_g1_ffma Tactic: 7222247112373541608
[03/24/2023-12:57:32] [V] [TRT] Tactic: 7222247112373541608 Time: 0.237312
[03/24/2023-12:57:32] [V] [TRT] Conv_160 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x128x16_stage4_warpsize2x2x1_g1_tensor16x8x8 Tactic: 7342025736444949634
[03/24/2023-12:57:32] [V] [TRT] Tactic: 7342025736444949634 Time: 0.07424
[03/24/2023-12:57:32] [V] [TRT] Conv_160 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize64x128x32_stage5_warpsize2x2x1_g1_tensor16x8x8 Tactic: 7347365539922924600
[03/24/2023-12:57:32] [V] [TRT] Tactic: 7347365539922924600 Time: 0.07872
[03/24/2023-12:57:32] [V] [TRT] Conv_160 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x64x32_stage5_warpsize2x2x1_g1_tensor16x8x8 Tactic: 7428197830878119671
[03/24/2023-12:57:32] [V] [TRT] Tactic: 7428197830878119671 Time: 0.051072
[03/24/2023-12:57:32] [V] [TRT] Conv_160 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize64x32x64_stage5_warpsize2x2x1_g1_tensor16x8x8_t1r3s3 Tactic: 7465323447915168822
[03/24/2023-12:57:32] [V] [TRT] Tactic: 7465323447915168822 Time: 0.043904
[03/24/2023-12:57:32] [V] [TRT] Conv_160 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize128x128x8_stage3_warpsize2x4x1_g1_ffma Tactic: 7472640475524677095
[03/24/2023-12:57:32] [V] [TRT] Tactic: 7472640475524677095 Time: 0.344576
[03/24/2023-12:57:32] [V] [TRT] Conv_160 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize64x32x64_stage5_warpsize2x2x1_g1_tensor16x8x8 Tactic: 7938223790021272801
[03/24/2023-12:57:32] [V] [TRT] Tactic: 7938223790021272801 Time: 0.047104
[03/24/2023-12:57:32] [V] [TRT] Conv_160 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize128x256x8_stage3_warpsize2x4x1_g1_ffma Tactic: 8498373915030836990
[03/24/2023-12:57:32] [V] [TRT] Tactic: 8498373915030836990 Time: 0.672768
[03/24/2023-12:57:32] [V] [TRT] Conv_160 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x64x32_stage5_warpsize2x2x1_g1_tensor16x8x8_t1r3s3 Tactic: 8836645772682419994
[03/24/2023-12:57:32] [V] [TRT] Tactic: 8836645772682419994 Time: 0.049024
[03/24/2023-12:57:32] [V] [TRT] Conv_160 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize256x64x8_stage3_warpsize1x4x1_g1_ffma Tactic: 8869697132622550639
[03/24/2023-12:57:32] [V] [TRT] Tactic: 8869697132622550639 Time: 0.263296
[03/24/2023-12:57:32] [V] [TRT] Conv_160 Set Tactic Name: ampere_scudnn_128x128_ldg4_relu_exp_medium_nhwc_tn_v1 Tactic: 8918020581761223752
[03/24/2023-12:57:32] [V] [TRT] Tactic: 8918020581761223752 Time: 0.33152
[03/24/2023-12:57:32] [V] [TRT] Conv_160 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize64x64x64_stage4_warpsize2x2x1_g1_tensor16x8x8 Tactic: -9114138070928278731
[03/24/2023-12:57:32] [V] [TRT] Tactic: -9114138070928278731 Time: 0.058112
[03/24/2023-12:57:32] [V] [TRT] Conv_160 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize256x128x8_stage3_warpsize2x4x1_g1_ffma_t1r3s3 Tactic: -8937725997228636978
[03/24/2023-12:57:32] [V] [TRT] Tactic: -8937725997228636978 Time: 0.447488
[03/24/2023-12:57:32] [V] [TRT] Conv_160 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize128x256x8_stage3_warpsize2x4x1_g1_ffma_t1r3s3 Tactic: -8833858409138163072
[03/24/2023-12:57:32] [V] [TRT] Tactic: -8833858409138163072 Time: 0.659968
[03/24/2023-12:57:32] [V] [TRT] Conv_160 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize64x64x8_stage3_warpsize1x4x1_g1_ffma_t1r3s3 Tactic: -7989138351613022500
[03/24/2023-12:57:32] [V] [TRT] Tactic: -7989138351613022500 Time: 0.147456
[03/24/2023-12:57:32] [V] [TRT] Conv_160 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize256x128x8_stage3_warpsize2x4x1_g1_ffma Tactic: -7872883691240863058
[03/24/2023-12:57:32] [V] [TRT] Tactic: -7872883691240863058 Time: 0.463872
[03/24/2023-12:57:32] [V] [TRT] Conv_160 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x256x32_stage3_warpsize2x4x1_g1_tensor16x8x8 Tactic: -7382359095196034537
[03/24/2023-12:57:32] [V] [TRT] Tactic: -7382359095196034537 Time: 0.11264
[03/24/2023-12:57:32] [V] [TRT] Conv_160 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x128x16_stage4_warpsize2x2x1_g1_tensor16x8x8_t1r3s3 Tactic: -7377458734869418330
[03/24/2023-12:57:32] [V] [TRT] Tactic: -7377458734869418330 Time: 0.067328
[03/24/2023-12:57:32] [V] [TRT] Conv_160 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize128x128x8_stage3_warpsize2x4x1_g1_ffma Tactic: -6729618519651721910
[03/24/2023-12:57:32] [V] [TRT] Tactic: -6729618519651721910 Time: 0.34112
[03/24/2023-12:57:32] [V] [TRT] Conv_160 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize256x64x32_stage3_warpsize4x2x1_g1_tensor16x8x8_t1r3s3 Tactic: -6223854811627385844
[03/24/2023-12:57:32] [V] [TRT] Tactic: -6223854811627385844 Time: 0.050304
[03/24/2023-12:57:32] [V] [TRT] Conv_160 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize256x64x8_stage3_warpsize1x4x1_g1_ffma Tactic: -5893833996418445881
[03/24/2023-12:57:32] [V] [TRT] Tactic: -5893833996418445881 Time: 0.256512
[03/24/2023-12:57:32] [V] [TRT] Conv_160 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize128x256x8_stage3_warpsize2x4x1_g1_ffma Tactic: -5701562095007058349
[03/24/2023-12:57:32] [V] [TRT] Tactic: -5701562095007058349 Time: 0.66432
[03/24/2023-12:57:32] [V] [TRT] Conv_160 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize128x64x8_stage3_warpsize1x4x1_g1_ffma Tactic: -5685503422376017600
[03/24/2023-12:57:33] [V] [TRT] Tactic: -5685503422376017600 Time: 0.2304
[03/24/2023-12:57:33] [V] [TRT] Conv_160 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize64x64x8_stage3_warpsize1x4x1_g1_ffma Tactic: -5521125187060117489
[03/24/2023-12:57:33] [V] [TRT] Tactic: -5521125187060117489 Time: 0.160384
[03/24/2023-12:57:33] [V] [TRT] Conv_160 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x128x16_stage4_warpsize2x2x1_g1_tensor16x8x8 Tactic: -5457304872213719461
[03/24/2023-12:57:33] [V] [TRT] Tactic: -5457304872213719461 Time: 0.069376
[03/24/2023-12:57:33] [V] [TRT] Conv_160 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x64x64_stage3_warpsize2x2x1_g1_tensor16x8x8 Tactic: -5441054706931585554
[03/24/2023-12:57:33] [V] [TRT] Tactic: -5441054706931585554 Time: 0.052224
[03/24/2023-12:57:33] [V] [TRT] Conv_160 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize256x64x32_stage3_warpsize4x2x1_g1_tensor16x8x8 Tactic: -5043603702497465467
[03/24/2023-12:57:33] [V] [TRT] Tactic: -5043603702497465467 Time: 0.058752
[03/24/2023-12:57:33] [V] [TRT] Conv_160 Set Tactic Name: ampere_scudnn_128x64_sliced1x2_ldg4_relu_exp_large_nhwc_tn_v1 Tactic: -4756382386362004279
[03/24/2023-12:57:33] [V] [TRT] Tactic: -4756382386362004279 Time: 0.174848
[03/24/2023-12:57:33] [V] [TRT] Conv_160 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize64x64x8_stage3_warpsize1x4x1_g1_ffma Tactic: -4615000974950361663
[03/24/2023-12:57:33] [V] [TRT] Tactic: -4615000974950361663 Time: 0.153472
[03/24/2023-12:57:33] [V] [TRT] Conv_160 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x64x64_stage3_warpsize2x2x1_g1_tensor16x8x8 Tactic: -4564655677311401797
[03/24/2023-12:57:33] [V] [TRT] Tactic: -4564655677311401797 Time: 0.052992
[03/24/2023-12:57:33] [V] [TRT] Conv_160 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize256x64x8_stage3_warpsize1x4x1_g1_ffma_t1r3s3 Tactic: -4314913710375142296
[03/24/2023-12:57:33] [V] [TRT] Tactic: -4314913710375142296 Time: 0.246784
[03/24/2023-12:57:33] [V] [TRT] Conv_160 Set Tactic Name: ampere_scudnn_128x128_relu_exp_large_nhwc_tn_v1 Tactic: -3855385237722507464
[03/24/2023-12:57:33] [V] [TRT] Tactic: -3855385237722507464 Time: 0.334592
[03/24/2023-12:57:33] [V] [TRT] Conv_160 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize128x64x8_stage3_warpsize1x4x1_g1_ffma_t1r3s3 Tactic: -3697587361057948972
[03/24/2023-12:57:33] [V] [TRT] Tactic: -3697587361057948972 Time: 0.230912
[03/24/2023-12:57:33] [V] [TRT] Conv_160 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize256x64x32_stage3_warpsize4x2x1_g1_tensor16x8x8 Tactic: -3540975627865078064
[03/24/2023-12:57:33] [V] [TRT] Tactic: -3540975627865078064 Time: 0.053376
[03/24/2023-12:57:33] [V] [TRT] Conv_160 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize64x128x32_stage5_warpsize2x2x1_g1_tensor16x8x8_t1r3s3 Tactic: -3151804561246216835
[03/24/2023-12:57:33] [V] [TRT] Tactic: -3151804561246216835 Time: 0.074752
[03/24/2023-12:57:33] [V] [TRT] Conv_160 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize64x32x64_stage5_warpsize2x2x1_g1_tensor16x8x8 Tactic: -2885165284206163001
[03/24/2023-12:57:33] [V] [TRT] Tactic: -2885165284206163001 Time: 0.048128
[03/24/2023-12:57:33] [V] [TRT] Conv_160 Set Tactic Name: ampere_scudnn_128x128_relu_exp_medium_nhwc_tn_v1 Tactic: -2809379259463049391
[03/24/2023-12:57:33] [V] [TRT] Tactic: -2809379259463049391 Time: 0.33408
[03/24/2023-12:57:33] [V] [TRT] Conv_160 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x128x32_stage4_warpsize2x2x1_g1_tensor16x8x8_t1r3s3 Tactic: -2801041895330778813
[03/24/2023-12:57:33] [V] [TRT] Tactic: -2801041895330778813 Time: 0.074752
[03/24/2023-12:57:33] [V] [TRT] Conv_160 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize64x256x8_stage3_warpsize1x4x1_g1_ffma_t1r3s3 Tactic: -2747929399988666512
[03/24/2023-12:57:33] [V] [TRT] Tactic: -2747929399988666512 Time: 0.658304
[03/24/2023-12:57:33] [V] [TRT] Conv_160 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize256x128x32_stage3_warpsize4x2x1_g1_tensor16x8x8 Tactic: -1758690179295738332
[03/24/2023-12:57:33] [V] [TRT] Tactic: -1758690179295738332 Time: 0.084224
[03/24/2023-12:57:33] [V] [TRT] Conv_160 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x64x64_stage3_warpsize2x2x1_g1_tensor16x8x8_t1r3s3 Tactic: -1484546572846226796
[03/24/2023-12:57:33] [V] [TRT] Tactic: -1484546572846226796 Time: 0.050048
[03/24/2023-12:57:33] [V] [TRT] Conv_160 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize64x256x8_stage3_warpsize1x4x1_g1_ffma Tactic: -1472061967969061456
[03/24/2023-12:57:33] [V] [TRT] Tactic: -1472061967969061456 Time: 0.674688
[03/24/2023-12:57:33] [V] [TRT] Conv_160 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x128x32_stage4_warpsize2x2x1_g1_tensor16x8x8 Tactic: -858667497925695276
[03/24/2023-12:57:33] [V] [TRT] Tactic: -858667497925695276 Time: 0.105472
[03/24/2023-12:57:33] [V] [TRT] Conv_160 Set Tactic Name: ampere_scudnn_128x128_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: -504296718212024303
[03/24/2023-12:57:33] [V] [TRT] Tactic: -504296718212024303 Time: 0.331264
[03/24/2023-12:57:33] [V] [TRT] Conv_160 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize64x128x8_stage3_warpsize1x4x1_g1_ffma Tactic: -444093195553988951
[03/24/2023-12:57:33] [V] [TRT] Tactic: -444093195553988951 Time: 0.294016
[03/24/2023-12:57:33] [V] [TRT] Fastest Tactic: 7465323447915168822 Time: 0.043904
[03/24/2023-12:57:33] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: 7465323447915168822
[03/24/2023-12:57:33] [V] [TRT] *************** Autotuning format combination: Half(8294400,32400,180,1) -> Half(97200,32400,180,1) ***************
[03/24/2023-12:57:33] [V] [TRT] --------------- Timing Runner: Conv_160 (CudnnConvolution)
[03/24/2023-12:57:33] [V] [TRT] Tactic: 0 Time: 0.361344
[03/24/2023-12:57:33] [V] [TRT] Tactic: 1 Time: 0.196224
[03/24/2023-12:57:33] [V] [TRT] Tactic: 2 Time: 0.43136
[03/24/2023-12:57:33] [V] [TRT] Tactic: 4 Time: 0.41792
[03/24/2023-12:57:33] [V] [TRT] Tactic: 5 Time: 0.410496
[03/24/2023-12:57:33] [V] [TRT] Tactic: 6 Time: 0.39232
[03/24/2023-12:57:33] [V] [TRT] Tactic: 56 Time: 0.361344
[03/24/2023-12:57:33] [V] [TRT] Tactic: 58 Time: 0.431488
[03/24/2023-12:57:33] [V] [TRT] Tactic: 60 Time: 0.419968
[03/24/2023-12:57:33] [V] [TRT] Tactic: 61 Time: 0.412032
[03/24/2023-12:57:33] [V] [TRT] Tactic: 62 Time: 0.39488
[03/24/2023-12:57:33] [V] [TRT] Fastest Tactic: 1 Time: 0.196224
[03/24/2023-12:57:33] [V] [TRT] --------------- Timing Runner: Conv_160 (CaskConvolution)
[03/24/2023-12:57:33] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[03/24/2023-12:57:33] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CudnnConvolution Tactic: 1
[03/24/2023-12:57:33] [V] [TRT] *************** Autotuning format combination: Half(4147200,32400:2,180,1) -> Half(64800,32400:2,180,1) ***************
[03/24/2023-12:57:33] [V] [TRT] --------------- Timing Runner: Conv_160 (FusedConvActConvolution)
[03/24/2023-12:57:33] [V] [TRT] Tactic: 524287 Time: 0.04992
[03/24/2023-12:57:33] [V] [TRT] Tactic: 1048575 Time: 0.04608
[03/24/2023-12:57:33] [V] [TRT] Tactic: 1703935 Time: 0.045056
[03/24/2023-12:57:33] [V] [TRT] Tactic: 2228223 Time: 0.062336
[03/24/2023-12:57:33] [V] [TRT] Tactic: 2424831 Time: 0.064128
[03/24/2023-12:57:33] [V] [TRT] Tactic: 2621439 Time: 0.046848
[03/24/2023-12:57:33] [V] [TRT] Tactic: 3014655 Time: 0.047104
[03/24/2023-12:57:33] [V] [TRT] Tactic: 3604479 Time: 0.047104
[03/24/2023-12:57:33] [V] [TRT] Tactic: 5046271 Time: 0.047488
[03/24/2023-12:57:33] [V] [TRT] Tactic: 6160383 Time: 0.050048
[03/24/2023-12:57:33] [V] [TRT] Tactic: 6488063 Time: 0.05504
[03/24/2023-12:57:33] [V] [TRT] Tactic: 7864319 Time: 0.050944
[03/24/2023-12:57:33] [V] [TRT] Tactic: 8585215 Time: 0.058496
[03/24/2023-12:57:33] [V] [TRT] Tactic: 8847359 Time: 0.051072
[03/24/2023-12:57:33] [V] [TRT] Tactic: 9043967 Time: 0.047616
[03/24/2023-12:57:33] [V] [TRT] Tactic: 9175039 Time: 0.046976
[03/24/2023-12:57:33] [V] [TRT] Tactic: 9961471 Time: 0.061184
[03/24/2023-12:57:33] [V] [TRT] Tactic: 10027007 Time: 0.047616
[03/24/2023-12:57:33] [V] [TRT] Tactic: 10485759 Time: 0.044416
[03/24/2023-12:57:33] [V] [TRT] Tactic: 10682367 Time: 0.049024
[03/24/2023-12:57:33] [V] [TRT] Fastest Tactic: 10485759 Time: 0.044416
[03/24/2023-12:57:33] [V] [TRT] --------------- Timing Runner: Conv_160 (CudnnConvolution)
[03/24/2023-12:57:33] [V] [TRT] CudnnConvolution has no valid tactics for this config, skipping
[03/24/2023-12:57:33] [V] [TRT] --------------- Timing Runner: Conv_160 (CaskConvolution)
[03/24/2023-12:57:33] [V] [TRT] Conv_160 Set Tactic Name: ampere_fp16x2_hcudnn_fp16x2_128x32_relu_medium_nn_v1 Tactic: 2195670545862694453
[03/24/2023-12:57:33] [V] [TRT] Tactic: 2195670545862694453 Time: 0.073728
[03/24/2023-12:57:33] [V] [TRT] Conv_160 Set Tactic Name: ampere_fp16x2_hcudnn_fp16x2_128x64_relu_large_nn_v1 Tactic: 3419182076704469245
[03/24/2023-12:57:33] [V] [TRT] Tactic: 3419182076704469245 Time: 0.101504
[03/24/2023-12:57:33] [V] [TRT] Conv_160 Set Tactic Name: ampere_fp16x2_hcudnn_fp16x2_128x128_relu_medium_nn_v1 Tactic: 3891805945559659536
[03/24/2023-12:57:33] [V] [TRT] Tactic: 3891805945559659536 Time: 0.1824
[03/24/2023-12:57:33] [V] [TRT] Conv_160 Set Tactic Name: ampere_fp16x2_hcudnn_fp16x2_128x64_relu_medium_nn_v1 Tactic: 5548126322150286555
[03/24/2023-12:57:33] [V] [TRT] Tactic: 5548126322150286555 Time: 0.100736
[03/24/2023-12:57:33] [V] [TRT] Conv_160 Set Tactic Name: ampere_fp16x2_hcudnn_fp16x2_128x64_relu_small_nn_v1 Tactic: 6057304366605292508
[03/24/2023-12:57:33] [V] [TRT] Tactic: 6057304366605292508 Time: 0.098176
[03/24/2023-12:57:33] [V] [TRT] Conv_160 Set Tactic Name: ampere_fp16x2_hcudnn_fp16x2_128x128_relu_large_nn_v1 Tactic: -7928611605886347652
[03/24/2023-12:57:33] [V] [TRT] Tactic: -7928611605886347652 Time: 0.188416
[03/24/2023-12:57:33] [V] [TRT] Conv_160 Set Tactic Name: ampere_fp16x2_hcudnn_fp16x2_128x32_relu_large_nn_v1 Tactic: -5172391392092686714
[03/24/2023-12:57:33] [V] [TRT] Tactic: -5172391392092686714 Time: 0.073984
[03/24/2023-12:57:33] [V] [TRT] Conv_160 Set Tactic Name: ampere_fp16x2_hcudnn_fp16x2_128x32_relu_small_nn_v1 Tactic: -4374269919094467161
[03/24/2023-12:57:33] [V] [TRT] Tactic: -4374269919094467161 Time: 0.071552
[03/24/2023-12:57:33] [V] [TRT] Conv_160 Set Tactic Name: ampere_fp16x2_hcudnn_winograd_fp16x2_128x128_ldg1_ldg4_relu_tile148t_nt_v1 Tactic: -4083394051665370953
[03/24/2023-12:57:33] [V] [TRT] Tactic: -4083394051665370953 Time: 0.032256
[03/24/2023-12:57:33] [V] [TRT] Conv_160 Set Tactic Name: ampere_fp16x2_hcudnn_fp16x2_128x128_relu_small_nn_v1 Tactic: -1546027692247304867
[03/24/2023-12:57:33] [V] [TRT] Tactic: -1546027692247304867 Time: 0.183296
[03/24/2023-12:57:33] [V] [TRT] Fastest Tactic: -4083394051665370953 Time: 0.032256
[03/24/2023-12:57:33] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: -4083394051665370953
[03/24/2023-12:57:33] [V] [TRT] *************** Autotuning format combination: Half(1036800,1:8,5760,32) -> Float(97200,32400,180,1) ***************
[03/24/2023-12:57:33] [V] [TRT] --------------- Timing Runner: Conv_160 (CudnnConvolution)
[03/24/2023-12:57:33] [V] [TRT] CudnnConvolution has no valid tactics for this config, skipping
[03/24/2023-12:57:33] [V] [TRT] --------------- Timing Runner: Conv_160 (CaskConvolution)
[03/24/2023-12:57:33] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[03/24/2023-12:57:33] [V] [TRT] *************** Autotuning format combination: Half(1036800,1:8,5760,32) -> Half(32400,1:8,180,1) ***************
[03/24/2023-12:57:33] [V] [TRT] --------------- Timing Runner: Conv_160 (CudaDepthwiseConvolution)
[03/24/2023-12:57:33] [V] [TRT] CudaDepthwiseConvolution has no valid tactics for this config, skipping
[03/24/2023-12:57:33] [V] [TRT] --------------- Timing Runner: Conv_160 (CudnnConvolution)
[03/24/2023-12:57:33] [V] [TRT] CudnnConvolution has no valid tactics for this config, skipping
[03/24/2023-12:57:33] [V] [TRT] --------------- Timing Runner: Conv_160 (CaskConvolution)
[03/24/2023-12:57:33] [V] [TRT] Conv_160 Set Tactic Name: ampere_h16816cudnn_256x128_ldg8_relu_exp_medium_nhwc_tn_v1 Tactic: 254850674756030979
[03/24/2023-12:57:33] [V] [TRT] Tactic: 254850674756030979 Time: 0.045056
[03/24/2023-12:57:33] [V] [TRT] Conv_160 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x128x32_stage3_warpsize4x2x1_g1_tensor16x8x16_t1r3s3 Tactic: 328038211831149625
[03/24/2023-12:57:33] [V] [TRT] Tactic: 328038211831149625 Time: 0.044032
[03/24/2023-12:57:33] [V] [TRT] Conv_160 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x64x64_stage3_warpsize2x2x1_g1_tensor16x8x16_t1r3s3 Tactic: 411553864378931917
[03/24/2023-12:57:33] [V] [TRT] Tactic: 411553864378931917 Time: 0.024704
[03/24/2023-12:57:33] [V] [TRT] Conv_160 Set Tactic Name: sm75_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x128x32_stage1_warpsize4x2x1_g1_tensor16x8x8_t1r3s3 Tactic: 864841579020773074
[03/24/2023-12:57:33] [V] [TRT] Tactic: 864841579020773074 Time: 0.050048
[03/24/2023-12:57:33] [V] [TRT] Conv_160 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x128x32_stage4_warpsize2x2x1_g1_tensor16x8x16 Tactic: 1011057357468998345
[03/24/2023-12:57:33] [V] [TRT] Tactic: 1011057357468998345 Time: 0.037376
[03/24/2023-12:57:33] [V] [TRT] Conv_160 Set Tactic Name: sm75_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x64x32_stage1_warpsize4x1x1_g1_tensor16x8x8 Tactic: 1013168150133367738
[03/24/2023-12:57:33] [V] [TRT] Tactic: 1013168150133367738 Time: 0.033664
[03/24/2023-12:57:33] [V] [TRT] Conv_160 Set Tactic Name: ampere_h16816cudnn_256x128_ldg8_relu_exp_stages_64x3_small_nhwc_tn_v1 Tactic: 1016009564074305832
[03/24/2023-12:57:33] [V] [TRT] Tactic: 1016009564074305832 Time: 0.045312
[03/24/2023-12:57:33] [V] [TRT] Conv_160 Set Tactic Name: sm75_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x128x32_stage1_warpsize2x2x1_g1_tensor16x8x8 Tactic: 1067227531433278814
[03/24/2023-12:57:33] [V] [TRT] Tactic: 1067227531433278814 Time: 0.04096
[03/24/2023-12:57:33] [V] [TRT] Conv_160 Set Tactic Name: ampere_h1688cudnn_128x128_ldg8_relu_exp_medium_nhwc_tn_v1 Tactic: 1156328698016730421
[03/24/2023-12:57:33] [V] [TRT] Tactic: 1156328698016730421 Time: 0.04992
[03/24/2023-12:57:33] [V] [TRT] Conv_160 Set Tactic Name: sm75_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x128x32_stage1_warpsize2x2x1_g1_tensor16x8x8 Tactic: 1579845938601132607
[03/24/2023-12:57:33] [V] [TRT] Tactic: 1579845938601132607 Time: 0.04096
[03/24/2023-12:57:33] [V] [TRT] Conv_160 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x128x32_stage5_warpsize2x2x1_g1_tensor16x8x16_t1r3s3 Tactic: 1723736032573714698
[03/24/2023-12:57:33] [V] [TRT] Tactic: 1723736032573714698 Time: 0.035712
[03/24/2023-12:57:33] [V] [TRT] Conv_160 Set Tactic Name: sm75_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x32x32_stage1_warpsize4x1x1_g1_tensor16x8x8 Tactic: 1796821236841789338
[03/24/2023-12:57:33] [V] [TRT] Tactic: 1796821236841789338 Time: 0.025472
[03/24/2023-12:57:33] [V] [TRT] Conv_160 Set Tactic Name: ampere_h16816cudnn_128x64_ldg8_relu_exp_stages_64x4_medium_nhwc_tn_v1 Tactic: 1832046141070096030
[03/24/2023-12:57:33] [V] [TRT] Tactic: 1832046141070096030 Time: 0.030592
[03/24/2023-12:57:33] [V] [TRT] Conv_160 Set Tactic Name: ampere_h16816cudnn_128x64_sliced1x2_ldg8_relu_exp_stages_64x3_small_nhwc_tn_v1 Tactic: 1838082074606840426
[03/24/2023-12:57:33] [V] [TRT] Tactic: 1838082074606840426 Time: 0.026112
[03/24/2023-12:57:33] [V] [TRT] Conv_160 Set Tactic Name: ampere_h16816cudnn_64x64_sliced1x2_ldg8_relu_exp_stages_64x5_small_nhwc_tn_v1 Tactic: 1899296423087490472
[03/24/2023-12:57:33] [V] [TRT] Tactic: 1899296423087490472 Time: 0.031744
[03/24/2023-12:57:33] [V] [TRT] Conv_160 Set Tactic Name: sm75_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x32x32_stage1_warpsize4x1x1_g1_tensor16x8x8 Tactic: 1948263663414159978
[03/24/2023-12:57:33] [V] [TRT] Tactic: 1948263663414159978 Time: 0.028416
[03/24/2023-12:57:33] [V] [TRT] Conv_160 Set Tactic Name: sm75_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x256x64_stage1_warpsize1x4x2_g1_tensor16x8x8 Tactic: 2027733232253711640
[03/24/2023-12:57:33] [V] [TRT] Tactic: 2027733232253711640 Time: 0.070528
[03/24/2023-12:57:33] [V] [TRT] Conv_160 Set Tactic Name: sm75_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x64x32_stage1_warpsize2x2x1_g1_tensor16x8x8_t1r3s3 Tactic: 2154731107061273008
[03/24/2023-12:57:33] [V] [TRT] Tactic: 2154731107061273008 Time: 0.029568
[03/24/2023-12:57:33] [V] [TRT] Conv_160 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x64x64_stage3_warpsize2x2x1_g1_tensor16x8x16 Tactic: 2428167804343994714
[03/24/2023-12:57:33] [V] [TRT] Tactic: 2428167804343994714 Time: 0.025856
[03/24/2023-12:57:33] [V] [TRT] Conv_160 Set Tactic Name: ampere_h16816cudnn_128x128_ldg8_relu_exp_medium_nhwc_tn_v1 Tactic: 2541579301352125276
[03/24/2023-12:57:33] [V] [TRT] Tactic: 2541579301352125276 Time: 0.034944
[03/24/2023-12:57:33] [V] [TRT] Conv_160 Set Tactic Name: ampere_h16816cudnn_64x64_sliced1x2_ldg8_relu_exp_stages_64x6_small_nhwc_tn_v1 Tactic: 2657157263811141609
[03/24/2023-12:57:33] [V] [TRT] Tactic: 2657157263811141609 Time: 0.036736
[03/24/2023-12:57:33] [V] [TRT] Conv_160 Set Tactic Name: ampere_h16816cudnn_64x128_sliced1x2_ldg8_relu_exp_stages_64x4_large_nhwc_tn_v1 Tactic: 2819719497590964443
[03/24/2023-12:57:33] [V] [TRT] Tactic: 2819719497590964443 Time: 0.049024
[03/24/2023-12:57:33] [V] [TRT] Conv_160 Set Tactic Name: ampere_h16816cudnn_128x64_sliced1x2_ldg8_relu_exp_stages_64x3_medium_nhwc_tn_v1 Tactic: 2968605903460894194
[03/24/2023-12:57:33] [V] [TRT] Tactic: 2968605903460894194 Time: 0.026368
[03/24/2023-12:57:33] [V] [TRT] Conv_160 Set Tactic Name: ampere_h16816cudnn_128x128_ldg8_relu_exp_large_nhwc_tn_v1 Tactic: 2986078304285316765
[03/24/2023-12:57:33] [V] [TRT] Tactic: 2986078304285316765 Time: 0.035456
[03/24/2023-12:57:33] [V] [TRT] Conv_160 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x256x64_stage3_warpsize1x4x1_g1_tensor16x8x16 Tactic: 3016308193087082166
[03/24/2023-12:57:33] [V] [TRT] Tactic: 3016308193087082166 Time: 0.065408
[03/24/2023-12:57:33] [V] [TRT] Conv_160 Set Tactic Name: ampere_h16816cudnn_256x64_ldg8_relu_exp_stages_64x3_large_nhwc_tn_v1 Tactic: 3221382575080507859
[03/24/2023-12:57:33] [V] [TRT] Tactic: 3221382575080507859 Time: 0.03072
[03/24/2023-12:57:33] [V] [TRT] Conv_160 Set Tactic Name: ampere_h16816cudnn_128x128_ldg8_relu_exp_stages_64x3_medium_nhwc_tn_v1 Tactic: 3362537467505018070
[03/24/2023-12:57:33] [V] [TRT] Tactic: 3362537467505018070 Time: 0.040832
[03/24/2023-12:57:33] [V] [TRT] Conv_160 Set Tactic Name: sm75_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x64x32_stage1_warpsize4x1x1_g1_tensor16x8x8_t1r3s3 Tactic: 3464689803495983377
[03/24/2023-12:57:33] [V] [TRT] Tactic: 3464689803495983377 Time: 0.03264
[03/24/2023-12:57:33] [V] [TRT] Conv_160 Set Tactic Name: ampere_h1688cudnn_256x128_ldg8_relu_exp_medium_nhwc_tn_v1 Tactic: 3513075359009385578
[03/24/2023-12:57:33] [V] [TRT] Tactic: 3513075359009385578 Time: 0.053248
[03/24/2023-12:57:33] [V] [TRT] Conv_160 Set Tactic Name: ampere_h16816cudnn_128x64_ldg8_relu_exp_stages_64x4_large_nhwc_tn_v1 Tactic: 3573559043797674382
[03/24/2023-12:57:33] [V] [TRT] Tactic: 3573559043797674382 Time: 0.031744
[03/24/2023-12:57:33] [V] [TRT] Conv_160 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x64x64_stage4_warpsize2x2x1_g1_tensor16x8x16_t1r3s3 Tactic: 3591970081995419777
[03/24/2023-12:57:33] [V] [TRT] Tactic: 3591970081995419777 Time: 0.028672
[03/24/2023-12:57:33] [V] [TRT] Conv_160 Set Tactic Name: sm75_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x128x32_stage1_warpsize2x2x1_g1_tensor16x8x8_t1r3s3 Tactic: 3636831327753843771
[03/24/2023-12:57:33] [V] [TRT] Tactic: 3636831327753843771 Time: 0.037888
[03/24/2023-12:57:33] [V] [TRT] Conv_160 Set Tactic Name: ampere_h1688cudnn_128x128_ldg8_relu_exp_small_nhwc_tn_v1 Tactic: 3704534001553878387
[03/24/2023-12:57:33] [V] [TRT] Tactic: 3704534001553878387 Time: 0.04608
[03/24/2023-12:57:33] [V] [TRT] Conv_160 Set Tactic Name: ampere_h16816cudnn_64x128_ldg8_relu_exp_stages_64x4_small_nhwc_tn_v1 Tactic: 4278315135102886928
[03/24/2023-12:57:33] [V] [TRT] Tactic: 4278315135102886928 Time: 0.043008
[03/24/2023-12:57:33] [V] [TRT] Conv_160 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x32x32_stage4_warpsize4x1x1_g1_tensor16x8x16_t1r3s3 Tactic: 4503233883285355107
[03/24/2023-12:57:33] [V] [TRT] Tactic: 4503233883285355107 Time: 0.020224
[03/24/2023-12:57:33] [V] [TRT] Conv_160 Set Tactic Name: ampere_h16816cudnn_256x64_ldg8_relu_exp_stages_64x3_medium_nhwc_tn_v1 Tactic: 4540505769798915372
[03/24/2023-12:57:33] [V] [TRT] Tactic: 4540505769798915372 Time: 0.030592
[03/24/2023-12:57:33] [V] [TRT] Conv_160 Set Tactic Name: ampere_h16816cudnn_256x64_sliced1x2_ldg8_relu_exp_small_nhwc_tn_v1 Tactic: 4802447371470387646
[03/24/2023-12:57:33] [V] [TRT] Tactic: 4802447371470387646 Time: 0.03264
[03/24/2023-12:57:33] [V] [TRT] Conv_160 Set Tactic Name: ampere_h16816cudnn_256x128_ldg8_relu_exp_small_nhwc_tn_v1 Tactic: 5059676457552313631
[03/24/2023-12:57:33] [V] [TRT] Tactic: 5059676457552313631 Time: 0.045056
[03/24/2023-12:57:33] [V] [TRT] Conv_160 Set Tactic Name: sm75_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x128x64_stage1_warpsize2x2x1_g1_tensor16x8x8_t1r3s3 Tactic: 5263029549013613567
[03/24/2023-12:57:33] [V] [TRT] Tactic: 5263029549013613567 Time: 0.038656
[03/24/2023-12:57:33] [V] [TRT] Conv_160 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x64x64_stage4_warpsize2x2x1_g1_tensor16x8x16 Tactic: 5368829646735632944
[03/24/2023-12:57:33] [V] [TRT] Tactic: 5368829646735632944 Time: 0.030464
[03/24/2023-12:57:33] [V] [TRT] Conv_160 Set Tactic Name: ampere_h1688cudnn_256x64_sliced1x2_ldg8_relu_exp_small_nhwc_tn_v1 Tactic: 5398999388616959893
[03/24/2023-12:57:33] [V] [TRT] Tactic: 5398999388616959893 Time: 0.035712
[03/24/2023-12:57:33] [V] [TRT] Conv_160 Set Tactic Name: sm75_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x256x32_stage1_warpsize2x4x1_g1_tensor16x8x8_t1r3s3 Tactic: 5506334059535811602
[03/24/2023-12:57:33] [V] [TRT] Tactic: 5506334059535811602 Time: 0.068992
[03/24/2023-12:57:33] [V] [TRT] Conv_160 Set Tactic Name: ampere_h16816cudnn_64x128_sliced1x2_ldg8_relu_exp_stages_64x3_large_nhwc_tn_v1 Tactic: 5746691132547383910
[03/24/2023-12:57:33] [V] [TRT] Tactic: 5746691132547383910 Time: 0.036736
[03/24/2023-12:57:33] [V] [TRT] Conv_160 Set Tactic Name: ampere_h16816cudnn_256x64_ldg8_relu_exp_large_nhwc_tn_v1 Tactic: 5770170567977052602
[03/24/2023-12:57:33] [V] [TRT] Tactic: 5770170567977052602 Time: 0.031616
[03/24/2023-12:57:33] [V] [TRT] Conv_160 Set Tactic Name: sm75_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x32x64_stage1_warpsize2x1x2_g1_tensor16x8x8_t1r3s3 Tactic: 5932046018238429951
[03/24/2023-12:57:33] [V] [TRT] Tactic: 5932046018238429951 Time: 0.0224
[03/24/2023-12:57:33] [V] [TRT] Conv_160 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x64x32_stage3_warpsize4x1x1_g1_tensor16x8x16_t1r3s3 Tactic: 5953552212833506549
[03/24/2023-12:57:33] [V] [TRT] Tactic: 5953552212833506549 Time: 0.027264
[03/24/2023-12:57:33] [V] [TRT] Conv_160 Set Tactic Name: ampere_h16816cudnn_64x128_ldg8_relu_exp_stages_64x3_small_nhwc_tn_v1 Tactic: 6034364043891107501
[03/24/2023-12:57:34] [V] [TRT] Tactic: 6034364043891107501 Time: 0.03776
[03/24/2023-12:57:34] [V] [TRT] Conv_160 Set Tactic Name: ampere_h16816cudnn_64x64_ldg8_relu_exp_stages_64x5_large_nhwc_tn_v1 Tactic: 6074229447555668232
[03/24/2023-12:57:34] [V] [TRT] Tactic: 6074229447555668232 Time: 0.033408
[03/24/2023-12:57:34] [V] [TRT] Conv_160 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x64x64_stage3_warpsize2x2x1_g1_tensor16x8x16 Tactic: 6154447660803990543
[03/24/2023-12:57:34] [V] [TRT] Tactic: 6154447660803990543 Time: 0.025728
[03/24/2023-12:57:34] [V] [TRT] Conv_160 Set Tactic Name: sm75_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x32x64_stage1_warpsize2x1x2_g1_tensor16x8x8 Tactic: 6195603576432354734
[03/24/2023-12:57:34] [V] [TRT] Tactic: 6195603576432354734 Time: 0.02432
[03/24/2023-12:57:34] [V] [TRT] Conv_160 Set Tactic Name: sm75_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x32x32_stage1_warpsize4x1x1_g1_tensor16x8x8_t1r3s3 Tactic: 6252808259936499253
[03/24/2023-12:57:34] [V] [TRT] Tactic: 6252808259936499253 Time: 0.027904
[03/24/2023-12:57:34] [V] [TRT] Conv_160 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x128x64_stage3_warpsize2x2x1_g1_tensor16x8x16 Tactic: 6325769668000961702
[03/24/2023-12:57:34] [V] [TRT] Tactic: 6325769668000961702 Time: 0.04224
[03/24/2023-12:57:34] [V] [TRT] Conv_160 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x32x64_stage5_warpsize2x2x1_g1_tensor16x8x16 Tactic: 6350273239113254096
[03/24/2023-12:57:34] [V] [TRT] Tactic: 6350273239113254096 Time: 0.026496
[03/24/2023-12:57:34] [V] [TRT] Conv_160 Set Tactic Name: ampere_h16816cudnn_128x128_ldg8_relu_exp_stages_64x3_small_nhwc_tn_v1 Tactic: 6377497238381488891
[03/24/2023-12:57:34] [V] [TRT] Tactic: 6377497238381488891 Time: 0.040448
[03/24/2023-12:57:34] [V] [TRT] Conv_160 Set Tactic Name: sm75_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x64x64_stage1_warpsize2x2x1_g1_tensor16x8x8 Tactic: 6408235920257988861
[03/24/2023-12:57:34] [V] [TRT] Tactic: 6408235920257988861 Time: 0.028544
[03/24/2023-12:57:34] [V] [TRT] Conv_160 Set Tactic Name: ampere_h16816cudnn_128x64_ldg8_relu_exp_stages_64x3_large_nhwc_tn_v1 Tactic: 6446388116965632819
[03/24/2023-12:57:34] [V] [TRT] Tactic: 6446388116965632819 Time: 0.028416
[03/24/2023-12:57:34] [V] [TRT] Conv_160 Set Tactic Name: ampere_h16816cudnn_128x64_sliced1x2_ldg8_relu_exp_stages_64x4_medium_nhwc_tn_v1 Tactic: 6468794451065529747
[03/24/2023-12:57:34] [V] [TRT] Tactic: 6468794451065529747 Time: 0.03136
[03/24/2023-12:57:34] [V] [TRT] Conv_160 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x128x64_stage3_warpsize4x2x1_g1_tensor16x8x16 Tactic: 6509152032538119080
[03/24/2023-12:57:34] [V] [TRT] Tactic: 6509152032538119080 Time: 0.046464
[03/24/2023-12:57:34] [V] [TRT] Conv_160 Set Tactic Name: ampere_h1688cudnn_256x128_ldg8_relu_exp_large_nhwc_tn_v1 Tactic: 6642277870194067185
[03/24/2023-12:57:34] [V] [TRT] Tactic: 6642277870194067185 Time: 0.054144
[03/24/2023-12:57:34] [V] [TRT] Conv_160 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x256x64_stage3_warpsize1x4x1_g1_tensor16x8x16 Tactic: 6703181542003057635
[03/24/2023-12:57:34] [V] [TRT] Tactic: 6703181542003057635 Time: 0.064768
[03/24/2023-12:57:34] [V] [TRT] Conv_160 Set Tactic Name: ampere_h16816cudnn_64x64_ldg8_relu_exp_stages_64x5_medium_nhwc_tn_v1 Tactic: 6859477213531075460
[03/24/2023-12:57:34] [V] [TRT] Tactic: 6859477213531075460 Time: 0.032768
[03/24/2023-12:57:34] [V] [TRT] Conv_160 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x128x32_stage4_warpsize2x2x1_g1_tensor16x8x16_t1r3s3 Tactic: 6972489290272968208
[03/24/2023-12:57:34] [V] [TRT] Tactic: 6972489290272968208 Time: 0.033536
[03/24/2023-12:57:34] [V] [TRT] Conv_160 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x128x32_stage3_warpsize4x2x1_g1_tensor16x8x16 Tactic: 6979044990896381511
[03/24/2023-12:57:34] [V] [TRT] Tactic: 6979044990896381511 Time: 0.044032
[03/24/2023-12:57:34] [V] [TRT] Conv_160 Set Tactic Name: ampere_h1688cudnn_256x64_ldg8_relu_exp_medium_nhwc_tn_v1 Tactic: 7216571380637776659
[03/24/2023-12:57:34] [V] [TRT] Tactic: 7216571380637776659 Time: 0.03584
[03/24/2023-12:57:34] [V] [TRT] Conv_160 Set Tactic Name: ampere_h16816cudnn_128x64_ldg8_relu_exp_stages_64x3_medium_nhwc_tn_v1 Tactic: 7609923741161019135
[03/24/2023-12:57:34] [V] [TRT] Tactic: 7609923741161019135 Time: 0.027904
[03/24/2023-12:57:34] [V] [TRT] Conv_160 Set Tactic Name: sm75_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x64x32_stage1_warpsize2x2x1_g1_tensor16x8x8 Tactic: 7612687199567064086
[03/24/2023-12:57:34] [V] [TRT] Tactic: 7612687199567064086 Time: 0.030848
[03/24/2023-12:57:34] [V] [TRT] Conv_160 Set Tactic Name: ampere_h16816cudnn_64x64_ldg8_relu_exp_stages_64x6_large_nhwc_tn_v1 Tactic: 7705739241028240201
[03/24/2023-12:57:34] [V] [TRT] Tactic: 7705739241028240201 Time: 0.038784
[03/24/2023-12:57:34] [V] [TRT] Conv_160 Set Tactic Name: sm75_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x128x32_stage1_warpsize2x2x1_g1_tensor16x8x8 Tactic: 7729555994715864793
[03/24/2023-12:57:34] [V] [TRT] Tactic: 7729555994715864793 Time: 0.04096
[03/24/2023-12:57:34] [V] [TRT] Conv_160 Set Tactic Name: sm75_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x64x64_stage1_warpsize2x2x1_g1_tensor16x8x8_t1r3s3 Tactic: 7849296535223586261
[03/24/2023-12:57:34] [V] [TRT] Tactic: 7849296535223586261 Time: 0.028288
[03/24/2023-12:57:34] [V] [TRT] Conv_160 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x256x32_stage3_warpsize2x4x1_g1_tensor16x8x16 Tactic: 8072087735545283117
[03/24/2023-12:57:34] [V] [TRT] Tactic: 8072087735545283117 Time: 0.06144
[03/24/2023-12:57:34] [V] [TRT] Conv_160 Set Tactic Name: ampere_h16816cudnn_64x64_sliced1x2_ldg8_relu_exp_stages_64x5_medium_nhwc_tn_v1 Tactic: 8101703987960976805
[03/24/2023-12:57:34] [V] [TRT] Tactic: 8101703987960976805 Time: 0.031744
[03/24/2023-12:57:34] [V] [TRT] Conv_160 Set Tactic Name: ampere_h16816cudnn_128x64_sliced1x2_ldg8_relu_exp_stages_64x4_small_nhwc_tn_v1 Tactic: 8170606396342855895
[03/24/2023-12:57:34] [V] [TRT] Tactic: 8170606396342855895 Time: 0.030336
[03/24/2023-12:57:34] [V] [TRT] Conv_160 Set Tactic Name: sm75_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x32x64_stage1_warpsize2x1x2_g1_tensor16x8x8 Tactic: 8455608235315878803
[03/24/2023-12:57:34] [V] [TRT] Tactic: 8455608235315878803 Time: 0.0256
[03/24/2023-12:57:34] [V] [TRT] Conv_160 Set Tactic Name: sm75_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x64x64_stage1_warpsize2x2x1_g1_tensor16x8x8 Tactic: 8668812313058150080
[03/24/2023-12:57:34] [V] [TRT] Tactic: 8668812313058150080 Time: 0.029568
[03/24/2023-12:57:34] [V] [TRT] Conv_160 Set Tactic Name: ampere_h1688cudnn_256x64_ldg8_relu_exp_small_nhwc_tn_v1 Tactic: 8839784824303350101
[03/24/2023-12:57:34] [V] [TRT] Tactic: 8839784824303350101 Time: 0.033664
[03/24/2023-12:57:34] [V] [TRT] Conv_160 Set Tactic Name: ampere_h16816cudnn_64x64_sliced1x2_ldg8_relu_exp_stages_64x5_large_nhwc_tn_v1 Tactic: -9217371357561775773
[03/24/2023-12:57:34] [V] [TRT] Tactic: -9217371357561775773 Time: 0.03072
[03/24/2023-12:57:34] [V] [TRT] Conv_160 Set Tactic Name: ampere_h16816cudnn_256x64_sliced1x2_ldg8_relu_exp_medium_nhwc_tn_v1 Tactic: -9009272790678027912
[03/24/2023-12:57:34] [V] [TRT] Tactic: -9009272790678027912 Time: 0.035584
[03/24/2023-12:57:34] [V] [TRT] Conv_160 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x32x32_stage4_warpsize4x1x1_g1_tensor16x8x16 Tactic: -8985224497679592364
[03/24/2023-12:57:34] [V] [TRT] Tactic: -8985224497679592364 Time: 0.02048
[03/24/2023-12:57:34] [V] [TRT] Conv_160 Set Tactic Name: ampere_h16816cudnn_128x64_sliced1x2_ldg8_relu_exp_stages_64x3_large_nhwc_tn_v1 Tactic: -8949544755481315679
[03/24/2023-12:57:34] [V] [TRT] Tactic: -8949544755481315679 Time: 0.026624
[03/24/2023-12:57:34] [V] [TRT] Conv_160 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x64x64_stage3_warpsize4x1x1_g1_tensor16x8x16_t1r3s3 Tactic: -8867999442759527766
[03/24/2023-12:57:34] [V] [TRT] Tactic: -8867999442759527766 Time: 0.03264
[03/24/2023-12:57:34] [V] [TRT] Conv_160 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x128x64_stage3_warpsize2x2x1_g1_tensor16x8x16 Tactic: -8759929675070720385
[03/24/2023-12:57:34] [V] [TRT] Tactic: -8759929675070720385 Time: 0.040704
[03/24/2023-12:57:34] [V] [TRT] Conv_160 Set Tactic Name: ampere_h16816cudnn_64x64_ldg8_relu_exp_stages_64x6_medium_nhwc_tn_v1 Tactic: -8604374562669615024
[03/24/2023-12:57:34] [V] [TRT] Tactic: -8604374562669615024 Time: 0.03776
[03/24/2023-12:57:34] [V] [TRT] Conv_160 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x128x64_stage3_warpsize4x2x1_g1_tensor16x8x16 Tactic: -8362347876645295759
[03/24/2023-12:57:34] [V] [TRT] Tactic: -8362347876645295759 Time: 0.045056
[03/24/2023-12:57:34] [V] [TRT] Conv_160 Set Tactic Name: sm75_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x128x32_stage1_warpsize4x2x1_g1_tensor16x8x8 Tactic: -8254009616492665198
[03/24/2023-12:57:34] [V] [TRT] Tactic: -8254009616492665198 Time: 0.050048
[03/24/2023-12:57:34] [V] [TRT] Conv_160 Set Tactic Name: ampere_h16816cudnn_256x128_ldg8_relu_exp_stages_64x3_large_nhwc_tn_v1 Tactic: -7757610000269494813
[03/24/2023-12:57:34] [V] [TRT] Tactic: -7757610000269494813 Time: 0.04608
[03/24/2023-12:57:34] [V] [TRT] Conv_160 Set Tactic Name: sm75_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x128x32_stage1_warpsize4x2x1_g1_tensor16x8x8 Tactic: -7615325597099025933
[03/24/2023-12:57:34] [V] [TRT] Tactic: -7615325597099025933 Time: 0.051072
[03/24/2023-12:57:34] [V] [TRT] Conv_160 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x64x64_stage3_warpsize4x1x1_g1_tensor16x8x16 Tactic: -6917689122519989488
[03/24/2023-12:57:34] [V] [TRT] Tactic: -6917689122519989488 Time: 0.031616
[03/24/2023-12:57:34] [V] [TRT] Conv_160 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x32x64_stage5_warpsize2x2x1_g1_tensor16x8x16_t1r3s3 Tactic: -6902925267326201166
[03/24/2023-12:57:34] [V] [TRT] Tactic: -6902925267326201166 Time: 0.0256
[03/24/2023-12:57:34] [V] [TRT] Conv_160 Set Tactic Name: ampere_h16816cudnn_64x128_ldg8_relu_exp_stages_64x4_large_nhwc_tn_v1 Tactic: -6840588038605932325
[03/24/2023-12:57:34] [V] [TRT] Tactic: -6840588038605932325 Time: 0.04416
[03/24/2023-12:57:34] [V] [TRT] Conv_160 Set Tactic Name: sm75_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x32x32_stage1_warpsize4x1x1_g1_tensor16x8x8 Tactic: -6828337260021572283
[03/24/2023-12:57:34] [V] [TRT] Tactic: -6828337260021572283 Time: 0.026496
[03/24/2023-12:57:34] [V] [TRT] Conv_160 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x256x32_stage3_warpsize2x4x1_g1_tensor16x8x16 Tactic: -6799856376604253964
[03/24/2023-12:57:34] [V] [TRT] Tactic: -6799856376604253964 Time: 0.06144
[03/24/2023-12:57:34] [V] [TRT] Conv_160 Set Tactic Name: sm75_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x32x32_stage1_warpsize4x1x1_g1_tensor16x8x8 Tactic: -6711815420995272523
[03/24/2023-12:57:34] [V] [TRT] Tactic: -6711815420995272523 Time: 0.030208
[03/24/2023-12:57:34] [V] [TRT] Conv_160 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x32x32_stage4_warpsize4x1x1_g1_tensor16x8x16_t1r3s3 Tactic: -6625722781282978136
[03/24/2023-12:57:34] [V] [TRT] Tactic: -6625722781282978136 Time: 0.021376
[03/24/2023-12:57:34] [V] [TRT] Conv_160 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x64x32_stage3_warpsize4x1x1_g1_tensor16x8x16 Tactic: -6525498856028268801
[03/24/2023-12:57:34] [V] [TRT] Tactic: -6525498856028268801 Time: 0.027776
[03/24/2023-12:57:34] [V] [TRT] Conv_160 Set Tactic Name: sm75_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x256x64_stage1_warpsize1x4x2_g1_tensor16x8x8 Tactic: -6489479581011009593
[03/24/2023-12:57:34] [V] [TRT] Tactic: -6489479581011009593 Time: 0.0704
[03/24/2023-12:57:34] [V] [TRT] Conv_160 Set Tactic Name: ampere_h16816cudnn_64x64_sliced1x2_ldg8_relu_exp_stages_64x6_medium_nhwc_tn_v1 Tactic: -6356316196810535311
[03/24/2023-12:57:34] [V] [TRT] Tactic: -6356316196810535311 Time: 0.039552
[03/24/2023-12:57:34] [V] [TRT] Conv_160 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x32x32_stage4_warpsize4x1x1_g1_tensor16x8x16 Tactic: -6324345858751792783
[03/24/2023-12:57:34] [V] [TRT] Tactic: -6324345858751792783 Time: 0.0224
[03/24/2023-12:57:34] [V] [TRT] Conv_160 Set Tactic Name: sm75_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x256x64_stage1_warpsize1x4x2_g1_tensor16x8x8_t1r3s3 Tactic: -6320761427625651496
[03/24/2023-12:57:34] [V] [TRT] Tactic: -6320761427625651496 Time: 0.069504
[03/24/2023-12:57:34] [V] [TRT] Conv_160 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x256x32_stage3_warpsize2x4x1_g1_tensor16x8x16_t1r3s3 Tactic: -6262400699544994312
[03/24/2023-12:57:34] [V] [TRT] Tactic: -6262400699544994312 Time: 0.060288
[03/24/2023-12:57:34] [V] [TRT] Conv_160 Set Tactic Name: ampere_h1688cudnn_128x128_ldg8_relu_exp_large_nhwc_tn_v1 Tactic: -6257787336162086472
[03/24/2023-12:57:34] [V] [TRT] Tactic: -6257787336162086472 Time: 0.052096
[03/24/2023-12:57:34] [V] [TRT] Conv_160 Set Tactic Name: sm75_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x128x64_stage1_warpsize2x2x1_g1_tensor16x8x8 Tactic: -6080892721161662420
[03/24/2023-12:57:34] [V] [TRT] Tactic: -6080892721161662420 Time: 0.039808
[03/24/2023-12:57:34] [V] [TRT] Conv_160 Set Tactic Name: ampere_h16816cudnn_128x64_ldg8_relu_exp_stages_64x4_small_nhwc_tn_v1 Tactic: -6063766379489217211
[03/24/2023-12:57:34] [V] [TRT] Tactic: -6063766379489217211 Time: 0.030592
[03/24/2023-12:57:34] [V] [TRT] Conv_160 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x128x32_stage5_warpsize2x2x1_g1_tensor16x8x16 Tactic: -5777580938094193096
[03/24/2023-12:57:34] [V] [TRT] Tactic: -5777580938094193096 Time: 0.035456
[03/24/2023-12:57:34] [V] [TRT] Conv_160 Set Tactic Name: sm75_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x128x64_stage1_warpsize2x2x1_g1_tensor16x8x8 Tactic: -5710735840878760115
[03/24/2023-12:57:34] [V] [TRT] Tactic: -5710735840878760115 Time: 0.040832
[03/24/2023-12:57:34] [V] [TRT] Conv_160 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x128x32_stage3_warpsize4x2x1_g1_tensor16x8x16 Tactic: -5657273398217409378
[03/24/2023-12:57:34] [V] [TRT] Tactic: -5657273398217409378 Time: 0.043904
[03/24/2023-12:57:34] [V] [TRT] Conv_160 Set Tactic Name: sm75_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x128x32_stage1_warpsize2x2x1_g1_tensor16x8x8_t1r3s3 Tactic: -5546257196173962281
[03/24/2023-12:57:34] [V] [TRT] Tactic: -5546257196173962281 Time: 0.038912
[03/24/2023-12:57:34] [V] [TRT] Conv_160 Set Tactic Name: ampere_h16816cudnn_128x128_ldg8_relu_exp_small_nhwc_tn_v1 Tactic: -5530886555766748586
[03/24/2023-12:57:34] [V] [TRT] Tactic: -5530886555766748586 Time: 0.034688
[03/24/2023-12:57:34] [V] [TRT] Conv_160 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x64x32_stage5_warpsize2x2x1_g1_tensor16x8x16_t1r3s3 Tactic: -5422685219138380548
[03/24/2023-12:57:34] [V] [TRT] Tactic: -5422685219138380548 Time: 0.024832
[03/24/2023-12:57:34] [V] [TRT] Conv_160 Set Tactic Name: ampere_h16816cudnn_256x64_ldg8_relu_exp_stages_64x3_small_nhwc_tn_v1 Tactic: -5261787675443473128
[03/24/2023-12:57:34] [V] [TRT] Tactic: -5261787675443473128 Time: 0.030336
[03/24/2023-12:57:34] [V] [TRT] Conv_160 Set Tactic Name: sm75_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x64x32_stage1_warpsize4x1x1_g1_tensor16x8x8 Tactic: -5198219374380660379
[03/24/2023-12:57:34] [V] [TRT] Tactic: -5198219374380660379 Time: 0.033152
[03/24/2023-12:57:34] [V] [TRT] Conv_160 Set Tactic Name: ampere_h16816cudnn_64x128_sliced1x2_ldg8_relu_exp_stages_64x3_medium_nhwc_tn_v1 Tactic: -5161596964442251102
[03/24/2023-12:57:34] [V] [TRT] Tactic: -5161596964442251102 Time: 0.036096
[03/24/2023-12:57:34] [V] [TRT] Conv_160 Set Tactic Name: ampere_h16816cudnn_64x128_ldg8_relu_exp_stages_64x3_medium_nhwc_tn_v1 Tactic: -5127240325355316006
[03/24/2023-12:57:34] [V] [TRT] Tactic: -5127240325355316006 Time: 0.037632
[03/24/2023-12:57:34] [V] [TRT] Conv_160 Set Tactic Name: ampere_h16816cudnn_256x128_ldg8_relu_exp_stages_64x3_medium_nhwc_tn_v1 Tactic: -5109582882231362997
[03/24/2023-12:57:34] [V] [TRT] Tactic: -5109582882231362997 Time: 0.045824
[03/24/2023-12:57:34] [V] [TRT] Conv_160 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x64x32_stage5_warpsize2x2x1_g1_tensor16x8x16 Tactic: -4825567853927730435
[03/24/2023-12:57:34] [V] [TRT] Tactic: -4825567853927730435 Time: 0.02944
[03/24/2023-12:57:34] [V] [TRT] Conv_160 Set Tactic Name: ampere_h16816cudnn_64x128_sliced1x2_ldg8_relu_exp_stages_64x4_small_nhwc_tn_v1 Tactic: -4796511246675321840
[03/24/2023-12:57:34] [V] [TRT] Tactic: -4796511246675321840 Time: 0.046848
[03/24/2023-12:57:34] [V] [TRT] Conv_160 Set Tactic Name: ampere_h16816cudnn_64x64_sliced1x2_ldg8_relu_exp_stages_64x6_large_nhwc_tn_v1 Tactic: -4706569565442112734
[03/24/2023-12:57:34] [V] [TRT] Tactic: -4706569565442112734 Time: 0.040064
[03/24/2023-12:57:34] [V] [TRT] Conv_160 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x128x64_stage3_warpsize2x2x1_g1_tensor16x8x16_t1r3s3 Tactic: -4566599693570369588
[03/24/2023-12:57:34] [V] [TRT] Tactic: -4566599693570369588 Time: 0.04096
[03/24/2023-12:57:34] [V] [TRT] Conv_160 Set Tactic Name: ampere_h16816cudnn_128x128_ldg8_relu_exp_stages_64x3_large_nhwc_tn_v1 Tactic: -4409144516525410768
[03/24/2023-12:57:34] [V] [TRT] Tactic: -4409144516525410768 Time: 0.040576
[03/24/2023-12:57:34] [V] [TRT] Conv_160 Set Tactic Name: ampere_h16816cudnn_128x64_ldg8_relu_exp_stages_64x3_small_nhwc_tn_v1 Tactic: -4379519430184503304
[03/24/2023-12:57:34] [V] [TRT] Tactic: -4379519430184503304 Time: 0.027776
[03/24/2023-12:57:34] [V] [TRT] Conv_160 Set Tactic Name: ampere_h1688cudnn_256x128_ldg8_relu_exp_small_nhwc_tn_v1 Tactic: -4152066959007262150
[03/24/2023-12:57:34] [V] [TRT] Tactic: -4152066959007262150 Time: 0.050176
[03/24/2023-12:57:34] [V] [TRT] Conv_160 Set Tactic Name: ampere_h16816cudnn_64x128_ldg8_relu_exp_stages_64x4_medium_nhwc_tn_v1 Tactic: -4021926646879732549
[03/24/2023-12:57:34] [V] [TRT] Tactic: -4021926646879732549 Time: 0.043648
[03/24/2023-12:57:34] [V] [TRT] Conv_160 Set Tactic Name: ampere_h16816cudnn_64x128_sliced1x2_ldg8_relu_exp_stages_64x4_medium_nhwc_tn_v1 Tactic: -3987638434926559037
[03/24/2023-12:57:34] [V] [TRT] Tactic: -3987638434926559037 Time: 0.047104
[03/24/2023-12:57:34] [V] [TRT] Conv_160 Set Tactic Name: ampere_h1688cudnn_256x64_sliced1x2_ldg8_relu_exp_medium_nhwc_tn_v1 Tactic: -3905653247016903130
[03/24/2023-12:57:34] [V] [TRT] Tactic: -3905653247016903130 Time: 0.038144
[03/24/2023-12:57:34] [V] [TRT] Conv_160 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x64x32_stage5_warpsize2x2x1_g1_tensor16x8x16 Tactic: -3903974568488493144
[03/24/2023-12:57:34] [V] [TRT] Tactic: -3903974568488493144 Time: 0.02944
[03/24/2023-12:57:34] [V] [TRT] Conv_160 Set Tactic Name: ampere_h16816cudnn_64x128_ldg8_relu_exp_stages_64x3_large_nhwc_tn_v1 Tactic: -3895429239811098010
[03/24/2023-12:57:34] [V] [TRT] Tactic: -3895429239811098010 Time: 0.037888
[03/24/2023-12:57:34] [V] [TRT] Conv_160 Set Tactic Name: ampere_h16816cudnn_256x64_ldg8_relu_exp_small_nhwc_tn_v1 Tactic: -3864869056275745423
[03/24/2023-12:57:34] [V] [TRT] Tactic: -3864869056275745423 Time: 0.030464
[03/24/2023-12:57:34] [V] [TRT] Conv_160 Set Tactic Name: sm75_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x32x32_stage1_warpsize4x1x1_g1_tensor16x8x8_t1r3s3 Tactic: -3784342055748695733
[03/24/2023-12:57:34] [V] [TRT] Tactic: -3784342055748695733 Time: 0.024832
[03/24/2023-12:57:34] [V] [TRT] Conv_160 Set Tactic Name: ampere_h16816cudnn_64x64_ldg8_relu_exp_stages_64x5_small_nhwc_tn_v1 Tactic: -3601464762214218301
[03/24/2023-12:57:34] [V] [TRT] Tactic: -3601464762214218301 Time: 0.03264
[03/24/2023-12:57:34] [V] [TRT] Conv_160 Set Tactic Name: sm75_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x64x32_stage1_warpsize2x2x1_g1_tensor16x8x8 Tactic: -3425274793298557239
[03/24/2023-12:57:34] [V] [TRT] Tactic: -3425274793298557239 Time: 0.030336
[03/24/2023-12:57:34] [V] [TRT] Conv_160 Set Tactic Name: ampere_h1688cudnn_256x64_sliced1x2_ldg8_relu_exp_large_nhwc_tn_v1 Tactic: -3412636942650049698
[03/24/2023-12:57:34] [V] [TRT] Tactic: -3412636942650049698 Time: 0.038784
[03/24/2023-12:57:34] [V] [TRT] Conv_160 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x64x32_stage3_warpsize4x1x1_g1_tensor16x8x16 Tactic: -3338665856053412950
[03/24/2023-12:57:34] [V] [TRT] Tactic: -3338665856053412950 Time: 0.02688
[03/24/2023-12:57:34] [V] [TRT] Conv_160 Set Tactic Name: sm75_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x128x32_stage1_warpsize2x2x1_g1_tensor16x8x8 Tactic: -3271955096576257018
[03/24/2023-12:57:34] [V] [TRT] Tactic: -3271955096576257018 Time: 0.03968
[03/24/2023-12:57:34] [V] [TRT] Conv_160 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x128x64_stage3_warpsize4x2x1_g1_tensor16x8x16_t1r3s3 Tactic: -3243541398692466074
[03/24/2023-12:57:34] [V] [TRT] Tactic: -3243541398692466074 Time: 0.045952
[03/24/2023-12:57:34] [V] [TRT] Conv_160 Set Tactic Name: ampere_h16816cudnn_64x128_sliced1x2_ldg8_relu_exp_stages_64x3_small_nhwc_tn_v1 Tactic: -3058330359340425555
[03/24/2023-12:57:34] [V] [TRT] Tactic: -3058330359340425555 Time: 0.036352
[03/24/2023-12:57:34] [V] [TRT] Conv_160 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x256x64_stage3_warpsize1x4x1_g1_tensor16x8x16_t1r3s3 Tactic: -2899647483672319239
[03/24/2023-12:57:34] [V] [TRT] Tactic: -2899647483672319239 Time: 0.063232
[03/24/2023-12:57:34] [V] [TRT] Conv_160 Set Tactic Name: ampere_h16816cudnn_256x64_sliced1x2_ldg8_relu_exp_large_nhwc_tn_v1 Tactic: -2816084650627734155
[03/24/2023-12:57:34] [V] [TRT] Tactic: -2816084650627734155 Time: 0.035584
[03/24/2023-12:57:34] [V] [TRT] Conv_160 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x128x32_stage5_warpsize2x2x1_g1_tensor16x8x16 Tactic: -2662892962457732243
[03/24/2023-12:57:34] [V] [TRT] Tactic: -2662892962457732243 Time: 0.034688
[03/24/2023-12:57:34] [V] [TRT] Conv_160 Set Tactic Name: ampere_h16816cudnn_256x128_ldg8_relu_exp_large_nhwc_tn_v1 Tactic: -2559894581585337900
[03/24/2023-12:57:34] [V] [TRT] Tactic: -2559894581585337900 Time: 0.045312
[03/24/2023-12:57:34] [V] [TRT] Conv_160 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x32x32_stage4_warpsize4x1x1_g1_tensor16x8x16 Tactic: -2530740716768816092
[03/24/2023-12:57:34] [V] [TRT] Tactic: -2530740716768816092 Time: 0.023168
[03/24/2023-12:57:34] [V] [TRT] Conv_160 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x128x32_stage4_warpsize2x2x1_g1_tensor16x8x16 Tactic: -2332828394978346992
[03/24/2023-12:57:34] [V] [TRT] Tactic: -2332828394978346992 Time: 0.03456
[03/24/2023-12:57:34] [V] [TRT] Conv_160 Set Tactic Name: ampere_h1688cudnn_256x64_ldg8_relu_exp_large_nhwc_tn_v1 Tactic: -2241736083352441442
[03/24/2023-12:57:34] [V] [TRT] Tactic: -2241736083352441442 Time: 0.035072
[03/24/2023-12:57:34] [V] [TRT] Conv_160 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x32x64_stage5_warpsize2x2x1_g1_tensor16x8x16 Tactic: -2161909437867201546
[03/24/2023-12:57:34] [V] [TRT] Tactic: -2161909437867201546 Time: 0.026496
[03/24/2023-12:57:34] [V] [TRT] Conv_160 Set Tactic Name: ampere_h16816cudnn_256x64_ldg8_relu_exp_medium_nhwc_tn_v1 Tactic: -1985778916402815946
[03/24/2023-12:57:34] [V] [TRT] Tactic: -1985778916402815946 Time: 0.030848
[03/24/2023-12:57:34] [V] [TRT] Conv_160 Set Tactic Name: sm75_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x256x32_stage1_warpsize2x4x1_g1_tensor16x8x8 Tactic: -1708101578041178688
[03/24/2023-12:57:34] [V] [TRT] Tactic: -1708101578041178688 Time: 0.070656
[03/24/2023-12:57:34] [V] [TRT] Conv_160 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x64x64_stage3_warpsize4x1x1_g1_tensor16x8x16 Tactic: -1502788097503482299
[03/24/2023-12:57:34] [V] [TRT] Tactic: -1502788097503482299 Time: 0.033152
[03/24/2023-12:57:34] [V] [TRT] Conv_160 Set Tactic Name: ampere_h16816cudnn_128x64_sliced1x2_ldg8_relu_exp_stages_64x4_large_nhwc_tn_v1 Tactic: -1500496213132463076
[03/24/2023-12:57:34] [V] [TRT] Tactic: -1500496213132463076 Time: 0.03264
[03/24/2023-12:57:34] [V] [TRT] Conv_160 Set Tactic Name: ampere_h16816cudnn_64x64_ldg8_relu_exp_stages_64x6_small_nhwc_tn_v1 Tactic: -1099247066487349374
[03/24/2023-12:57:34] [V] [TRT] Tactic: -1099247066487349374 Time: 0.035712
[03/24/2023-12:57:34] [V] [TRT] Conv_160 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x64x64_stage4_warpsize2x2x1_g1_tensor16x8x16 Tactic: -910286698936744682
[03/24/2023-12:57:34] [V] [TRT] Tactic: -910286698936744682 Time: 0.029952
[03/24/2023-12:57:34] [V] [TRT] Conv_160 Set Tactic Name: sm75_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x256x32_stage1_warpsize2x4x1_g1_tensor16x8x8 Tactic: -907287437357565279
[03/24/2023-12:57:34] [V] [TRT] Tactic: -907287437357565279 Time: 0.069632
[03/24/2023-12:57:34] [V] [TRT] Conv_160 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x32x32_stage4_warpsize4x1x1_g1_tensor16x8x16 Tactic: -606726295133751039
[03/24/2023-12:57:34] [V] [TRT] Tactic: -606726295133751039 Time: 0.021248
[03/24/2023-12:57:34] [V] [TRT] Fastest Tactic: 4503233883285355107 Time: 0.020224
[03/24/2023-12:57:34] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: 4503233883285355107
[03/24/2023-12:57:34] [V] [TRT] *************** Autotuning format combination: Half(518400,1:16,2880,16) -> Half(32400,1:16,180,1) ***************
[03/24/2023-12:57:34] [V] [TRT] --------------- Timing Runner: Conv_160 (CudnnConvolution)
[03/24/2023-12:57:34] [V] [TRT] CudnnConvolution has no valid tactics for this config, skipping
[03/24/2023-12:57:34] [V] [TRT] --------------- Timing Runner: Conv_160 (CaskConvolution)
[03/24/2023-12:57:34] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[03/24/2023-12:57:34] [V] [TRT] =============== Computing costs for 
[03/24/2023-12:57:34] [V] [TRT] *************** Autotuning format combination: Float(8294400,32400,180,1) -> Float(64800,32400,180,1) ***************
[03/24/2023-12:57:34] [V] [TRT] --------------- Timing Runner: Conv_163 (CudaDepthwiseConvolution)
[03/24/2023-12:57:34] [V] [TRT] CudaDepthwiseConvolution has no valid tactics for this config, skipping
[03/24/2023-12:57:34] [V] [TRT] --------------- Timing Runner: Conv_163 (FusedConvActConvolution)
[03/24/2023-12:57:34] [V] [TRT] Tactic: 524287 Time: 0.0992
[03/24/2023-12:57:34] [V] [TRT] Tactic: 720895 Time: 0.173824
[03/24/2023-12:57:34] [V] [TRT] Tactic: 983039 Time: 0.147456
[03/24/2023-12:57:34] [V] [TRT] Tactic: 1048575 Time: 0.091008
[03/24/2023-12:57:34] [V] [TRT] Tactic: 1703935 Time: 0.086912
[03/24/2023-12:57:34] [V] [TRT] Tactic: 1769471 Time: 0.170752
[03/24/2023-12:57:34] [V] [TRT] Tactic: 1966079 Time: 0.18816
[03/24/2023-12:57:34] [V] [TRT] Tactic: 2031615 Time: 0.153728
[03/24/2023-12:57:34] [V] [TRT] Tactic: 2228223 Time: 0.102272
[03/24/2023-12:57:35] [V] [TRT] Tactic: 2424831 Time: 0.104064
[03/24/2023-12:57:35] [V] [TRT] Tactic: 2621439 Time: 0.087168
[03/24/2023-12:57:35] [V] [TRT] Tactic: 2752511 Time: 0.170752
[03/24/2023-12:57:35] [V] [TRT] Tactic: 3014655 Time: 0.108672
[03/24/2023-12:57:35] [V] [TRT] Tactic: 3145727 Time: 0.182912
[03/24/2023-12:57:35] [V] [TRT] Tactic: 3604479 Time: 0.107904
[03/24/2023-12:57:35] [V] [TRT] Tactic: 4390911 Time: 0.251776
[03/24/2023-12:57:35] [V] [TRT] Tactic: 5046271 Time: 0.114816
[03/24/2023-12:57:35] [V] [TRT] Tactic: 5963775 Time: 0.207104
[03/24/2023-12:57:35] [V] [TRT] Tactic: 6160383 Time: 0.116736
[03/24/2023-12:57:35] [V] [TRT] Tactic: 6488063 Time: 0.128896
[03/24/2023-12:57:35] [V] [TRT] Tactic: 6881279 Time: 0.205184
[03/24/2023-12:57:35] [V] [TRT] Tactic: 7274495 Time: 0.19008
[03/24/2023-12:57:35] [V] [TRT] Tactic: 7864319 Time: 0.110592
[03/24/2023-12:57:35] [V] [TRT] Tactic: 7995391 Time: 0.217984
[03/24/2023-12:57:35] [V] [TRT] Tactic: 8585215 Time: 0.140544
[03/24/2023-12:57:35] [V] [TRT] Tactic: 8847359 Time: 0.1088
[03/24/2023-12:57:35] [V] [TRT] Tactic: 8978431 Time: 0.203392
[03/24/2023-12:57:35] [V] [TRT] Tactic: 9043967 Time: 0.108928
[03/24/2023-12:57:35] [V] [TRT] Tactic: 9175039 Time: 0.106496
[03/24/2023-12:57:35] [V] [TRT] Tactic: 9502719 Time: 0.246272
[03/24/2023-12:57:35] [V] [TRT] Tactic: 9961471 Time: 0.116352
[03/24/2023-12:57:35] [V] [TRT] Tactic: 10027007 Time: 0.113792
[03/24/2023-12:57:35] [V] [TRT] Tactic: 10092543 Time: 0.246528
[03/24/2023-12:57:35] [V] [TRT] Tactic: 10289151 Time: 0.226176
[03/24/2023-12:57:35] [V] [TRT] Tactic: 10485759 Time: 0.101376
[03/24/2023-12:57:35] [V] [TRT] Tactic: 10682367 Time: 0.104448
[03/24/2023-12:57:35] [V] [TRT] Tactic: 10813439 Time: 0.183296
[03/24/2023-12:57:35] [V] [TRT] Fastest Tactic: 1703935 Time: 0.086912
[03/24/2023-12:57:35] [V] [TRT] --------------- Timing Runner: Conv_163 (CudnnConvolution)
[03/24/2023-12:57:35] [V] [TRT] Tactic: 0 Time: 0.172928
[03/24/2023-12:57:35] [V] [TRT] Tactic: 1 Time: 0.09728
[03/24/2023-12:57:35] [V] [TRT] Tactic: 2 Time: 0.242048
[03/24/2023-12:57:35] [V] [TRT] Tactic: 4 Time: 0.367744
[03/24/2023-12:57:35] [V] [TRT] Tactic: 5 Time: 0.500608
[03/24/2023-12:57:35] [V] [TRT] Tactic: 6 Time: 0.072704
[03/24/2023-12:57:35] [V] [TRT] Tactic: 56 Time: 0.173056
[03/24/2023-12:57:35] [V] [TRT] Tactic: 57 Time: 0.097536
[03/24/2023-12:57:35] [V] [TRT] Tactic: 58 Time: 0.241536
[03/24/2023-12:57:35] [V] [TRT] Tactic: 60 Time: 0.369408
[03/24/2023-12:57:35] [V] [TRT] Tactic: 61 Time: 0.487296
[03/24/2023-12:57:35] [V] [TRT] Tactic: 62 Time: 0.072832
[03/24/2023-12:57:35] [V] [TRT] Tactic: 112 Time: 0.172928
[03/24/2023-12:57:35] [V] [TRT] Tactic: 113 Time: 0.2304
[03/24/2023-12:57:35] [V] [TRT] Tactic: 114 Time: 0.24128
[03/24/2023-12:57:35] [V] [TRT] Tactic: 116 Time: 0.368896
[03/24/2023-12:57:35] [V] [TRT] Tactic: 117 Time: 0.482048
[03/24/2023-12:57:35] [V] [TRT] Tactic: 118 Time: 0.073472
[03/24/2023-12:57:35] [V] [TRT] Fastest Tactic: 6 Time: 0.072704
[03/24/2023-12:57:35] [V] [TRT] --------------- Timing Runner: Conv_163 (CaskConvolution)
[03/24/2023-12:57:35] [V] [TRT] Conv_163 Set Tactic Name: ampere_scudnn_128x64_relu_small_nn_v1 Tactic: 4549827808004681195
[03/24/2023-12:57:35] [V] [TRT] Tactic: 4549827808004681195 Time: 0.218496
[03/24/2023-12:57:35] [V] [TRT] Conv_163 Set Tactic Name: ampere_scudnn_128x128_relu_small_nn_v1 Tactic: 5779835512569528575
[03/24/2023-12:57:35] [V] [TRT] Tactic: 5779835512569528575 Time: 0.379392
[03/24/2023-12:57:35] [V] [TRT] Conv_163 Set Tactic Name: ampere_scudnn_128x128_relu_xregs_large_nn_v1 Tactic: 6053873026024413720
[03/24/2023-12:57:35] [V] [TRT] Tactic: 6053873026024413720 Time: 0.40128
[03/24/2023-12:57:35] [V] [TRT] Conv_163 Set Tactic Name: ampere_scudnn_128x64_relu_xregs_large_nn_v1 Tactic: 6767548733843469815
[03/24/2023-12:57:35] [V] [TRT] Tactic: 6767548733843469815 Time: 0.208256
[03/24/2023-12:57:35] [V] [TRT] Conv_163 Set Tactic Name: ampere_scudnn_128x32_relu_small_nn_v1 Tactic: -6313876406580483184
[03/24/2023-12:57:35] [V] [TRT] Tactic: -6313876406580483184 Time: 0.155264
[03/24/2023-12:57:35] [V] [TRT] Conv_163 Set Tactic Name: ampere_scudnn_128x128_relu_medium_nn_v1 Tactic: -1123676555321336786
[03/24/2023-12:57:35] [V] [TRT] Tactic: -1123676555321336786 Time: 0.379776
[03/24/2023-12:57:35] [V] [TRT] Conv_163 Set Tactic Name: ampere_scudnn_128x64_relu_medium_nn_v1 Tactic: -701551393537224327
[03/24/2023-12:57:35] [V] [TRT] Tactic: -701551393537224327 Time: 0.211328
[03/24/2023-12:57:35] [V] [TRT] Fastest Tactic: -6313876406580483184 Time: 0.155264
[03/24/2023-12:57:35] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CudnnConvolution Tactic: 6
[03/24/2023-12:57:35] [V] [TRT] *************** Autotuning format combination: Float(8294400,1,46080,256) -> Float(64800,1,360,2) ***************
[03/24/2023-12:57:35] [V] [TRT] --------------- Timing Runner: Conv_163 (CudnnConvolution)
[03/24/2023-12:57:35] [V] [TRT] CudnnConvolution has no valid tactics for this config, skipping
[03/24/2023-12:57:35] [V] [TRT] --------------- Timing Runner: Conv_163 (CaskConvolution)
[03/24/2023-12:57:35] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[03/24/2023-12:57:35] [V] [TRT] *************** Autotuning format combination: Float(2073600,1:4,11520,64) -> Float(32400,1:4,180,1) ***************
[03/24/2023-12:57:35] [V] [TRT] --------------- Timing Runner: Conv_163 (CudnnConvolution)
[03/24/2023-12:57:35] [V] [TRT] CudnnConvolution has no valid tactics for this config, skipping
[03/24/2023-12:57:35] [V] [TRT] --------------- Timing Runner: Conv_163 (CaskConvolution)
[03/24/2023-12:57:35] [V] [TRT] Conv_163 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize64x128x32_stage5_warpsize2x2x1_g1_tensor16x8x8 Tactic: 1237784342446422381
[03/24/2023-12:57:35] [V] [TRT] Tactic: 1237784342446422381 Time: 0.092288
[03/24/2023-12:57:35] [V] [TRT] Conv_163 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x64x32_stage5_warpsize2x2x1_g1_tensor16x8x8 Tactic: 1426562292875733922
[03/24/2023-12:57:35] [V] [TRT] Tactic: 1426562292875733922 Time: 0.0608
[03/24/2023-12:57:35] [V] [TRT] Conv_163 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize64x128x8_stage3_warpsize1x4x1_g1_ffma_t1r3s3 Tactic: 2086609538387166260
[03/24/2023-12:57:35] [V] [TRT] Tactic: 2086609538387166260 Time: 0.318464
[03/24/2023-12:57:35] [V] [TRT] Conv_163 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize256x128x32_stage3_warpsize4x2x1_g1_tensor16x8x8_t1r3s3 Tactic: 2388153022056233219
[03/24/2023-12:57:35] [V] [TRT] Tactic: 2388153022056233219 Time: 0.090112
[03/24/2023-12:57:35] [V] [TRT] Conv_163 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x128x32_stage4_warpsize2x2x1_g1_tensor16x8x8 Tactic: 2716437853123234317
[03/24/2023-12:57:35] [V] [TRT] Tactic: 2716437853123234317 Time: 0.080384
[03/24/2023-12:57:35] [V] [TRT] Conv_163 Set Tactic Name: ampere_scudnn_128x64_sliced1x2_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: 2860655430572478466
[03/24/2023-12:57:35] [V] [TRT] Tactic: 2860655430572478466 Time: 0.19968
[03/24/2023-12:57:35] [V] [TRT] Conv_163 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize64x128x8_stage3_warpsize1x4x1_g1_ffma Tactic: 3239733199291090177
[03/24/2023-12:57:35] [V] [TRT] Tactic: 3239733199291090177 Time: 0.317824
[03/24/2023-12:57:35] [V] [TRT] Conv_163 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize64x64x64_stage4_warpsize2x2x1_g1_tensor16x8x8_t1r3s3 Tactic: 3278852197192504305
[03/24/2023-12:57:35] [V] [TRT] Tactic: 3278852197192504305 Time: 0.060032
[03/24/2023-12:57:35] [V] [TRT] Conv_163 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize256x128x32_stage3_warpsize4x2x1_g1_tensor16x8x8 Tactic: 3904690393614050557
[03/24/2023-12:57:35] [V] [TRT] Tactic: 3904690393614050557 Time: 0.111232
[03/24/2023-12:57:35] [V] [TRT] Conv_163 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize64x64x64_stage4_warpsize2x2x1_g1_tensor16x8x8 Tactic: 4061115162338989075
[03/24/2023-12:57:35] [V] [TRT] Tactic: 4061115162338989075 Time: 0.065664
[03/24/2023-12:57:35] [V] [TRT] Conv_163 Set Tactic Name: ampere_scudnn_128x32_sliced1x4_ldg4_relu_exp_medium_nhwc_tn_v1 Tactic: 4474630279712975759
[03/24/2023-12:57:35] [V] [TRT] Tactic: 4474630279712975759 Time: 0.1088
[03/24/2023-12:57:35] [V] [TRT] Conv_163 Set Tactic Name: ampere_scudnn_128x32_sliced1x4_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: 4479823862704990365
[03/24/2023-12:57:35] [V] [TRT] Tactic: 4479823862704990365 Time: 0.107648
[03/24/2023-12:57:35] [V] [TRT] Conv_163 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize64x256x8_stage3_warpsize1x4x1_g1_ffma Tactic: 4517590677127196184
[03/24/2023-12:57:35] [V] [TRT] Tactic: 4517590677127196184 Time: 0.749952
[03/24/2023-12:57:35] [V] [TRT] Conv_163 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize128x128x8_stage3_warpsize2x4x1_g1_ffma_t1r3s3 Tactic: 4634080872644479428
[03/24/2023-12:57:35] [V] [TRT] Tactic: 4634080872644479428 Time: 0.382208
[03/24/2023-12:57:35] [V] [TRT] Conv_163 Set Tactic Name: ampere_scudnn_128x64_sliced1x2_ldg4_relu_exp_medium_nhwc_tn_v1 Tactic: 4696204239951173149
[03/24/2023-12:57:35] [V] [TRT] Tactic: 4696204239951173149 Time: 0.19968
[03/24/2023-12:57:35] [V] [TRT] Conv_163 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x256x32_stage3_warpsize2x4x1_g1_tensor16x8x8 Tactic: 5200329514761435342
[03/24/2023-12:57:35] [V] [TRT] Tactic: 5200329514761435342 Time: 0.1248
[03/24/2023-12:57:35] [V] [TRT] Conv_163 Set Tactic Name: ampere_scudnn_128x128_relu_exp_small_nhwc_tn_v1 Tactic: 5778138195697110003
[03/24/2023-12:57:35] [V] [TRT] Tactic: 5778138195697110003 Time: 0.376064
[03/24/2023-12:57:35] [V] [TRT] Conv_163 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize256x128x8_stage3_warpsize2x4x1_g1_ffma Tactic: 6310198979346901507
[03/24/2023-12:57:35] [V] [TRT] Tactic: 6310198979346901507 Time: 0.523904
[03/24/2023-12:57:35] [V] [TRT] Conv_163 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x256x32_stage3_warpsize2x4x1_g1_tensor16x8x8_t1r3s3 Tactic: 7011693366046809027
[03/24/2023-12:57:35] [V] [TRT] Tactic: 7011693366046809027 Time: 0.122112
[03/24/2023-12:57:35] [V] [TRT] Conv_163 Set Tactic Name: ampere_scudnn_128x128_ldg4_relu_exp_large_nhwc_tn_v1 Tactic: 7155825427510256858
[03/24/2023-12:57:35] [V] [TRT] Tactic: 7155825427510256858 Time: 0.378112
[03/24/2023-12:57:35] [V] [TRT] Conv_163 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize128x64x8_stage3_warpsize1x4x1_g1_ffma Tactic: 7222247112373541608
[03/24/2023-12:57:35] [V] [TRT] Tactic: 7222247112373541608 Time: 0.26752
[03/24/2023-12:57:35] [V] [TRT] Conv_163 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x128x16_stage4_warpsize2x2x1_g1_tensor16x8x8 Tactic: 7342025736444949634
[03/24/2023-12:57:35] [V] [TRT] Tactic: 7342025736444949634 Time: 0.082944
[03/24/2023-12:57:35] [V] [TRT] Conv_163 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize64x128x32_stage5_warpsize2x2x1_g1_tensor16x8x8 Tactic: 7347365539922924600
[03/24/2023-12:57:35] [V] [TRT] Tactic: 7347365539922924600 Time: 0.088192
[03/24/2023-12:57:35] [V] [TRT] Conv_163 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x64x32_stage5_warpsize2x2x1_g1_tensor16x8x8 Tactic: 7428197830878119671
[03/24/2023-12:57:35] [V] [TRT] Tactic: 7428197830878119671 Time: 0.057088
[03/24/2023-12:57:35] [V] [TRT] Conv_163 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize64x32x64_stage5_warpsize2x2x1_g1_tensor16x8x8_t1r3s3 Tactic: 7465323447915168822
[03/24/2023-12:57:35] [V] [TRT] Tactic: 7465323447915168822 Time: 0.049024
[03/24/2023-12:57:35] [V] [TRT] Conv_163 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize128x128x8_stage3_warpsize2x4x1_g1_ffma Tactic: 7472640475524677095
[03/24/2023-12:57:35] [V] [TRT] Tactic: 7472640475524677095 Time: 0.38912
[03/24/2023-12:57:35] [V] [TRT] Conv_163 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize64x32x64_stage5_warpsize2x2x1_g1_tensor16x8x8 Tactic: 7938223790021272801
[03/24/2023-12:57:35] [V] [TRT] Tactic: 7938223790021272801 Time: 0.052352
[03/24/2023-12:57:35] [V] [TRT] Conv_163 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize128x256x8_stage3_warpsize2x4x1_g1_ffma Tactic: 8498373915030836990
[03/24/2023-12:57:35] [V] [TRT] Tactic: 8498373915030836990 Time: 0.761856
[03/24/2023-12:57:35] [V] [TRT] Conv_163 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x64x32_stage5_warpsize2x2x1_g1_tensor16x8x8_t1r3s3 Tactic: 8836645772682419994
[03/24/2023-12:57:35] [V] [TRT] Tactic: 8836645772682419994 Time: 0.054272
[03/24/2023-12:57:35] [V] [TRT] Conv_163 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize256x64x8_stage3_warpsize1x4x1_g1_ffma Tactic: 8869697132622550639
[03/24/2023-12:57:35] [V] [TRT] Tactic: 8869697132622550639 Time: 0.29696
[03/24/2023-12:57:35] [V] [TRT] Conv_163 Set Tactic Name: ampere_scudnn_128x128_ldg4_relu_exp_medium_nhwc_tn_v1 Tactic: 8918020581761223752
[03/24/2023-12:57:35] [V] [TRT] Tactic: 8918020581761223752 Time: 0.375168
[03/24/2023-12:57:35] [V] [TRT] Conv_163 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize64x64x64_stage4_warpsize2x2x1_g1_tensor16x8x8 Tactic: -9114138070928278731
[03/24/2023-12:57:35] [V] [TRT] Tactic: -9114138070928278731 Time: 0.064896
[03/24/2023-12:57:35] [V] [TRT] Conv_163 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize256x128x8_stage3_warpsize2x4x1_g1_ffma_t1r3s3 Tactic: -8937725997228636978
[03/24/2023-12:57:36] [V] [TRT] Tactic: -8937725997228636978 Time: 0.505728
[03/24/2023-12:57:36] [V] [TRT] Conv_163 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize128x256x8_stage3_warpsize2x4x1_g1_ffma_t1r3s3 Tactic: -8833858409138163072
[03/24/2023-12:57:36] [V] [TRT] Tactic: -8833858409138163072 Time: 0.747648
[03/24/2023-12:57:36] [V] [TRT] Conv_163 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize64x64x8_stage3_warpsize1x4x1_g1_ffma_t1r3s3 Tactic: -7989138351613022500
[03/24/2023-12:57:36] [V] [TRT] Tactic: -7989138351613022500 Time: 0.153344
[03/24/2023-12:57:36] [V] [TRT] Conv_163 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize256x128x8_stage3_warpsize2x4x1_g1_ffma Tactic: -7872883691240863058
[03/24/2023-12:57:36] [V] [TRT] Tactic: -7872883691240863058 Time: 0.463872
[03/24/2023-12:57:36] [V] [TRT] Conv_163 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x256x32_stage3_warpsize2x4x1_g1_tensor16x8x8 Tactic: -7382359095196034537
[03/24/2023-12:57:36] [V] [TRT] Tactic: -7382359095196034537 Time: 0.112768
[03/24/2023-12:57:36] [V] [TRT] Conv_163 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x128x16_stage4_warpsize2x2x1_g1_tensor16x8x8_t1r3s3 Tactic: -7377458734869418330
[03/24/2023-12:57:36] [V] [TRT] Tactic: -7377458734869418330 Time: 0.067584
[03/24/2023-12:57:36] [V] [TRT] Conv_163 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize128x128x8_stage3_warpsize2x4x1_g1_ffma Tactic: -6729618519651721910
[03/24/2023-12:57:36] [V] [TRT] Tactic: -6729618519651721910 Time: 0.341504
[03/24/2023-12:57:36] [V] [TRT] Conv_163 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize256x64x32_stage3_warpsize4x2x1_g1_tensor16x8x8_t1r3s3 Tactic: -6223854811627385844
[03/24/2023-12:57:36] [V] [TRT] Tactic: -6223854811627385844 Time: 0.05056
[03/24/2023-12:57:36] [V] [TRT] Conv_163 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize256x64x8_stage3_warpsize1x4x1_g1_ffma Tactic: -5893833996418445881
[03/24/2023-12:57:36] [V] [TRT] Tactic: -5893833996418445881 Time: 0.256768
[03/24/2023-12:57:36] [V] [TRT] Conv_163 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize128x256x8_stage3_warpsize2x4x1_g1_ffma Tactic: -5701562095007058349
[03/24/2023-12:57:36] [V] [TRT] Tactic: -5701562095007058349 Time: 0.665856
[03/24/2023-12:57:36] [V] [TRT] Conv_163 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize128x64x8_stage3_warpsize1x4x1_g1_ffma Tactic: -5685503422376017600
[03/24/2023-12:57:36] [V] [TRT] Tactic: -5685503422376017600 Time: 0.230272
[03/24/2023-12:57:36] [V] [TRT] Conv_163 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize64x64x8_stage3_warpsize1x4x1_g1_ffma Tactic: -5521125187060117489
[03/24/2023-12:57:36] [V] [TRT] Tactic: -5521125187060117489 Time: 0.159616
[03/24/2023-12:57:36] [V] [TRT] Conv_163 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x128x16_stage4_warpsize2x2x1_g1_tensor16x8x8 Tactic: -5457304872213719461
[03/24/2023-12:57:36] [V] [TRT] Tactic: -5457304872213719461 Time: 0.069376
[03/24/2023-12:57:36] [V] [TRT] Conv_163 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x64x64_stage3_warpsize2x2x1_g1_tensor16x8x8 Tactic: -5441054706931585554
[03/24/2023-12:57:36] [V] [TRT] Tactic: -5441054706931585554 Time: 0.052224
[03/24/2023-12:57:36] [V] [TRT] Conv_163 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize256x64x32_stage3_warpsize4x2x1_g1_tensor16x8x8 Tactic: -5043603702497465467
[03/24/2023-12:57:36] [V] [TRT] Tactic: -5043603702497465467 Time: 0.05888
[03/24/2023-12:57:36] [V] [TRT] Conv_163 Set Tactic Name: ampere_scudnn_128x64_sliced1x2_ldg4_relu_exp_large_nhwc_tn_v1 Tactic: -4756382386362004279
[03/24/2023-12:57:36] [V] [TRT] Tactic: -4756382386362004279 Time: 0.175104
[03/24/2023-12:57:36] [V] [TRT] Conv_163 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize64x64x8_stage3_warpsize1x4x1_g1_ffma Tactic: -4615000974950361663
[03/24/2023-12:57:36] [V] [TRT] Tactic: -4615000974950361663 Time: 0.152832
[03/24/2023-12:57:36] [V] [TRT] Conv_163 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x64x64_stage3_warpsize2x2x1_g1_tensor16x8x8 Tactic: -4564655677311401797
[03/24/2023-12:57:36] [V] [TRT] Tactic: -4564655677311401797 Time: 0.053248
[03/24/2023-12:57:36] [V] [TRT] Conv_163 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize256x64x8_stage3_warpsize1x4x1_g1_ffma_t1r3s3 Tactic: -4314913710375142296
[03/24/2023-12:57:36] [V] [TRT] Tactic: -4314913710375142296 Time: 0.246784
[03/24/2023-12:57:36] [V] [TRT] Conv_163 Set Tactic Name: ampere_scudnn_128x128_relu_exp_large_nhwc_tn_v1 Tactic: -3855385237722507464
[03/24/2023-12:57:36] [V] [TRT] Tactic: -3855385237722507464 Time: 0.334464
[03/24/2023-12:57:36] [V] [TRT] Conv_163 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize128x64x8_stage3_warpsize1x4x1_g1_ffma_t1r3s3 Tactic: -3697587361057948972
[03/24/2023-12:57:36] [V] [TRT] Tactic: -3697587361057948972 Time: 0.230784
[03/24/2023-12:57:36] [V] [TRT] Conv_163 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize256x64x32_stage3_warpsize4x2x1_g1_tensor16x8x8 Tactic: -3540975627865078064
[03/24/2023-12:57:36] [V] [TRT] Tactic: -3540975627865078064 Time: 0.054016
[03/24/2023-12:57:36] [V] [TRT] Conv_163 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize64x128x32_stage5_warpsize2x2x1_g1_tensor16x8x8_t1r3s3 Tactic: -3151804561246216835
[03/24/2023-12:57:36] [V] [TRT] Tactic: -3151804561246216835 Time: 0.075008
[03/24/2023-12:57:36] [V] [TRT] Conv_163 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize64x32x64_stage5_warpsize2x2x1_g1_tensor16x8x8 Tactic: -2885165284206163001
[03/24/2023-12:57:36] [V] [TRT] Tactic: -2885165284206163001 Time: 0.048768
[03/24/2023-12:57:36] [V] [TRT] Conv_163 Set Tactic Name: ampere_scudnn_128x128_relu_exp_medium_nhwc_tn_v1 Tactic: -2809379259463049391
[03/24/2023-12:57:36] [V] [TRT] Tactic: -2809379259463049391 Time: 0.334208
[03/24/2023-12:57:36] [V] [TRT] Conv_163 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x128x32_stage4_warpsize2x2x1_g1_tensor16x8x8_t1r3s3 Tactic: -2801041895330778813
[03/24/2023-12:57:36] [V] [TRT] Tactic: -2801041895330778813 Time: 0.07488
[03/24/2023-12:57:36] [V] [TRT] Conv_163 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize64x256x8_stage3_warpsize1x4x1_g1_ffma_t1r3s3 Tactic: -2747929399988666512
[03/24/2023-12:57:36] [V] [TRT] Tactic: -2747929399988666512 Time: 0.659712
[03/24/2023-12:57:36] [V] [TRT] Conv_163 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize256x128x32_stage3_warpsize4x2x1_g1_tensor16x8x8 Tactic: -1758690179295738332
[03/24/2023-12:57:36] [V] [TRT] Tactic: -1758690179295738332 Time: 0.083968
[03/24/2023-12:57:36] [V] [TRT] Conv_163 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x64x64_stage3_warpsize2x2x1_g1_tensor16x8x8_t1r3s3 Tactic: -1484546572846226796
[03/24/2023-12:57:36] [V] [TRT] Tactic: -1484546572846226796 Time: 0.050432
[03/24/2023-12:57:36] [V] [TRT] Conv_163 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize64x256x8_stage3_warpsize1x4x1_g1_ffma Tactic: -1472061967969061456
[03/24/2023-12:57:36] [V] [TRT] Tactic: -1472061967969061456 Time: 0.674816
[03/24/2023-12:57:36] [V] [TRT] Conv_163 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x128x32_stage4_warpsize2x2x1_g1_tensor16x8x8 Tactic: -858667497925695276
[03/24/2023-12:57:36] [V] [TRT] Tactic: -858667497925695276 Time: 0.105472
[03/24/2023-12:57:36] [V] [TRT] Conv_163 Set Tactic Name: ampere_scudnn_128x128_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: -504296718212024303
[03/24/2023-12:57:36] [V] [TRT] Tactic: -504296718212024303 Time: 0.331264
[03/24/2023-12:57:36] [V] [TRT] Conv_163 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize64x128x8_stage3_warpsize1x4x1_g1_ffma Tactic: -444093195553988951
[03/24/2023-12:57:36] [V] [TRT] Tactic: -444093195553988951 Time: 0.293888
[03/24/2023-12:57:36] [V] [TRT] Fastest Tactic: -2885165284206163001 Time: 0.048768
[03/24/2023-12:57:36] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: -2885165284206163001
[03/24/2023-12:57:36] [V] [TRT] *************** Autotuning format combination: Half(8294400,32400,180,1) -> Half(64800,32400,180,1) ***************
[03/24/2023-12:57:36] [V] [TRT] --------------- Timing Runner: Conv_163 (CudnnConvolution)
[03/24/2023-12:57:36] [V] [TRT] Tactic: 0 Time: 0.360704
[03/24/2023-12:57:36] [V] [TRT] Tactic: 1 Time: 0.147456
[03/24/2023-12:57:36] [V] [TRT] Tactic: 2 Time: 0.430592
[03/24/2023-12:57:36] [V] [TRT] Tactic: 4 Time: 0.344064
[03/24/2023-12:57:36] [V] [TRT] Tactic: 5 Time: 0.400768
[03/24/2023-12:57:36] [V] [TRT] Tactic: 6 Time: 0.397568
[03/24/2023-12:57:36] [V] [TRT] Tactic: 56 Time: 0.360704
[03/24/2023-12:57:36] [V] [TRT] Tactic: 58 Time: 0.430848
[03/24/2023-12:57:36] [V] [TRT] Tactic: 60 Time: 0.344448
[03/24/2023-12:57:36] [V] [TRT] Tactic: 61 Time: 0.427776
[03/24/2023-12:57:36] [V] [TRT] Tactic: 62 Time: 0.391936
[03/24/2023-12:57:36] [V] [TRT] Fastest Tactic: 1 Time: 0.147456
[03/24/2023-12:57:36] [V] [TRT] --------------- Timing Runner: Conv_163 (CaskConvolution)
[03/24/2023-12:57:36] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[03/24/2023-12:57:36] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CudnnConvolution Tactic: 1
[03/24/2023-12:57:36] [V] [TRT] *************** Autotuning format combination: Half(4147200,32400:2,180,1) -> Half(32400,32400:2,180,1) ***************
[03/24/2023-12:57:36] [V] [TRT] --------------- Timing Runner: Conv_163 (FusedConvActConvolution)
[03/24/2023-12:57:36] [V] [TRT] Tactic: 524287 Time: 0.047744
[03/24/2023-12:57:36] [V] [TRT] Tactic: 720895 Time: 0.072704
[03/24/2023-12:57:36] [V] [TRT] Tactic: 983039 Time: 0.067584
[03/24/2023-12:57:36] [V] [TRT] Tactic: 1048575 Time: 0.043904
[03/24/2023-12:57:36] [V] [TRT] Tactic: 1703935 Time: 0.043904
[03/24/2023-12:57:36] [V] [TRT] Tactic: 1769471 Time: 0.082944
[03/24/2023-12:57:36] [V] [TRT] Tactic: 1966079 Time: 0.077184
[03/24/2023-12:57:36] [V] [TRT] Tactic: 2031615 Time: 0.063104
[03/24/2023-12:57:36] [V] [TRT] Tactic: 2228223 Time: 0.058752
[03/24/2023-12:57:36] [V] [TRT] Tactic: 2424831 Time: 0.060416
[03/24/2023-12:57:36] [V] [TRT] Tactic: 2621439 Time: 0.045184
[03/24/2023-12:57:36] [V] [TRT] Tactic: 2752511 Time: 0.072064
[03/24/2023-12:57:36] [V] [TRT] Tactic: 3014655 Time: 0.044672
[03/24/2023-12:57:36] [V] [TRT] Tactic: 3145727 Time: 0.067456
[03/24/2023-12:57:36] [V] [TRT] Tactic: 3604479 Time: 0.045056
[03/24/2023-12:57:36] [V] [TRT] Tactic: 4390911 Time: 0.082688
[03/24/2023-12:57:36] [V] [TRT] Tactic: 5046271 Time: 0.045056
[03/24/2023-12:57:36] [V] [TRT] Tactic: 5963775 Time: 0.069504
[03/24/2023-12:57:36] [V] [TRT] Tactic: 6160383 Time: 0.046976
[03/24/2023-12:57:36] [V] [TRT] Tactic: 6488063 Time: 0.052096
[03/24/2023-12:57:36] [V] [TRT] Tactic: 6881279 Time: 0.072576
[03/24/2023-12:57:36] [V] [TRT] Tactic: 7274495 Time: 0.07872
[03/24/2023-12:57:36] [V] [TRT] Tactic: 7864319 Time: 0.048128
[03/24/2023-12:57:36] [V] [TRT] Tactic: 7995391 Time: 0.078848
[03/24/2023-12:57:36] [V] [TRT] Tactic: 8585215 Time: 0.055424
[03/24/2023-12:57:36] [V] [TRT] Tactic: 8847359 Time: 0.048896
[03/24/2023-12:57:36] [V] [TRT] Tactic: 8978431 Time: 0.069888
[03/24/2023-12:57:36] [V] [TRT] Tactic: 9043967 Time: 0.045056
[03/24/2023-12:57:36] [V] [TRT] Tactic: 9175039 Time: 0.0448
[03/24/2023-12:57:36] [V] [TRT] Tactic: 9502719 Time: 0.08128
[03/24/2023-12:57:36] [V] [TRT] Tactic: 9961471 Time: 0.059008
[03/24/2023-12:57:36] [V] [TRT] Tactic: 10027007 Time: 0.045312
[03/24/2023-12:57:36] [V] [TRT] Tactic: 10092543 Time: 0.082688
[03/24/2023-12:57:36] [V] [TRT] Tactic: 10289151 Time: 0.077312
[03/24/2023-12:57:36] [V] [TRT] Tactic: 10485759 Time: 0.04224
[03/24/2023-12:57:36] [V] [TRT] Tactic: 10682367 Time: 0.046976
[03/24/2023-12:57:36] [V] [TRT] Tactic: 10813439 Time: 0.077824
[03/24/2023-12:57:36] [V] [TRT] Fastest Tactic: 10485759 Time: 0.04224
[03/24/2023-12:57:36] [V] [TRT] --------------- Timing Runner: Conv_163 (CudnnConvolution)
[03/24/2023-12:57:36] [V] [TRT] CudnnConvolution has no valid tactics for this config, skipping
[03/24/2023-12:57:36] [V] [TRT] --------------- Timing Runner: Conv_163 (CaskConvolution)
[03/24/2023-12:57:36] [V] [TRT] Conv_163 Set Tactic Name: ampere_fp16x2_hcudnn_fp16x2_128x32_relu_medium_nn_v1 Tactic: 2195670545862694453
[03/24/2023-12:57:36] [V] [TRT] Tactic: 2195670545862694453 Time: 0.073728
[03/24/2023-12:57:36] [V] [TRT] Conv_163 Set Tactic Name: ampere_fp16x2_hcudnn_fp16x2_128x64_relu_large_nn_v1 Tactic: 3419182076704469245
[03/24/2023-12:57:36] [V] [TRT] Tactic: 3419182076704469245 Time: 0.101376
[03/24/2023-12:57:36] [V] [TRT] Conv_163 Set Tactic Name: ampere_fp16x2_hcudnn_fp16x2_128x128_relu_medium_nn_v1 Tactic: 3891805945559659536
[03/24/2023-12:57:36] [V] [TRT] Tactic: 3891805945559659536 Time: 0.1824
[03/24/2023-12:57:36] [V] [TRT] Conv_163 Set Tactic Name: ampere_fp16x2_hcudnn_fp16x2_128x64_relu_medium_nn_v1 Tactic: 5548126322150286555
[03/24/2023-12:57:36] [V] [TRT] Tactic: 5548126322150286555 Time: 0.100352
[03/24/2023-12:57:36] [V] [TRT] Conv_163 Set Tactic Name: ampere_fp16x2_hcudnn_fp16x2_128x64_relu_small_nn_v1 Tactic: 6057304366605292508
[03/24/2023-12:57:36] [V] [TRT] Tactic: 6057304366605292508 Time: 0.098176
[03/24/2023-12:57:36] [V] [TRT] Conv_163 Set Tactic Name: ampere_fp16x2_hcudnn_fp16x2_128x128_relu_large_nn_v1 Tactic: -7928611605886347652
[03/24/2023-12:57:36] [V] [TRT] Tactic: -7928611605886347652 Time: 0.188416
[03/24/2023-12:57:36] [V] [TRT] Conv_163 Set Tactic Name: ampere_fp16x2_hcudnn_fp16x2_128x32_relu_large_nn_v1 Tactic: -5172391392092686714
[03/24/2023-12:57:36] [V] [TRT] Tactic: -5172391392092686714 Time: 0.07424
[03/24/2023-12:57:36] [V] [TRT] Conv_163 Set Tactic Name: ampere_fp16x2_hcudnn_fp16x2_128x32_relu_small_nn_v1 Tactic: -4374269919094467161
[03/24/2023-12:57:36] [V] [TRT] Tactic: -4374269919094467161 Time: 0.07168
[03/24/2023-12:57:36] [V] [TRT] Conv_163 Set Tactic Name: ampere_fp16x2_hcudnn_winograd_fp16x2_128x128_ldg1_ldg4_relu_tile148t_nt_v1 Tactic: -4083394051665370953
[03/24/2023-12:57:36] [V] [TRT] Tactic: -4083394051665370953 Time: 0.032
[03/24/2023-12:57:36] [V] [TRT] Conv_163 Set Tactic Name: ampere_fp16x2_hcudnn_fp16x2_128x128_relu_small_nn_v1 Tactic: -1546027692247304867
[03/24/2023-12:57:36] [V] [TRT] Tactic: -1546027692247304867 Time: 0.183168
[03/24/2023-12:57:36] [V] [TRT] Fastest Tactic: -4083394051665370953 Time: 0.032
[03/24/2023-12:57:36] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: -4083394051665370953
[03/24/2023-12:57:36] [V] [TRT] *************** Autotuning format combination: Half(1036800,1:8,5760,32) -> Float(64800,32400,180,1) ***************
[03/24/2023-12:57:36] [V] [TRT] --------------- Timing Runner: Conv_163 (CudnnConvolution)
[03/24/2023-12:57:36] [V] [TRT] CudnnConvolution has no valid tactics for this config, skipping
[03/24/2023-12:57:36] [V] [TRT] --------------- Timing Runner: Conv_163 (CaskConvolution)
[03/24/2023-12:57:36] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[03/24/2023-12:57:36] [V] [TRT] *************** Autotuning format combination: Half(1036800,1:8,5760,32) -> Half(32400,1:8,180,1) ***************
[03/24/2023-12:57:36] [V] [TRT] --------------- Timing Runner: Conv_163 (CudaDepthwiseConvolution)
[03/24/2023-12:57:36] [V] [TRT] CudaDepthwiseConvolution has no valid tactics for this config, skipping
[03/24/2023-12:57:36] [V] [TRT] --------------- Timing Runner: Conv_163 (CudnnConvolution)
[03/24/2023-12:57:36] [V] [TRT] CudnnConvolution has no valid tactics for this config, skipping
[03/24/2023-12:57:36] [V] [TRT] --------------- Timing Runner: Conv_163 (CaskConvolution)
[03/24/2023-12:57:36] [V] [TRT] Conv_163 Set Tactic Name: ampere_h16816cudnn_256x128_ldg8_relu_exp_medium_nhwc_tn_v1 Tactic: 254850674756030979
[03/24/2023-12:57:36] [V] [TRT] Tactic: 254850674756030979 Time: 0.045184
[03/24/2023-12:57:36] [V] [TRT] Conv_163 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x128x32_stage3_warpsize4x2x1_g1_tensor16x8x16_t1r3s3 Tactic: 328038211831149625
[03/24/2023-12:57:36] [V] [TRT] Tactic: 328038211831149625 Time: 0.043904
[03/24/2023-12:57:36] [V] [TRT] Conv_163 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x64x64_stage3_warpsize2x2x1_g1_tensor16x8x16_t1r3s3 Tactic: 411553864378931917
[03/24/2023-12:57:37] [V] [TRT] Tactic: 411553864378931917 Time: 0.024704
[03/24/2023-12:57:37] [V] [TRT] Conv_163 Set Tactic Name: sm75_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x128x32_stage1_warpsize4x2x1_g1_tensor16x8x8_t1r3s3 Tactic: 864841579020773074
[03/24/2023-12:57:37] [V] [TRT] Tactic: 864841579020773074 Time: 0.050176
[03/24/2023-12:57:37] [V] [TRT] Conv_163 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x128x32_stage4_warpsize2x2x1_g1_tensor16x8x16 Tactic: 1011057357468998345
[03/24/2023-12:57:37] [V] [TRT] Tactic: 1011057357468998345 Time: 0.037248
[03/24/2023-12:57:37] [V] [TRT] Conv_163 Set Tactic Name: sm75_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x64x32_stage1_warpsize4x1x1_g1_tensor16x8x8 Tactic: 1013168150133367738
[03/24/2023-12:57:37] [V] [TRT] Tactic: 1013168150133367738 Time: 0.033536
[03/24/2023-12:57:37] [V] [TRT] Conv_163 Set Tactic Name: ampere_h16816cudnn_256x128_ldg8_relu_exp_stages_64x3_small_nhwc_tn_v1 Tactic: 1016009564074305832
[03/24/2023-12:57:37] [V] [TRT] Tactic: 1016009564074305832 Time: 0.045568
[03/24/2023-12:57:37] [V] [TRT] Conv_163 Set Tactic Name: sm75_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x128x32_stage1_warpsize2x2x1_g1_tensor16x8x8 Tactic: 1067227531433278814
[03/24/2023-12:57:37] [V] [TRT] Tactic: 1067227531433278814 Time: 0.041088
[03/24/2023-12:57:37] [V] [TRT] Conv_163 Set Tactic Name: ampere_h1688cudnn_128x128_ldg8_relu_exp_medium_nhwc_tn_v1 Tactic: 1156328698016730421
[03/24/2023-12:57:37] [V] [TRT] Tactic: 1156328698016730421 Time: 0.049792
[03/24/2023-12:57:37] [V] [TRT] Conv_163 Set Tactic Name: sm75_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x128x32_stage1_warpsize2x2x1_g1_tensor16x8x8 Tactic: 1579845938601132607
[03/24/2023-12:57:37] [V] [TRT] Tactic: 1579845938601132607 Time: 0.04096
[03/24/2023-12:57:37] [V] [TRT] Conv_163 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x128x32_stage5_warpsize2x2x1_g1_tensor16x8x16_t1r3s3 Tactic: 1723736032573714698
[03/24/2023-12:57:37] [V] [TRT] Tactic: 1723736032573714698 Time: 0.0352
[03/24/2023-12:57:37] [V] [TRT] Conv_163 Set Tactic Name: sm75_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x32x32_stage1_warpsize4x1x1_g1_tensor16x8x8 Tactic: 1796821236841789338
[03/24/2023-12:57:37] [V] [TRT] Tactic: 1796821236841789338 Time: 0.025344
[03/24/2023-12:57:37] [V] [TRT] Conv_163 Set Tactic Name: ampere_h16816cudnn_128x64_ldg8_relu_exp_stages_64x4_medium_nhwc_tn_v1 Tactic: 1832046141070096030
[03/24/2023-12:57:37] [V] [TRT] Tactic: 1832046141070096030 Time: 0.03072
[03/24/2023-12:57:37] [V] [TRT] Conv_163 Set Tactic Name: ampere_h16816cudnn_128x64_sliced1x2_ldg8_relu_exp_stages_64x3_small_nhwc_tn_v1 Tactic: 1838082074606840426
[03/24/2023-12:57:37] [V] [TRT] Tactic: 1838082074606840426 Time: 0.025856
[03/24/2023-12:57:37] [V] [TRT] Conv_163 Set Tactic Name: ampere_h16816cudnn_64x64_sliced1x2_ldg8_relu_exp_stages_64x5_small_nhwc_tn_v1 Tactic: 1899296423087490472
[03/24/2023-12:57:37] [V] [TRT] Tactic: 1899296423087490472 Time: 0.031744
[03/24/2023-12:57:37] [V] [TRT] Conv_163 Set Tactic Name: sm75_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x32x32_stage1_warpsize4x1x1_g1_tensor16x8x8 Tactic: 1948263663414159978
[03/24/2023-12:57:37] [V] [TRT] Tactic: 1948263663414159978 Time: 0.028288
[03/24/2023-12:57:37] [V] [TRT] Conv_163 Set Tactic Name: sm75_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x256x64_stage1_warpsize1x4x2_g1_tensor16x8x8 Tactic: 2027733232253711640
[03/24/2023-12:57:37] [V] [TRT] Tactic: 2027733232253711640 Time: 0.0704
[03/24/2023-12:57:37] [V] [TRT] Conv_163 Set Tactic Name: sm75_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x64x32_stage1_warpsize2x2x1_g1_tensor16x8x8_t1r3s3 Tactic: 2154731107061273008
[03/24/2023-12:57:37] [V] [TRT] Tactic: 2154731107061273008 Time: 0.029568
[03/24/2023-12:57:37] [V] [TRT] Conv_163 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x64x64_stage3_warpsize2x2x1_g1_tensor16x8x16 Tactic: 2428167804343994714
[03/24/2023-12:57:37] [V] [TRT] Tactic: 2428167804343994714 Time: 0.025728
[03/24/2023-12:57:37] [V] [TRT] Conv_163 Set Tactic Name: ampere_h16816cudnn_128x128_ldg8_relu_exp_medium_nhwc_tn_v1 Tactic: 2541579301352125276
[03/24/2023-12:57:37] [V] [TRT] Tactic: 2541579301352125276 Time: 0.034944
[03/24/2023-12:57:37] [V] [TRT] Conv_163 Set Tactic Name: ampere_h16816cudnn_64x64_sliced1x2_ldg8_relu_exp_stages_64x6_small_nhwc_tn_v1 Tactic: 2657157263811141609
[03/24/2023-12:57:37] [V] [TRT] Tactic: 2657157263811141609 Time: 0.036736
[03/24/2023-12:57:37] [V] [TRT] Conv_163 Set Tactic Name: ampere_h16816cudnn_64x128_sliced1x2_ldg8_relu_exp_stages_64x4_large_nhwc_tn_v1 Tactic: 2819719497590964443
[03/24/2023-12:57:37] [V] [TRT] Tactic: 2819719497590964443 Time: 0.049152
[03/24/2023-12:57:37] [V] [TRT] Conv_163 Set Tactic Name: ampere_h16816cudnn_128x64_sliced1x2_ldg8_relu_exp_stages_64x3_medium_nhwc_tn_v1 Tactic: 2968605903460894194
[03/24/2023-12:57:37] [V] [TRT] Tactic: 2968605903460894194 Time: 0.026368
[03/24/2023-12:57:37] [V] [TRT] Conv_163 Set Tactic Name: ampere_h16816cudnn_128x128_ldg8_relu_exp_large_nhwc_tn_v1 Tactic: 2986078304285316765
[03/24/2023-12:57:37] [V] [TRT] Tactic: 2986078304285316765 Time: 0.035456
[03/24/2023-12:57:37] [V] [TRT] Conv_163 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x256x64_stage3_warpsize1x4x1_g1_tensor16x8x16 Tactic: 3016308193087082166
[03/24/2023-12:57:37] [V] [TRT] Tactic: 3016308193087082166 Time: 0.065408
[03/24/2023-12:57:37] [V] [TRT] Conv_163 Set Tactic Name: ampere_h16816cudnn_256x64_ldg8_relu_exp_stages_64x3_large_nhwc_tn_v1 Tactic: 3221382575080507859
[03/24/2023-12:57:37] [V] [TRT] Tactic: 3221382575080507859 Time: 0.030592
[03/24/2023-12:57:37] [V] [TRT] Conv_163 Set Tactic Name: ampere_h16816cudnn_128x128_ldg8_relu_exp_stages_64x3_medium_nhwc_tn_v1 Tactic: 3362537467505018070
[03/24/2023-12:57:37] [V] [TRT] Tactic: 3362537467505018070 Time: 0.04096
[03/24/2023-12:57:37] [V] [TRT] Conv_163 Set Tactic Name: sm75_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x64x32_stage1_warpsize4x1x1_g1_tensor16x8x8_t1r3s3 Tactic: 3464689803495983377
[03/24/2023-12:57:37] [V] [TRT] Tactic: 3464689803495983377 Time: 0.032512
[03/24/2023-12:57:37] [V] [TRT] Conv_163 Set Tactic Name: ampere_h1688cudnn_256x128_ldg8_relu_exp_medium_nhwc_tn_v1 Tactic: 3513075359009385578
[03/24/2023-12:57:37] [V] [TRT] Tactic: 3513075359009385578 Time: 0.052992
[03/24/2023-12:57:37] [V] [TRT] Conv_163 Set Tactic Name: ampere_h16816cudnn_128x64_ldg8_relu_exp_stages_64x4_large_nhwc_tn_v1 Tactic: 3573559043797674382
[03/24/2023-12:57:37] [V] [TRT] Tactic: 3573559043797674382 Time: 0.031616
[03/24/2023-12:57:37] [V] [TRT] Conv_163 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x64x64_stage4_warpsize2x2x1_g1_tensor16x8x16_t1r3s3 Tactic: 3591970081995419777
[03/24/2023-12:57:37] [V] [TRT] Tactic: 3591970081995419777 Time: 0.028672
[03/24/2023-12:57:37] [V] [TRT] Conv_163 Set Tactic Name: sm75_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x128x32_stage1_warpsize2x2x1_g1_tensor16x8x8_t1r3s3 Tactic: 3636831327753843771
[03/24/2023-12:57:37] [V] [TRT] Tactic: 3636831327753843771 Time: 0.038144
[03/24/2023-12:57:37] [V] [TRT] Conv_163 Set Tactic Name: ampere_h1688cudnn_128x128_ldg8_relu_exp_small_nhwc_tn_v1 Tactic: 3704534001553878387
[03/24/2023-12:57:37] [V] [TRT] Tactic: 3704534001553878387 Time: 0.04608
[03/24/2023-12:57:37] [V] [TRT] Conv_163 Set Tactic Name: ampere_h16816cudnn_64x128_ldg8_relu_exp_stages_64x4_small_nhwc_tn_v1 Tactic: 4278315135102886928
[03/24/2023-12:57:37] [V] [TRT] Tactic: 4278315135102886928 Time: 0.043008
[03/24/2023-12:57:37] [V] [TRT] Conv_163 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x32x32_stage4_warpsize4x1x1_g1_tensor16x8x16_t1r3s3 Tactic: 4503233883285355107
[03/24/2023-12:57:37] [V] [TRT] Tactic: 4503233883285355107 Time: 0.020352
[03/24/2023-12:57:37] [V] [TRT] Conv_163 Set Tactic Name: ampere_h16816cudnn_256x64_ldg8_relu_exp_stages_64x3_medium_nhwc_tn_v1 Tactic: 4540505769798915372
[03/24/2023-12:57:37] [V] [TRT] Tactic: 4540505769798915372 Time: 0.030592
[03/24/2023-12:57:37] [V] [TRT] Conv_163 Set Tactic Name: ampere_h16816cudnn_256x64_sliced1x2_ldg8_relu_exp_small_nhwc_tn_v1 Tactic: 4802447371470387646
[03/24/2023-12:57:37] [V] [TRT] Tactic: 4802447371470387646 Time: 0.03264
[03/24/2023-12:57:37] [V] [TRT] Conv_163 Set Tactic Name: ampere_h16816cudnn_256x128_ldg8_relu_exp_small_nhwc_tn_v1 Tactic: 5059676457552313631
[03/24/2023-12:57:37] [V] [TRT] Tactic: 5059676457552313631 Time: 0.044928
[03/24/2023-12:57:37] [V] [TRT] Conv_163 Set Tactic Name: sm75_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x128x64_stage1_warpsize2x2x1_g1_tensor16x8x8_t1r3s3 Tactic: 5263029549013613567
[03/24/2023-12:57:37] [V] [TRT] Tactic: 5263029549013613567 Time: 0.038784
[03/24/2023-12:57:37] [V] [TRT] Conv_163 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x64x64_stage4_warpsize2x2x1_g1_tensor16x8x16 Tactic: 5368829646735632944
[03/24/2023-12:57:37] [V] [TRT] Tactic: 5368829646735632944 Time: 0.030336
[03/24/2023-12:57:37] [V] [TRT] Conv_163 Set Tactic Name: ampere_h1688cudnn_256x64_sliced1x2_ldg8_relu_exp_small_nhwc_tn_v1 Tactic: 5398999388616959893
[03/24/2023-12:57:37] [V] [TRT] Tactic: 5398999388616959893 Time: 0.03584
[03/24/2023-12:57:37] [V] [TRT] Conv_163 Set Tactic Name: sm75_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x256x32_stage1_warpsize2x4x1_g1_tensor16x8x8_t1r3s3 Tactic: 5506334059535811602
[03/24/2023-12:57:37] [V] [TRT] Tactic: 5506334059535811602 Time: 0.068736
[03/24/2023-12:57:37] [V] [TRT] Conv_163 Set Tactic Name: ampere_h16816cudnn_64x128_sliced1x2_ldg8_relu_exp_stages_64x3_large_nhwc_tn_v1 Tactic: 5746691132547383910
[03/24/2023-12:57:37] [V] [TRT] Tactic: 5746691132547383910 Time: 0.036736
[03/24/2023-12:57:37] [V] [TRT] Conv_163 Set Tactic Name: ampere_h16816cudnn_256x64_ldg8_relu_exp_large_nhwc_tn_v1 Tactic: 5770170567977052602
[03/24/2023-12:57:37] [V] [TRT] Tactic: 5770170567977052602 Time: 0.031616
[03/24/2023-12:57:37] [V] [TRT] Conv_163 Set Tactic Name: sm75_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x32x64_stage1_warpsize2x1x2_g1_tensor16x8x8_t1r3s3 Tactic: 5932046018238429951
[03/24/2023-12:57:37] [V] [TRT] Tactic: 5932046018238429951 Time: 0.022272
[03/24/2023-12:57:37] [V] [TRT] Conv_163 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x64x32_stage3_warpsize4x1x1_g1_tensor16x8x16_t1r3s3 Tactic: 5953552212833506549
[03/24/2023-12:57:37] [V] [TRT] Tactic: 5953552212833506549 Time: 0.02688
[03/24/2023-12:57:37] [V] [TRT] Conv_163 Set Tactic Name: ampere_h16816cudnn_64x128_ldg8_relu_exp_stages_64x3_small_nhwc_tn_v1 Tactic: 6034364043891107501
[03/24/2023-12:57:37] [V] [TRT] Tactic: 6034364043891107501 Time: 0.037888
[03/24/2023-12:57:37] [V] [TRT] Conv_163 Set Tactic Name: ampere_h16816cudnn_64x64_ldg8_relu_exp_stages_64x5_large_nhwc_tn_v1 Tactic: 6074229447555668232
[03/24/2023-12:57:37] [V] [TRT] Tactic: 6074229447555668232 Time: 0.03328
[03/24/2023-12:57:37] [V] [TRT] Conv_163 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x64x64_stage3_warpsize2x2x1_g1_tensor16x8x16 Tactic: 6154447660803990543
[03/24/2023-12:57:37] [V] [TRT] Tactic: 6154447660803990543 Time: 0.025728
[03/24/2023-12:57:37] [V] [TRT] Conv_163 Set Tactic Name: sm75_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x32x64_stage1_warpsize2x1x2_g1_tensor16x8x8 Tactic: 6195603576432354734
[03/24/2023-12:57:37] [V] [TRT] Tactic: 6195603576432354734 Time: 0.024448
[03/24/2023-12:57:37] [V] [TRT] Conv_163 Set Tactic Name: sm75_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x32x32_stage1_warpsize4x1x1_g1_tensor16x8x8_t1r3s3 Tactic: 6252808259936499253
[03/24/2023-12:57:37] [V] [TRT] Tactic: 6252808259936499253 Time: 0.027904
[03/24/2023-12:57:37] [V] [TRT] Conv_163 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x128x64_stage3_warpsize2x2x1_g1_tensor16x8x16 Tactic: 6325769668000961702
[03/24/2023-12:57:37] [V] [TRT] Tactic: 6325769668000961702 Time: 0.042496
[03/24/2023-12:57:37] [V] [TRT] Conv_163 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x32x64_stage5_warpsize2x2x1_g1_tensor16x8x16 Tactic: 6350273239113254096
[03/24/2023-12:57:37] [V] [TRT] Tactic: 6350273239113254096 Time: 0.026752
[03/24/2023-12:57:37] [V] [TRT] Conv_163 Set Tactic Name: ampere_h16816cudnn_128x128_ldg8_relu_exp_stages_64x3_small_nhwc_tn_v1 Tactic: 6377497238381488891
[03/24/2023-12:57:37] [V] [TRT] Tactic: 6377497238381488891 Time: 0.040704
[03/24/2023-12:57:37] [V] [TRT] Conv_163 Set Tactic Name: sm75_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x64x64_stage1_warpsize2x2x1_g1_tensor16x8x8 Tactic: 6408235920257988861
[03/24/2023-12:57:37] [V] [TRT] Tactic: 6408235920257988861 Time: 0.028544
[03/24/2023-12:57:37] [V] [TRT] Conv_163 Set Tactic Name: ampere_h16816cudnn_128x64_ldg8_relu_exp_stages_64x3_large_nhwc_tn_v1 Tactic: 6446388116965632819
[03/24/2023-12:57:37] [V] [TRT] Tactic: 6446388116965632819 Time: 0.028544
[03/24/2023-12:57:37] [V] [TRT] Conv_163 Set Tactic Name: ampere_h16816cudnn_128x64_sliced1x2_ldg8_relu_exp_stages_64x4_medium_nhwc_tn_v1 Tactic: 6468794451065529747
[03/24/2023-12:57:37] [V] [TRT] Tactic: 6468794451065529747 Time: 0.03136
[03/24/2023-12:57:37] [V] [TRT] Conv_163 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x128x64_stage3_warpsize4x2x1_g1_tensor16x8x16 Tactic: 6509152032538119080
[03/24/2023-12:57:37] [V] [TRT] Tactic: 6509152032538119080 Time: 0.046464
[03/24/2023-12:57:37] [V] [TRT] Conv_163 Set Tactic Name: ampere_h1688cudnn_256x128_ldg8_relu_exp_large_nhwc_tn_v1 Tactic: 6642277870194067185
[03/24/2023-12:57:37] [V] [TRT] Tactic: 6642277870194067185 Time: 0.054272
[03/24/2023-12:57:37] [V] [TRT] Conv_163 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x256x64_stage3_warpsize1x4x1_g1_tensor16x8x16 Tactic: 6703181542003057635
[03/24/2023-12:57:37] [V] [TRT] Tactic: 6703181542003057635 Time: 0.064512
[03/24/2023-12:57:37] [V] [TRT] Conv_163 Set Tactic Name: ampere_h16816cudnn_64x64_ldg8_relu_exp_stages_64x5_medium_nhwc_tn_v1 Tactic: 6859477213531075460
[03/24/2023-12:57:37] [V] [TRT] Tactic: 6859477213531075460 Time: 0.032896
[03/24/2023-12:57:37] [V] [TRT] Conv_163 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x128x32_stage4_warpsize2x2x1_g1_tensor16x8x16_t1r3s3 Tactic: 6972489290272968208
[03/24/2023-12:57:37] [V] [TRT] Tactic: 6972489290272968208 Time: 0.033664
[03/24/2023-12:57:37] [V] [TRT] Conv_163 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x128x32_stage3_warpsize4x2x1_g1_tensor16x8x16 Tactic: 6979044990896381511
[03/24/2023-12:57:37] [V] [TRT] Tactic: 6979044990896381511 Time: 0.043904
[03/24/2023-12:57:37] [V] [TRT] Conv_163 Set Tactic Name: ampere_h1688cudnn_256x64_ldg8_relu_exp_medium_nhwc_tn_v1 Tactic: 7216571380637776659
[03/24/2023-12:57:37] [V] [TRT] Tactic: 7216571380637776659 Time: 0.03584
[03/24/2023-12:57:37] [V] [TRT] Conv_163 Set Tactic Name: ampere_h16816cudnn_128x64_ldg8_relu_exp_stages_64x3_medium_nhwc_tn_v1 Tactic: 7609923741161019135
[03/24/2023-12:57:37] [V] [TRT] Tactic: 7609923741161019135 Time: 0.027904
[03/24/2023-12:57:37] [V] [TRT] Conv_163 Set Tactic Name: sm75_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x64x32_stage1_warpsize2x2x1_g1_tensor16x8x8 Tactic: 7612687199567064086
[03/24/2023-12:57:37] [V] [TRT] Tactic: 7612687199567064086 Time: 0.03072
[03/24/2023-12:57:37] [V] [TRT] Conv_163 Set Tactic Name: ampere_h16816cudnn_64x64_ldg8_relu_exp_stages_64x6_large_nhwc_tn_v1 Tactic: 7705739241028240201
[03/24/2023-12:57:37] [V] [TRT] Tactic: 7705739241028240201 Time: 0.038912
[03/24/2023-12:57:37] [V] [TRT] Conv_163 Set Tactic Name: sm75_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x128x32_stage1_warpsize2x2x1_g1_tensor16x8x8 Tactic: 7729555994715864793
[03/24/2023-12:57:37] [V] [TRT] Tactic: 7729555994715864793 Time: 0.040832
[03/24/2023-12:57:37] [V] [TRT] Conv_163 Set Tactic Name: sm75_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x64x64_stage1_warpsize2x2x1_g1_tensor16x8x8_t1r3s3 Tactic: 7849296535223586261
[03/24/2023-12:57:37] [V] [TRT] Tactic: 7849296535223586261 Time: 0.028544
[03/24/2023-12:57:37] [V] [TRT] Conv_163 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x256x32_stage3_warpsize2x4x1_g1_tensor16x8x16 Tactic: 8072087735545283117
[03/24/2023-12:57:37] [V] [TRT] Tactic: 8072087735545283117 Time: 0.061184
[03/24/2023-12:57:37] [V] [TRT] Conv_163 Set Tactic Name: ampere_h16816cudnn_64x64_sliced1x2_ldg8_relu_exp_stages_64x5_medium_nhwc_tn_v1 Tactic: 8101703987960976805
[03/24/2023-12:57:37] [V] [TRT] Tactic: 8101703987960976805 Time: 0.031744
[03/24/2023-12:57:37] [V] [TRT] Conv_163 Set Tactic Name: ampere_h16816cudnn_128x64_sliced1x2_ldg8_relu_exp_stages_64x4_small_nhwc_tn_v1 Tactic: 8170606396342855895
[03/24/2023-12:57:37] [V] [TRT] Tactic: 8170606396342855895 Time: 0.030592
[03/24/2023-12:57:37] [V] [TRT] Conv_163 Set Tactic Name: sm75_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x32x64_stage1_warpsize2x1x2_g1_tensor16x8x8 Tactic: 8455608235315878803
[03/24/2023-12:57:37] [V] [TRT] Tactic: 8455608235315878803 Time: 0.025472
[03/24/2023-12:57:37] [V] [TRT] Conv_163 Set Tactic Name: sm75_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x64x64_stage1_warpsize2x2x1_g1_tensor16x8x8 Tactic: 8668812313058150080
[03/24/2023-12:57:37] [V] [TRT] Tactic: 8668812313058150080 Time: 0.029568
[03/24/2023-12:57:37] [V] [TRT] Conv_163 Set Tactic Name: ampere_h1688cudnn_256x64_ldg8_relu_exp_small_nhwc_tn_v1 Tactic: 8839784824303350101
[03/24/2023-12:57:37] [V] [TRT] Tactic: 8839784824303350101 Time: 0.033664
[03/24/2023-12:57:37] [V] [TRT] Conv_163 Set Tactic Name: ampere_h16816cudnn_64x64_sliced1x2_ldg8_relu_exp_stages_64x5_large_nhwc_tn_v1 Tactic: -9217371357561775773
[03/24/2023-12:57:37] [V] [TRT] Tactic: -9217371357561775773 Time: 0.030464
[03/24/2023-12:57:37] [V] [TRT] Conv_163 Set Tactic Name: ampere_h16816cudnn_256x64_sliced1x2_ldg8_relu_exp_medium_nhwc_tn_v1 Tactic: -9009272790678027912
[03/24/2023-12:57:37] [V] [TRT] Tactic: -9009272790678027912 Time: 0.035584
[03/24/2023-12:57:37] [V] [TRT] Conv_163 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x32x32_stage4_warpsize4x1x1_g1_tensor16x8x16 Tactic: -8985224497679592364
[03/24/2023-12:57:37] [V] [TRT] Tactic: -8985224497679592364 Time: 0.020224
[03/24/2023-12:57:37] [V] [TRT] Conv_163 Set Tactic Name: ampere_h16816cudnn_128x64_sliced1x2_ldg8_relu_exp_stages_64x3_large_nhwc_tn_v1 Tactic: -8949544755481315679
[03/24/2023-12:57:37] [V] [TRT] Tactic: -8949544755481315679 Time: 0.026624
[03/24/2023-12:57:37] [V] [TRT] Conv_163 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x64x64_stage3_warpsize4x1x1_g1_tensor16x8x16_t1r3s3 Tactic: -8867999442759527766
[03/24/2023-12:57:37] [V] [TRT] Tactic: -8867999442759527766 Time: 0.032512
[03/24/2023-12:57:37] [V] [TRT] Conv_163 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x128x64_stage3_warpsize2x2x1_g1_tensor16x8x16 Tactic: -8759929675070720385
[03/24/2023-12:57:37] [V] [TRT] Tactic: -8759929675070720385 Time: 0.040832
[03/24/2023-12:57:37] [V] [TRT] Conv_163 Set Tactic Name: ampere_h16816cudnn_64x64_ldg8_relu_exp_stages_64x6_medium_nhwc_tn_v1 Tactic: -8604374562669615024
[03/24/2023-12:57:37] [V] [TRT] Tactic: -8604374562669615024 Time: 0.037888
[03/24/2023-12:57:37] [V] [TRT] Conv_163 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x128x64_stage3_warpsize4x2x1_g1_tensor16x8x16 Tactic: -8362347876645295759
[03/24/2023-12:57:37] [V] [TRT] Tactic: -8362347876645295759 Time: 0.0448
[03/24/2023-12:57:37] [V] [TRT] Conv_163 Set Tactic Name: sm75_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x128x32_stage1_warpsize4x2x1_g1_tensor16x8x8 Tactic: -8254009616492665198
[03/24/2023-12:57:37] [V] [TRT] Tactic: -8254009616492665198 Time: 0.050048
[03/24/2023-12:57:37] [V] [TRT] Conv_163 Set Tactic Name: ampere_h16816cudnn_256x128_ldg8_relu_exp_stages_64x3_large_nhwc_tn_v1 Tactic: -7757610000269494813
[03/24/2023-12:57:37] [V] [TRT] Tactic: -7757610000269494813 Time: 0.045952
[03/24/2023-12:57:37] [V] [TRT] Conv_163 Set Tactic Name: sm75_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x128x32_stage1_warpsize4x2x1_g1_tensor16x8x8 Tactic: -7615325597099025933
[03/24/2023-12:57:37] [V] [TRT] Tactic: -7615325597099025933 Time: 0.0512
[03/24/2023-12:57:37] [V] [TRT] Conv_163 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x64x64_stage3_warpsize4x1x1_g1_tensor16x8x16 Tactic: -6917689122519989488
[03/24/2023-12:57:37] [V] [TRT] Tactic: -6917689122519989488 Time: 0.03136
[03/24/2023-12:57:37] [V] [TRT] Conv_163 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x32x64_stage5_warpsize2x2x1_g1_tensor16x8x16_t1r3s3 Tactic: -6902925267326201166
[03/24/2023-12:57:37] [V] [TRT] Tactic: -6902925267326201166 Time: 0.025472
[03/24/2023-12:57:37] [V] [TRT] Conv_163 Set Tactic Name: ampere_h16816cudnn_64x128_ldg8_relu_exp_stages_64x4_large_nhwc_tn_v1 Tactic: -6840588038605932325
[03/24/2023-12:57:37] [V] [TRT] Tactic: -6840588038605932325 Time: 0.04416
[03/24/2023-12:57:37] [V] [TRT] Conv_163 Set Tactic Name: sm75_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x32x32_stage1_warpsize4x1x1_g1_tensor16x8x8 Tactic: -6828337260021572283
[03/24/2023-12:57:37] [V] [TRT] Tactic: -6828337260021572283 Time: 0.026496
[03/24/2023-12:57:37] [V] [TRT] Conv_163 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x256x32_stage3_warpsize2x4x1_g1_tensor16x8x16 Tactic: -6799856376604253964
[03/24/2023-12:57:37] [V] [TRT] Tactic: -6799856376604253964 Time: 0.061568
[03/24/2023-12:57:37] [V] [TRT] Conv_163 Set Tactic Name: sm75_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x32x32_stage1_warpsize4x1x1_g1_tensor16x8x8 Tactic: -6711815420995272523
[03/24/2023-12:57:37] [V] [TRT] Tactic: -6711815420995272523 Time: 0.030464
[03/24/2023-12:57:37] [V] [TRT] Conv_163 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x32x32_stage4_warpsize4x1x1_g1_tensor16x8x16_t1r3s3 Tactic: -6625722781282978136
[03/24/2023-12:57:37] [V] [TRT] Tactic: -6625722781282978136 Time: 0.021248
[03/24/2023-12:57:37] [V] [TRT] Conv_163 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x64x32_stage3_warpsize4x1x1_g1_tensor16x8x16 Tactic: -6525498856028268801
[03/24/2023-12:57:37] [V] [TRT] Tactic: -6525498856028268801 Time: 0.028032
[03/24/2023-12:57:37] [V] [TRT] Conv_163 Set Tactic Name: sm75_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x256x64_stage1_warpsize1x4x2_g1_tensor16x8x8 Tactic: -6489479581011009593
[03/24/2023-12:57:37] [V] [TRT] Tactic: -6489479581011009593 Time: 0.070528
[03/24/2023-12:57:37] [V] [TRT] Conv_163 Set Tactic Name: ampere_h16816cudnn_64x64_sliced1x2_ldg8_relu_exp_stages_64x6_medium_nhwc_tn_v1 Tactic: -6356316196810535311
[03/24/2023-12:57:37] [V] [TRT] Tactic: -6356316196810535311 Time: 0.03968
[03/24/2023-12:57:37] [V] [TRT] Conv_163 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x32x32_stage4_warpsize4x1x1_g1_tensor16x8x16 Tactic: -6324345858751792783
[03/24/2023-12:57:37] [V] [TRT] Tactic: -6324345858751792783 Time: 0.0224
[03/24/2023-12:57:37] [V] [TRT] Conv_163 Set Tactic Name: sm75_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x256x64_stage1_warpsize1x4x2_g1_tensor16x8x8_t1r3s3 Tactic: -6320761427625651496
[03/24/2023-12:57:37] [V] [TRT] Tactic: -6320761427625651496 Time: 0.069632
[03/24/2023-12:57:37] [V] [TRT] Conv_163 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x256x32_stage3_warpsize2x4x1_g1_tensor16x8x16_t1r3s3 Tactic: -6262400699544994312
[03/24/2023-12:57:37] [V] [TRT] Tactic: -6262400699544994312 Time: 0.060416
[03/24/2023-12:57:37] [V] [TRT] Conv_163 Set Tactic Name: ampere_h1688cudnn_128x128_ldg8_relu_exp_large_nhwc_tn_v1 Tactic: -6257787336162086472
[03/24/2023-12:57:37] [V] [TRT] Tactic: -6257787336162086472 Time: 0.052096
[03/24/2023-12:57:37] [V] [TRT] Conv_163 Set Tactic Name: sm75_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x128x64_stage1_warpsize2x2x1_g1_tensor16x8x8 Tactic: -6080892721161662420
[03/24/2023-12:57:37] [V] [TRT] Tactic: -6080892721161662420 Time: 0.039936
[03/24/2023-12:57:37] [V] [TRT] Conv_163 Set Tactic Name: ampere_h16816cudnn_128x64_ldg8_relu_exp_stages_64x4_small_nhwc_tn_v1 Tactic: -6063766379489217211
[03/24/2023-12:57:37] [V] [TRT] Tactic: -6063766379489217211 Time: 0.030464
[03/24/2023-12:57:37] [V] [TRT] Conv_163 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x128x32_stage5_warpsize2x2x1_g1_tensor16x8x16 Tactic: -5777580938094193096
[03/24/2023-12:57:37] [V] [TRT] Tactic: -5777580938094193096 Time: 0.035072
[03/24/2023-12:57:37] [V] [TRT] Conv_163 Set Tactic Name: sm75_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x128x64_stage1_warpsize2x2x1_g1_tensor16x8x8 Tactic: -5710735840878760115
[03/24/2023-12:57:37] [V] [TRT] Tactic: -5710735840878760115 Time: 0.040704
[03/24/2023-12:57:37] [V] [TRT] Conv_163 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x128x32_stage3_warpsize4x2x1_g1_tensor16x8x16 Tactic: -5657273398217409378
[03/24/2023-12:57:37] [V] [TRT] Tactic: -5657273398217409378 Time: 0.044032
[03/24/2023-12:57:37] [V] [TRT] Conv_163 Set Tactic Name: sm75_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x128x32_stage1_warpsize2x2x1_g1_tensor16x8x8_t1r3s3 Tactic: -5546257196173962281
[03/24/2023-12:57:37] [V] [TRT] Tactic: -5546257196173962281 Time: 0.039424
[03/24/2023-12:57:37] [V] [TRT] Conv_163 Set Tactic Name: ampere_h16816cudnn_128x128_ldg8_relu_exp_small_nhwc_tn_v1 Tactic: -5530886555766748586
[03/24/2023-12:57:37] [V] [TRT] Tactic: -5530886555766748586 Time: 0.034688
[03/24/2023-12:57:37] [V] [TRT] Conv_163 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x64x32_stage5_warpsize2x2x1_g1_tensor16x8x16_t1r3s3 Tactic: -5422685219138380548
[03/24/2023-12:57:37] [V] [TRT] Tactic: -5422685219138380548 Time: 0.024832
[03/24/2023-12:57:37] [V] [TRT] Conv_163 Set Tactic Name: ampere_h16816cudnn_256x64_ldg8_relu_exp_stages_64x3_small_nhwc_tn_v1 Tactic: -5261787675443473128
[03/24/2023-12:57:37] [V] [TRT] Tactic: -5261787675443473128 Time: 0.030336
[03/24/2023-12:57:37] [V] [TRT] Conv_163 Set Tactic Name: sm75_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x64x32_stage1_warpsize4x1x1_g1_tensor16x8x8 Tactic: -5198219374380660379
[03/24/2023-12:57:37] [V] [TRT] Tactic: -5198219374380660379 Time: 0.033152
[03/24/2023-12:57:37] [V] [TRT] Conv_163 Set Tactic Name: ampere_h16816cudnn_64x128_sliced1x2_ldg8_relu_exp_stages_64x3_medium_nhwc_tn_v1 Tactic: -5161596964442251102
[03/24/2023-12:57:37] [V] [TRT] Tactic: -5161596964442251102 Time: 0.035968
[03/24/2023-12:57:37] [V] [TRT] Conv_163 Set Tactic Name: ampere_h16816cudnn_64x128_ldg8_relu_exp_stages_64x3_medium_nhwc_tn_v1 Tactic: -5127240325355316006
[03/24/2023-12:57:37] [V] [TRT] Tactic: -5127240325355316006 Time: 0.03776
[03/24/2023-12:57:37] [V] [TRT] Conv_163 Set Tactic Name: ampere_h16816cudnn_256x128_ldg8_relu_exp_stages_64x3_medium_nhwc_tn_v1 Tactic: -5109582882231362997
[03/24/2023-12:57:37] [V] [TRT] Tactic: -5109582882231362997 Time: 0.045824
[03/24/2023-12:57:37] [V] [TRT] Conv_163 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x64x32_stage5_warpsize2x2x1_g1_tensor16x8x16 Tactic: -4825567853927730435
[03/24/2023-12:57:37] [V] [TRT] Tactic: -4825567853927730435 Time: 0.029696
[03/24/2023-12:57:37] [V] [TRT] Conv_163 Set Tactic Name: ampere_h16816cudnn_64x128_sliced1x2_ldg8_relu_exp_stages_64x4_small_nhwc_tn_v1 Tactic: -4796511246675321840
[03/24/2023-12:57:37] [V] [TRT] Tactic: -4796511246675321840 Time: 0.046464
[03/24/2023-12:57:37] [V] [TRT] Conv_163 Set Tactic Name: ampere_h16816cudnn_64x64_sliced1x2_ldg8_relu_exp_stages_64x6_large_nhwc_tn_v1 Tactic: -4706569565442112734
[03/24/2023-12:57:37] [V] [TRT] Tactic: -4706569565442112734 Time: 0.040064
[03/24/2023-12:57:37] [V] [TRT] Conv_163 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x128x64_stage3_warpsize2x2x1_g1_tensor16x8x16_t1r3s3 Tactic: -4566599693570369588
[03/24/2023-12:57:37] [V] [TRT] Tactic: -4566599693570369588 Time: 0.040832
[03/24/2023-12:57:37] [V] [TRT] Conv_163 Set Tactic Name: ampere_h16816cudnn_128x128_ldg8_relu_exp_stages_64x3_large_nhwc_tn_v1 Tactic: -4409144516525410768
[03/24/2023-12:57:37] [V] [TRT] Tactic: -4409144516525410768 Time: 0.040704
[03/24/2023-12:57:37] [V] [TRT] Conv_163 Set Tactic Name: ampere_h16816cudnn_128x64_ldg8_relu_exp_stages_64x3_small_nhwc_tn_v1 Tactic: -4379519430184503304
[03/24/2023-12:57:37] [V] [TRT] Tactic: -4379519430184503304 Time: 0.027776
[03/24/2023-12:57:37] [V] [TRT] Conv_163 Set Tactic Name: ampere_h1688cudnn_256x128_ldg8_relu_exp_small_nhwc_tn_v1 Tactic: -4152066959007262150
[03/24/2023-12:57:37] [V] [TRT] Tactic: -4152066959007262150 Time: 0.050176
[03/24/2023-12:57:37] [V] [TRT] Conv_163 Set Tactic Name: ampere_h16816cudnn_64x128_ldg8_relu_exp_stages_64x4_medium_nhwc_tn_v1 Tactic: -4021926646879732549
[03/24/2023-12:57:37] [V] [TRT] Tactic: -4021926646879732549 Time: 0.044032
[03/24/2023-12:57:37] [V] [TRT] Conv_163 Set Tactic Name: ampere_h16816cudnn_64x128_sliced1x2_ldg8_relu_exp_stages_64x4_medium_nhwc_tn_v1 Tactic: -3987638434926559037
[03/24/2023-12:57:37] [V] [TRT] Tactic: -3987638434926559037 Time: 0.047104
[03/24/2023-12:57:37] [V] [TRT] Conv_163 Set Tactic Name: ampere_h1688cudnn_256x64_sliced1x2_ldg8_relu_exp_medium_nhwc_tn_v1 Tactic: -3905653247016903130
[03/24/2023-12:57:37] [V] [TRT] Tactic: -3905653247016903130 Time: 0.038272
[03/24/2023-12:57:37] [V] [TRT] Conv_163 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x64x32_stage5_warpsize2x2x1_g1_tensor16x8x16 Tactic: -3903974568488493144
[03/24/2023-12:57:37] [V] [TRT] Tactic: -3903974568488493144 Time: 0.028672
[03/24/2023-12:57:37] [V] [TRT] Conv_163 Set Tactic Name: ampere_h16816cudnn_64x128_ldg8_relu_exp_stages_64x3_large_nhwc_tn_v1 Tactic: -3895429239811098010
[03/24/2023-12:57:37] [V] [TRT] Tactic: -3895429239811098010 Time: 0.038144
[03/24/2023-12:57:37] [V] [TRT] Conv_163 Set Tactic Name: ampere_h16816cudnn_256x64_ldg8_relu_exp_small_nhwc_tn_v1 Tactic: -3864869056275745423
[03/24/2023-12:57:37] [V] [TRT] Tactic: -3864869056275745423 Time: 0.03072
[03/24/2023-12:57:37] [V] [TRT] Conv_163 Set Tactic Name: sm75_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x32x32_stage1_warpsize4x1x1_g1_tensor16x8x8_t1r3s3 Tactic: -3784342055748695733
[03/24/2023-12:57:38] [V] [TRT] Tactic: -3784342055748695733 Time: 0.024832
[03/24/2023-12:57:38] [V] [TRT] Conv_163 Set Tactic Name: ampere_h16816cudnn_64x64_ldg8_relu_exp_stages_64x5_small_nhwc_tn_v1 Tactic: -3601464762214218301
[03/24/2023-12:57:38] [V] [TRT] Tactic: -3601464762214218301 Time: 0.03264
[03/24/2023-12:57:38] [V] [TRT] Conv_163 Set Tactic Name: sm75_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x64x32_stage1_warpsize2x2x1_g1_tensor16x8x8 Tactic: -3425274793298557239
[03/24/2023-12:57:38] [V] [TRT] Tactic: -3425274793298557239 Time: 0.030464
[03/24/2023-12:57:38] [V] [TRT] Conv_163 Set Tactic Name: ampere_h1688cudnn_256x64_sliced1x2_ldg8_relu_exp_large_nhwc_tn_v1 Tactic: -3412636942650049698
[03/24/2023-12:57:38] [V] [TRT] Tactic: -3412636942650049698 Time: 0.038784
[03/24/2023-12:57:38] [V] [TRT] Conv_163 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x64x32_stage3_warpsize4x1x1_g1_tensor16x8x16 Tactic: -3338665856053412950
[03/24/2023-12:57:38] [V] [TRT] Tactic: -3338665856053412950 Time: 0.026752
[03/24/2023-12:57:38] [V] [TRT] Conv_163 Set Tactic Name: sm75_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x128x32_stage1_warpsize2x2x1_g1_tensor16x8x8 Tactic: -3271955096576257018
[03/24/2023-12:57:38] [V] [TRT] Tactic: -3271955096576257018 Time: 0.03968
[03/24/2023-12:57:38] [V] [TRT] Conv_163 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x128x64_stage3_warpsize4x2x1_g1_tensor16x8x16_t1r3s3 Tactic: -3243541398692466074
[03/24/2023-12:57:38] [V] [TRT] Tactic: -3243541398692466074 Time: 0.04608
[03/24/2023-12:57:38] [V] [TRT] Conv_163 Set Tactic Name: ampere_h16816cudnn_64x128_sliced1x2_ldg8_relu_exp_stages_64x3_small_nhwc_tn_v1 Tactic: -3058330359340425555
[03/24/2023-12:57:38] [V] [TRT] Tactic: -3058330359340425555 Time: 0.035968
[03/24/2023-12:57:38] [V] [TRT] Conv_163 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x256x64_stage3_warpsize1x4x1_g1_tensor16x8x16_t1r3s3 Tactic: -2899647483672319239
[03/24/2023-12:57:38] [V] [TRT] Tactic: -2899647483672319239 Time: 0.06336
[03/24/2023-12:57:38] [V] [TRT] Conv_163 Set Tactic Name: ampere_h16816cudnn_256x64_sliced1x2_ldg8_relu_exp_large_nhwc_tn_v1 Tactic: -2816084650627734155
[03/24/2023-12:57:38] [V] [TRT] Tactic: -2816084650627734155 Time: 0.035712
[03/24/2023-12:57:38] [V] [TRT] Conv_163 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x128x32_stage5_warpsize2x2x1_g1_tensor16x8x16 Tactic: -2662892962457732243
[03/24/2023-12:57:38] [V] [TRT] Tactic: -2662892962457732243 Time: 0.034688
[03/24/2023-12:57:38] [V] [TRT] Conv_163 Set Tactic Name: ampere_h16816cudnn_256x128_ldg8_relu_exp_large_nhwc_tn_v1 Tactic: -2559894581585337900
[03/24/2023-12:57:38] [V] [TRT] Tactic: -2559894581585337900 Time: 0.045056
[03/24/2023-12:57:38] [V] [TRT] Conv_163 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x32x32_stage4_warpsize4x1x1_g1_tensor16x8x16 Tactic: -2530740716768816092
[03/24/2023-12:57:38] [V] [TRT] Tactic: -2530740716768816092 Time: 0.023424
[03/24/2023-12:57:38] [V] [TRT] Conv_163 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x128x32_stage4_warpsize2x2x1_g1_tensor16x8x16 Tactic: -2332828394978346992
[03/24/2023-12:57:38] [V] [TRT] Tactic: -2332828394978346992 Time: 0.034688
[03/24/2023-12:57:38] [V] [TRT] Conv_163 Set Tactic Name: ampere_h1688cudnn_256x64_ldg8_relu_exp_large_nhwc_tn_v1 Tactic: -2241736083352441442
[03/24/2023-12:57:38] [V] [TRT] Tactic: -2241736083352441442 Time: 0.034944
[03/24/2023-12:57:38] [V] [TRT] Conv_163 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x32x64_stage5_warpsize2x2x1_g1_tensor16x8x16 Tactic: -2161909437867201546
[03/24/2023-12:57:38] [V] [TRT] Tactic: -2161909437867201546 Time: 0.026368
[03/24/2023-12:57:38] [V] [TRT] Conv_163 Set Tactic Name: ampere_h16816cudnn_256x64_ldg8_relu_exp_medium_nhwc_tn_v1 Tactic: -1985778916402815946
[03/24/2023-12:57:38] [V] [TRT] Tactic: -1985778916402815946 Time: 0.03072
[03/24/2023-12:57:38] [V] [TRT] Conv_163 Set Tactic Name: sm75_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x256x32_stage1_warpsize2x4x1_g1_tensor16x8x8 Tactic: -1708101578041178688
[03/24/2023-12:57:38] [V] [TRT] Tactic: -1708101578041178688 Time: 0.070656
[03/24/2023-12:57:38] [V] [TRT] Conv_163 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x64x64_stage3_warpsize4x1x1_g1_tensor16x8x16 Tactic: -1502788097503482299
[03/24/2023-12:57:38] [V] [TRT] Tactic: -1502788097503482299 Time: 0.033024
[03/24/2023-12:57:38] [V] [TRT] Conv_163 Set Tactic Name: ampere_h16816cudnn_128x64_sliced1x2_ldg8_relu_exp_stages_64x4_large_nhwc_tn_v1 Tactic: -1500496213132463076
[03/24/2023-12:57:38] [V] [TRT] Tactic: -1500496213132463076 Time: 0.03264
[03/24/2023-12:57:38] [V] [TRT] Conv_163 Set Tactic Name: ampere_h16816cudnn_64x64_ldg8_relu_exp_stages_64x6_small_nhwc_tn_v1 Tactic: -1099247066487349374
[03/24/2023-12:57:38] [V] [TRT] Tactic: -1099247066487349374 Time: 0.03584
[03/24/2023-12:57:38] [V] [TRT] Conv_163 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x64x64_stage4_warpsize2x2x1_g1_tensor16x8x16 Tactic: -910286698936744682
[03/24/2023-12:57:38] [V] [TRT] Tactic: -910286698936744682 Time: 0.029696
[03/24/2023-12:57:38] [V] [TRT] Conv_163 Set Tactic Name: sm75_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x256x32_stage1_warpsize2x4x1_g1_tensor16x8x8 Tactic: -907287437357565279
[03/24/2023-12:57:38] [V] [TRT] Tactic: -907287437357565279 Time: 0.069632
[03/24/2023-12:57:38] [V] [TRT] Conv_163 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x32x32_stage4_warpsize4x1x1_g1_tensor16x8x16 Tactic: -606726295133751039
[03/24/2023-12:57:38] [V] [TRT] Tactic: -606726295133751039 Time: 0.021376
[03/24/2023-12:57:38] [V] [TRT] Fastest Tactic: -8985224497679592364 Time: 0.020224
[03/24/2023-12:57:38] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: -8985224497679592364
[03/24/2023-12:57:38] [V] [TRT] *************** Autotuning format combination: Half(518400,1:16,2880,16) -> Half(32400,1:16,180,1) ***************
[03/24/2023-12:57:38] [V] [TRT] --------------- Timing Runner: Conv_163 (CudnnConvolution)
[03/24/2023-12:57:38] [V] [TRT] CudnnConvolution has no valid tactics for this config, skipping
[03/24/2023-12:57:38] [V] [TRT] --------------- Timing Runner: Conv_163 (CaskConvolution)
[03/24/2023-12:57:38] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[03/24/2023-12:57:38] [V] [TRT] =============== Computing costs for 
[03/24/2023-12:57:38] [V] [TRT] *************** Autotuning format combination: Float(8294400,32400,180,1) -> Float(64800,32400,180,1) ***************
[03/24/2023-12:57:38] [V] [TRT] *************** Autotuning format combination: Float(8294400,1,46080,256) -> Float(64800,1,360,2) ***************
[03/24/2023-12:57:38] [V] [TRT] *************** Autotuning format combination: Float(2073600,1:4,11520,64) -> Float(32400,1:4,180,1) ***************
[03/24/2023-12:57:38] [V] [TRT] *************** Autotuning format combination: Half(8294400,32400,180,1) -> Half(64800,32400,180,1) ***************
[03/24/2023-12:57:38] [V] [TRT] *************** Autotuning format combination: Half(4147200,32400:2,180,1) -> Half(32400,32400:2,180,1) ***************
[03/24/2023-12:57:38] [V] [TRT] *************** Autotuning format combination: Half(1036800,1:8,5760,32) -> Float(64800,32400,180,1) ***************
[03/24/2023-12:57:38] [V] [TRT] *************** Autotuning format combination: Half(1036800,1:8,5760,32) -> Half(32400,1:8,180,1) ***************
[03/24/2023-12:57:38] [V] [TRT] *************** Autotuning format combination: Half(518400,1:16,2880,16) -> Half(32400,1:16,180,1) ***************
[03/24/2023-12:57:38] [V] [TRT] =============== Computing costs for 
[03/24/2023-12:57:38] [V] [TRT] *************** Autotuning format combination: Float(8294400,32400,180,1) -> Float(64800,32400,180,1) ***************
[03/24/2023-12:57:38] [V] [TRT] *************** Autotuning format combination: Float(8294400,1,46080,256) -> Float(64800,1,360,2) ***************
[03/24/2023-12:57:38] [V] [TRT] *************** Autotuning format combination: Float(2073600,1:4,11520,64) -> Float(32400,1:4,180,1) ***************
[03/24/2023-12:57:38] [V] [TRT] *************** Autotuning format combination: Half(8294400,32400,180,1) -> Half(64800,32400,180,1) ***************
[03/24/2023-12:57:38] [V] [TRT] *************** Autotuning format combination: Half(4147200,32400:2,180,1) -> Half(32400,32400:2,180,1) ***************
[03/24/2023-12:57:38] [V] [TRT] *************** Autotuning format combination: Half(1036800,1:8,5760,32) -> Float(64800,32400,180,1) ***************
[03/24/2023-12:57:38] [V] [TRT] *************** Autotuning format combination: Half(1036800,1:8,5760,32) -> Half(32400,1:8,180,1) ***************
[03/24/2023-12:57:38] [V] [TRT] *************** Autotuning format combination: Half(518400,1:16,2880,16) -> Half(32400,1:16,180,1) ***************
[03/24/2023-12:57:38] [V] [TRT] Adding reformat layer: Reformatted Input Tensor 0 to Conv_15 + Relu_16 (input) from Half(8294400,32400,180,1) to Half(1036800,1:8,5760,32)
[03/24/2023-12:57:38] [V] [TRT] Adding reformat layer: Reformatted Output Tensor 0 to Conv_64 (reg_0) from Half(32400,1:8,180,1) to Half(64800,32400,180,1)
[03/24/2023-12:57:38] [V] [TRT] Adding reformat layer: Reformatted Output Tensor 0 to Conv_67 (height_0) from Half(32400,1:8,180,1) to Half(32400,32400,180,1)
[03/24/2023-12:57:38] [V] [TRT] Adding reformat layer: Reformatted Output Tensor 0 to Conv_70 (dim_0) from Half(32400,1:8,180,1) to Half(97200,32400,180,1)
[03/24/2023-12:57:38] [V] [TRT] Adding reformat layer: Reformatted Output Tensor 0 to Conv_73 (rot_0) from Half(32400,1:8,180,1) to Half(64800,32400,180,1)
[03/24/2023-12:57:38] [V] [TRT] Adding reformat layer: Reformatted Output Tensor 0 to Conv_76 (vel_0) from Half(32400,1:8,180,1) to Half(64800,32400,180,1)
[03/24/2023-12:57:38] [V] [TRT] Adding reformat layer: Reformatted Output Tensor 0 to Conv_79 (hm_0) from Half(32400,1:8,180,1) to Half(32400,32400,180,1)
[03/24/2023-12:57:38] [V] [TRT] Adding reformat layer: Reformatted Output Tensor 0 to Conv_82 (reg_1) from Half(32400,1:8,180,1) to Half(64800,32400,180,1)
[03/24/2023-12:57:38] [V] [TRT] Adding reformat layer: Reformatted Output Tensor 0 to Conv_85 (height_1) from Half(32400,1:8,180,1) to Half(32400,32400,180,1)
[03/24/2023-12:57:38] [V] [TRT] Adding reformat layer: Reformatted Output Tensor 0 to Conv_88 (dim_1) from Half(32400,1:8,180,1) to Half(97200,32400,180,1)
[03/24/2023-12:57:38] [V] [TRT] Adding reformat layer: Reformatted Output Tensor 0 to Conv_91 (rot_1) from Half(32400,1:8,180,1) to Half(64800,32400,180,1)
[03/24/2023-12:57:38] [V] [TRT] Adding reformat layer: Reformatted Output Tensor 0 to Conv_94 (vel_1) from Half(32400,1:8,180,1) to Half(64800,32400,180,1)
[03/24/2023-12:57:38] [V] [TRT] Adding reformat layer: Reformatted Output Tensor 0 to Conv_97 (hm_1) from Half(32400,1:8,180,1) to Half(64800,32400,180,1)
[03/24/2023-12:57:38] [V] [TRT] Adding reformat layer: Reformatted Output Tensor 0 to Conv_100 (reg_2) from Half(32400,1:8,180,1) to Half(64800,32400,180,1)
[03/24/2023-12:57:38] [V] [TRT] Adding reformat layer: Reformatted Output Tensor 0 to Conv_103 (height_2) from Half(32400,1:8,180,1) to Half(32400,32400,180,1)
[03/24/2023-12:57:38] [V] [TRT] Adding reformat layer: Reformatted Output Tensor 0 to Conv_106 (dim_2) from Half(32400,1:8,180,1) to Half(97200,32400,180,1)
[03/24/2023-12:57:38] [V] [TRT] Adding reformat layer: Reformatted Output Tensor 0 to Conv_109 (rot_2) from Half(32400,1:8,180,1) to Half(64800,32400,180,1)
[03/24/2023-12:57:38] [V] [TRT] Adding reformat layer: Reformatted Output Tensor 0 to Conv_112 (vel_2) from Half(32400,1:8,180,1) to Half(64800,32400,180,1)
[03/24/2023-12:57:38] [V] [TRT] Adding reformat layer: Reformatted Output Tensor 0 to Conv_115 (hm_2) from Half(32400,1:8,180,1) to Half(64800,32400,180,1)
[03/24/2023-12:57:38] [V] [TRT] Adding reformat layer: Reformatted Output Tensor 0 to Conv_118 (reg_3) from Half(32400,1:8,180,1) to Half(64800,32400,180,1)
[03/24/2023-12:57:38] [V] [TRT] Adding reformat layer: Reformatted Output Tensor 0 to Conv_121 (height_3) from Half(32400,1:8,180,1) to Half(32400,32400,180,1)
[03/24/2023-12:57:38] [V] [TRT] Adding reformat layer: Reformatted Output Tensor 0 to Conv_124 (dim_3) from Half(32400,1:8,180,1) to Half(97200,32400,180,1)
[03/24/2023-12:57:38] [V] [TRT] Adding reformat layer: Reformatted Output Tensor 0 to Conv_127 (rot_3) from Half(32400,1:8,180,1) to Half(64800,32400,180,1)
[03/24/2023-12:57:38] [V] [TRT] Adding reformat layer: Reformatted Output Tensor 0 to Conv_130 (vel_3) from Half(32400,1:8,180,1) to Half(64800,32400,180,1)
[03/24/2023-12:57:38] [V] [TRT] Adding reformat layer: Reformatted Output Tensor 0 to Conv_133 (hm_3) from Half(32400,1:8,180,1) to Half(32400,32400,180,1)
[03/24/2023-12:57:38] [V] [TRT] Adding reformat layer: Reformatted Output Tensor 0 to Conv_136 (reg_4) from Half(32400,1:8,180,1) to Half(64800,32400,180,1)
[03/24/2023-12:57:38] [V] [TRT] Adding reformat layer: Reformatted Output Tensor 0 to Conv_139 (height_4) from Half(32400,1:8,180,1) to Half(32400,32400,180,1)
[03/24/2023-12:57:38] [V] [TRT] Adding reformat layer: Reformatted Output Tensor 0 to Conv_142 (dim_4) from Half(32400,1:8,180,1) to Half(97200,32400,180,1)
[03/24/2023-12:57:38] [V] [TRT] Adding reformat layer: Reformatted Output Tensor 0 to Conv_145 (rot_4) from Half(32400,1:8,180,1) to Half(64800,32400,180,1)
[03/24/2023-12:57:38] [V] [TRT] Adding reformat layer: Reformatted Output Tensor 0 to Conv_148 (vel_4) from Half(32400,1:8,180,1) to Half(64800,32400,180,1)
[03/24/2023-12:57:38] [V] [TRT] Adding reformat layer: Reformatted Output Tensor 0 to Conv_151 (hm_4) from Half(32400,1:8,180,1) to Half(64800,32400,180,1)
[03/24/2023-12:57:38] [V] [TRT] Adding reformat layer: Reformatted Output Tensor 0 to Conv_154 (reg_5) from Half(32400,1:8,180,1) to Half(64800,32400,180,1)
[03/24/2023-12:57:38] [V] [TRT] Adding reformat layer: Reformatted Output Tensor 0 to Conv_157 (height_5) from Half(32400,1:8,180,1) to Half(32400,32400,180,1)
[03/24/2023-12:57:38] [V] [TRT] Adding reformat layer: Reformatted Output Tensor 0 to Conv_160 (dim_5) from Half(32400,1:8,180,1) to Half(97200,32400,180,1)
[03/24/2023-12:57:38] [V] [TRT] Adding reformat layer: Reformatted Output Tensor 0 to Conv_163 (rot_5) from Half(32400,1:8,180,1) to Half(64800,32400,180,1)
[03/24/2023-12:57:38] [V] [TRT] Adding reformat layer: Reformatted Output Tensor 0 to Conv_166 (vel_5) from Half(32400,1:8,180,1) to Half(64800,32400,180,1)
[03/24/2023-12:57:38] [V] [TRT] Adding reformat layer: Reformatted Output Tensor 0 to Conv_169 (hm_5) from Half(32400,1:8,180,1) to Half(64800,32400,180,1)
[03/24/2023-12:57:38] [V] [TRT] Formats and tactics selection completed in 81.6789 seconds.
[03/24/2023-12:57:38] [V] [TRT] After reformat layers: 94 layers
[03/24/2023-12:57:38] [V] [TRT] Pre-optimized block assignment.
[03/24/2023-12:57:38] [V] [TRT] Block size 8294400
[03/24/2023-12:57:38] [V] [TRT] Block size 8294400
[03/24/2023-12:57:38] [V] [TRT] Block size 8294400
[03/24/2023-12:57:38] [V] [TRT] Block size 8294400
[03/24/2023-12:57:38] [V] [TRT] Block size 8294400
[03/24/2023-12:57:38] [V] [TRT] Block size 8294400
[03/24/2023-12:57:38] [V] [TRT] Block size 4147200
[03/24/2023-12:57:38] [V] [TRT] Block size 4147200
[03/24/2023-12:57:38] [V] [TRT] Block size 4147200
[03/24/2023-12:57:38] [V] [TRT] Block size 4147200
[03/24/2023-12:57:38] [V] [TRT] Block size 4147200
[03/24/2023-12:57:38] [V] [TRT] Block size 4147200
[03/24/2023-12:57:38] [V] [TRT] Block size 16588800
[03/24/2023-12:57:38] [V] [TRT] Block size 33177600
[03/24/2023-12:57:38] [V] [TRT] Block size 4147200
[03/24/2023-12:57:38] [V] [TRT] Block size 33177600
[03/24/2023-12:57:38] [V] [TRT] Block size 33177600
[03/24/2023-12:57:38] [V] [TRT] Block size 33177600
[03/24/2023-12:57:38] [V] [TRT] Block size 33177600
[03/24/2023-12:57:38] [V] [TRT] Block size 16588800
[03/24/2023-12:57:38] [V] [TRT] Block size 16588800
[03/24/2023-12:57:38] [V] [TRT] Block size 518656
[03/24/2023-12:57:38] [V] [TRT] Block size 518656
[03/24/2023-12:57:38] [V] [TRT] Block size 518656
[03/24/2023-12:57:38] [V] [TRT] Block size 518656
[03/24/2023-12:57:38] [V] [TRT] Block size 518656
[03/24/2023-12:57:38] [V] [TRT] Block size 518656
[03/24/2023-12:57:38] [V] [TRT] Block size 518656
[03/24/2023-12:57:38] [V] [TRT] Block size 518656
[03/24/2023-12:57:38] [V] [TRT] Block size 518656
[03/24/2023-12:57:38] [V] [TRT] Block size 518656
[03/24/2023-12:57:38] [V] [TRT] Block size 518656
[03/24/2023-12:57:38] [V] [TRT] Block size 518656
[03/24/2023-12:57:38] [V] [TRT] Block size 518656
[03/24/2023-12:57:38] [V] [TRT] Block size 518656
[03/24/2023-12:57:38] [V] [TRT] Block size 518656
[03/24/2023-12:57:38] [V] [TRT] Block size 518656
[03/24/2023-12:57:38] [V] [TRT] Block size 518656
[03/24/2023-12:57:38] [V] [TRT] Block size 518656
[03/24/2023-12:57:38] [V] [TRT] Block size 518656
[03/24/2023-12:57:38] [V] [TRT] Block size 518656
[03/24/2023-12:57:38] [V] [TRT] Block size 518656
[03/24/2023-12:57:38] [V] [TRT] Block size 518656
[03/24/2023-12:57:38] [V] [TRT] Block size 518656
[03/24/2023-12:57:38] [V] [TRT] Block size 518656
[03/24/2023-12:57:38] [V] [TRT] Block size 518656
[03/24/2023-12:57:38] [V] [TRT] Block size 518656
[03/24/2023-12:57:38] [V] [TRT] Block size 518656
[03/24/2023-12:57:38] [V] [TRT] Block size 518656
[03/24/2023-12:57:38] [V] [TRT] Block size 518656
[03/24/2023-12:57:38] [V] [TRT] Block size 518656
[03/24/2023-12:57:38] [V] [TRT] Block size 518656
[03/24/2023-12:57:38] [V] [TRT] Block size 518656
[03/24/2023-12:57:38] [V] [TRT] Block size 518656
[03/24/2023-12:57:38] [V] [TRT] Block size 518656
[03/24/2023-12:57:38] [V] [TRT] Block size 518656
[03/24/2023-12:57:38] [V] [TRT] Block size 518656
[03/24/2023-12:57:38] [V] [TRT] Block size 4294967296
[03/24/2023-12:57:38] [V] [TRT] Total Activation Memory: 4608090112
[03/24/2023-12:57:38] [I] [TRT] Detected 1 inputs and 36 output network tensors.
[03/24/2023-12:57:38] [V] [TRT] Conv_15 + Relu_16 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x128x32_stage4_warpsize2x2x1_g1_tensor16x8x16_t1r3s3 Tactic: 6972489290272968208
[03/24/2023-12:57:38] [V] [TRT] Conv_17 + Relu_18 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x128x32_stage4_warpsize2x2x1_g1_tensor16x8x16_t1r3s3 Tactic: 6972489290272968208
[03/24/2023-12:57:38] [V] [TRT] Conv_19 + Relu_20 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x128x32_stage4_warpsize2x2x1_g1_tensor16x8x16_t1r3s3 Tactic: 6972489290272968208
[03/24/2023-12:57:38] [V] [TRT] Conv_21 + Relu_22 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x128x32_stage4_warpsize2x2x1_g1_tensor16x8x16_t1r3s3 Tactic: 6972489290272968208
[03/24/2023-12:57:38] [V] [TRT] Conv_23 + Relu_24 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x128x32_stage4_warpsize2x2x1_g1_tensor16x8x16_t1r3s3 Tactic: 6972489290272968208
[03/24/2023-12:57:38] [V] [TRT] Conv_25 + Relu_26 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x128x32_stage4_warpsize2x2x1_g1_tensor16x8x16_t1r3s3 Tactic: 6972489290272968208
[03/24/2023-12:57:38] [V] [TRT] Conv_27 + Relu_28 Set Tactic Name: sm75_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x128x32_stage1_warpsize2x2x1_g1_tensor16x8x8_t1r1s1 Tactic: -5121883532434354186
[03/24/2023-12:57:38] [V] [TRT] Conv_44 + Relu_45 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x128x32_stage3_warpsize4x2x1_g1_tensor16x8x16_t1r3s3 Tactic: 328038211831149625
[03/24/2023-12:57:38] [V] [TRT] Conv_46 + Relu_47 Set Tactic Name: ampere_h16816cudnn_128x64_sliced1x2_ldg8_relu_exp_stages_64x3_small_nhwc_tn_v1 Tactic: 1838082074606840426
[03/24/2023-12:57:38] [V] [TRT] Conv_48 + Relu_49 Set Tactic Name: ampere_h16816cudnn_128x64_sliced1x2_ldg8_relu_exp_stages_64x3_small_nhwc_tn_v1 Tactic: 1838082074606840426
[03/24/2023-12:57:38] [V] [TRT] Conv_50 + Relu_51 Set Tactic Name: ampere_h16816cudnn_128x64_sliced1x2_ldg8_relu_exp_stages_64x3_small_nhwc_tn_v1 Tactic: 1838082074606840426
[03/24/2023-12:57:38] [V] [TRT] Conv_52 + Relu_53 Set Tactic Name: ampere_h16816cudnn_128x64_sliced1x2_ldg8_relu_exp_stages_64x3_small_nhwc_tn_v1 Tactic: 1838082074606840426
[03/24/2023-12:57:38] [V] [TRT] Conv_54 + Relu_55 Set Tactic Name: ampere_h16816cudnn_128x64_sliced1x2_ldg8_relu_exp_stages_64x3_small_nhwc_tn_v1 Tactic: 1838082074606840426
[03/24/2023-12:57:38] [V] [TRT] Conv_60 + Relu_61 Set Tactic Name: ampere_h16816cudnn_128x64_sliced1x2_ldg8_relu_exp_stages_64x4_small_nhwc_tn_v1 Tactic: 8170606396342855895
[03/24/2023-12:57:38] [V] [TRT] Conv_62 + Relu_63 || Conv_65 + Relu_66 || Conv_68 + Relu_69 || Conv_71 + Relu_72 || Conv_74 + Relu_75 || Conv_77 + Relu_78 || Conv_80 + Relu_81 || Conv_83 + Relu_84 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x128x32_stage4_warpsize2x2x1_g1_tensor16x8x16_t1r3s3 Tactic: 6972489290272968208
[03/24/2023-12:57:38] [V] [TRT] Conv_64 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x32x32_stage4_warpsize4x1x1_g1_tensor16x8x16_t1r3s3 Tactic: 4503233883285355107
[03/24/2023-12:57:38] [V] [TRT] Conv_67 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x32x32_stage4_warpsize4x1x1_g1_tensor16x8x16_t1r3s3 Tactic: 4503233883285355107
[03/24/2023-12:57:38] [V] [TRT] Conv_70 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x32x32_stage4_warpsize4x1x1_g1_tensor16x8x16_t1r3s3 Tactic: 4503233883285355107
[03/24/2023-12:57:38] [V] [TRT] Conv_73 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x32x32_stage4_warpsize4x1x1_g1_tensor16x8x16_t1r3s3 Tactic: 4503233883285355107
[03/24/2023-12:57:38] [V] [TRT] Conv_76 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x32x32_stage4_warpsize4x1x1_g1_tensor16x8x16_t1r3s3 Tactic: 4503233883285355107
[03/24/2023-12:57:38] [V] [TRT] Conv_79 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x32x32_stage4_warpsize4x1x1_g1_tensor16x8x16_t1r3s3 Tactic: 4503233883285355107
[03/24/2023-12:57:38] [V] [TRT] Conv_82 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x32x32_stage4_warpsize4x1x1_g1_tensor16x8x16_t1r3s3 Tactic: 4503233883285355107
[03/24/2023-12:57:38] [V] [TRT] Conv_85 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x32x32_stage4_warpsize4x1x1_g1_tensor16x8x16_t1r3s3 Tactic: 4503233883285355107
[03/24/2023-12:57:38] [V] [TRT] Conv_86 + Relu_87 || Conv_89 + Relu_90 || Conv_92 + Relu_93 || Conv_95 + Relu_96 || Conv_98 + Relu_99 || Conv_101 + Relu_102 || Conv_104 + Relu_105 || Conv_107 + Relu_108 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x128x32_stage4_warpsize2x2x1_g1_tensor16x8x16_t1r3s3 Tactic: 6972489290272968208
[03/24/2023-12:57:38] [V] [TRT] Conv_88 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x32x32_stage4_warpsize4x1x1_g1_tensor16x8x16_t1r3s3 Tactic: 4503233883285355107
[03/24/2023-12:57:38] [V] [TRT] Conv_91 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x32x32_stage4_warpsize4x1x1_g1_tensor16x8x16_t1r3s3 Tactic: 4503233883285355107
[03/24/2023-12:57:38] [V] [TRT] Conv_94 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x32x32_stage4_warpsize4x1x1_g1_tensor16x8x16_t1r3s3 Tactic: 4503233883285355107
[03/24/2023-12:57:38] [V] [TRT] Conv_97 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x32x32_stage4_warpsize4x1x1_g1_tensor16x8x16_t1r3s3 Tactic: 4503233883285355107
[03/24/2023-12:57:38] [V] [TRT] Conv_100 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x32x32_stage4_warpsize4x1x1_g1_tensor16x8x16_t1r3s3 Tactic: 4503233883285355107
[03/24/2023-12:57:38] [V] [TRT] Conv_103 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x32x32_stage4_warpsize4x1x1_g1_tensor16x8x16_t1r3s3 Tactic: 4503233883285355107
[03/24/2023-12:57:38] [V] [TRT] Conv_106 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x32x32_stage4_warpsize4x1x1_g1_tensor16x8x16_t1r3s3 Tactic: 4503233883285355107
[03/24/2023-12:57:38] [V] [TRT] Conv_109 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x32x32_stage4_warpsize4x1x1_g1_tensor16x8x16_t1r3s3 Tactic: 4503233883285355107
[03/24/2023-12:57:38] [V] [TRT] Conv_110 + Relu_111 || Conv_113 + Relu_114 || Conv_116 + Relu_117 || Conv_119 + Relu_120 || Conv_122 + Relu_123 || Conv_125 + Relu_126 || Conv_128 + Relu_129 || Conv_131 + Relu_132 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x128x32_stage4_warpsize2x2x1_g1_tensor16x8x16_t1r3s3 Tactic: 6972489290272968208
[03/24/2023-12:57:38] [V] [TRT] Conv_112 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x32x32_stage4_warpsize4x1x1_g1_tensor16x8x16_t1r3s3 Tactic: 4503233883285355107
[03/24/2023-12:57:38] [V] [TRT] Conv_115 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x32x32_stage4_warpsize4x1x1_g1_tensor16x8x16_t1r3s3 Tactic: 4503233883285355107
[03/24/2023-12:57:38] [V] [TRT] Conv_118 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x32x32_stage4_warpsize4x1x1_g1_tensor16x8x16_t1r3s3 Tactic: 4503233883285355107
[03/24/2023-12:57:38] [V] [TRT] Conv_121 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x32x32_stage4_warpsize4x1x1_g1_tensor16x8x16_t1r3s3 Tactic: 4503233883285355107
[03/24/2023-12:57:38] [V] [TRT] Conv_124 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x32x32_stage4_warpsize4x1x1_g1_tensor16x8x16_t1r3s3 Tactic: 4503233883285355107
[03/24/2023-12:57:38] [V] [TRT] Conv_127 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x32x32_stage4_warpsize4x1x1_g1_tensor16x8x16_t1r3s3 Tactic: 4503233883285355107
[03/24/2023-12:57:38] [V] [TRT] Conv_130 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x32x32_stage4_warpsize4x1x1_g1_tensor16x8x16_t1r3s3 Tactic: 4503233883285355107
[03/24/2023-12:57:38] [V] [TRT] Conv_133 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x32x32_stage4_warpsize4x1x1_g1_tensor16x8x16_t1r3s3 Tactic: 4503233883285355107
[03/24/2023-12:57:38] [V] [TRT] Conv_134 + Relu_135 || Conv_137 + Relu_138 || Conv_140 + Relu_141 || Conv_143 + Relu_144 || Conv_146 + Relu_147 || Conv_149 + Relu_150 || Conv_152 + Relu_153 || Conv_155 + Relu_156 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x128x32_stage4_warpsize2x2x1_g1_tensor16x8x16_t1r3s3 Tactic: 6972489290272968208
[03/24/2023-12:57:38] [V] [TRT] Conv_136 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x32x32_stage4_warpsize4x1x1_g1_tensor16x8x16_t1r3s3 Tactic: 4503233883285355107
[03/24/2023-12:57:38] [V] [TRT] Conv_139 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x32x32_stage4_warpsize4x1x1_g1_tensor16x8x16_t1r3s3 Tactic: 4503233883285355107
[03/24/2023-12:57:38] [V] [TRT] Conv_142 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x32x32_stage4_warpsize4x1x1_g1_tensor16x8x16_t1r3s3 Tactic: 4503233883285355107
[03/24/2023-12:57:38] [V] [TRT] Conv_145 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x32x32_stage4_warpsize4x1x1_g1_tensor16x8x16_t1r3s3 Tactic: 4503233883285355107
[03/24/2023-12:57:38] [V] [TRT] Conv_148 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x32x32_stage4_warpsize4x1x1_g1_tensor16x8x16_t1r3s3 Tactic: 4503233883285355107
[03/24/2023-12:57:38] [V] [TRT] Conv_151 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x32x32_stage4_warpsize4x1x1_g1_tensor16x8x16_t1r3s3 Tactic: 4503233883285355107
[03/24/2023-12:57:38] [V] [TRT] Conv_154 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x32x32_stage4_warpsize4x1x1_g1_tensor16x8x16_t1r3s3 Tactic: 4503233883285355107
[03/24/2023-12:57:38] [V] [TRT] Conv_157 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x32x32_stage4_warpsize4x1x1_g1_tensor16x8x16_t1r3s3 Tactic: 4503233883285355107
[03/24/2023-12:57:38] [V] [TRT] Conv_158 + Relu_159 || Conv_161 + Relu_162 || Conv_164 + Relu_165 || Conv_167 + Relu_168 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x128x32_stage4_warpsize2x2x1_g1_tensor16x8x16_t1r3s3 Tactic: 6972489290272968208
[03/24/2023-12:57:38] [V] [TRT] Conv_160 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x32x32_stage4_warpsize4x1x1_g1_tensor16x8x16_t1r3s3 Tactic: 4503233883285355107
[03/24/2023-12:57:38] [V] [TRT] Conv_163 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x32x32_stage4_warpsize4x1x1_g1_tensor16x8x16 Tactic: -8985224497679592364
[03/24/2023-12:57:38] [V] [TRT] Conv_166 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x32x32_stage4_warpsize4x1x1_g1_tensor16x8x16 Tactic: -8985224497679592364
[03/24/2023-12:57:38] [V] [TRT] Conv_169 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x32x32_stage4_warpsize4x1x1_g1_tensor16x8x16 Tactic: -8985224497679592364
[03/24/2023-12:57:38] [V] [TRT] Layer: Reformatting CopyNode for Input Tensor 0 to Conv_15 + Relu_16 Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0
[03/24/2023-12:57:38] [V] [TRT] Layer: Conv_15 + Relu_16 Host Persistent: 2400 Device Persistent: 590848 Scratch Memory: 0
[03/24/2023-12:57:38] [V] [TRT] Layer: Conv_17 + Relu_18 Host Persistent: 2400 Device Persistent: 295936 Scratch Memory: 0
[03/24/2023-12:57:38] [V] [TRT] Layer: Conv_19 + Relu_20 Host Persistent: 2400 Device Persistent: 295936 Scratch Memory: 0
[03/24/2023-12:57:38] [V] [TRT] Layer: Conv_21 + Relu_22 Host Persistent: 2400 Device Persistent: 295936 Scratch Memory: 0
[03/24/2023-12:57:38] [V] [TRT] Layer: Conv_23 + Relu_24 Host Persistent: 2400 Device Persistent: 295936 Scratch Memory: 0
[03/24/2023-12:57:38] [V] [TRT] Layer: Conv_25 + Relu_26 Host Persistent: 2400 Device Persistent: 295936 Scratch Memory: 0
[03/24/2023-12:57:38] [V] [TRT] Layer: Conv_27 + Relu_28 Host Persistent: 2400 Device Persistent: 67072 Scratch Memory: 0
[03/24/2023-12:57:38] [V] [TRT] Layer: Conv_44 + Relu_45 Host Persistent: 2400 Device Persistent: 591360 Scratch Memory: 0
[03/24/2023-12:57:38] [V] [TRT] Layer: Conv_46 + Relu_47 Host Persistent: 1664 Device Persistent: 1228800 Scratch Memory: 0
[03/24/2023-12:57:38] [V] [TRT] Layer: Conv_48 + Relu_49 Host Persistent: 1664 Device Persistent: 1228800 Scratch Memory: 0
[03/24/2023-12:57:38] [V] [TRT] Layer: Conv_50 + Relu_51 Host Persistent: 1664 Device Persistent: 1228800 Scratch Memory: 0
[03/24/2023-12:57:38] [V] [TRT] Layer: Conv_52 + Relu_53 Host Persistent: 1664 Device Persistent: 1228800 Scratch Memory: 0
[03/24/2023-12:57:38] [V] [TRT] Layer: Conv_54 + Relu_55 Host Persistent: 1664 Device Persistent: 1228800 Scratch Memory: 0
[03/24/2023-12:57:38] [V] [TRT] Layer: ConvTranspose_56 + BatchNormalization_57 + Relu_58 Host Persistent: 0 Device Persistent: 0 Scratch Memory: 20746240
[03/24/2023-12:57:38] [V] [TRT] Layer: onnx::Concat_647 copy Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0
[03/24/2023-12:57:38] [V] [TRT] Layer: Conv_60 + Relu_61 Host Persistent: 1664 Device Persistent: 784384 Scratch Memory: 0
[03/24/2023-12:57:38] [V] [TRT] Layer: Conv_62 + Relu_63 || Conv_65 + Relu_66 || Conv_68 + Relu_69 || Conv_71 + Relu_72 || Conv_74 + Relu_75 || Conv_77 + Relu_78 || Conv_80 + Relu_81 || Conv_83 + Relu_84 Host Persistent: 2400 Device Persistent: 592896 Scratch Memory: 0
[03/24/2023-12:57:38] [V] [TRT] Layer: Conv_64 Host Persistent: 2400 Device Persistent: 9728 Scratch Memory: 0
[03/24/2023-12:57:38] [V] [TRT] Layer: Reformatting CopyNode for Output Tensor 0 to Conv_64 Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0
[03/24/2023-12:57:38] [V] [TRT] Layer: Conv_67 Host Persistent: 2400 Device Persistent: 9728 Scratch Memory: 0
[03/24/2023-12:57:38] [V] [TRT] Layer: Reformatting CopyNode for Output Tensor 0 to Conv_67 Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0
[03/24/2023-12:57:38] [V] [TRT] Layer: Conv_70 Host Persistent: 2400 Device Persistent: 9728 Scratch Memory: 0
[03/24/2023-12:57:38] [V] [TRT] Layer: Reformatting CopyNode for Output Tensor 0 to Conv_70 Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0
[03/24/2023-12:57:38] [V] [TRT] Layer: Conv_73 Host Persistent: 2400 Device Persistent: 9728 Scratch Memory: 0
[03/24/2023-12:57:38] [V] [TRT] Layer: Reformatting CopyNode for Output Tensor 0 to Conv_73 Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0
[03/24/2023-12:57:38] [V] [TRT] Layer: Conv_76 Host Persistent: 2400 Device Persistent: 9728 Scratch Memory: 0
[03/24/2023-12:57:38] [V] [TRT] Layer: Reformatting CopyNode for Output Tensor 0 to Conv_76 Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0
[03/24/2023-12:57:38] [V] [TRT] Layer: Conv_79 Host Persistent: 2400 Device Persistent: 9728 Scratch Memory: 0
[03/24/2023-12:57:38] [V] [TRT] Layer: Reformatting CopyNode for Output Tensor 0 to Conv_79 Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0
[03/24/2023-12:57:38] [V] [TRT] Layer: Conv_82 Host Persistent: 2400 Device Persistent: 9728 Scratch Memory: 0
[03/24/2023-12:57:38] [V] [TRT] Layer: Reformatting CopyNode for Output Tensor 0 to Conv_82 Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0
[03/24/2023-12:57:38] [V] [TRT] Layer: Conv_85 Host Persistent: 2400 Device Persistent: 9728 Scratch Memory: 0
[03/24/2023-12:57:38] [V] [TRT] Layer: Reformatting CopyNode for Output Tensor 0 to Conv_85 Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0
[03/24/2023-12:57:38] [V] [TRT] Layer: Conv_86 + Relu_87 || Conv_89 + Relu_90 || Conv_92 + Relu_93 || Conv_95 + Relu_96 || Conv_98 + Relu_99 || Conv_101 + Relu_102 || Conv_104 + Relu_105 || Conv_107 + Relu_108 Host Persistent: 2400 Device Persistent: 592896 Scratch Memory: 0
[03/24/2023-12:57:38] [V] [TRT] Layer: Conv_88 Host Persistent: 2400 Device Persistent: 9728 Scratch Memory: 0
[03/24/2023-12:57:38] [V] [TRT] Layer: Reformatting CopyNode for Output Tensor 0 to Conv_88 Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0
[03/24/2023-12:57:38] [V] [TRT] Layer: Conv_91 Host Persistent: 2400 Device Persistent: 9728 Scratch Memory: 0
[03/24/2023-12:57:38] [V] [TRT] Layer: Reformatting CopyNode for Output Tensor 0 to Conv_91 Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0
[03/24/2023-12:57:38] [V] [TRT] Layer: Conv_94 Host Persistent: 2400 Device Persistent: 9728 Scratch Memory: 0
[03/24/2023-12:57:38] [V] [TRT] Layer: Reformatting CopyNode for Output Tensor 0 to Conv_94 Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0
[03/24/2023-12:57:38] [V] [TRT] Layer: Conv_97 Host Persistent: 2400 Device Persistent: 9728 Scratch Memory: 0
[03/24/2023-12:57:38] [V] [TRT] Layer: Reformatting CopyNode for Output Tensor 0 to Conv_97 Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0
[03/24/2023-12:57:38] [V] [TRT] Layer: Conv_100 Host Persistent: 2400 Device Persistent: 9728 Scratch Memory: 0
[03/24/2023-12:57:38] [V] [TRT] Layer: Reformatting CopyNode for Output Tensor 0 to Conv_100 Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0
[03/24/2023-12:57:38] [V] [TRT] Layer: Conv_103 Host Persistent: 2400 Device Persistent: 9728 Scratch Memory: 0
[03/24/2023-12:57:38] [V] [TRT] Layer: Reformatting CopyNode for Output Tensor 0 to Conv_103 Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0
[03/24/2023-12:57:38] [V] [TRT] Layer: Conv_106 Host Persistent: 2400 Device Persistent: 9728 Scratch Memory: 0
[03/24/2023-12:57:38] [V] [TRT] Layer: Reformatting CopyNode for Output Tensor 0 to Conv_106 Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0
[03/24/2023-12:57:38] [V] [TRT] Layer: Conv_109 Host Persistent: 2400 Device Persistent: 9728 Scratch Memory: 0
[03/24/2023-12:57:38] [V] [TRT] Layer: Reformatting CopyNode for Output Tensor 0 to Conv_109 Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0
[03/24/2023-12:57:38] [V] [TRT] Layer: Conv_110 + Relu_111 || Conv_113 + Relu_114 || Conv_116 + Relu_117 || Conv_119 + Relu_120 || Conv_122 + Relu_123 || Conv_125 + Relu_126 || Conv_128 + Relu_129 || Conv_131 + Relu_132 Host Persistent: 2400 Device Persistent: 592896 Scratch Memory: 0
[03/24/2023-12:57:38] [V] [TRT] Layer: Conv_112 Host Persistent: 2400 Device Persistent: 9728 Scratch Memory: 0
[03/24/2023-12:57:38] [V] [TRT] Layer: Reformatting CopyNode for Output Tensor 0 to Conv_112 Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0
[03/24/2023-12:57:38] [V] [TRT] Layer: Conv_115 Host Persistent: 2400 Device Persistent: 9728 Scratch Memory: 0
[03/24/2023-12:57:38] [V] [TRT] Layer: Reformatting CopyNode for Output Tensor 0 to Conv_115 Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0
[03/24/2023-12:57:38] [V] [TRT] Layer: Conv_118 Host Persistent: 2400 Device Persistent: 9728 Scratch Memory: 0
[03/24/2023-12:57:38] [V] [TRT] Layer: Reformatting CopyNode for Output Tensor 0 to Conv_118 Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0
[03/24/2023-12:57:38] [V] [TRT] Layer: Conv_121 Host Persistent: 2400 Device Persistent: 9728 Scratch Memory: 0
[03/24/2023-12:57:38] [V] [TRT] Layer: Reformatting CopyNode for Output Tensor 0 to Conv_121 Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0
[03/24/2023-12:57:38] [V] [TRT] Layer: Conv_124 Host Persistent: 2400 Device Persistent: 9728 Scratch Memory: 0
[03/24/2023-12:57:38] [V] [TRT] Layer: Reformatting CopyNode for Output Tensor 0 to Conv_124 Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0
[03/24/2023-12:57:38] [V] [TRT] Layer: Conv_127 Host Persistent: 2400 Device Persistent: 9728 Scratch Memory: 0
[03/24/2023-12:57:38] [V] [TRT] Layer: Reformatting CopyNode for Output Tensor 0 to Conv_127 Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0
[03/24/2023-12:57:38] [V] [TRT] Layer: Conv_130 Host Persistent: 2400 Device Persistent: 9728 Scratch Memory: 0
[03/24/2023-12:57:38] [V] [TRT] Layer: Reformatting CopyNode for Output Tensor 0 to Conv_130 Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0
[03/24/2023-12:57:38] [V] [TRT] Layer: Conv_133 Host Persistent: 2400 Device Persistent: 9728 Scratch Memory: 0
[03/24/2023-12:57:38] [V] [TRT] Layer: Reformatting CopyNode for Output Tensor 0 to Conv_133 Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0
[03/24/2023-12:57:38] [V] [TRT] Layer: Conv_134 + Relu_135 || Conv_137 + Relu_138 || Conv_140 + Relu_141 || Conv_143 + Relu_144 || Conv_146 + Relu_147 || Conv_149 + Relu_150 || Conv_152 + Relu_153 || Conv_155 + Relu_156 Host Persistent: 2400 Device Persistent: 592896 Scratch Memory: 0
[03/24/2023-12:57:38] [V] [TRT] Layer: Conv_136 Host Persistent: 2400 Device Persistent: 9728 Scratch Memory: 0
[03/24/2023-12:57:38] [V] [TRT] Layer: Reformatting CopyNode for Output Tensor 0 to Conv_136 Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0
[03/24/2023-12:57:38] [V] [TRT] Layer: Conv_139 Host Persistent: 2400 Device Persistent: 9728 Scratch Memory: 0
[03/24/2023-12:57:38] [V] [TRT] Layer: Reformatting CopyNode for Output Tensor 0 to Conv_139 Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0
[03/24/2023-12:57:38] [V] [TRT] Layer: Conv_142 Host Persistent: 2400 Device Persistent: 9728 Scratch Memory: 0
[03/24/2023-12:57:38] [V] [TRT] Layer: Reformatting CopyNode for Output Tensor 0 to Conv_142 Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0
[03/24/2023-12:57:38] [V] [TRT] Layer: Conv_145 Host Persistent: 2400 Device Persistent: 9728 Scratch Memory: 0
[03/24/2023-12:57:38] [V] [TRT] Layer: Reformatting CopyNode for Output Tensor 0 to Conv_145 Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0
[03/24/2023-12:57:38] [V] [TRT] Layer: Conv_148 Host Persistent: 2400 Device Persistent: 9728 Scratch Memory: 0
[03/24/2023-12:57:38] [V] [TRT] Layer: Reformatting CopyNode for Output Tensor 0 to Conv_148 Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0
[03/24/2023-12:57:38] [V] [TRT] Layer: Conv_151 Host Persistent: 2400 Device Persistent: 9728 Scratch Memory: 0
[03/24/2023-12:57:38] [V] [TRT] Layer: Reformatting CopyNode for Output Tensor 0 to Conv_151 Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0
[03/24/2023-12:57:38] [V] [TRT] Layer: Conv_154 Host Persistent: 2400 Device Persistent: 9728 Scratch Memory: 0
[03/24/2023-12:57:38] [V] [TRT] Layer: Reformatting CopyNode for Output Tensor 0 to Conv_154 Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0
[03/24/2023-12:57:38] [V] [TRT] Layer: Conv_157 Host Persistent: 2400 Device Persistent: 9728 Scratch Memory: 0
[03/24/2023-12:57:38] [V] [TRT] Layer: Reformatting CopyNode for Output Tensor 0 to Conv_157 Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0
[03/24/2023-12:57:38] [V] [TRT] Layer: Conv_158 + Relu_159 || Conv_161 + Relu_162 || Conv_164 + Relu_165 || Conv_167 + Relu_168 Host Persistent: 2400 Device Persistent: 296448 Scratch Memory: 0
[03/24/2023-12:57:38] [V] [TRT] Layer: Conv_160 Host Persistent: 2400 Device Persistent: 9728 Scratch Memory: 0
[03/24/2023-12:57:38] [V] [TRT] Layer: Reformatting CopyNode for Output Tensor 0 to Conv_160 Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0
[03/24/2023-12:57:38] [V] [TRT] Layer: Conv_163 Host Persistent: 2400 Device Persistent: 9728 Scratch Memory: 0
[03/24/2023-12:57:38] [V] [TRT] Layer: Reformatting CopyNode for Output Tensor 0 to Conv_163 Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0
[03/24/2023-12:57:38] [V] [TRT] Layer: Conv_166 Host Persistent: 2400 Device Persistent: 9728 Scratch Memory: 0
[03/24/2023-12:57:38] [V] [TRT] Layer: Reformatting CopyNode for Output Tensor 0 to Conv_166 Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0
[03/24/2023-12:57:38] [V] [TRT] Layer: Conv_169 Host Persistent: 2400 Device Persistent: 9728 Scratch Memory: 0
[03/24/2023-12:57:38] [V] [TRT] Layer: Reformatting CopyNode for Output Tensor 0 to Conv_169 Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0
[03/24/2023-12:57:38] [I] [TRT] Total Host Persistent Memory: 127584
[03/24/2023-12:57:38] [I] [TRT] Total Device Persistent Memory: 12675584
[03/24/2023-12:57:38] [I] [TRT] Total Scratch Memory: 20746240
[03/24/2023-12:57:38] [I] [TRT] [MemUsageStats] Peak memory usage of TRT CPU/GPU memory allocators: CPU 18 MiB, GPU 682 MiB
[03/24/2023-12:57:38] [I] [TRT] [BlockAssignment] Algorithm ShiftNTopDown took 2.14934ms to assign 4 blocks to 58 nodes requiring 74659840 bytes.
[03/24/2023-12:57:38] [V] [TRT] Optimized block assignment.
[03/24/2023-12:57:38] [V] [TRT] Block size 33177600
[03/24/2023-12:57:38] [V] [TRT] Block size 20746240
[03/24/2023-12:57:38] [V] [TRT] Block size 16588800
[03/24/2023-12:57:38] [V] [TRT] Block size 4147200
[03/24/2023-12:57:38] [I] [TRT] Total Activation Memory: 74659840
[03/24/2023-12:57:38] [V] [TRT] Using cublasLt as a tactic source
[03/24/2023-12:57:38] [I] [TRT] [MemUsageChange] Init cuBLAS/cuBLASLt: CPU +0, GPU +8, now: CPU 2497, GPU 1590 (MiB)
[03/24/2023-12:57:38] [V] [TRT] Using cuDNN as a tactic source
[03/24/2023-12:57:38] [I] [TRT] [MemUsageChange] Init cuDNN: CPU +0, GPU +10, now: CPU 2497, GPU 1600 (MiB)
[03/24/2023-12:57:38] [V] [TRT] Engine generation completed in 82.8537 seconds.
[03/24/2023-12:57:38] [V] [TRT] Deleting timing cache: 598 entries, 2718 hits
[03/24/2023-12:57:38] [V] [TRT] Engine Layer Information:
Layer(Reformat): Reformatting CopyNode for Input Tensor 0 to Conv_15 + Relu_16, Tactic: 0, input[Half(1,256,180,180)] -> Reformatted Input Tensor 0 to Conv_15 + Relu_16[Half(1,256,180,180)]
Layer(CaskConvolution): Conv_15 + Relu_16, Tactic: 6972489290272968208, Reformatted Input Tensor 0 to Conv_15 + Relu_16[Half(1,256,180,180)] -> input.12[Half(1,128,180,180)]
Layer(CaskConvolution): Conv_17 + Relu_18, Tactic: 6972489290272968208, input.12[Half(1,128,180,180)] -> input.24[Half(1,128,180,180)]
Layer(CaskConvolution): Conv_19 + Relu_20, Tactic: 6972489290272968208, input.24[Half(1,128,180,180)] -> input.36[Half(1,128,180,180)]
Layer(CaskConvolution): Conv_21 + Relu_22, Tactic: 6972489290272968208, input.36[Half(1,128,180,180)] -> input.48[Half(1,128,180,180)]
Layer(CaskConvolution): Conv_23 + Relu_24, Tactic: 6972489290272968208, input.48[Half(1,128,180,180)] -> input.60[Half(1,128,180,180)]
Layer(CaskConvolution): Conv_25 + Relu_26, Tactic: 6972489290272968208, input.60[Half(1,128,180,180)] -> input.72[Half(1,128,180,180)]
Layer(CaskConvolution): Conv_27 + Relu_28, Tactic: -5121883532434354186, input.72[Half(1,128,180,180)] -> input.164[Half(1,256,180,180)]
Layer(CaskConvolution): Conv_44 + Relu_45, Tactic: 328038211831149625, input.72[Half(1,128,180,180)] -> input.96[Half(1,256,90,90)]
Layer(CaskConvolution): Conv_46 + Relu_47, Tactic: 1838082074606840426, input.96[Half(1,256,90,90)] -> input.108[Half(1,256,90,90)]
Layer(CaskConvolution): Conv_48 + Relu_49, Tactic: 1838082074606840426, input.108[Half(1,256,90,90)] -> input.120[Half(1,256,90,90)]
Layer(CaskConvolution): Conv_50 + Relu_51, Tactic: 1838082074606840426, input.120[Half(1,256,90,90)] -> input.132[Half(1,256,90,90)]
Layer(CaskConvolution): Conv_52 + Relu_53, Tactic: 1838082074606840426, input.132[Half(1,256,90,90)] -> input.144[Half(1,256,90,90)]
Layer(CaskConvolution): Conv_54 + Relu_55, Tactic: 1838082074606840426, input.144[Half(1,256,90,90)] -> onnx::ConvTranspose_644[Half(1,256,90,90)]
Layer(GemmDeconvolution): ConvTranspose_56 + BatchNormalization_57 + Relu_58, Tactic: 0, onnx::ConvTranspose_644[Half(1,256,90,90)] -> onnx::Concat_647[Half(1,256,180,180)]
Layer(Reformat): onnx::Concat_647 copy, Tactic: 1002, onnx::Concat_647[Half(1,256,180,180)] -> input.164[Half(1,256,180,180)]
Layer(CaskConvolution): Conv_60 + Relu_61, Tactic: 8170606396342855895, input.164[Half(1,512,180,180)] -> onnx::Conv_651[Half(1,64,180,180)]
Layer(CaskConvolution): Conv_62 + Relu_63 || Conv_65 + Relu_66 || Conv_68 + Relu_69 || Conv_71 + Relu_72 || Conv_74 + Relu_75 || Conv_77 + Relu_78 || Conv_80 + Relu_81 || Conv_83 + Relu_84, Tactic: 6972489290272968208, onnx::Conv_651[Half(1,64,180,180)] -> Conv_62 + Relu_63 || Conv_65 + Relu_66 || Conv_68 + Relu_69 || Conv_71 + Relu_72 || Conv_74 + Relu_75 || Conv_77 + Relu_78 || Conv_80 + Relu_81 || Conv_83 + Relu_84[Half(1,512,180,180)]
Layer(CaskConvolution): Conv_64, Tactic: 4503233883285355107, Conv_62 + Relu_63 || Conv_65 + Relu_66 || Conv_68 + Relu_69 || Conv_71 + Relu_72 || Conv_74 + Relu_75 || Conv_77 + Relu_78 || Conv_80 + Relu_81 || Conv_83 + Relu_84[Half(1,64,180,180)] -> Reformatted Output Tensor 0 to Conv_64[Half(1,2,180,180)]
Layer(Reformat): Reformatting CopyNode for Output Tensor 0 to Conv_64, Tactic: 0, Reformatted Output Tensor 0 to Conv_64[Half(1,2,180,180)] -> reg_0[Half(1,2,180,180)]
Layer(CaskConvolution): Conv_67, Tactic: 4503233883285355107, Conv_62 + Relu_63 || Conv_65 + Relu_66 || Conv_68 + Relu_69 || Conv_71 + Relu_72 || Conv_74 + Relu_75 || Conv_77 + Relu_78 || Conv_80 + Relu_81 || Conv_83 + Relu_84[Half(1,64,180,180)] -> Reformatted Output Tensor 0 to Conv_67[Half(1,1,180,180)]
Layer(Reformat): Reformatting CopyNode for Output Tensor 0 to Conv_67, Tactic: 0, Reformatted Output Tensor 0 to Conv_67[Half(1,1,180,180)] -> height_0[Half(1,1,180,180)]
Layer(CaskConvolution): Conv_70, Tactic: 4503233883285355107, Conv_62 + Relu_63 || Conv_65 + Relu_66 || Conv_68 + Relu_69 || Conv_71 + Relu_72 || Conv_74 + Relu_75 || Conv_77 + Relu_78 || Conv_80 + Relu_81 || Conv_83 + Relu_84[Half(1,64,180,180)] -> Reformatted Output Tensor 0 to Conv_70[Half(1,3,180,180)]
Layer(Reformat): Reformatting CopyNode for Output Tensor 0 to Conv_70, Tactic: 0, Reformatted Output Tensor 0 to Conv_70[Half(1,3,180,180)] -> dim_0[Half(1,3,180,180)]
Layer(CaskConvolution): Conv_73, Tactic: 4503233883285355107, Conv_62 + Relu_63 || Conv_65 + Relu_66 || Conv_68 + Relu_69 || Conv_71 + Relu_72 || Conv_74 + Relu_75 || Conv_77 + Relu_78 || Conv_80 + Relu_81 || Conv_83 + Relu_84[Half(1,64,180,180)] -> Reformatted Output Tensor 0 to Conv_73[Half(1,2,180,180)]
Layer(Reformat): Reformatting CopyNode for Output Tensor 0 to Conv_73, Tactic: 0, Reformatted Output Tensor 0 to Conv_73[Half(1,2,180,180)] -> rot_0[Half(1,2,180,180)]
Layer(CaskConvolution): Conv_76, Tactic: 4503233883285355107, Conv_62 + Relu_63 || Conv_65 + Relu_66 || Conv_68 + Relu_69 || Conv_71 + Relu_72 || Conv_74 + Relu_75 || Conv_77 + Relu_78 || Conv_80 + Relu_81 || Conv_83 + Relu_84[Half(1,64,180,180)] -> Reformatted Output Tensor 0 to Conv_76[Half(1,2,180,180)]
Layer(Reformat): Reformatting CopyNode for Output Tensor 0 to Conv_76, Tactic: 0, Reformatted Output Tensor 0 to Conv_76[Half(1,2,180,180)] -> vel_0[Half(1,2,180,180)]
Layer(CaskConvolution): Conv_79, Tactic: 4503233883285355107, Conv_62 + Relu_63 || Conv_65 + Relu_66 || Conv_68 + Relu_69 || Conv_71 + Relu_72 || Conv_74 + Relu_75 || Conv_77 + Relu_78 || Conv_80 + Relu_81 || Conv_83 + Relu_84[Half(1,64,180,180)] -> Reformatted Output Tensor 0 to Conv_79[Half(1,1,180,180)]
Layer(Reformat): Reformatting CopyNode for Output Tensor 0 to Conv_79, Tactic: 0, Reformatted Output Tensor 0 to Conv_79[Half(1,1,180,180)] -> hm_0[Half(1,1,180,180)]
Layer(CaskConvolution): Conv_82, Tactic: 4503233883285355107, Conv_62 + Relu_63 || Conv_65 + Relu_66 || Conv_68 + Relu_69 || Conv_71 + Relu_72 || Conv_74 + Relu_75 || Conv_77 + Relu_78 || Conv_80 + Relu_81 || Conv_83 + Relu_84[Half(1,64,180,180)] -> Reformatted Output Tensor 0 to Conv_82[Half(1,2,180,180)]
Layer(Reformat): Reformatting CopyNode for Output Tensor 0 to Conv_82, Tactic: 0, Reformatted Output Tensor 0 to Conv_82[Half(1,2,180,180)] -> reg_1[Half(1,2,180,180)]
Layer(CaskConvolution): Conv_85, Tactic: 4503233883285355107, Conv_62 + Relu_63 || Conv_65 + Relu_66 || Conv_68 + Relu_69 || Conv_71 + Relu_72 || Conv_74 + Relu_75 || Conv_77 + Relu_78 || Conv_80 + Relu_81 || Conv_83 + Relu_84[Half(1,64,180,180)] -> Reformatted Output Tensor 0 to Conv_85[Half(1,1,180,180)]
Layer(Reformat): Reformatting CopyNode for Output Tensor 0 to Conv_85, Tactic: 0, Reformatted Output Tensor 0 to Conv_85[Half(1,1,180,180)] -> height_1[Half(1,1,180,180)]
Layer(CaskConvolution): Conv_86 + Relu_87 || Conv_89 + Relu_90 || Conv_92 + Relu_93 || Conv_95 + Relu_96 || Conv_98 + Relu_99 || Conv_101 + Relu_102 || Conv_104 + Relu_105 || Conv_107 + Relu_108, Tactic: 6972489290272968208, onnx::Conv_651[Half(1,64,180,180)] -> Conv_86 + Relu_87 || Conv_89 + Relu_90 || Conv_92 + Relu_93 || Conv_95 + Relu_96 || Conv_98 + Relu_99 || Conv_101 + Relu_102 || Conv_104 + Relu_105 || Conv_107 + Relu_108[Half(1,512,180,180)]
Layer(CaskConvolution): Conv_88, Tactic: 4503233883285355107, Conv_86 + Relu_87 || Conv_89 + Relu_90 || Conv_92 + Relu_93 || Conv_95 + Relu_96 || Conv_98 + Relu_99 || Conv_101 + Relu_102 || Conv_104 + Relu_105 || Conv_107 + Relu_108[Half(1,64,180,180)] -> Reformatted Output Tensor 0 to Conv_88[Half(1,3,180,180)]
Layer(Reformat): Reformatting CopyNode for Output Tensor 0 to Conv_88, Tactic: 0, Reformatted Output Tensor 0 to Conv_88[Half(1,3,180,180)] -> dim_1[Half(1,3,180,180)]
Layer(CaskConvolution): Conv_91, Tactic: 4503233883285355107, Conv_86 + Relu_87 || Conv_89 + Relu_90 || Conv_92 + Relu_93 || Conv_95 + Relu_96 || Conv_98 + Relu_99 || Conv_101 + Relu_102 || Conv_104 + Relu_105 || Conv_107 + Relu_108[Half(1,64,180,180)] -> Reformatted Output Tensor 0 to Conv_91[Half(1,2,180,180)]
Layer(Reformat): Reformatting CopyNode for Output Tensor 0 to Conv_91, Tactic: 0, Reformatted Output Tensor 0 to Conv_91[Half(1,2,180,180)] -> rot_1[Half(1,2,180,180)]
Layer(CaskConvolution): Conv_94, Tactic: 4503233883285355107, Conv_86 + Relu_87 || Conv_89 + Relu_90 || Conv_92 + Relu_93 || Conv_95 + Relu_96 || Conv_98 + Relu_99 || Conv_101 + Relu_102 || Conv_104 + Relu_105 || Conv_107 + Relu_108[Half(1,64,180,180)] -> Reformatted Output Tensor 0 to Conv_94[Half(1,2,180,180)]
Layer(Reformat): Reformatting CopyNode for Output Tensor 0 to Conv_94, Tactic: 0, Reformatted Output Tensor 0 to Conv_94[Half(1,2,180,180)] -> vel_1[Half(1,2,180,180)]
Layer(CaskConvolution): Conv_97, Tactic: 4503233883285355107, Conv_86 + Relu_87 || Conv_89 + Relu_90 || Conv_92 + Relu_93 || Conv_95 + Relu_96 || Conv_98 + Relu_99 || Conv_101 + Relu_102 || Conv_104 + Relu_105 || Conv_107 + Relu_108[Half(1,64,180,180)] -> Reformatted Output Tensor 0 to Conv_97[Half(1,2,180,180)]
Layer(Reformat): Reformatting CopyNode for Output Tensor 0 to Conv_97, Tactic: 0, Reformatted Output Tensor 0 to Conv_97[Half(1,2,180,180)] -> hm_1[Half(1,2,180,180)]
Layer(CaskConvolution): Conv_100, Tactic: 4503233883285355107, Conv_86 + Relu_87 || Conv_89 + Relu_90 || Conv_92 + Relu_93 || Conv_95 + Relu_96 || Conv_98 + Relu_99 || Conv_101 + Relu_102 || Conv_104 + Relu_105 || Conv_107 + Relu_108[Half(1,64,180,180)] -> Reformatted Output Tensor 0 to Conv_100[Half(1,2,180,180)]
Layer(Reformat): Reformatting CopyNode for Output Tensor 0 to Conv_100, Tactic: 0, Reformatted Output Tensor 0 to Conv_100[Half(1,2,180,180)] -> reg_2[Half(1,2,180,180)]
Layer(CaskConvolution): Conv_103, Tactic: 4503233883285355107, Conv_86 + Relu_87 || Conv_89 + Relu_90 || Conv_92 + Relu_93 || Conv_95 + Relu_96 || Conv_98 + Relu_99 || Conv_101 + Relu_102 || Conv_104 + Relu_105 || Conv_107 + Relu_108[Half(1,64,180,180)] -> Reformatted Output Tensor 0 to Conv_103[Half(1,1,180,180)]
Layer(Reformat): Reformatting CopyNode for Output Tensor 0 to Conv_103, Tactic: 0, Reformatted Output Tensor 0 to Conv_103[Half(1,1,180,180)] -> height_2[Half(1,1,180,180)]
Layer(CaskConvolution): Conv_106, Tactic: 4503233883285355107, Conv_86 + Relu_87 || Conv_89 + Relu_90 || Conv_92 + Relu_93 || Conv_95 + Relu_96 || Conv_98 + Relu_99 || Conv_101 + Relu_102 || Conv_104 + Relu_105 || Conv_107 + Relu_108[Half(1,64,180,180)] -> Reformatted Output Tensor 0 to Conv_106[Half(1,3,180,180)]
Layer(Reformat): Reformatting CopyNode for Output Tensor 0 to Conv_106, Tactic: 0, Reformatted Output Tensor 0 to Conv_106[Half(1,3,180,180)] -> dim_2[Half(1,3,180,180)]
Layer(CaskConvolution): Conv_109, Tactic: 4503233883285355107, Conv_86 + Relu_87 || Conv_89 + Relu_90 || Conv_92 + Relu_93 || Conv_95 + Relu_96 || Conv_98 + Relu_99 || Conv_101 + Relu_102 || Conv_104 + Relu_105 || Conv_107 + Relu_108[Half(1,64,180,180)] -> Reformatted Output Tensor 0 to Conv_109[Half(1,2,180,180)]
Layer(Reformat): Reformatting CopyNode for Output Tensor 0 to Conv_109, Tactic: 0, Reformatted Output Tensor 0 to Conv_109[Half(1,2,180,180)] -> rot_2[Half(1,2,180,180)]
Layer(CaskConvolution): Conv_110 + Relu_111 || Conv_113 + Relu_114 || Conv_116 + Relu_117 || Conv_119 + Relu_120 || Conv_122 + Relu_123 || Conv_125 + Relu_126 || Conv_128 + Relu_129 || Conv_131 + Relu_132, Tactic: 6972489290272968208, onnx::Conv_651[Half(1,64,180,180)] -> Conv_110 + Relu_111 || Conv_113 + Relu_114 || Conv_116 + Relu_117 || Conv_119 + Relu_120 || Conv_122 + Relu_123 || Conv_125 + Relu_126 || Conv_128 + Relu_129 || Conv_131 + Relu_132[Half(1,512,180,180)]
Layer(CaskConvolution): Conv_112, Tactic: 4503233883285355107, Conv_110 + Relu_111 || Conv_113 + Relu_114 || Conv_116 + Relu_117 || Conv_119 + Relu_120 || Conv_122 + Relu_123 || Conv_125 + Relu_126 || Conv_128 + Relu_129 || Conv_131 + Relu_132[Half(1,64,180,180)] -> Reformatted Output Tensor 0 to Conv_112[Half(1,2,180,180)]
Layer(Reformat): Reformatting CopyNode for Output Tensor 0 to Conv_112, Tactic: 0, Reformatted Output Tensor 0 to Conv_112[Half(1,2,180,180)] -> vel_2[Half(1,2,180,180)]
Layer(CaskConvolution): Conv_115, Tactic: 4503233883285355107, Conv_110 + Relu_111 || Conv_113 + Relu_114 || Conv_116 + Relu_117 || Conv_119 + Relu_120 || Conv_122 + Relu_123 || Conv_125 + Relu_126 || Conv_128 + Relu_129 || Conv_131 + Relu_132[Half(1,64,180,180)] -> Reformatted Output Tensor 0 to Conv_115[Half(1,2,180,180)]
Layer(Reformat): Reformatting CopyNode for Output Tensor 0 to Conv_115, Tactic: 0, Reformatted Output Tensor 0 to Conv_115[Half(1,2,180,180)] -> hm_2[Half(1,2,180,180)]
Layer(CaskConvolution): Conv_118, Tactic: 4503233883285355107, Conv_110 + Relu_111 || Conv_113 + Relu_114 || Conv_116 + Relu_117 || Conv_119 + Relu_120 || Conv_122 + Relu_123 || Conv_125 + Relu_126 || Conv_128 + Relu_129 || Conv_131 + Relu_132[Half(1,64,180,180)] -> Reformatted Output Tensor 0 to Conv_118[Half(1,2,180,180)]
Layer(Reformat): Reformatting CopyNode for Output Tensor 0 to Conv_118, Tactic: 0, Reformatted Output Tensor 0 to Conv_118[Half(1,2,180,180)] -> reg_3[Half(1,2,180,180)]
Layer(CaskConvolution): Conv_121, Tactic: 4503233883285355107, Conv_110 + Relu_111 || Conv_113 + Relu_114 || Conv_116 + Relu_117 || Conv_119 + Relu_120 || Conv_122 + Relu_123 || Conv_125 + Relu_126 || Conv_128 + Relu_129 || Conv_131 + Relu_132[Half(1,64,180,180)] -> Reformatted Output Tensor 0 to Conv_121[Half(1,1,180,180)]
Layer(Reformat): Reformatting CopyNode for Output Tensor 0 to Conv_121, Tactic: 0, Reformatted Output Tensor 0 to Conv_121[Half(1,1,180,180)] -> height_3[Half(1,1,180,180)]
Layer(CaskConvolution): Conv_124, Tactic: 4503233883285355107, Conv_110 + Relu_111 || Conv_113 + Relu_114 || Conv_116 + Relu_117 || Conv_119 + Relu_120 || Conv_122 + Relu_123 || Conv_125 + Relu_126 || Conv_128 + Relu_129 || Conv_131 + Relu_132[Half(1,64,180,180)] -> Reformatted Output Tensor 0 to Conv_124[Half(1,3,180,180)]
Layer(Reformat): Reformatting CopyNode for Output Tensor 0 to Conv_124, Tactic: 0, Reformatted Output Tensor 0 to Conv_124[Half(1,3,180,180)] -> dim_3[Half(1,3,180,180)]
Layer(CaskConvolution): Conv_127, Tactic: 4503233883285355107, Conv_110 + Relu_111 || Conv_113 + Relu_114 || Conv_116 + Relu_117 || Conv_119 + Relu_120 || Conv_122 + Relu_123 || Conv_125 + Relu_126 || Conv_128 + Relu_129 || Conv_131 + Relu_132[Half(1,64,180,180)] -> Reformatted Output Tensor 0 to Conv_127[Half(1,2,180,180)]
Layer(Reformat): Reformatting CopyNode for Output Tensor 0 to Conv_127, Tactic: 0, Reformatted Output Tensor 0 to Conv_127[Half(1,2,180,180)] -> rot_3[Half(1,2,180,180)]
Layer(CaskConvolution): Conv_130, Tactic: 4503233883285355107, Conv_110 + Relu_111 || Conv_113 + Relu_114 || Conv_116 + Relu_117 || Conv_119 + Relu_120 || Conv_122 + Relu_123 || Conv_125 + Relu_126 || Conv_128 + Relu_129 || Conv_131 + Relu_132[Half(1,64,180,180)] -> Reformatted Output Tensor 0 to Conv_130[Half(1,2,180,180)]
Layer(Reformat): Reformatting CopyNode for Output Tensor 0 to Conv_130, Tactic: 0, Reformatted Output Tensor 0 to Conv_130[Half(1,2,180,180)] -> vel_3[Half(1,2,180,180)]
Layer(CaskConvolution): Conv_133, Tactic: 4503233883285355107, Conv_110 + Relu_111 || Conv_113 + Relu_114 || Conv_116 + Relu_117 || Conv_119 + Relu_120 || Conv_122 + Relu_123 || Conv_125 + Relu_126 || Conv_128 + Relu_129 || Conv_131 + Relu_132[Half(1,64,180,180)] -> Reformatted Output Tensor 0 to Conv_133[Half(1,1,180,180)]
Layer(Reformat): Reformatting CopyNode for Output Tensor 0 to Conv_133, Tactic: 0, Reformatted Output Tensor 0 to Conv_133[Half(1,1,180,180)] -> hm_3[Half(1,1,180,180)]
Layer(CaskConvolution): Conv_134 + Relu_135 || Conv_137 + Relu_138 || Conv_140 + Relu_141 || Conv_143 + Relu_144 || Conv_146 + Relu_147 || Conv_149 + Relu_150 || Conv_152 + Relu_153 || Conv_155 + Relu_156, Tactic: 6972489290272968208, onnx::Conv_651[Half(1,64,180,180)] -> Conv_134 + Relu_135 || Conv_137 + Relu_138 || Conv_140 + Relu_141 || Conv_143 + Relu_144 || Conv_146 + Relu_147 || Conv_149 + Relu_150 || Conv_152 + Relu_153 || Conv_155 + Relu_156[Half(1,512,180,180)]
Layer(CaskConvolution): Conv_136, Tactic: 4503233883285355107, Conv_134 + Relu_135 || Conv_137 + Relu_138 || Conv_140 + Relu_141 || Conv_143 + Relu_144 || Conv_146 + Relu_147 || Conv_149 + Relu_150 || Conv_152 + Relu_153 || Conv_155 + Relu_156[Half(1,64,180,180)] -> Reformatted Output Tensor 0 to Conv_136[Half(1,2,180,180)]
Layer(Reformat): Reformatting CopyNode for Output Tensor 0 to Conv_136, Tactic: 0, Reformatted Output Tensor 0 to Conv_136[Half(1,2,180,180)] -> reg_4[Half(1,2,180,180)]
Layer(CaskConvolution): Conv_139, Tactic: 4503233883285355107, Conv_134 + Relu_135 || Conv_137 + Relu_138 || Conv_140 + Relu_141 || Conv_143 + Relu_144 || Conv_146 + Relu_147 || Conv_149 + Relu_150 || Conv_152 + Relu_153 || Conv_155 + Relu_156[Half(1,64,180,180)] -> Reformatted Output Tensor 0 to Conv_139[Half(1,1,180,180)]
Layer(Reformat): Reformatting CopyNode for Output Tensor 0 to Conv_139, Tactic: 0, Reformatted Output Tensor 0 to Conv_139[Half(1,1,180,180)] -> height_4[Half(1,1,180,180)]
Layer(CaskConvolution): Conv_142, Tactic: 4503233883285355107, Conv_134 + Relu_135 || Conv_137 + Relu_138 || Conv_140 + Relu_141 || Conv_143 + Relu_144 || Conv_146 + Relu_147 || Conv_149 + Relu_150 || Conv_152 + Relu_153 || Conv_155 + Relu_156[Half(1,64,180,180)] -> Reformatted Output Tensor 0 to Conv_142[Half(1,3,180,180)]
Layer(Reformat): Reformatting CopyNode for Output Tensor 0 to Conv_142, Tactic: 0, Reformatted Output Tensor 0 to Conv_142[Half(1,3,180,180)] -> dim_4[Half(1,3,180,180)]
Layer(CaskConvolution): Conv_145, Tactic: 4503233883285355107, Conv_134 + Relu_135 || Conv_137 + Relu_138 || Conv_140 + Relu_141 || Conv_143 + Relu_144 || Conv_146 + Relu_147 || Conv_149 + Relu_150 || Conv_152 + Relu_153 || Conv_155 + Relu_156[Half(1,64,180,180)] -> Reformatted Output Tensor 0 to Conv_145[Half(1,2,180,180)]
Layer(Reformat): Reformatting CopyNode for Output Tensor 0 to Conv_145, Tactic: 0, Reformatted Output Tensor 0 to Conv_145[Half(1,2,180,180)] -> rot_4[Half(1,2,180,180)]
Layer(CaskConvolution): Conv_148, Tactic: 4503233883285355107, Conv_134 + Relu_135 || Conv_137 + Relu_138 || Conv_140 + Relu_141 || Conv_143 + Relu_144 || Conv_146 + Relu_147 || Conv_149 + Relu_150 || Conv_152 + Relu_153 || Conv_155 + Relu_156[Half(1,64,180,180)] -> Reformatted Output Tensor 0 to Conv_148[Half(1,2,180,180)]
Layer(Reformat): Reformatting CopyNode for Output Tensor 0 to Conv_148, Tactic: 0, Reformatted Output Tensor 0 to Conv_148[Half(1,2,180,180)] -> vel_4[Half(1,2,180,180)]
Layer(CaskConvolution): Conv_151, Tactic: 4503233883285355107, Conv_134 + Relu_135 || Conv_137 + Relu_138 || Conv_140 + Relu_141 || Conv_143 + Relu_144 || Conv_146 + Relu_147 || Conv_149 + Relu_150 || Conv_152 + Relu_153 || Conv_155 + Relu_156[Half(1,64,180,180)] -> Reformatted Output Tensor 0 to Conv_151[Half(1,2,180,180)]
Layer(Reformat): Reformatting CopyNode for Output Tensor 0 to Conv_151, Tactic: 0, Reformatted Output Tensor 0 to Conv_151[Half(1,2,180,180)] -> hm_4[Half(1,2,180,180)]
Layer(CaskConvolution): Conv_154, Tactic: 4503233883285355107, Conv_134 + Relu_135 || Conv_137 + Relu_138 || Conv_140 + Relu_141 || Conv_143 + Relu_144 || Conv_146 + Relu_147 || Conv_149 + Relu_150 || Conv_152 + Relu_153 || Conv_155 + Relu_156[Half(1,64,180,180)] -> Reformatted Output Tensor 0 to Conv_154[Half(1,2,180,180)]
Layer(Reformat): Reformatting CopyNode for Output Tensor 0 to Conv_154, Tactic: 0, Reformatted Output Tensor 0 to Conv_154[Half(1,2,180,180)] -> reg_5[Half(1,2,180,180)]
Layer(CaskConvolution): Conv_157, Tactic: 4503233883285355107, Conv_134 + Relu_135 || Conv_137 + Relu_138 || Conv_140 + Relu_141 || Conv_143 + Relu_144 || Conv_146 + Relu_147 || Conv_149 + Relu_150 || Conv_152 + Relu_153 || Conv_155 + Relu_156[Half(1,64,180,180)] -> Reformatted Output Tensor 0 to Conv_157[Half(1,1,180,180)]
Layer(Reformat): Reformatting CopyNode for Output Tensor 0 to Conv_157, Tactic: 0, Reformatted Output Tensor 0 to Conv_157[Half(1,1,180,180)] -> height_5[Half(1,1,180,180)]
Layer(CaskConvolution): Conv_158 + Relu_159 || Conv_161 + Relu_162 || Conv_164 + Relu_165 || Conv_167 + Relu_168, Tactic: 6972489290272968208, onnx::Conv_651[Half(1,64,180,180)] -> Conv_158 + Relu_159 || Conv_161 + Relu_162 || Conv_164 + Relu_165 || Conv_167 + Relu_168[Half(1,256,180,180)]
Layer(CaskConvolution): Conv_160, Tactic: 4503233883285355107, Conv_158 + Relu_159 || Conv_161 + Relu_162 || Conv_164 + Relu_165 || Conv_167 + Relu_168[Half(1,64,180,180)] -> Reformatted Output Tensor 0 to Conv_160[Half(1,3,180,180)]
Layer(Reformat): Reformatting CopyNode for Output Tensor 0 to Conv_160, Tactic: 0, Reformatted Output Tensor 0 to Conv_160[Half(1,3,180,180)] -> dim_5[Half(1,3,180,180)]
Layer(CaskConvolution): Conv_163, Tactic: -8985224497679592364, Conv_158 + Relu_159 || Conv_161 + Relu_162 || Conv_164 + Relu_165 || Conv_167 + Relu_168[Half(1,64,180,180)] -> Reformatted Output Tensor 0 to Conv_163[Half(1,2,180,180)]
Layer(Reformat): Reformatting CopyNode for Output Tensor 0 to Conv_163, Tactic: 0, Reformatted Output Tensor 0 to Conv_163[Half(1,2,180,180)] -> rot_5[Half(1,2,180,180)]
Layer(CaskConvolution): Conv_166, Tactic: -8985224497679592364, Conv_158 + Relu_159 || Conv_161 + Relu_162 || Conv_164 + Relu_165 || Conv_167 + Relu_168[Half(1,64,180,180)] -> Reformatted Output Tensor 0 to Conv_166[Half(1,2,180,180)]
Layer(Reformat): Reformatting CopyNode for Output Tensor 0 to Conv_166, Tactic: 0, Reformatted Output Tensor 0 to Conv_166[Half(1,2,180,180)] -> vel_5[Half(1,2,180,180)]
Layer(CaskConvolution): Conv_169, Tactic: -8985224497679592364, Conv_158 + Relu_159 || Conv_161 + Relu_162 || Conv_164 + Relu_165 || Conv_167 + Relu_168[Half(1,64,180,180)] -> Reformatted Output Tensor 0 to Conv_169[Half(1,2,180,180)]
Layer(Reformat): Reformatting CopyNode for Output Tensor 0 to Conv_169, Tactic: 0, Reformatted Output Tensor 0 to Conv_169[Half(1,2,180,180)] -> hm_5[Half(1,2,180,180)]
[03/24/2023-12:57:38] [I] [TRT] [MemUsageChange] TensorRT-managed allocation in building engine: CPU +12, GPU +13, now: CPU 12, GPU 13 (MiB)
[03/24/2023-12:57:38] [I] [TRT] [MemUsageChange] Init CUDA: CPU +0, GPU +0, now: CPU 2491, GPU 1552 (MiB)
[03/24/2023-12:57:38] [I] [TRT] Loaded engine size: 13 MiB
[03/24/2023-12:57:38] [V] [TRT] Using cublasLt as a tactic source
[03/24/2023-12:57:38] [I] [TRT] [MemUsageChange] Init cuBLAS/cuBLASLt: CPU +0, GPU +10, now: CPU 2492, GPU 1576 (MiB)
[03/24/2023-12:57:38] [V] [TRT] Using cuDNN as a tactic source
[03/24/2023-12:57:38] [I] [TRT] [MemUsageChange] Init cuDNN: CPU +0, GPU +8, now: CPU 2492, GPU 1584 (MiB)
[03/24/2023-12:57:38] [V] [TRT] Deserialization required 10792 microseconds.
[03/24/2023-12:57:38] [I] [TRT] [MemUsageChange] TensorRT-managed allocation in engine deserialization: CPU +0, GPU +12, now: CPU 0, GPU 12 (MiB)
[03/24/2023-12:57:38] [I] Engine built in 85.4169 sec.
[03/24/2023-12:57:38] [I] Layer Information:
[03/24/2023-12:57:38] [I] [TRT] [MemUsageChange] Init CUDA: CPU +0, GPU +0, now: CPU 2238, GPU 1530 (MiB)
[03/24/2023-12:57:38] [I] Layers:
Name: Reformatting CopyNode for Input Tensor 0 to Conv_15 + Relu_16, LayerType: Reformat, Inputs: [ { Name: input, Dimensions: [1,256,180,180], Format/Datatype: Row major linear FP16 format }], Outputs: [ { Name: Reformatted Input Tensor 0 to Conv_15 + Relu_16, Dimensions: [1,256,180,180], Format/Datatype: Channel major FP16 format where channel % 8 == 0 }], ParameterType: Reformat, Origin: REFORMAT, TacticValue: 0x0
Name: Conv_15 + Relu_16, LayerType: CaskConvolution, Inputs: [ { Name: Reformatted Input Tensor 0 to Conv_15 + Relu_16, Dimensions: [1,256,180,180], Format/Datatype: Channel major FP16 format where channel % 8 == 0 }], Outputs: [ { Name: input.12, Dimensions: [1,128,180,180], Format/Datatype: Channel major FP16 format where channel % 8 == 0 }], ParameterType: Convolution, Kernel: [3,3], PaddingMode: kEXPLICIT_ROUND_DOWN, PrePadding: [1,1], PostPadding: [1,1], Stride: [1,1], Dilation: [1,1], OutMaps: 128, Groups: 1, Weights: {"Type": "Half", "Count": 294912}, Bias: {"Type": "Half", "Count": 128}, AllowSparse: 0, Activation: RELU, HasBias: 1, HasReLU: 1, TacticName: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x128x32_stage4_warpsize2x2x1_g1_tensor16x8x16_t1r3s3, TacticValue: 0x60c3421152ef8e10
Name: Conv_17 + Relu_18, LayerType: CaskConvolution, Inputs: [ { Name: input.12, Dimensions: [1,128,180,180], Format/Datatype: Channel major FP16 format where channel % 8 == 0 }], Outputs: [ { Name: input.24, Dimensions: [1,128,180,180], Format/Datatype: Channel major FP16 format where channel % 8 == 0 }], ParameterType: Convolution, Kernel: [3,3], PaddingMode: kEXPLICIT_ROUND_DOWN, PrePadding: [1,1], PostPadding: [1,1], Stride: [1,1], Dilation: [1,1], OutMaps: 128, Groups: 1, Weights: {"Type": "Half", "Count": 147456}, Bias: {"Type": "Half", "Count": 128}, AllowSparse: 0, Activation: RELU, HasBias: 1, HasReLU: 1, TacticName: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x128x32_stage4_warpsize2x2x1_g1_tensor16x8x16_t1r3s3, TacticValue: 0x60c3421152ef8e10
Name: Conv_19 + Relu_20, LayerType: CaskConvolution, Inputs: [ { Name: input.24, Dimensions: [1,128,180,180], Format/Datatype: Channel major FP16 format where channel % 8 == 0 }], Outputs: [ { Name: input.36, Dimensions: [1,128,180,180], Format/Datatype: Channel major FP16 format where channel % 8 == 0 }], ParameterType: Convolution, Kernel: [3,3], PaddingMode: kEXPLICIT_ROUND_DOWN, PrePadding: [1,1], PostPadding: [1,1], Stride: [1,1], Dilation: [1,1], OutMaps: 128, Groups: 1, Weights: {"Type": "Half", "Count": 147456}, Bias: {"Type": "Half", "Count": 128}, AllowSparse: 0, Activation: RELU, HasBias: 1, HasReLU: 1, TacticName: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x128x32_stage4_warpsize2x2x1_g1_tensor16x8x16_t1r3s3, TacticValue: 0x60c3421152ef8e10
Name: Conv_21 + Relu_22, LayerType: CaskConvolution, Inputs: [ { Name: input.36, Dimensions: [1,128,180,180], Format/Datatype: Channel major FP16 format where channel % 8 == 0 }], Outputs: [ { Name: input.48, Dimensions: [1,128,180,180], Format/Datatype: Channel major FP16 format where channel % 8 == 0 }], ParameterType: Convolution, Kernel: [3,3], PaddingMode: kEXPLICIT_ROUND_DOWN, PrePadding: [1,1], PostPadding: [1,1], Stride: [1,1], Dilation: [1,1], OutMaps: 128, Groups: 1, Weights: {"Type": "Half", "Count": 147456}, Bias: {"Type": "Half", "Count": 128}, AllowSparse: 0, Activation: RELU, HasBias: 1, HasReLU: 1, TacticName: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x128x32_stage4_warpsize2x2x1_g1_tensor16x8x16_t1r3s3, TacticValue: 0x60c3421152ef8e10
Name: Conv_23 + Relu_24, LayerType: CaskConvolution, Inputs: [ { Name: input.48, Dimensions: [1,128,180,180], Format/Datatype: Channel major FP16 format where channel % 8 == 0 }], Outputs: [ { Name: input.60, Dimensions: [1,128,180,180], Format/Datatype: Channel major FP16 format where channel % 8 == 0 }], ParameterType: Convolution, Kernel: [3,3], PaddingMode: kEXPLICIT_ROUND_DOWN, PrePadding: [1,1], PostPadding: [1,1], Stride: [1,1], Dilation: [1,1], OutMaps: 128, Groups: 1, Weights: {"Type": "Half", "Count": 147456}, Bias: {"Type": "Half", "Count": 128}, AllowSparse: 0, Activation: RELU, HasBias: 1, HasReLU: 1, TacticName: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x128x32_stage4_warpsize2x2x1_g1_tensor16x8x16_t1r3s3, TacticValue: 0x60c3421152ef8e10
Name: Conv_25 + Relu_26, LayerType: CaskConvolution, Inputs: [ { Name: input.60, Dimensions: [1,128,180,180], Format/Datatype: Channel major FP16 format where channel % 8 == 0 }], Outputs: [ { Name: input.72, Dimensions: [1,128,180,180], Format/Datatype: Channel major FP16 format where channel % 8 == 0 }], ParameterType: Convolution, Kernel: [3,3], PaddingMode: kEXPLICIT_ROUND_DOWN, PrePadding: [1,1], PostPadding: [1,1], Stride: [1,1], Dilation: [1,1], OutMaps: 128, Groups: 1, Weights: {"Type": "Half", "Count": 147456}, Bias: {"Type": "Half", "Count": 128}, AllowSparse: 0, Activation: RELU, HasBias: 1, HasReLU: 1, TacticName: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x128x32_stage4_warpsize2x2x1_g1_tensor16x8x16_t1r3s3, TacticValue: 0x60c3421152ef8e10
Name: Conv_27 + Relu_28, LayerType: CaskConvolution, Inputs: [ { Name: input.72, Dimensions: [1,128,180,180], Format/Datatype: Channel major FP16 format where channel % 8 == 0 }], Outputs: [ { Name: input.164, Dimensions: [1,256,180,180], Format/Datatype: Channel major FP16 format where channel % 8 == 0 }], ParameterType: Convolution, Kernel: [1,1], PaddingMode: kEXPLICIT_ROUND_DOWN, PrePadding: [0,0], PostPadding: [0,0], Stride: [1,1], Dilation: [1,1], OutMaps: 256, Groups: 1, Weights: {"Type": "Half", "Count": 32768}, Bias: {"Type": "Half", "Count": 256}, AllowSparse: 0, Activation: RELU, HasBias: 1, HasReLU: 1, TacticName: sm75_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x128x32_stage1_warpsize2x2x1_g1_tensor16x8x8_t1r1s1, TacticValue: 0xb8eb6a106c53cff6
Name: Conv_44 + Relu_45, LayerType: CaskConvolution, Inputs: [ { Name: input.72, Dimensions: [1,128,180,180], Format/Datatype: Channel major FP16 format where channel % 8 == 0 }], Outputs: [ { Name: input.96, Dimensions: [1,256,90,90], Format/Datatype: Channel major FP16 format where channel % 8 == 0 }], ParameterType: Convolution, Kernel: [3,3], PaddingMode: kEXPLICIT_ROUND_DOWN, PrePadding: [1,1], PostPadding: [1,1], Stride: [2,2], Dilation: [1,1], OutMaps: 256, Groups: 1, Weights: {"Type": "Half", "Count": 294912}, Bias: {"Type": "Half", "Count": 256}, AllowSparse: 0, Activation: RELU, HasBias: 1, HasReLU: 1, TacticName: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x128x32_stage3_warpsize4x2x1_g1_tensor16x8x16_t1r3s3, TacticValue: 0x48d6d0400f33439
Name: Conv_46 + Relu_47, LayerType: CaskConvolution, Inputs: [ { Name: input.96, Dimensions: [1,256,90,90], Format/Datatype: Channel major FP16 format where channel % 8 == 0 }], Outputs: [ { Name: input.108, Dimensions: [1,256,90,90], Format/Datatype: Channel major FP16 format where channel % 8 == 0 }], ParameterType: Convolution, Kernel: [3,3], PaddingMode: kEXPLICIT_ROUND_DOWN, PrePadding: [1,1], PostPadding: [1,1], Stride: [1,1], Dilation: [1,1], OutMaps: 256, Groups: 1, Weights: {"Type": "Half", "Count": 589824}, Bias: {"Type": "Half", "Count": 256}, AllowSparse: 0, Activation: RELU, HasBias: 1, HasReLU: 1, TacticName: ampere_h16816cudnn_128x64_sliced1x2_ldg8_relu_exp_stages_64x3_small_nhwc_tn_v1, TacticValue: 0x19822de884f42a6a
Name: Conv_48 + Relu_49, LayerType: CaskConvolution, Inputs: [ { Name: input.108, Dimensions: [1,256,90,90], Format/Datatype: Channel major FP16 format where channel % 8 == 0 }], Outputs: [ { Name: input.120, Dimensions: [1,256,90,90], Format/Datatype: Channel major FP16 format where channel % 8 == 0 }], ParameterType: Convolution, Kernel: [3,3], PaddingMode: kEXPLICIT_ROUND_DOWN, PrePadding: [1,1], PostPadding: [1,1], Stride: [1,1], Dilation: [1,1], OutMaps: 256, Groups: 1, Weights: {"Type": "Half", "Count": 589824}, Bias: {"Type": "Half", "Count": 256}, AllowSparse: 0, Activation: RELU, HasBias: 1, HasReLU: 1, TacticName: ampere_h16816cudnn_128x64_sliced1x2_ldg8_relu_exp_stages_64x3_small_nhwc_tn_v1, TacticValue: 0x19822de884f42a6a
Name: Conv_50 + Relu_51, LayerType: CaskConvolution, Inputs: [ { Name: input.120, Dimensions: [1,256,90,90], Format/Datatype: Channel major FP16 format where channel % 8 == 0 }], Outputs: [ { Name: input.132, Dimensions: [1,256,90,90], Format/Datatype: Channel major FP16 format where channel % 8 == 0 }], ParameterType: Convolution, Kernel: [3,3], PaddingMode: kEXPLICIT_ROUND_DOWN, PrePadding: [1,1], PostPadding: [1,1], Stride: [1,1], Dilation: [1,1], OutMaps: 256, Groups: 1, Weights: {"Type": "Half", "Count": 589824}, Bias: {"Type": "Half", "Count": 256}, AllowSparse: 0, Activation: RELU, HasBias: 1, HasReLU: 1, TacticName: ampere_h16816cudnn_128x64_sliced1x2_ldg8_relu_exp_stages_64x3_small_nhwc_tn_v1, TacticValue: 0x19822de884f42a6a
Name: Conv_52 + Relu_53, LayerType: CaskConvolution, Inputs: [ { Name: input.132, Dimensions: [1,256,90,90], Format/Datatype: Channel major FP16 format where channel % 8 == 0 }], Outputs: [ { Name: input.144, Dimensions: [1,256,90,90], Format/Datatype: Channel major FP16 format where channel % 8 == 0 }], ParameterType: Convolution, Kernel: [3,3], PaddingMode: kEXPLICIT_ROUND_DOWN, PrePadding: [1,1], PostPadding: [1,1], Stride: [1,1], Dilation: [1,1], OutMaps: 256, Groups: 1, Weights: {"Type": "Half", "Count": 589824}, Bias: {"Type": "Half", "Count": 256}, AllowSparse: 0, Activation: RELU, HasBias: 1, HasReLU: 1, TacticName: ampere_h16816cudnn_128x64_sliced1x2_ldg8_relu_exp_stages_64x3_small_nhwc_tn_v1, TacticValue: 0x19822de884f42a6a
Name: Conv_54 + Relu_55, LayerType: CaskConvolution, Inputs: [ { Name: input.144, Dimensions: [1,256,90,90], Format/Datatype: Channel major FP16 format where channel % 8 == 0 }], Outputs: [ { Name: onnx::ConvTranspose_644, Dimensions: [1,256,90,90], Format/Datatype: Channel major FP16 format where channel % 8 == 0 }], ParameterType: Convolution, Kernel: [3,3], PaddingMode: kEXPLICIT_ROUND_DOWN, PrePadding: [1,1], PostPadding: [1,1], Stride: [1,1], Dilation: [1,1], OutMaps: 256, Groups: 1, Weights: {"Type": "Half", "Count": 589824}, Bias: {"Type": "Half", "Count": 256}, AllowSparse: 0, Activation: RELU, HasBias: 1, HasReLU: 1, TacticName: ampere_h16816cudnn_128x64_sliced1x2_ldg8_relu_exp_stages_64x3_small_nhwc_tn_v1, TacticValue: 0x19822de884f42a6a
Name: ConvTranspose_56 + BatchNormalization_57 + Relu_58, LayerType: GemmDeconvolution, Inputs: [ { Name: onnx::ConvTranspose_644, Dimensions: [1,256,90,90], Format/Datatype: Channel major FP16 format where channel % 8 == 0 }], Outputs: [ { Name: onnx::Concat_647, Dimensions: [1,256,180,180], Format/Datatype: Channel major FP16 format where channel % 8 == 0 }], ParameterType: Convolution, Kernel: [2,2], PaddingMode: kEXPLICIT_ROUND_DOWN, PrePadding: [0,0], PostPadding: [0,0], Stride: [2,2], Dilation: [1,1], OutMaps: 256, Groups: 1, Weights: {"Type": "Half", "Count": 262144}, Bias: {"Type": "Half", "Count": 256}, AllowSparse: 0, Activation: RELU, TacticValue: 0x0
Name: onnx::Concat_647 copy, LayerType: Reformat, Inputs: [ { Name: onnx::Concat_647, Dimensions: [1,256,180,180], Format/Datatype: Channel major FP16 format where channel % 8 == 0 }], Outputs: [ { Name: input.164, Dimensions: [1,256,180,180], Format/Datatype: Channel major FP16 format where channel % 8 == 0 }], ParameterType: Reformat, Origin: CONCAT, TacticValue: 0x3ea
Name: Conv_60 + Relu_61, LayerType: CaskConvolution, Inputs: [ { Name: input.164, Dimensions: [1,512,180,180], Format/Datatype: Channel major FP16 format where channel % 8 == 0 }], Outputs: [ { Name: onnx::Conv_651, Dimensions: [1,64,180,180], Format/Datatype: Channel major FP16 format where channel % 8 == 0 }], ParameterType: Convolution, Kernel: [3,3], PaddingMode: kEXPLICIT_ROUND_DOWN, PrePadding: [1,1], PostPadding: [1,1], Stride: [1,1], Dilation: [1,1], OutMaps: 64, Groups: 1, Weights: {"Type": "Half", "Count": 294912}, Bias: {"Type": "Half", "Count": 64}, AllowSparse: 0, Activation: RELU, HasBias: 1, HasReLU: 1, TacticName: ampere_h16816cudnn_128x64_sliced1x2_ldg8_relu_exp_stages_64x4_small_nhwc_tn_v1, TacticValue: 0x7163d33a4d8ce8d7
Name: Conv_62 + Relu_63 || Conv_65 + Relu_66 || Conv_68 + Relu_69 || Conv_71 + Relu_72 || Conv_74 + Relu_75 || Conv_77 + Relu_78 || Conv_80 + Relu_81 || Conv_83 + Relu_84, LayerType: CaskConvolution, Inputs: [ { Name: onnx::Conv_651, Dimensions: [1,64,180,180], Format/Datatype: Channel major FP16 format where channel % 8 == 0 }], Outputs: [ { Name: Conv_62 + Relu_63 || Conv_65 + Relu_66 || Conv_68 + Relu_69 || Conv_71 + Relu_72 || Conv_74 + Relu_75 || Conv_77 + Relu_78 || Conv_80 + Relu_81 || Conv_83 + Relu_84, Dimensions: [1,512,180,180], Format/Datatype: Channel major FP16 format where channel % 8 == 0 }], ParameterType: Convolution, Kernel: [3,3], PaddingMode: kEXPLICIT_ROUND_DOWN, PrePadding: [1,1], PostPadding: [1,1], Stride: [1,1], Dilation: [1,1], OutMaps: 512, Groups: 1, Weights: {"Type": "Half", "Count": 294912}, Bias: {"Type": "Half", "Count": 512}, AllowSparse: 0, Activation: RELU, HasBias: 1, HasReLU: 1, TacticName: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x128x32_stage4_warpsize2x2x1_g1_tensor16x8x16_t1r3s3, TacticValue: 0x60c3421152ef8e10
Name: Conv_64, LayerType: CaskConvolution, Inputs: [ { Name: Conv_62 + Relu_63 || Conv_65 + Relu_66 || Conv_68 + Relu_69 || Conv_71 + Relu_72 || Conv_74 + Relu_75 || Conv_77 + Relu_78 || Conv_80 + Relu_81 || Conv_83 + Relu_84, Dimensions: [1,64,180,180], Format/Datatype: Channel major FP16 format where channel % 8 == 0 }], Outputs: [ { Name: Reformatted Output Tensor 0 to Conv_64, Dimensions: [1,2,180,180], Format/Datatype: Channel major FP16 format where channel % 8 == 0 }], ParameterType: Convolution, Kernel: [3,3], PaddingMode: kEXPLICIT_ROUND_DOWN, PrePadding: [1,1], PostPadding: [1,1], Stride: [1,1], Dilation: [1,1], OutMaps: 2, Groups: 1, Weights: {"Type": "Half", "Count": 1152}, Bias: {"Type": "Half", "Count": 2}, AllowSparse: 0, Activation: NONE, HasBias: 1, HasReLU: 0, TacticName: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x32x32_stage4_warpsize4x1x1_g1_tensor16x8x16_t1r3s3, TacticValue: 0x3e7eb35b91b9fa63
Name: Reformatting CopyNode for Output Tensor 0 to Conv_64, LayerType: Reformat, Inputs: [ { Name: Reformatted Output Tensor 0 to Conv_64, Dimensions: [1,2,180,180], Format/Datatype: Channel major FP16 format where channel % 8 == 0 }], Outputs: [ { Name: reg_0, Dimensions: [1,2,180,180], Format/Datatype: Row major linear FP16 format }], ParameterType: Reformat, Origin: REFORMAT, TacticValue: 0x0
Name: Conv_67, LayerType: CaskConvolution, Inputs: [ { Name: Conv_62 + Relu_63 || Conv_65 + Relu_66 || Conv_68 + Relu_69 || Conv_71 + Relu_72 || Conv_74 + Relu_75 || Conv_77 + Relu_78 || Conv_80 + Relu_81 || Conv_83 + Relu_84, Dimensions: [1,64,180,180], Format/Datatype: Channel major FP16 format where channel % 8 == 0 }], Outputs: [ { Name: Reformatted Output Tensor 0 to Conv_67, Dimensions: [1,1,180,180], Format/Datatype: Channel major FP16 format where channel % 8 == 0 }], ParameterType: Convolution, Kernel: [3,3], PaddingMode: kEXPLICIT_ROUND_DOWN, PrePadding: [1,1], PostPadding: [1,1], Stride: [1,1], Dilation: [1,1], OutMaps: 1, Groups: 1, Weights: {"Type": "Half", "Count": 576}, Bias: {"Type": "Half", "Count": 1}, AllowSparse: 0, Activation: NONE, HasBias: 1, HasReLU: 0, TacticName: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x32x32_stage4_warpsize4x1x1_g1_tensor16x8x16_t1r3s3, TacticValue: 0x3e7eb35b91b9fa63
Name: Reformatting CopyNode for Output Tensor 0 to Conv_67, LayerType: Reformat, Inputs: [ { Name: Reformatted Output Tensor 0 to Conv_67, Dimensions: [1,1,180,180], Format/Datatype: Channel major FP16 format where channel % 8 == 0 }], Outputs: [ { Name: height_0, Dimensions: [1,1,180,180], Format/Datatype: Row major linear FP16 format }], ParameterType: Reformat, Origin: REFORMAT, TacticValue: 0x0
Name: Conv_70, LayerType: CaskConvolution, Inputs: [ { Name: Conv_62 + Relu_63 || Conv_65 + Relu_66 || Conv_68 + Relu_69 || Conv_71 + Relu_72 || Conv_74 + Relu_75 || Conv_77 + Relu_78 || Conv_80 + Relu_81 || Conv_83 + Relu_84, Dimensions: [1,64,180,180], Format/Datatype: Channel major FP16 format where channel % 8 == 0 }], Outputs: [ { Name: Reformatted Output Tensor 0 to Conv_70, Dimensions: [1,3,180,180], Format/Datatype: Channel major FP16 format where channel % 8 == 0 }], ParameterType: Convolution, Kernel: [3,3], PaddingMode: kEXPLICIT_ROUND_DOWN, PrePadding: [1,1], PostPadding: [1,1], Stride: [1,1], Dilation: [1,1], OutMaps: 3, Groups: 1, Weights: {"Type": "Half", "Count": 1728}, Bias: {"Type": "Half", "Count": 3}, AllowSparse: 0, Activation: NONE, HasBias: 1, HasReLU: 0, TacticName: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x32x32_stage4_warpsize4x1x1_g1_tensor16x8x16_t1r3s3, TacticValue: 0x3e7eb35b91b9fa63
Name: Reformatting CopyNode for Output Tensor 0 to Conv_70, LayerType: Reformat, Inputs: [ { Name: Reformatted Output Tensor 0 to Conv_70, Dimensions: [1,3,180,180], Format/Datatype: Channel major FP16 format where channel % 8 == 0 }], Outputs: [ { Name: dim_0, Dimensions: [1,3,180,180], Format/Datatype: Row major linear FP16 format }], ParameterType: Reformat, Origin: REFORMAT, TacticValue: 0x0
Name: Conv_73, LayerType: CaskConvolution, Inputs: [ { Name: Conv_62 + Relu_63 || Conv_65 + Relu_66 || Conv_68 + Relu_69 || Conv_71 + Relu_72 || Conv_74 + Relu_75 || Conv_77 + Relu_78 || Conv_80 + Relu_81 || Conv_83 + Relu_84, Dimensions: [1,64,180,180], Format/Datatype: Channel major FP16 format where channel % 8 == 0 }], Outputs: [ { Name: Reformatted Output Tensor 0 to Conv_73, Dimensions: [1,2,180,180], Format/Datatype: Channel major FP16 format where channel % 8 == 0 }], ParameterType: Convolution, Kernel: [3,3], PaddingMode: kEXPLICIT_ROUND_DOWN, PrePadding: [1,1], PostPadding: [1,1], Stride: [1,1], Dilation: [1,1], OutMaps: 2, Groups: 1, Weights: {"Type": "Half", "Count": 1152}, Bias: {"Type": "Half", "Count": 2}, AllowSparse: 0, Activation: NONE, HasBias: 1, HasReLU: 0, TacticName: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x32x32_stage4_warpsize4x1x1_g1_tensor16x8x16_t1r3s3, TacticValue: 0x3e7eb35b91b9fa63
Name: Reformatting CopyNode for Output Tensor 0 to Conv_73, LayerType: Reformat, Inputs: [ { Name: Reformatted Output Tensor 0 to Conv_73, Dimensions: [1,2,180,180], Format/Datatype: Channel major FP16 format where channel % 8 == 0 }], Outputs: [ { Name: rot_0, Dimensions: [1,2,180,180], Format/Datatype: Row major linear FP16 format }], ParameterType: Reformat, Origin: REFORMAT, TacticValue: 0x0
Name: Conv_76, LayerType: CaskConvolution, Inputs: [ { Name: Conv_62 + Relu_63 || Conv_65 + Relu_66 || Conv_68 + Relu_69 || Conv_71 + Relu_72 || Conv_74 + Relu_75 || Conv_77 + Relu_78 || Conv_80 + Relu_81 || Conv_83 + Relu_84, Dimensions: [1,64,180,180], Format/Datatype: Channel major FP16 format where channel % 8 == 0 }], Outputs: [ { Name: Reformatted Output Tensor 0 to Conv_76, Dimensions: [1,2,180,180], Format/Datatype: Channel major FP16 format where channel % 8 == 0 }], ParameterType: Convolution, Kernel: [3,3], PaddingMode: kEXPLICIT_ROUND_DOWN, PrePadding: [1,1], PostPadding: [1,1], Stride: [1,1], Dilation: [1,1], OutMaps: 2, Groups: 1, Weights: {"Type": "Half", "Count": 1152}, Bias: {"Type": "Half", "Count": 2}, AllowSparse: 0, Activation: NONE, HasBias: 1, HasReLU: 0, TacticName: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x32x32_stage4_warpsize4x1x1_g1_tensor16x8x16_t1r3s3, TacticValue: 0x3e7eb35b91b9fa63
Name: Reformatting CopyNode for Output Tensor 0 to Conv_76, LayerType: Reformat, Inputs: [ { Name: Reformatted Output Tensor 0 to Conv_76, Dimensions: [1,2,180,180], Format/Datatype: Channel major FP16 format where channel % 8 == 0 }], Outputs: [ { Name: vel_0, Dimensions: [1,2,180,180], Format/Datatype: Row major linear FP16 format }], ParameterType: Reformat, Origin: REFORMAT, TacticValue: 0x0
Name: Conv_79, LayerType: CaskConvolution, Inputs: [ { Name: Conv_62 + Relu_63 || Conv_65 + Relu_66 || Conv_68 + Relu_69 || Conv_71 + Relu_72 || Conv_74 + Relu_75 || Conv_77 + Relu_78 || Conv_80 + Relu_81 || Conv_83 + Relu_84, Dimensions: [1,64,180,180], Format/Datatype: Channel major FP16 format where channel % 8 == 0 }], Outputs: [ { Name: Reformatted Output Tensor 0 to Conv_79, Dimensions: [1,1,180,180], Format/Datatype: Channel major FP16 format where channel % 8 == 0 }], ParameterType: Convolution, Kernel: [3,3], PaddingMode: kEXPLICIT_ROUND_DOWN, PrePadding: [1,1], PostPadding: [1,1], Stride: [1,1], Dilation: [1,1], OutMaps: 1, Groups: 1, Weights: {"Type": "Half", "Count": 576}, Bias: {"Type": "Half", "Count": 1}, AllowSparse: 0, Activation: NONE, HasBias: 1, HasReLU: 0, TacticName: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x32x32_stage4_warpsize4x1x1_g1_tensor16x8x16_t1r3s3, TacticValue: 0x3e7eb35b91b9fa63
Name: Reformatting CopyNode for Output Tensor 0 to Conv_79, LayerType: Reformat, Inputs: [ { Name: Reformatted Output Tensor 0 to Conv_79, Dimensions: [1,1,180,180], Format/Datatype: Channel major FP16 format where channel % 8 == 0 }], Outputs: [ { Name: hm_0, Dimensions: [1,1,180,180], Format/Datatype: Row major linear FP16 format }], ParameterType: Reformat, Origin: REFORMAT, TacticValue: 0x0
Name: Conv_82, LayerType: CaskConvolution, Inputs: [ { Name: Conv_62 + Relu_63 || Conv_65 + Relu_66 || Conv_68 + Relu_69 || Conv_71 + Relu_72 || Conv_74 + Relu_75 || Conv_77 + Relu_78 || Conv_80 + Relu_81 || Conv_83 + Relu_84, Dimensions: [1,64,180,180], Format/Datatype: Channel major FP16 format where channel % 8 == 0 }], Outputs: [ { Name: Reformatted Output Tensor 0 to Conv_82, Dimensions: [1,2,180,180], Format/Datatype: Channel major FP16 format where channel % 8 == 0 }], ParameterType: Convolution, Kernel: [3,3], PaddingMode: kEXPLICIT_ROUND_DOWN, PrePadding: [1,1], PostPadding: [1,1], Stride: [1,1], Dilation: [1,1], OutMaps: 2, Groups: 1, Weights: {"Type": "Half", "Count": 1152}, Bias: {"Type": "Half", "Count": 2}, AllowSparse: 0, Activation: NONE, HasBias: 1, HasReLU: 0, TacticName: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x32x32_stage4_warpsize4x1x1_g1_tensor16x8x16_t1r3s3, TacticValue: 0x3e7eb35b91b9fa63
Name: Reformatting CopyNode for Output Tensor 0 to Conv_82, LayerType: Reformat, Inputs: [ { Name: Reformatted Output Tensor 0 to Conv_82, Dimensions: [1,2,180,180], Format/Datatype: Channel major FP16 format where channel % 8 == 0 }], Outputs: [ { Name: reg_1, Dimensions: [1,2,180,180], Format/Datatype: Row major linear FP16 format }], ParameterType: Reformat, Origin: REFORMAT, TacticValue: 0x0
Name: Conv_85, LayerType: CaskConvolution, Inputs: [ { Name: Conv_62 + Relu_63 || Conv_65 + Relu_66 || Conv_68 + Relu_69 || Conv_71 + Relu_72 || Conv_74 + Relu_75 || Conv_77 + Relu_78 || Conv_80 + Relu_81 || Conv_83 + Relu_84, Dimensions: [1,64,180,180], Format/Datatype: Channel major FP16 format where channel % 8 == 0 }], Outputs: [ { Name: Reformatted Output Tensor 0 to Conv_85, Dimensions: [1,1,180,180], Format/Datatype: Channel major FP16 format where channel % 8 == 0 }], ParameterType: Convolution, Kernel: [3,3], PaddingMode: kEXPLICIT_ROUND_DOWN, PrePadding: [1,1], PostPadding: [1,1], Stride: [1,1], Dilation: [1,1], OutMaps: 1, Groups: 1, Weights: {"Type": "Half", "Count": 576}, Bias: {"Type": "Half", "Count": 1}, AllowSparse: 0, Activation: NONE, HasBias: 1, HasReLU: 0, TacticName: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x32x32_stage4_warpsize4x1x1_g1_tensor16x8x16_t1r3s3, TacticValue: 0x3e7eb35b91b9fa63
Name: Reformatting CopyNode for Output Tensor 0 to Conv_85, LayerType: Reformat, Inputs: [ { Name: Reformatted Output Tensor 0 to Conv_85, Dimensions: [1,1,180,180], Format/Datatype: Channel major FP16 format where channel % 8 == 0 }], Outputs: [ { Name: height_1, Dimensions: [1,1,180,180], Format/Datatype: Row major linear FP16 format }], ParameterType: Reformat, Origin: REFORMAT, TacticValue: 0x0
Name: Conv_86 + Relu_87 || Conv_89 + Relu_90 || Conv_92 + Relu_93 || Conv_95 + Relu_96 || Conv_98 + Relu_99 || Conv_101 + Relu_102 || Conv_104 + Relu_105 || Conv_107 + Relu_108, LayerType: CaskConvolution, Inputs: [ { Name: onnx::Conv_651, Dimensions: [1,64,180,180], Format/Datatype: Channel major FP16 format where channel % 8 == 0 }], Outputs: [ { Name: Conv_86 + Relu_87 || Conv_89 + Relu_90 || Conv_92 + Relu_93 || Conv_95 + Relu_96 || Conv_98 + Relu_99 || Conv_101 + Relu_102 || Conv_104 + Relu_105 || Conv_107 + Relu_108, Dimensions: [1,512,180,180], Format/Datatype: Channel major FP16 format where channel % 8 == 0 }], ParameterType: Convolution, Kernel: [3,3], PaddingMode: kEXPLICIT_ROUND_DOWN, PrePadding: [1,1], PostPadding: [1,1], Stride: [1,1], Dilation: [1,1], OutMaps: 512, Groups: 1, Weights: {"Type": "Half", "Count": 294912}, Bias: {"Type": "Half", "Count": 512}, AllowSparse: 0, Activation: RELU, HasBias: 1, HasReLU: 1, TacticName: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x128x32_stage4_warpsize2x2x1_g1_tensor16x8x16_t1r3s3, TacticValue: 0x60c3421152ef8e10
Name: Conv_88, LayerType: CaskConvolution, Inputs: [ { Name: Conv_86 + Relu_87 || Conv_89 + Relu_90 || Conv_92 + Relu_93 || Conv_95 + Relu_96 || Conv_98 + Relu_99 || Conv_101 + Relu_102 || Conv_104 + Relu_105 || Conv_107 + Relu_108, Dimensions: [1,64,180,180], Format/Datatype: Channel major FP16 format where channel % 8 == 0 }], Outputs: [ { Name: Reformatted Output Tensor 0 to Conv_88, Dimensions: [1,3,180,180], Format/Datatype: Channel major FP16 format where channel % 8 == 0 }], ParameterType: Convolution, Kernel: [3,3], PaddingMode: kEXPLICIT_ROUND_DOWN, PrePadding: [1,1], PostPadding: [1,1], Stride: [1,1], Dilation: [1,1], OutMaps: 3, Groups: 1, Weights: {"Type": "Half", "Count": 1728}, Bias: {"Type": "Half", "Count": 3}, AllowSparse: 0, Activation: NONE, HasBias: 1, HasReLU: 0, TacticName: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x32x32_stage4_warpsize4x1x1_g1_tensor16x8x16_t1r3s3, TacticValue: 0x3e7eb35b91b9fa63
Name: Reformatting CopyNode for Output Tensor 0 to Conv_88, LayerType: Reformat, Inputs: [ { Name: Reformatted Output Tensor 0 to Conv_88, Dimensions: [1,3,180,180], Format/Datatype: Channel major FP16 format where channel % 8 == 0 }], Outputs: [ { Name: dim_1, Dimensions: [1,3,180,180], Format/Datatype: Row major linear FP16 format }], ParameterType: Reformat, Origin: REFORMAT, TacticValue: 0x0
Name: Conv_91, LayerType: CaskConvolution, Inputs: [ { Name: Conv_86 + Relu_87 || Conv_89 + Relu_90 || Conv_92 + Relu_93 || Conv_95 + Relu_96 || Conv_98 + Relu_99 || Conv_101 + Relu_102 || Conv_104 + Relu_105 || Conv_107 + Relu_108, Dimensions: [1,64,180,180], Format/Datatype: Channel major FP16 format where channel % 8 == 0 }], Outputs: [ { Name: Reformatted Output Tensor 0 to Conv_91, Dimensions: [1,2,180,180], Format/Datatype: Channel major FP16 format where channel % 8 == 0 }], ParameterType: Convolution, Kernel: [3,3], PaddingMode: kEXPLICIT_ROUND_DOWN, PrePadding: [1,1], PostPadding: [1,1], Stride: [1,1], Dilation: [1,1], OutMaps: 2, Groups: 1, Weights: {"Type": "Half", "Count": 1152}, Bias: {"Type": "Half", "Count": 2}, AllowSparse: 0, Activation: NONE, HasBias: 1, HasReLU: 0, TacticName: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x32x32_stage4_warpsize4x1x1_g1_tensor16x8x16_t1r3s3, TacticValue: 0x3e7eb35b91b9fa63
Name: Reformatting CopyNode for Output Tensor 0 to Conv_91, LayerType: Reformat, Inputs: [ { Name: Reformatted Output Tensor 0 to Conv_91, Dimensions: [1,2,180,180], Format/Datatype: Channel major FP16 format where channel % 8 == 0 }], Outputs: [ { Name: rot_1, Dimensions: [1,2,180,180], Format/Datatype: Row major linear FP16 format }], ParameterType: Reformat, Origin: REFORMAT, TacticValue: 0x0
Name: Conv_94, LayerType: CaskConvolution, Inputs: [ { Name: Conv_86 + Relu_87 || Conv_89 + Relu_90 || Conv_92 + Relu_93 || Conv_95 + Relu_96 || Conv_98 + Relu_99 || Conv_101 + Relu_102 || Conv_104 + Relu_105 || Conv_107 + Relu_108, Dimensions: [1,64,180,180], Format/Datatype: Channel major FP16 format where channel % 8 == 0 }], Outputs: [ { Name: Reformatted Output Tensor 0 to Conv_94, Dimensions: [1,2,180,180], Format/Datatype: Channel major FP16 format where channel % 8 == 0 }], ParameterType: Convolution, Kernel: [3,3], PaddingMode: kEXPLICIT_ROUND_DOWN, PrePadding: [1,1], PostPadding: [1,1], Stride: [1,1], Dilation: [1,1], OutMaps: 2, Groups: 1, Weights: {"Type": "Half", "Count": 1152}, Bias: {"Type": "Half", "Count": 2}, AllowSparse: 0, Activation: NONE, HasBias: 1, HasReLU: 0, TacticName: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x32x32_stage4_warpsize4x1x1_g1_tensor16x8x16_t1r3s3, TacticValue: 0x3e7eb35b91b9fa63
Name: Reformatting CopyNode for Output Tensor 0 to Conv_94, LayerType: Reformat, Inputs: [ { Name: Reformatted Output Tensor 0 to Conv_94, Dimensions: [1,2,180,180], Format/Datatype: Channel major FP16 format where channel % 8 == 0 }], Outputs: [ { Name: vel_1, Dimensions: [1,2,180,180], Format/Datatype: Row major linear FP16 format }], ParameterType: Reformat, Origin: REFORMAT, TacticValue: 0x0
Name: Conv_97, LayerType: CaskConvolution, Inputs: [ { Name: Conv_86 + Relu_87 || Conv_89 + Relu_90 || Conv_92 + Relu_93 || Conv_95 + Relu_96 || Conv_98 + Relu_99 || Conv_101 + Relu_102 || Conv_104 + Relu_105 || Conv_107 + Relu_108, Dimensions: [1,64,180,180], Format/Datatype: Channel major FP16 format where channel % 8 == 0 }], Outputs: [ { Name: Reformatted Output Tensor 0 to Conv_97, Dimensions: [1,2,180,180], Format/Datatype: Channel major FP16 format where channel % 8 == 0 }], ParameterType: Convolution, Kernel: [3,3], PaddingMode: kEXPLICIT_ROUND_DOWN, PrePadding: [1,1], PostPadding: [1,1], Stride: [1,1], Dilation: [1,1], OutMaps: 2, Groups: 1, Weights: {"Type": "Half", "Count": 1152}, Bias: {"Type": "Half", "Count": 2}, AllowSparse: 0, Activation: NONE, HasBias: 1, HasReLU: 0, TacticName: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x32x32_stage4_warpsize4x1x1_g1_tensor16x8x16_t1r3s3, TacticValue: 0x3e7eb35b91b9fa63
Name: Reformatting CopyNode for Output Tensor 0 to Conv_97, LayerType: Reformat, Inputs: [ { Name: Reformatted Output Tensor 0 to Conv_97, Dimensions: [1,2,180,180], Format/Datatype: Channel major FP16 format where channel % 8 == 0 }], Outputs: [ { Name: hm_1, Dimensions: [1,2,180,180], Format/Datatype: Row major linear FP16 format }], ParameterType: Reformat, Origin: REFORMAT, TacticValue: 0x0
Name: Conv_100, LayerType: CaskConvolution, Inputs: [ { Name: Conv_86 + Relu_87 || Conv_89 + Relu_90 || Conv_92 + Relu_93 || Conv_95 + Relu_96 || Conv_98 + Relu_99 || Conv_101 + Relu_102 || Conv_104 + Relu_105 || Conv_107 + Relu_108, Dimensions: [1,64,180,180], Format/Datatype: Channel major FP16 format where channel % 8 == 0 }], Outputs: [ { Name: Reformatted Output Tensor 0 to Conv_100, Dimensions: [1,2,180,180], Format/Datatype: Channel major FP16 format where channel % 8 == 0 }], ParameterType: Convolution, Kernel: [3,3], PaddingMode: kEXPLICIT_ROUND_DOWN, PrePadding: [1,1], PostPadding: [1,1], Stride: [1,1], Dilation: [1,1], OutMaps: 2, Groups: 1, Weights: {"Type": "Half", "Count": 1152}, Bias: {"Type": "Half", "Count": 2}, AllowSparse: 0, Activation: NONE, HasBias: 1, HasReLU: 0, TacticName: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x32x32_stage4_warpsize4x1x1_g1_tensor16x8x16_t1r3s3, TacticValue: 0x3e7eb35b91b9fa63
Name: Reformatting CopyNode for Output Tensor 0 to Conv_100, LayerType: Reformat, Inputs: [ { Name: Reformatted Output Tensor 0 to Conv_100, Dimensions: [1,2,180,180], Format/Datatype: Channel major FP16 format where channel % 8 == 0 }], Outputs: [ { Name: reg_2, Dimensions: [1,2,180,180], Format/Datatype: Row major linear FP16 format }], ParameterType: Reformat, Origin: REFORMAT, TacticValue: 0x0
Name: Conv_103, LayerType: CaskConvolution, Inputs: [ { Name: Conv_86 + Relu_87 || Conv_89 + Relu_90 || Conv_92 + Relu_93 || Conv_95 + Relu_96 || Conv_98 + Relu_99 || Conv_101 + Relu_102 || Conv_104 + Relu_105 || Conv_107 + Relu_108, Dimensions: [1,64,180,180], Format/Datatype: Channel major FP16 format where channel % 8 == 0 }], Outputs: [ { Name: Reformatted Output Tensor 0 to Conv_103, Dimensions: [1,1,180,180], Format/Datatype: Channel major FP16 format where channel % 8 == 0 }], ParameterType: Convolution, Kernel: [3,3], PaddingMode: kEXPLICIT_ROUND_DOWN, PrePadding: [1,1], PostPadding: [1,1], Stride: [1,1], Dilation: [1,1], OutMaps: 1, Groups: 1, Weights: {"Type": "Half", "Count": 576}, Bias: {"Type": "Half", "Count": 1}, AllowSparse: 0, Activation: NONE, HasBias: 1, HasReLU: 0, TacticName: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x32x32_stage4_warpsize4x1x1_g1_tensor16x8x16_t1r3s3, TacticValue: 0x3e7eb35b91b9fa63
Name: Reformatting CopyNode for Output Tensor 0 to Conv_103, LayerType: Reformat, Inputs: [ { Name: Reformatted Output Tensor 0 to Conv_103, Dimensions: [1,1,180,180], Format/Datatype: Channel major FP16 format where channel % 8 == 0 }], Outputs: [ { Name: height_2, Dimensions: [1,1,180,180], Format/Datatype: Row major linear FP16 format }], ParameterType: Reformat, Origin: REFORMAT, TacticValue: 0x0
Name: Conv_106, LayerType: CaskConvolution, Inputs: [ { Name: Conv_86 + Relu_87 || Conv_89 + Relu_90 || Conv_92 + Relu_93 || Conv_95 + Relu_96 || Conv_98 + Relu_99 || Conv_101 + Relu_102 || Conv_104 + Relu_105 || Conv_107 + Relu_108, Dimensions: [1,64,180,180], Format/Datatype: Channel major FP16 format where channel % 8 == 0 }], Outputs: [ { Name: Reformatted Output Tensor 0 to Conv_106, Dimensions: [1,3,180,180], Format/Datatype: Channel major FP16 format where channel % 8 == 0 }], ParameterType: Convolution, Kernel: [3,3], PaddingMode: kEXPLICIT_ROUND_DOWN, PrePadding: [1,1], PostPadding: [1,1], Stride: [1,1], Dilation: [1,1], OutMaps: 3, Groups: 1, Weights: {"Type": "Half", "Count": 1728}, Bias: {"Type": "Half", "Count": 3}, AllowSparse: 0, Activation: NONE, HasBias: 1, HasReLU: 0, TacticName: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x32x32_stage4_warpsize4x1x1_g1_tensor16x8x16_t1r3s3, TacticValue: 0x3e7eb35b91b9fa63
Name: Reformatting CopyNode for Output Tensor 0 to Conv_106, LayerType: Reformat, Inputs: [ { Name: Reformatted Output Tensor 0 to Conv_106, Dimensions: [1,3,180,180], Format/Datatype: Channel major FP16 format where channel % 8 == 0 }], Outputs: [ { Name: dim_2, Dimensions: [1,3,180,180], Format/Datatype: Row major linear FP16 format }], ParameterType: Reformat, Origin: REFORMAT, TacticValue: 0x0
Name: Conv_109, LayerType: CaskConvolution, Inputs: [ { Name: Conv_86 + Relu_87 || Conv_89 + Relu_90 || Conv_92 + Relu_93 || Conv_95 + Relu_96 || Conv_98 + Relu_99 || Conv_101 + Relu_102 || Conv_104 + Relu_105 || Conv_107 + Relu_108, Dimensions: [1,64,180,180], Format/Datatype: Channel major FP16 format where channel % 8 == 0 }], Outputs: [ { Name: Reformatted Output Tensor 0 to Conv_109, Dimensions: [1,2,180,180], Format/Datatype: Channel major FP16 format where channel % 8 == 0 }], ParameterType: Convolution, Kernel: [3,3], PaddingMode: kEXPLICIT_ROUND_DOWN, PrePadding: [1,1], PostPadding: [1,1], Stride: [1,1], Dilation: [1,1], OutMaps: 2, Groups: 1, Weights: {"Type": "Half", "Count": 1152}, Bias: {"Type": "Half", "Count": 2}, AllowSparse: 0, Activation: NONE, HasBias: 1, HasReLU: 0, TacticName: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x32x32_stage4_warpsize4x1x1_g1_tensor16x8x16_t1r3s3, TacticValue: 0x3e7eb35b91b9fa63
Name: Reformatting CopyNode for Output Tensor 0 to Conv_109, LayerType: Reformat, Inputs: [ { Name: Reformatted Output Tensor 0 to Conv_109, Dimensions: [1,2,180,180], Format/Datatype: Channel major FP16 format where channel % 8 == 0 }], Outputs: [ { Name: rot_2, Dimensions: [1,2,180,180], Format/Datatype: Row major linear FP16 format }], ParameterType: Reformat, Origin: REFORMAT, TacticValue: 0x0
Name: Conv_110 + Relu_111 || Conv_113 + Relu_114 || Conv_116 + Relu_117 || Conv_119 + Relu_120 || Conv_122 + Relu_123 || Conv_125 + Relu_126 || Conv_128 + Relu_129 || Conv_131 + Relu_132, LayerType: CaskConvolution, Inputs: [ { Name: onnx::Conv_651, Dimensions: [1,64,180,180], Format/Datatype: Channel major FP16 format where channel % 8 == 0 }], Outputs: [ { Name: Conv_110 + Relu_111 || Conv_113 + Relu_114 || Conv_116 + Relu_117 || Conv_119 + Relu_120 || Conv_122 + Relu_123 || Conv_125 + Relu_126 || Conv_128 + Relu_129 || Conv_131 + Relu_132, Dimensions: [1,512,180,180], Format/Datatype: Channel major FP16 format where channel % 8 == 0 }], ParameterType: Convolution, Kernel: [3,3], PaddingMode: kEXPLICIT_ROUND_DOWN, PrePadding: [1,1], PostPadding: [1,1], Stride: [1,1], Dilation: [1,1], OutMaps: 512, Groups: 1, Weights: {"Type": "Half", "Count": 294912}, Bias: {"Type": "Half", "Count": 512}, AllowSparse: 0, Activation: RELU, HasBias: 1, HasReLU: 1, TacticName: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x128x32_stage4_warpsize2x2x1_g1_tensor16x8x16_t1r3s3, TacticValue: 0x60c3421152ef8e10
Name: Conv_112, LayerType: CaskConvolution, Inputs: [ { Name: Conv_110 + Relu_111 || Conv_113 + Relu_114 || Conv_116 + Relu_117 || Conv_119 + Relu_120 || Conv_122 + Relu_123 || Conv_125 + Relu_126 || Conv_128 + Relu_129 || Conv_131 + Relu_132, Dimensions: [1,64,180,180], Format/Datatype: Channel major FP16 format where channel % 8 == 0 }], Outputs: [ { Name: Reformatted Output Tensor 0 to Conv_112, Dimensions: [1,2,180,180], Format/Datatype: Channel major FP16 format where channel % 8 == 0 }], ParameterType: Convolution, Kernel: [3,3], PaddingMode: kEXPLICIT_ROUND_DOWN, PrePadding: [1,1], PostPadding: [1,1], Stride: [1,1], Dilation: [1,1], OutMaps: 2, Groups: 1, Weights: {"Type": "Half", "Count": 1152}, Bias: {"Type": "Half", "Count": 2}, AllowSparse: 0, Activation: NONE, HasBias: 1, HasReLU: 0, TacticName: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x32x32_stage4_warpsize4x1x1_g1_tensor16x8x16_t1r3s3, TacticValue: 0x3e7eb35b91b9fa63
Name: Reformatting CopyNode for Output Tensor 0 to Conv_112, LayerType: Reformat, Inputs: [ { Name: Reformatted Output Tensor 0 to Conv_112, Dimensions: [1,2,180,180], Format/Datatype: Channel major FP16 format where channel % 8 == 0 }], Outputs: [ { Name: vel_2, Dimensions: [1,2,180,180], Format/Datatype: Row major linear FP16 format }], ParameterType: Reformat, Origin: REFORMAT, TacticValue: 0x0
Name: Conv_115, LayerType: CaskConvolution, Inputs: [ { Name: Conv_110 + Relu_111 || Conv_113 + Relu_114 || Conv_116 + Relu_117 || Conv_119 + Relu_120 || Conv_122 + Relu_123 || Conv_125 + Relu_126 || Conv_128 + Relu_129 || Conv_131 + Relu_132, Dimensions: [1,64,180,180], Format/Datatype: Channel major FP16 format where channel % 8 == 0 }], Outputs: [ { Name: Reformatted Output Tensor 0 to Conv_115, Dimensions: [1,2,180,180], Format/Datatype: Channel major FP16 format where channel % 8 == 0 }], ParameterType: Convolution, Kernel: [3,3], PaddingMode: kEXPLICIT_ROUND_DOWN, PrePadding: [1,1], PostPadding: [1,1], Stride: [1,1], Dilation: [1,1], OutMaps: 2, Groups: 1, Weights: {"Type": "Half", "Count": 1152}, Bias: {"Type": "Half", "Count": 2}, AllowSparse: 0, Activation: NONE, HasBias: 1, HasReLU: 0, TacticName: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x32x32_stage4_warpsize4x1x1_g1_tensor16x8x16_t1r3s3, TacticValue: 0x3e7eb35b91b9fa63
Name: Reformatting CopyNode for Output Tensor 0 to Conv_115, LayerType: Reformat, Inputs: [ { Name: Reformatted Output Tensor 0 to Conv_115, Dimensions: [1,2,180,180], Format/Datatype: Channel major FP16 format where channel % 8 == 0 }], Outputs: [ { Name: hm_2, Dimensions: [1,2,180,180], Format/Datatype: Row major linear FP16 format }], ParameterType: Reformat, Origin: REFORMAT, TacticValue: 0x0
Name: Conv_118, LayerType: CaskConvolution, Inputs: [ { Name: Conv_110 + Relu_111 || Conv_113 + Relu_114 || Conv_116 + Relu_117 || Conv_119 + Relu_120 || Conv_122 + Relu_123 || Conv_125 + Relu_126 || Conv_128 + Relu_129 || Conv_131 + Relu_132, Dimensions: [1,64,180,180], Format/Datatype: Channel major FP16 format where channel % 8 == 0 }], Outputs: [ { Name: Reformatted Output Tensor 0 to Conv_118, Dimensions: [1,2,180,180], Format/Datatype: Channel major FP16 format where channel % 8 == 0 }], ParameterType: Convolution, Kernel: [3,3], PaddingMode: kEXPLICIT_ROUND_DOWN, PrePadding: [1,1], PostPadding: [1,1], Stride: [1,1], Dilation: [1,1], OutMaps: 2, Groups: 1, Weights: {"Type": "Half", "Count": 1152}, Bias: {"Type": "Half", "Count": 2}, AllowSparse: 0, Activation: NONE, HasBias: 1, HasReLU: 0, TacticName: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x32x32_stage4_warpsize4x1x1_g1_tensor16x8x16_t1r3s3, TacticValue: 0x3e7eb35b91b9fa63
Name: Reformatting CopyNode for Output Tensor 0 to Conv_118, LayerType: Reformat, Inputs: [ { Name: Reformatted Output Tensor 0 to Conv_118, Dimensions: [1,2,180,180], Format/Datatype: Channel major FP16 format where channel % 8 == 0 }], Outputs: [ { Name: reg_3, Dimensions: [1,2,180,180], Format/Datatype: Row major linear FP16 format }], ParameterType: Reformat, Origin: REFORMAT, TacticValue: 0x0
Name: Conv_121, LayerType: CaskConvolution, Inputs: [ { Name: Conv_110 + Relu_111 || Conv_113 + Relu_114 || Conv_116 + Relu_117 || Conv_119 + Relu_120 || Conv_122 + Relu_123 || Conv_125 + Relu_126 || Conv_128 + Relu_129 || Conv_131 + Relu_132, Dimensions: [1,64,180,180], Format/Datatype: Channel major FP16 format where channel % 8 == 0 }], Outputs: [ { Name: Reformatted Output Tensor 0 to Conv_121, Dimensions: [1,1,180,180], Format/Datatype: Channel major FP16 format where channel % 8 == 0 }], ParameterType: Convolution, Kernel: [3,3], PaddingMode: kEXPLICIT_ROUND_DOWN, PrePadding: [1,1], PostPadding: [1,1], Stride: [1,1], Dilation: [1,1], OutMaps: 1, Groups: 1, Weights: {"Type": "Half", "Count": 576}, Bias: {"Type": "Half", "Count": 1}, AllowSparse: 0, Activation: NONE, HasBias: 1, HasReLU: 0, TacticName: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x32x32_stage4_warpsize4x1x1_g1_tensor16x8x16_t1r3s3, TacticValue: 0x3e7eb35b91b9fa63
Name: Reformatting CopyNode for Output Tensor 0 to Conv_121, LayerType: Reformat, Inputs: [ { Name: Reformatted Output Tensor 0 to Conv_121, Dimensions: [1,1,180,180], Format/Datatype: Channel major FP16 format where channel % 8 == 0 }], Outputs: [ { Name: height_3, Dimensions: [1,1,180,180], Format/Datatype: Row major linear FP16 format }], ParameterType: Reformat, Origin: REFORMAT, TacticValue: 0x0
Name: Conv_124, LayerType: CaskConvolution, Inputs: [ { Name: Conv_110 + Relu_111 || Conv_113 + Relu_114 || Conv_116 + Relu_117 || Conv_119 + Relu_120 || Conv_122 + Relu_123 || Conv_125 + Relu_126 || Conv_128 + Relu_129 || Conv_131 + Relu_132, Dimensions: [1,64,180,180], Format/Datatype: Channel major FP16 format where channel % 8 == 0 }], Outputs: [ { Name: Reformatted Output Tensor 0 to Conv_124, Dimensions: [1,3,180,180], Format/Datatype: Channel major FP16 format where channel % 8 == 0 }], ParameterType: Convolution, Kernel: [3,3], PaddingMode: kEXPLICIT_ROUND_DOWN, PrePadding: [1,1], PostPadding: [1,1], Stride: [1,1], Dilation: [1,1], OutMaps: 3, Groups: 1, Weights: {"Type": "Half", "Count": 1728}, Bias: {"Type": "Half", "Count": 3}, AllowSparse: 0, Activation: NONE, HasBias: 1, HasReLU: 0, TacticName: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x32x32_stage4_warpsize4x1x1_g1_tensor16x8x16_t1r3s3, TacticValue: 0x3e7eb35b91b9fa63
Name: Reformatting CopyNode for Output Tensor 0 to Conv_124, LayerType: Reformat, Inputs: [ { Name: Reformatted Output Tensor 0 to Conv_124, Dimensions: [1,3,180,180], Format/Datatype: Channel major FP16 format where channel % 8 == 0 }], Outputs: [ { Name: dim_3, Dimensions: [1,3,180,180], Format/Datatype: Row major linear FP16 format }], ParameterType: Reformat, Origin: REFORMAT, TacticValue: 0x0
Name: Conv_127, LayerType: CaskConvolution, Inputs: [ { Name: Conv_110 + Relu_111 || Conv_113 + Relu_114 || Conv_116 + Relu_117 || Conv_119 + Relu_120 || Conv_122 + Relu_123 || Conv_125 + Relu_126 || Conv_128 + Relu_129 || Conv_131 + Relu_132, Dimensions: [1,64,180,180], Format/Datatype: Channel major FP16 format where channel % 8 == 0 }], Outputs: [ { Name: Reformatted Output Tensor 0 to Conv_127, Dimensions: [1,2,180,180], Format/Datatype: Channel major FP16 format where channel % 8 == 0 }], ParameterType: Convolution, Kernel: [3,3], PaddingMode: kEXPLICIT_ROUND_DOWN, PrePadding: [1,1], PostPadding: [1,1], Stride: [1,1], Dilation: [1,1], OutMaps: 2, Groups: 1, Weights: {"Type": "Half", "Count": 1152}, Bias: {"Type": "Half", "Count": 2}, AllowSparse: 0, Activation: NONE, HasBias: 1, HasReLU: 0, TacticName: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x32x32_stage4_warpsize4x1x1_g1_tensor16x8x16_t1r3s3, TacticValue: 0x3e7eb35b91b9fa63
Name: Reformatting CopyNode for Output Tensor 0 to Conv_127, LayerType: Reformat, Inputs: [ { Name: Reformatted Output Tensor 0 to Conv_127, Dimensions: [1,2,180,180], Format/Datatype: Channel major FP16 format where channel % 8 == 0 }], Outputs: [ { Name: rot_3, Dimensions: [1,2,180,180], Format/Datatype: Row major linear FP16 format }], ParameterType: Reformat, Origin: REFORMAT, TacticValue: 0x0
Name: Conv_130, LayerType: CaskConvolution, Inputs: [ { Name: Conv_110 + Relu_111 || Conv_113 + Relu_114 || Conv_116 + Relu_117 || Conv_119 + Relu_120 || Conv_122 + Relu_123 || Conv_125 + Relu_126 || Conv_128 + Relu_129 || Conv_131 + Relu_132, Dimensions: [1,64,180,180], Format/Datatype: Channel major FP16 format where channel % 8 == 0 }], Outputs: [ { Name: Reformatted Output Tensor 0 to Conv_130, Dimensions: [1,2,180,180], Format/Datatype: Channel major FP16 format where channel % 8 == 0 }], ParameterType: Convolution, Kernel: [3,3], PaddingMode: kEXPLICIT_ROUND_DOWN, PrePadding: [1,1], PostPadding: [1,1], Stride: [1,1], Dilation: [1,1], OutMaps: 2, Groups: 1, Weights: {"Type": "Half", "Count": 1152}, Bias: {"Type": "Half", "Count": 2}, AllowSparse: 0, Activation: NONE, HasBias: 1, HasReLU: 0, TacticName: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x32x32_stage4_warpsize4x1x1_g1_tensor16x8x16_t1r3s3, TacticValue: 0x3e7eb35b91b9fa63
Name: Reformatting CopyNode for Output Tensor 0 to Conv_130, LayerType: Reformat, Inputs: [ { Name: Reformatted Output Tensor 0 to Conv_130, Dimensions: [1,2,180,180], Format/Datatype: Channel major FP16 format where channel % 8 == 0 }], Outputs: [ { Name: vel_3, Dimensions: [1,2,180,180], Format/Datatype: Row major linear FP16 format }], ParameterType: Reformat, Origin: REFORMAT, TacticValue: 0x0
Name: Conv_133, LayerType: CaskConvolution, Inputs: [ { Name: Conv_110 + Relu_111 || Conv_113 + Relu_114 || Conv_116 + Relu_117 || Conv_119 + Relu_120 || Conv_122 + Relu_123 || Conv_125 + Relu_126 || Conv_128 + Relu_129 || Conv_131 + Relu_132, Dimensions: [1,64,180,180], Format/Datatype: Channel major FP16 format where channel % 8 == 0 }], Outputs: [ { Name: Reformatted Output Tensor 0 to Conv_133, Dimensions: [1,1,180,180], Format/Datatype: Channel major FP16 format where channel % 8 == 0 }], ParameterType: Convolution, Kernel: [3,3], PaddingMode: kEXPLICIT_ROUND_DOWN, PrePadding: [1,1], PostPadding: [1,1], Stride: [1,1], Dilation: [1,1], OutMaps: 1, Groups: 1, Weights: {"Type": "Half", "Count": 576}, Bias: {"Type": "Half", "Count": 1}, AllowSparse: 0, Activation: NONE, HasBias: 1, HasReLU: 0, TacticName: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x32x32_stage4_warpsize4x1x1_g1_tensor16x8x16_t1r3s3, TacticValue: 0x3e7eb35b91b9fa63
Name: Reformatting CopyNode for Output Tensor 0 to Conv_133, LayerType: Reformat, Inputs: [ { Name: Reformatted Output Tensor 0 to Conv_133, Dimensions: [1,1,180,180], Format/Datatype: Channel major FP16 format where channel % 8 == 0 }], Outputs: [ { Name: hm_3, Dimensions: [1,1,180,180], Format/Datatype: Row major linear FP16 format }], ParameterType: Reformat, Origin: REFORMAT, TacticValue: 0x0
Name: Conv_134 + Relu_135 || Conv_137 + Relu_138 || Conv_140 + Relu_141 || Conv_143 + Relu_144 || Conv_146 + Relu_147 || Conv_149 + Relu_150 || Conv_152 + Relu_153 || Conv_155 + Relu_156, LayerType: CaskConvolution, Inputs: [ { Name: onnx::Conv_651, Dimensions: [1,64,180,180], Format/Datatype: Channel major FP16 format where channel % 8 == 0 }], Outputs: [ { Name: Conv_134 + Relu_135 || Conv_137 + Relu_138 || Conv_140 + Relu_141 || Conv_143 + Relu_144 || Conv_146 + Relu_147 || Conv_149 + Relu_150 || Conv_152 + Relu_153 || Conv_155 + Relu_156, Dimensions: [1,512,180,180], Format/Datatype: Channel major FP16 format where channel % 8 == 0 }], ParameterType: Convolution, Kernel: [3,3], PaddingMode: kEXPLICIT_ROUND_DOWN, PrePadding: [1,1], PostPadding: [1,1], Stride: [1,1], Dilation: [1,1], OutMaps: 512, Groups: 1, Weights: {"Type": "Half", "Count": 294912}, Bias: {"Type": "Half", "Count": 512}, AllowSparse: 0, Activation: RELU, HasBias: 1, HasReLU: 1, TacticName: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x128x32_stage4_warpsize2x2x1_g1_tensor16x8x16_t1r3s3, TacticValue: 0x60c3421152ef8e10
Name: Conv_136, LayerType: CaskConvolution, Inputs: [ { Name: Conv_134 + Relu_135 || Conv_137 + Relu_138 || Conv_140 + Relu_141 || Conv_143 + Relu_144 || Conv_146 + Relu_147 || Conv_149 + Relu_150 || Conv_152 + Relu_153 || Conv_155 + Relu_156, Dimensions: [1,64,180,180], Format/Datatype: Channel major FP16 format where channel % 8 == 0 }], Outputs: [ { Name: Reformatted Output Tensor 0 to Conv_136, Dimensions: [1,2,180,180], Format/Datatype: Channel major FP16 format where channel % 8 == 0 }], ParameterType: Convolution, Kernel: [3,3], PaddingMode: kEXPLICIT_ROUND_DOWN, PrePadding: [1,1], PostPadding: [1,1], Stride: [1,1], Dilation: [1,1], OutMaps: 2, Groups: 1, Weights: {"Type": "Half", "Count": 1152}, Bias: {"Type": "Half", "Count": 2}, AllowSparse: 0, Activation: NONE, HasBias: 1, HasReLU: 0, TacticName: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x32x32_stage4_warpsize4x1x1_g1_tensor16x8x16_t1r3s3, TacticValue: 0x3e7eb35b91b9fa63
Name: Reformatting CopyNode for Output Tensor 0 to Conv_136, LayerType: Reformat, Inputs: [ { Name: Reformatted Output Tensor 0 to Conv_136, Dimensions: [1,2,180,180], Format/Datatype: Channel major FP16 format where channel % 8 == 0 }], Outputs: [ { Name: reg_4, Dimensions: [1,2,180,180], Format/Datatype: Row major linear FP16 format }], ParameterType: Reformat, Origin: REFORMAT, TacticValue: 0x0
Name: Conv_139, LayerType: CaskConvolution, Inputs: [ { Name: Conv_134 + Relu_135 || Conv_137 + Relu_138 || Conv_140 + Relu_141 || Conv_143 + Relu_144 || Conv_146 + Relu_147 || Conv_149 + Relu_150 || Conv_152 + Relu_153 || Conv_155 + Relu_156, Dimensions: [1,64,180,180], Format/Datatype: Channel major FP16 format where channel % 8 == 0 }], Outputs: [ { Name: Reformatted Output Tensor 0 to Conv_139, Dimensions: [1,1,180,180], Format/Datatype: Channel major FP16 format where channel % 8 == 0 }], ParameterType: Convolution, Kernel: [3,3], PaddingMode: kEXPLICIT_ROUND_DOWN, PrePadding: [1,1], PostPadding: [1,1], Stride: [1,1], Dilation: [1,1], OutMaps: 1, Groups: 1, Weights: {"Type": "Half", "Count": 576}, Bias: {"Type": "Half", "Count": 1}, AllowSparse: 0, Activation: NONE, HasBias: 1, HasReLU: 0, TacticName: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x32x32_stage4_warpsize4x1x1_g1_tensor16x8x16_t1r3s3, TacticValue: 0x3e7eb35b91b9fa63
Name: Reformatting CopyNode for Output Tensor 0 to Conv_139, LayerType: Reformat, Inputs: [ { Name: Reformatted Output Tensor 0 to Conv_139, Dimensions: [1,1,180,180], Format/Datatype: Channel major FP16 format where channel % 8 == 0 }], Outputs: [ { Name: height_4, Dimensions: [1,1,180,180], Format/Datatype: Row major linear FP16 format }], ParameterType: Reformat, Origin: REFORMAT, TacticValue: 0x0
Name: Conv_142, LayerType: CaskConvolution, Inputs: [ { Name: Conv_134 + Relu_135 || Conv_137 + Relu_138 || Conv_140 + Relu_141 || Conv_143 + Relu_144 || Conv_146 + Relu_147 || Conv_149 + Relu_150 || Conv_152 + Relu_153 || Conv_155 + Relu_156, Dimensions: [1,64,180,180], Format/Datatype: Channel major FP16 format where channel % 8 == 0 }], Outputs: [ { Name: Reformatted Output Tensor 0 to Conv_142, Dimensions: [1,3,180,180], Format/Datatype: Channel major FP16 format where channel % 8 == 0 }], ParameterType: Convolution, Kernel: [3,3], PaddingMode: kEXPLICIT_ROUND_DOWN, PrePadding: [1,1], PostPadding: [1,1], Stride: [1,1], Dilation: [1,1], OutMaps: 3, Groups: 1, Weights: {"Type": "Half", "Count": 1728}, Bias: {"Type": "Half", "Count": 3}, AllowSparse: 0, Activation: NONE, HasBias: 1, HasReLU: 0, TacticName: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x32x32_stage4_warpsize4x1x1_g1_tensor16x8x16_t1r3s3, TacticValue: 0x3e7eb35b91b9fa63
Name: Reformatting CopyNode for Output Tensor 0 to Conv_142, LayerType: Reformat, Inputs: [ { Name: Reformatted Output Tensor 0 to Conv_142, Dimensions: [1,3,180,180], Format/Datatype: Channel major FP16 format where channel % 8 == 0 }], Outputs: [ { Name: dim_4, Dimensions: [1,3,180,180], Format/Datatype: Row major linear FP16 format }], ParameterType: Reformat, Origin: REFORMAT, TacticValue: 0x0
Name: Conv_145, LayerType: CaskConvolution, Inputs: [ { Name: Conv_134 + Relu_135 || Conv_137 + Relu_138 || Conv_140 + Relu_141 || Conv_143 + Relu_144 || Conv_146 + Relu_147 || Conv_149 + Relu_150 || Conv_152 + Relu_153 || Conv_155 + Relu_156, Dimensions: [1,64,180,180], Format/Datatype: Channel major FP16 format where channel % 8 == 0 }], Outputs: [ { Name: Reformatted Output Tensor 0 to Conv_145, Dimensions: [1,2,180,180], Format/Datatype: Channel major FP16 format where channel % 8 == 0 }], ParameterType: Convolution, Kernel: [3,3], PaddingMode: kEXPLICIT_ROUND_DOWN, PrePadding: [1,1], PostPadding: [1,1], Stride: [1,1], Dilation: [1,1], OutMaps: 2, Groups: 1, Weights: {"Type": "Half", "Count": 1152}, Bias: {"Type": "Half", "Count": 2}, AllowSparse: 0, Activation: NONE, HasBias: 1, HasReLU: 0, TacticName: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x32x32_stage4_warpsize4x1x1_g1_tensor16x8x16_t1r3s3, TacticValue: 0x3e7eb35b91b9fa63
Name: Reformatting CopyNode for Output Tensor 0 to Conv_145, LayerType: Reformat, Inputs: [ { Name: Reformatted Output Tensor 0 to Conv_145, Dimensions: [1,2,180,180], Format/Datatype: Channel major FP16 format where channel % 8 == 0 }], Outputs: [ { Name: rot_4, Dimensions: [1,2,180,180], Format/Datatype: Row major linear FP16 format }], ParameterType: Reformat, Origin: REFORMAT, TacticValue: 0x0
Name: Conv_148, LayerType: CaskConvolution, Inputs: [ { Name: Conv_134 + Relu_135 || Conv_137 + Relu_138 || Conv_140 + Relu_141 || Conv_143 + Relu_144 || Conv_146 + Relu_147 || Conv_149 + Relu_150 || Conv_152 + Relu_153 || Conv_155 + Relu_156, Dimensions: [1,64,180,180], Format/Datatype: Channel major FP16 format where channel % 8 == 0 }], Outputs: [ { Name: Reformatted Output Tensor 0 to Conv_148, Dimensions: [1,2,180,180], Format/Datatype: Channel major FP16 format where channel % 8 == 0 }], ParameterType: Convolution, Kernel: [3,3], PaddingMode: kEXPLICIT_ROUND_DOWN, PrePadding: [1,1], PostPadding: [1,1], Stride: [1,1], Dilation: [1,1], OutMaps: 2, Groups: 1, Weights: {"Type": "Half", "Count": 1152}, Bias: {"Type": "Half", "Count": 2}, AllowSparse: 0, Activation: NONE, HasBias: 1, HasReLU: 0, TacticName: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x32x32_stage4_warpsize4x1x1_g1_tensor16x8x16_t1r3s3, TacticValue: 0x3e7eb35b91b9fa63
Name: Reformatting CopyNode for Output Tensor 0 to Conv_148, LayerType: Reformat, Inputs: [ { Name: Reformatted Output Tensor 0 to Conv_148, Dimensions: [1,2,180,180], Format/Datatype: Channel major FP16 format where channel % 8 == 0 }], Outputs: [ { Name: vel_4, Dimensions: [1,2,180,180], Format/Datatype: Row major linear FP16 format }], ParameterType: Reformat, Origin: REFORMAT, TacticValue: 0x0
Name: Conv_151, LayerType: CaskConvolution, Inputs: [ { Name: Conv_134 + Relu_135 || Conv_137 + Relu_138 || Conv_140 + Relu_141 || Conv_143 + Relu_144 || Conv_146 + Relu_147 || Conv_149 + Relu_150 || Conv_152 + Relu_153 || Conv_155 + Relu_156, Dimensions: [1,64,180,180], Format/Datatype: Channel major FP16 format where channel % 8 == 0 }], Outputs: [ { Name: Reformatted Output Tensor 0 to Conv_151, Dimensions: [1,2,180,180], Format/Datatype: Channel major FP16 format where channel % 8 == 0 }], ParameterType: Convolution, Kernel: [3,3], PaddingMode: kEXPLICIT_ROUND_DOWN, PrePadding: [1,1], PostPadding: [1,1], Stride: [1,1], Dilation: [1,1], OutMaps: 2, Groups: 1, Weights: {"Type": "Half", "Count": 1152}, Bias: {"Type": "Half", "Count": 2}, AllowSparse: 0, Activation: NONE, HasBias: 1, HasReLU: 0, TacticName: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x32x32_stage4_warpsize4x1x1_g1_tensor16x8x16_t1r3s3, TacticValue: 0x3e7eb35b91b9fa63
Name: Reformatting CopyNode for Output Tensor 0 to Conv_151, LayerType: Reformat, Inputs: [ { Name: Reformatted Output Tensor 0 to Conv_151, Dimensions: [1,2,180,180], Format/Datatype: Channel major FP16 format where channel % 8 == 0 }], Outputs: [ { Name: hm_4, Dimensions: [1,2,180,180], Format/Datatype: Row major linear FP16 format }], ParameterType: Reformat, Origin: REFORMAT, TacticValue: 0x0
Name: Conv_154, LayerType: CaskConvolution, Inputs: [ { Name: Conv_134 + Relu_135 || Conv_137 + Relu_138 || Conv_140 + Relu_141 || Conv_143 + Relu_144 || Conv_146 + Relu_147 || Conv_149 + Relu_150 || Conv_152 + Relu_153 || Conv_155 + Relu_156, Dimensions: [1,64,180,180], Format/Datatype: Channel major FP16 format where channel % 8 == 0 }], Outputs: [ { Name: Reformatted Output Tensor 0 to Conv_154, Dimensions: [1,2,180,180], Format/Datatype: Channel major FP16 format where channel % 8 == 0 }], ParameterType: Convolution, Kernel: [3,3], PaddingMode: kEXPLICIT_ROUND_DOWN, PrePadding: [1,1], PostPadding: [1,1], Stride: [1,1], Dilation: [1,1], OutMaps: 2, Groups: 1, Weights: {"Type": "Half", "Count": 1152}, Bias: {"Type": "Half", "Count": 2}, AllowSparse: 0, Activation: NONE, HasBias: 1, HasReLU: 0, TacticName: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x32x32_stage4_warpsize4x1x1_g1_tensor16x8x16_t1r3s3, TacticValue: 0x3e7eb35b91b9fa63
Name: Reformatting CopyNode for Output Tensor 0 to Conv_154, LayerType: Reformat, Inputs: [ { Name: Reformatted Output Tensor 0 to Conv_154, Dimensions: [1,2,180,180], Format/Datatype: Channel major FP16 format where channel % 8 == 0 }], Outputs: [ { Name: reg_5, Dimensions: [1,2,180,180], Format/Datatype: Row major linear FP16 format }], ParameterType: Reformat, Origin: REFORMAT, TacticValue: 0x0
Name: Conv_157, LayerType: CaskConvolution, Inputs: [ { Name: Conv_134 + Relu_135 || Conv_137 + Relu_138 || Conv_140 + Relu_141 || Conv_143 + Relu_144 || Conv_146 + Relu_147 || Conv_149 + Relu_150 || Conv_152 + Relu_153 || Conv_155 + Relu_156, Dimensions: [1,64,180,180], Format/Datatype: Channel major FP16 format where channel % 8 == 0 }], Outputs: [ { Name: Reformatted Output Tensor 0 to Conv_157, Dimensions: [1,1,180,180], Format/Datatype: Channel major FP16 format where channel % 8 == 0 }], ParameterType: Convolution, Kernel: [3,3], PaddingMode: kEXPLICIT_ROUND_DOWN, PrePadding: [1,1], PostPadding: [1,1], Stride: [1,1], Dilation: [1,1], OutMaps: 1, Groups: 1, Weights: {"Type": "Half", "Count": 576}, Bias: {"Type": "Half", "Count": 1}, AllowSparse: 0, Activation: NONE, HasBias: 1, HasReLU: 0, TacticName: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x32x32_stage4_warpsize4x1x1_g1_tensor16x8x16_t1r3s3, TacticValue: 0x3e7eb35b91b9fa63
Name: Reformatting CopyNode for Output Tensor 0 to Conv_157, LayerType: Reformat, Inputs: [ { Name: Reformatted Output Tensor 0 to Conv_157, Dimensions: [1,1,180,180], Format/Datatype: Channel major FP16 format where channel % 8 == 0 }], Outputs: [ { Name: height_5, Dimensions: [1,1,180,180], Format/Datatype: Row major linear FP16 format }], ParameterType: Reformat, Origin: REFORMAT, TacticValue: 0x0
Name: Conv_158 + Relu_159 || Conv_161 + Relu_162 || Conv_164 + Relu_165 || Conv_167 + Relu_168, LayerType: CaskConvolution, Inputs: [ { Name: onnx::Conv_651, Dimensions: [1,64,180,180], Format/Datatype: Channel major FP16 format where channel % 8 == 0 }], Outputs: [ { Name: Conv_158 + Relu_159 || Conv_161 + Relu_162 || Conv_164 + Relu_165 || Conv_167 + Relu_168, Dimensions: [1,256,180,180], Format/Datatype: Channel major FP16 format where channel % 8 == 0 }], ParameterType: Convolution, Kernel: [3,3], PaddingMode: kEXPLICIT_ROUND_DOWN, PrePadding: [1,1], PostPadding: [1,1], Stride: [1,1], Dilation: [1,1], OutMaps: 256, Groups: 1, Weights: {"Type": "Half", "Count": 147456}, Bias: {"Type": "Half", "Count": 256}, AllowSparse: 0, Activation: RELU, HasBias: 1, HasReLU: 1, TacticName: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x128x32_stage4_warpsize2x2x1_g1_tensor16x8x16_t1r3s3, TacticValue: 0x60c3421152ef8e10
Name: Conv_160, LayerType: CaskConvolution, Inputs: [ { Name: Conv_158 + Relu_159 || Conv_161 + Relu_162 || Conv_164 + Relu_165 || Conv_167 + Relu_168, Dimensions: [1,64,180,180], Format/Datatype: Channel major FP16 format where channel % 8 == 0 }], Outputs: [ { Name: Reformatted Output Tensor 0 to Conv_160, Dimensions: [1,3,180,180], Format/Datatype: Channel major FP16 format where channel % 8 == 0 }], ParameterType: Convolution, Kernel: [3,3], PaddingMode: kEXPLICIT_ROUND_DOWN, PrePadding: [1,1], PostPadding: [1,1], Stride: [1,1], Dilation: [1,1], OutMaps: 3, Groups: 1, Weights: {"Type": "Half", "Count": 1728}, Bias: {"Type": "Half", "Count": 3}, AllowSparse: 0, Activation: NONE, HasBias: 1, HasReLU: 0, TacticName: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x32x32_stage4_warpsize4x1x1_g1_tensor16x8x16_t1r3s3, TacticValue: 0x3e7eb35b91b9fa63
Name: Reformatting CopyNode for Output Tensor 0 to Conv_160, LayerType: Reformat, Inputs: [ { Name: Reformatted Output Tensor 0 to Conv_160, Dimensions: [1,3,180,180], Format/Datatype: Channel major FP16 format where channel % 8 == 0 }], Outputs: [ { Name: dim_5, Dimensions: [1,3,180,180], Format/Datatype: Row major linear FP16 format }], ParameterType: Reformat, Origin: REFORMAT, TacticValue: 0x0
Name: Conv_163, LayerType: CaskConvolution, Inputs: [ { Name: Conv_158 + Relu_159 || Conv_161 + Relu_162 || Conv_164 + Relu_165 || Conv_167 + Relu_168, Dimensions: [1,64,180,180], Format/Datatype: Channel major FP16 format where channel % 8 == 0 }], Outputs: [ { Name: Reformatted Output Tensor 0 to Conv_163, Dimensions: [1,2,180,180], Format/Datatype: Channel major FP16 format where channel % 8 == 0 }], ParameterType: Convolution, Kernel: [3,3], PaddingMode: kEXPLICIT_ROUND_DOWN, PrePadding: [1,1], PostPadding: [1,1], Stride: [1,1], Dilation: [1,1], OutMaps: 2, Groups: 1, Weights: {"Type": "Half", "Count": 1152}, Bias: {"Type": "Half", "Count": 2}, AllowSparse: 0, Activation: NONE, HasBias: 1, HasReLU: 0, TacticName: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x32x32_stage4_warpsize4x1x1_g1_tensor16x8x16, TacticValue: 0x834e11ecd4ab9454
Name: Reformatting CopyNode for Output Tensor 0 to Conv_163, LayerType: Reformat, Inputs: [ { Name: Reformatted Output Tensor 0 to Conv_163, Dimensions: [1,2,180,180], Format/Datatype: Channel major FP16 format where channel % 8 == 0 }], Outputs: [ { Name: rot_5, Dimensions: [1,2,180,180], Format/Datatype: Row major linear FP16 format }], ParameterType: Reformat, Origin: REFORMAT, TacticValue: 0x0
Name: Conv_166, LayerType: CaskConvolution, Inputs: [ { Name: Conv_158 + Relu_159 || Conv_161 + Relu_162 || Conv_164 + Relu_165 || Conv_167 + Relu_168, Dimensions: [1,64,180,180], Format/Datatype: Channel major FP16 format where channel % 8 == 0 }], Outputs: [ { Name: Reformatted Output Tensor 0 to Conv_166, Dimensions: [1,2,180,180], Format/Datatype: Channel major FP16 format where channel % 8 == 0 }], ParameterType: Convolution, Kernel: [3,3], PaddingMode: kEXPLICIT_ROUND_DOWN, PrePadding: [1,1], PostPadding: [1,1], Stride: [1,1], Dilation: [1,1], OutMaps: 2, Groups: 1, Weights: {"Type": "Half", "Count": 1152}, Bias: {"Type": "Half", "Count": 2}, AllowSparse: 0, Activation: NONE, HasBias: 1, HasReLU: 0, TacticName: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x32x32_stage4_warpsize4x1x1_g1_tensor16x8x16, TacticValue: 0x834e11ecd4ab9454
Name: Reformatting CopyNode for Output Tensor 0 to Conv_166, LayerType: Reformat, Inputs: [ { Name: Reformatted Output Tensor 0 to Conv_166, Dimensions: [1,2,180,180], Format/Datatype: Channel major FP16 format where channel % 8 == 0 }], Outputs: [ { Name: vel_5, Dimensions: [1,2,180,180], Format/Datatype: Row major linear FP16 format }], ParameterType: Reformat, Origin: REFORMAT, TacticValue: 0x0
Name: Conv_169, LayerType: CaskConvolution, Inputs: [ { Name: Conv_158 + Relu_159 || Conv_161 + Relu_162 || Conv_164 + Relu_165 || Conv_167 + Relu_168, Dimensions: [1,64,180,180], Format/Datatype: Channel major FP16 format where channel % 8 == 0 }], Outputs: [ { Name: Reformatted Output Tensor 0 to Conv_169, Dimensions: [1,2,180,180], Format/Datatype: Channel major FP16 format where channel % 8 == 0 }], ParameterType: Convolution, Kernel: [3,3], PaddingMode: kEXPLICIT_ROUND_DOWN, PrePadding: [1,1], PostPadding: [1,1], Stride: [1,1], Dilation: [1,1], OutMaps: 2, Groups: 1, Weights: {"Type": "Half", "Count": 1152}, Bias: {"Type": "Half", "Count": 2}, AllowSparse: 0, Activation: NONE, HasBias: 1, HasReLU: 0, TacticName: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x32x32_stage4_warpsize4x1x1_g1_tensor16x8x16, TacticValue: 0x834e11ecd4ab9454
Name: Reformatting CopyNode for Output Tensor 0 to Conv_169, LayerType: Reformat, Inputs: [ { Name: Reformatted Output Tensor 0 to Conv_169, Dimensions: [1,2,180,180], Format/Datatype: Channel major FP16 format where channel % 8 == 0 }], Outputs: [ { Name: hm_5, Dimensions: [1,2,180,180], Format/Datatype: Row major linear FP16 format }], ParameterType: Reformat, Origin: REFORMAT, TacticValue: 0x0

Bindings:
input
reg_0
height_0
dim_0
rot_0
vel_0
hm_0
reg_1
height_1
dim_1
rot_1
vel_1
hm_1
reg_2
height_2
dim_2
rot_2
vel_2
hm_2
reg_3
height_3
dim_3
rot_3
vel_3
hm_3
reg_4
height_4
dim_4
rot_4
vel_4
hm_4
reg_5
height_5
dim_5
rot_5
vel_5
hm_5
[03/24/2023-12:57:38] [V] [TRT] Using cublasLt as a tactic source
[03/24/2023-12:57:38] [I] [TRT] [MemUsageChange] Init cuBLAS/cuBLASLt: CPU +0, GPU +10, now: CPU 2238, GPU 1540 (MiB)
[03/24/2023-12:57:38] [V] [TRT] Using cuDNN as a tactic source
[03/24/2023-12:57:38] [I] [TRT] [MemUsageChange] Init cuDNN: CPU +0, GPU +8, now: CPU 2238, GPU 1548 (MiB)
[03/24/2023-12:57:38] [V] [TRT] Total per-runner device persistent memory is 12675584
[03/24/2023-12:57:38] [V] [TRT] Total per-runner host persistent memory is 127584
[03/24/2023-12:57:38] [V] [TRT] Allocated activation device memory of size 74659840
[03/24/2023-12:57:38] [I] [TRT] [MemUsageChange] TensorRT-managed allocation in IExecutionContext creation: CPU +0, GPU +83, now: CPU 0, GPU 95 (MiB)
[03/24/2023-12:57:38] [I] Using random values for input input
[03/24/2023-12:57:39] [I] Created input binding for input with dimensions 1x256x180x180
[03/24/2023-12:57:39] [I] Using random values for output reg_0
[03/24/2023-12:57:39] [I] Created output binding for reg_0 with dimensions 1x2x180x180
[03/24/2023-12:57:39] [I] Using random values for output height_0
[03/24/2023-12:57:39] [I] Created output binding for height_0 with dimensions 1x1x180x180
[03/24/2023-12:57:39] [I] Using random values for output dim_0
[03/24/2023-12:57:39] [I] Created output binding for dim_0 with dimensions 1x3x180x180
[03/24/2023-12:57:39] [I] Using random values for output rot_0
[03/24/2023-12:57:39] [I] Created output binding for rot_0 with dimensions 1x2x180x180
[03/24/2023-12:57:39] [I] Using random values for output vel_0
[03/24/2023-12:57:39] [I] Created output binding for vel_0 with dimensions 1x2x180x180
[03/24/2023-12:57:39] [I] Using random values for output hm_0
[03/24/2023-12:57:39] [I] Created output binding for hm_0 with dimensions 1x1x180x180
[03/24/2023-12:57:39] [I] Using random values for output reg_1
[03/24/2023-12:57:39] [I] Created output binding for reg_1 with dimensions 1x2x180x180
[03/24/2023-12:57:39] [I] Using random values for output height_1
[03/24/2023-12:57:39] [I] Created output binding for height_1 with dimensions 1x1x180x180
[03/24/2023-12:57:39] [I] Using random values for output dim_1
[03/24/2023-12:57:39] [I] Created output binding for dim_1 with dimensions 1x3x180x180
[03/24/2023-12:57:39] [I] Using random values for output rot_1
[03/24/2023-12:57:39] [I] Created output binding for rot_1 with dimensions 1x2x180x180
[03/24/2023-12:57:39] [I] Using random values for output vel_1
[03/24/2023-12:57:39] [I] Created output binding for vel_1 with dimensions 1x2x180x180
[03/24/2023-12:57:39] [I] Using random values for output hm_1
[03/24/2023-12:57:39] [I] Created output binding for hm_1 with dimensions 1x2x180x180
[03/24/2023-12:57:39] [I] Using random values for output reg_2
[03/24/2023-12:57:39] [I] Created output binding for reg_2 with dimensions 1x2x180x180
[03/24/2023-12:57:39] [I] Using random values for output height_2
[03/24/2023-12:57:39] [I] Created output binding for height_2 with dimensions 1x1x180x180
[03/24/2023-12:57:39] [I] Using random values for output dim_2
[03/24/2023-12:57:39] [I] Created output binding for dim_2 with dimensions 1x3x180x180
[03/24/2023-12:57:39] [I] Using random values for output rot_2
[03/24/2023-12:57:39] [I] Created output binding for rot_2 with dimensions 1x2x180x180
[03/24/2023-12:57:39] [I] Using random values for output vel_2
[03/24/2023-12:57:39] [I] Created output binding for vel_2 with dimensions 1x2x180x180
[03/24/2023-12:57:39] [I] Using random values for output hm_2
[03/24/2023-12:57:39] [I] Created output binding for hm_2 with dimensions 1x2x180x180
[03/24/2023-12:57:39] [I] Using random values for output reg_3
[03/24/2023-12:57:39] [I] Created output binding for reg_3 with dimensions 1x2x180x180
[03/24/2023-12:57:39] [I] Using random values for output height_3
[03/24/2023-12:57:39] [I] Created output binding for height_3 with dimensions 1x1x180x180
[03/24/2023-12:57:39] [I] Using random values for output dim_3
[03/24/2023-12:57:39] [I] Created output binding for dim_3 with dimensions 1x3x180x180
[03/24/2023-12:57:39] [I] Using random values for output rot_3
[03/24/2023-12:57:39] [I] Created output binding for rot_3 with dimensions 1x2x180x180
[03/24/2023-12:57:39] [I] Using random values for output vel_3
[03/24/2023-12:57:39] [I] Created output binding for vel_3 with dimensions 1x2x180x180
[03/24/2023-12:57:39] [I] Using random values for output hm_3
[03/24/2023-12:57:39] [I] Created output binding for hm_3 with dimensions 1x1x180x180
[03/24/2023-12:57:39] [I] Using random values for output reg_4
[03/24/2023-12:57:39] [I] Created output binding for reg_4 with dimensions 1x2x180x180
[03/24/2023-12:57:39] [I] Using random values for output height_4
[03/24/2023-12:57:39] [I] Created output binding for height_4 with dimensions 1x1x180x180
[03/24/2023-12:57:39] [I] Using random values for output dim_4
[03/24/2023-12:57:39] [I] Created output binding for dim_4 with dimensions 1x3x180x180
[03/24/2023-12:57:39] [I] Using random values for output rot_4
[03/24/2023-12:57:39] [I] Created output binding for rot_4 with dimensions 1x2x180x180
[03/24/2023-12:57:39] [I] Using random values for output vel_4
[03/24/2023-12:57:39] [I] Created output binding for vel_4 with dimensions 1x2x180x180
[03/24/2023-12:57:39] [I] Using random values for output hm_4
[03/24/2023-12:57:39] [I] Created output binding for hm_4 with dimensions 1x2x180x180
[03/24/2023-12:57:39] [I] Using random values for output reg_5
[03/24/2023-12:57:39] [I] Created output binding for reg_5 with dimensions 1x2x180x180
[03/24/2023-12:57:39] [I] Using random values for output height_5
[03/24/2023-12:57:39] [I] Created output binding for height_5 with dimensions 1x1x180x180
[03/24/2023-12:57:39] [I] Using random values for output dim_5
[03/24/2023-12:57:39] [I] Created output binding for dim_5 with dimensions 1x3x180x180
[03/24/2023-12:57:39] [I] Using random values for output rot_5
[03/24/2023-12:57:39] [I] Created output binding for rot_5 with dimensions 1x2x180x180
[03/24/2023-12:57:39] [I] Using random values for output vel_5
[03/24/2023-12:57:39] [I] Created output binding for vel_5 with dimensions 1x2x180x180
[03/24/2023-12:57:39] [I] Using random values for output hm_5
[03/24/2023-12:57:39] [I] Created output binding for hm_5 with dimensions 1x2x180x180
[03/24/2023-12:57:39] [I] Starting inference
[03/24/2023-12:57:42] [I] Warmup completed 86 queries over 200 ms
[03/24/2023-12:57:42] [I] Timing trace has 1275 queries over 3.00508 s
[03/24/2023-12:57:42] [I] 
[03/24/2023-12:57:42] [I] === Trace details ===
[03/24/2023-12:57:42] [I] Trace averages of 10 runs:
[03/24/2023-12:57:42] [I] Average on 10 runs - GPU latency: 2.33923 ms - Host latency: 4.15632 ms (end to end 4.53902 ms, enqueue 0.716142 ms)
[03/24/2023-12:57:42] [I] Average on 10 runs - GPU latency: 2.33933 ms - Host latency: 4.157 ms (end to end 4.54683 ms, enqueue 0.707748 ms)
[03/24/2023-12:57:42] [I] Average on 10 runs - GPU latency: 2.34076 ms - Host latency: 4.1578 ms (end to end 4.54509 ms, enqueue 0.69886 ms)
[03/24/2023-12:57:42] [I] Average on 10 runs - GPU latency: 2.33984 ms - Host latency: 4.16 ms (end to end 4.54513 ms, enqueue 0.709009 ms)
[03/24/2023-12:57:42] [I] Average on 10 runs - GPU latency: 2.33851 ms - Host latency: 4.15882 ms (end to end 4.55114 ms, enqueue 0.718243 ms)
[03/24/2023-12:57:42] [I] Average on 10 runs - GPU latency: 2.3384 ms - Host latency: 4.15895 ms (end to end 4.54044 ms, enqueue 0.733313 ms)
[03/24/2023-12:57:42] [I] Average on 10 runs - GPU latency: 2.33738 ms - Host latency: 4.15404 ms (end to end 4.54566 ms, enqueue 0.666217 ms)
[03/24/2023-12:57:42] [I] Average on 10 runs - GPU latency: 2.33933 ms - Host latency: 4.15728 ms (end to end 4.54991 ms, enqueue 0.827637 ms)
[03/24/2023-12:57:42] [I] Average on 10 runs - GPU latency: 2.3386 ms - Host latency: 4.15202 ms (end to end 4.56099 ms, enqueue 0.650589 ms)
[03/24/2023-12:57:42] [I] Average on 10 runs - GPU latency: 2.33922 ms - Host latency: 4.15342 ms (end to end 4.55266 ms, enqueue 0.695709 ms)
[03/24/2023-12:57:42] [I] Average on 10 runs - GPU latency: 2.33718 ms - Host latency: 4.15135 ms (end to end 4.55361 ms, enqueue 0.678436 ms)
[03/24/2023-12:57:42] [I] Average on 10 runs - GPU latency: 2.33758 ms - Host latency: 4.15542 ms (end to end 4.53784 ms, enqueue 0.723996 ms)
[03/24/2023-12:57:42] [I] Average on 10 runs - GPU latency: 2.33738 ms - Host latency: 4.15602 ms (end to end 4.5375 ms, enqueue 0.704843 ms)
[03/24/2023-12:57:42] [I] Average on 10 runs - GPU latency: 2.33871 ms - Host latency: 4.15708 ms (end to end 4.54285 ms, enqueue 0.709125 ms)
[03/24/2023-12:57:42] [I] Average on 10 runs - GPU latency: 2.33861 ms - Host latency: 4.15668 ms (end to end 4.54636 ms, enqueue 0.732648 ms)
[03/24/2023-12:57:42] [I] Average on 10 runs - GPU latency: 2.33799 ms - Host latency: 4.15454 ms (end to end 4.5355 ms, enqueue 0.708209 ms)
[03/24/2023-12:57:42] [I] Average on 10 runs - GPU latency: 2.33707 ms - Host latency: 4.15445 ms (end to end 4.54485 ms, enqueue 0.692084 ms)
[03/24/2023-12:57:42] [I] Average on 10 runs - GPU latency: 2.33912 ms - Host latency: 4.15221 ms (end to end 4.56645 ms, enqueue 0.659772 ms)
[03/24/2023-12:57:42] [I] Average on 10 runs - GPU latency: 2.33729 ms - Host latency: 4.15017 ms (end to end 4.56325 ms, enqueue 0.68208 ms)
[03/24/2023-12:57:42] [I] Average on 10 runs - GPU latency: 2.33821 ms - Host latency: 4.15096 ms (end to end 4.56956 ms, enqueue 0.748474 ms)
[03/24/2023-12:57:42] [I] Average on 10 runs - GPU latency: 2.33768 ms - Host latency: 4.15338 ms (end to end 4.5623 ms, enqueue 0.717023 ms)
[03/24/2023-12:57:42] [I] Average on 10 runs - GPU latency: 2.33842 ms - Host latency: 4.15577 ms (end to end 4.54005 ms, enqueue 0.684174 ms)
[03/24/2023-12:57:42] [I] Average on 10 runs - GPU latency: 2.33726 ms - Host latency: 4.15594 ms (end to end 4.54073 ms, enqueue 0.714758 ms)
[03/24/2023-12:57:42] [I] Average on 10 runs - GPU latency: 2.33801 ms - Host latency: 4.15828 ms (end to end 4.54494 ms, enqueue 0.706171 ms)
[03/24/2023-12:57:42] [I] Average on 10 runs - GPU latency: 2.33799 ms - Host latency: 4.15671 ms (end to end 4.53863 ms, enqueue 0.704584 ms)
[03/24/2023-12:57:42] [I] Average on 10 runs - GPU latency: 2.34148 ms - Host latency: 4.16333 ms (end to end 4.54167 ms, enqueue 0.72724 ms)
[03/24/2023-12:57:42] [I] Average on 10 runs - GPU latency: 2.33934 ms - Host latency: 4.15913 ms (end to end 4.53311 ms, enqueue 0.726672 ms)
[03/24/2023-12:57:42] [I] Average on 10 runs - GPU latency: 2.33811 ms - Host latency: 4.15447 ms (end to end 4.54615 ms, enqueue 0.72124 ms)
[03/24/2023-12:57:42] [I] Average on 10 runs - GPU latency: 2.34095 ms - Host latency: 4.16025 ms (end to end 4.56998 ms, enqueue 0.676416 ms)
[03/24/2023-12:57:42] [I] Average on 10 runs - GPU latency: 2.3511 ms - Host latency: 4.16854 ms (end to end 4.57333 ms, enqueue 0.727216 ms)
[03/24/2023-12:57:42] [I] Average on 10 runs - GPU latency: 2.37148 ms - Host latency: 4.18653 ms (end to end 4.63438 ms, enqueue 0.713812 ms)
[03/24/2023-12:57:42] [I] Average on 10 runs - GPU latency: 2.37732 ms - Host latency: 4.19766 ms (end to end 4.6163 ms, enqueue 0.731311 ms)
[03/24/2023-12:57:42] [I] Average on 10 runs - GPU latency: 2.37619 ms - Host latency: 4.19458 ms (end to end 4.62512 ms, enqueue 0.704333 ms)
[03/24/2023-12:57:42] [I] Average on 10 runs - GPU latency: 2.36882 ms - Host latency: 4.19052 ms (end to end 4.6041 ms, enqueue 0.725995 ms)
[03/24/2023-12:57:42] [I] Average on 10 runs - GPU latency: 2.36133 ms - Host latency: 4.18143 ms (end to end 4.57686 ms, enqueue 0.725848 ms)
[03/24/2023-12:57:42] [I] Average on 10 runs - GPU latency: 2.36402 ms - Host latency: 4.18467 ms (end to end 4.59082 ms, enqueue 0.715381 ms)
[03/24/2023-12:57:42] [I] Average on 10 runs - GPU latency: 2.363 ms - Host latency: 4.18295 ms (end to end 4.59176 ms, enqueue 0.733069 ms)
[03/24/2023-12:57:42] [I] Average on 10 runs - GPU latency: 2.36143 ms - Host latency: 4.18225 ms (end to end 4.59033 ms, enqueue 0.726038 ms)
[03/24/2023-12:57:42] [I] Average on 10 runs - GPU latency: 2.34662 ms - Host latency: 4.16398 ms (end to end 4.56104 ms, enqueue 0.691772 ms)
[03/24/2023-12:57:42] [I] Average on 10 runs - GPU latency: 2.3468 ms - Host latency: 4.16461 ms (end to end 4.56534 ms, enqueue 0.703528 ms)
[03/24/2023-12:57:42] [I] Average on 10 runs - GPU latency: 2.3455 ms - Host latency: 4.16458 ms (end to end 4.56821 ms, enqueue 0.708813 ms)
[03/24/2023-12:57:42] [I] Average on 10 runs - GPU latency: 2.34354 ms - Host latency: 4.16222 ms (end to end 4.55304 ms, enqueue 0.718762 ms)
[03/24/2023-12:57:42] [I] Average on 10 runs - GPU latency: 2.34651 ms - Host latency: 4.16572 ms (end to end 4.5526 ms, enqueue 0.720935 ms)
[03/24/2023-12:57:42] [I] Average on 10 runs - GPU latency: 2.33762 ms - Host latency: 4.15753 ms (end to end 4.53492 ms, enqueue 0.722632 ms)
[03/24/2023-12:57:42] [I] Average on 10 runs - GPU latency: 2.33993 ms - Host latency: 4.15719 ms (end to end 4.55166 ms, enqueue 0.733765 ms)
[03/24/2023-12:57:42] [I] Average on 10 runs - GPU latency: 2.33768 ms - Host latency: 4.15497 ms (end to end 4.54769 ms, enqueue 0.697888 ms)
[03/24/2023-12:57:42] [I] Average on 10 runs - GPU latency: 2.34139 ms - Host latency: 4.158 ms (end to end 4.56287 ms, enqueue 0.717969 ms)
[03/24/2023-12:57:42] [I] Average on 10 runs - GPU latency: 2.33883 ms - Host latency: 4.15358 ms (end to end 4.56283 ms, enqueue 0.679858 ms)
[03/24/2023-12:57:42] [I] Average on 10 runs - GPU latency: 2.33821 ms - Host latency: 4.15881 ms (end to end 4.55798 ms, enqueue 0.711047 ms)
[03/24/2023-12:57:42] [I] Average on 10 runs - GPU latency: 2.33904 ms - Host latency: 4.15708 ms (end to end 4.54498 ms, enqueue 0.706592 ms)
[03/24/2023-12:57:42] [I] Average on 10 runs - GPU latency: 2.3386 ms - Host latency: 4.15933 ms (end to end 4.53501 ms, enqueue 0.723962 ms)
[03/24/2023-12:57:42] [I] Average on 10 runs - GPU latency: 2.33854 ms - Host latency: 4.15762 ms (end to end 4.54031 ms, enqueue 0.726514 ms)
[03/24/2023-12:57:42] [I] Average on 10 runs - GPU latency: 2.33868 ms - Host latency: 4.15743 ms (end to end 4.53452 ms, enqueue 0.689062 ms)
[03/24/2023-12:57:42] [I] Average on 10 runs - GPU latency: 2.34127 ms - Host latency: 4.16212 ms (end to end 4.54357 ms, enqueue 0.730786 ms)
[03/24/2023-12:57:42] [I] Average on 10 runs - GPU latency: 2.33728 ms - Host latency: 4.15824 ms (end to end 4.53477 ms, enqueue 0.730615 ms)
[03/24/2023-12:57:42] [I] Average on 10 runs - GPU latency: 2.34004 ms - Host latency: 4.16233 ms (end to end 4.5363 ms, enqueue 0.725476 ms)
[03/24/2023-12:57:42] [I] Average on 10 runs - GPU latency: 2.33809 ms - Host latency: 4.16029 ms (end to end 4.53551 ms, enqueue 0.727002 ms)
[03/24/2023-12:57:42] [I] Average on 10 runs - GPU latency: 2.33768 ms - Host latency: 4.15874 ms (end to end 4.52452 ms, enqueue 0.708325 ms)
[03/24/2023-12:57:42] [I] Average on 10 runs - GPU latency: 2.3385 ms - Host latency: 4.16038 ms (end to end 4.53163 ms, enqueue 0.734534 ms)
[03/24/2023-12:57:42] [I] Average on 10 runs - GPU latency: 2.33821 ms - Host latency: 4.15825 ms (end to end 4.53114 ms, enqueue 0.719971 ms)
[03/24/2023-12:57:42] [I] Average on 10 runs - GPU latency: 2.35292 ms - Host latency: 4.17094 ms (end to end 4.56691 ms, enqueue 0.704773 ms)
[03/24/2023-12:57:42] [I] Average on 10 runs - GPU latency: 2.35713 ms - Host latency: 4.1775 ms (end to end 4.57544 ms, enqueue 0.721375 ms)
[03/24/2023-12:57:42] [I] Average on 10 runs - GPU latency: 2.35767 ms - Host latency: 4.17987 ms (end to end 4.57151 ms, enqueue 0.747107 ms)
[03/24/2023-12:57:42] [I] Average on 10 runs - GPU latency: 2.34816 ms - Host latency: 4.16826 ms (end to end 4.55786 ms, enqueue 0.694434 ms)
[03/24/2023-12:57:42] [I] Average on 10 runs - GPU latency: 2.33727 ms - Host latency: 4.15864 ms (end to end 4.52631 ms, enqueue 0.71792 ms)
[03/24/2023-12:57:42] [I] Average on 10 runs - GPU latency: 2.33646 ms - Host latency: 4.15463 ms (end to end 4.53466 ms, enqueue 0.721265 ms)
[03/24/2023-12:57:42] [I] Average on 10 runs - GPU latency: 2.33717 ms - Host latency: 4.15535 ms (end to end 4.5381 ms, enqueue 0.726538 ms)
[03/24/2023-12:57:42] [I] Average on 10 runs - GPU latency: 2.33945 ms - Host latency: 4.15923 ms (end to end 4.5453 ms, enqueue 0.695679 ms)
[03/24/2023-12:57:42] [I] Average on 10 runs - GPU latency: 2.36031 ms - Host latency: 4.17985 ms (end to end 4.57371 ms, enqueue 0.741589 ms)
[03/24/2023-12:57:42] [I] Average on 10 runs - GPU latency: 2.3639 ms - Host latency: 4.18372 ms (end to end 4.59545 ms, enqueue 0.71521 ms)
[03/24/2023-12:57:42] [I] Average on 10 runs - GPU latency: 2.36526 ms - Host latency: 4.18102 ms (end to end 4.60736 ms, enqueue 0.711401 ms)
[03/24/2023-12:57:42] [I] Average on 10 runs - GPU latency: 2.36512 ms - Host latency: 4.17131 ms (end to end 4.65015 ms, enqueue 0.622888 ms)
[03/24/2023-12:57:42] [I] Average on 10 runs - GPU latency: 2.364 ms - Host latency: 4.18242 ms (end to end 4.59534 ms, enqueue 0.747961 ms)
[03/24/2023-12:57:42] [I] Average on 10 runs - GPU latency: 2.363 ms - Host latency: 4.18269 ms (end to end 4.58445 ms, enqueue 0.69928 ms)
[03/24/2023-12:57:42] [I] Average on 10 runs - GPU latency: 2.3636 ms - Host latency: 4.18601 ms (end to end 4.58472 ms, enqueue 0.728821 ms)
[03/24/2023-12:57:42] [I] Average on 10 runs - GPU latency: 2.35646 ms - Host latency: 4.17876 ms (end to end 4.57527 ms, enqueue 0.708606 ms)
[03/24/2023-12:57:42] [I] Average on 10 runs - GPU latency: 2.35652 ms - Host latency: 4.177 ms (end to end 4.56527 ms, enqueue 0.716113 ms)
[03/24/2023-12:57:42] [I] Average on 10 runs - GPU latency: 2.35981 ms - Host latency: 4.18156 ms (end to end 4.57235 ms, enqueue 0.727478 ms)
[03/24/2023-12:57:42] [I] Average on 10 runs - GPU latency: 2.35845 ms - Host latency: 4.17998 ms (end to end 4.57148 ms, enqueue 0.718005 ms)
[03/24/2023-12:57:42] [I] Average on 10 runs - GPU latency: 2.3571 ms - Host latency: 4.17598 ms (end to end 4.58791 ms, enqueue 0.723071 ms)
[03/24/2023-12:57:42] [I] Average on 10 runs - GPU latency: 2.35208 ms - Host latency: 4.17017 ms (end to end 4.57356 ms, enqueue 0.722754 ms)
[03/24/2023-12:57:42] [I] Average on 10 runs - GPU latency: 2.34155 ms - Host latency: 4.16335 ms (end to end 4.54155 ms, enqueue 0.717383 ms)
[03/24/2023-12:57:42] [I] Average on 10 runs - GPU latency: 2.34558 ms - Host latency: 4.16504 ms (end to end 4.54502 ms, enqueue 0.729858 ms)
[03/24/2023-12:57:42] [I] Average on 10 runs - GPU latency: 2.34597 ms - Host latency: 4.16882 ms (end to end 4.54517 ms, enqueue 0.709619 ms)
[03/24/2023-12:57:42] [I] Average on 10 runs - GPU latency: 2.36052 ms - Host latency: 4.18484 ms (end to end 4.57595 ms, enqueue 0.742798 ms)
[03/24/2023-12:57:42] [I] Average on 10 runs - GPU latency: 2.36501 ms - Host latency: 4.19053 ms (end to end 4.58147 ms, enqueue 0.745483 ms)
[03/24/2023-12:57:42] [I] Average on 10 runs - GPU latency: 2.36489 ms - Host latency: 4.18674 ms (end to end 4.58591 ms, enqueue 0.708105 ms)
[03/24/2023-12:57:42] [I] Average on 10 runs - GPU latency: 2.36479 ms - Host latency: 4.18989 ms (end to end 4.58276 ms, enqueue 0.747876 ms)
[03/24/2023-12:57:42] [I] Average on 10 runs - GPU latency: 2.36467 ms - Host latency: 4.1865 ms (end to end 4.5969 ms, enqueue 0.689795 ms)
[03/24/2023-12:57:42] [I] Average on 10 runs - GPU latency: 2.36555 ms - Host latency: 4.19023 ms (end to end 4.58608 ms, enqueue 0.736011 ms)
[03/24/2023-12:57:42] [I] Average on 10 runs - GPU latency: 2.35774 ms - Host latency: 4.17952 ms (end to end 4.57576 ms, enqueue 0.73064 ms)
[03/24/2023-12:57:42] [I] Average on 10 runs - GPU latency: 2.36516 ms - Host latency: 4.18772 ms (end to end 4.59312 ms, enqueue 0.709204 ms)
[03/24/2023-12:57:42] [I] Average on 10 runs - GPU latency: 2.36382 ms - Host latency: 4.18643 ms (end to end 4.5783 ms, enqueue 0.727417 ms)
[03/24/2023-12:57:42] [I] Average on 10 runs - GPU latency: 2.36316 ms - Host latency: 4.18662 ms (end to end 4.58245 ms, enqueue 0.720288 ms)
[03/24/2023-12:57:42] [I] Average on 10 runs - GPU latency: 2.36162 ms - Host latency: 4.18169 ms (end to end 4.56843 ms, enqueue 0.719458 ms)
[03/24/2023-12:57:42] [I] Average on 10 runs - GPU latency: 2.35613 ms - Host latency: 4.17676 ms (end to end 4.57109 ms, enqueue 0.745313 ms)
[03/24/2023-12:57:42] [I] Average on 10 runs - GPU latency: 2.3574 ms - Host latency: 4.17747 ms (end to end 4.56624 ms, enqueue 0.691528 ms)
[03/24/2023-12:57:42] [I] Average on 10 runs - GPU latency: 2.35669 ms - Host latency: 4.17532 ms (end to end 4.57275 ms, enqueue 0.721753 ms)
[03/24/2023-12:57:42] [I] Average on 10 runs - GPU latency: 2.35908 ms - Host latency: 4.17937 ms (end to end 4.5739 ms, enqueue 0.733521 ms)
[03/24/2023-12:57:42] [I] Average on 10 runs - GPU latency: 2.36497 ms - Host latency: 4.18643 ms (end to end 4.58918 ms, enqueue 0.726904 ms)
[03/24/2023-12:57:42] [I] Average on 10 runs - GPU latency: 2.36526 ms - Host latency: 4.18618 ms (end to end 4.58669 ms, enqueue 0.722437 ms)
[03/24/2023-12:57:42] [I] Average on 10 runs - GPU latency: 2.36533 ms - Host latency: 4.18591 ms (end to end 4.59631 ms, enqueue 0.722583 ms)
[03/24/2023-12:57:42] [I] Average on 10 runs - GPU latency: 2.36479 ms - Host latency: 4.18948 ms (end to end 4.58997 ms, enqueue 0.733032 ms)
[03/24/2023-12:57:42] [I] Average on 10 runs - GPU latency: 2.36553 ms - Host latency: 4.18674 ms (end to end 4.58684 ms, enqueue 0.729858 ms)
[03/24/2023-12:57:42] [I] Average on 10 runs - GPU latency: 2.36606 ms - Host latency: 4.19075 ms (end to end 4.59277 ms, enqueue 0.748486 ms)
[03/24/2023-12:57:42] [I] Average on 10 runs - GPU latency: 2.36633 ms - Host latency: 4.19324 ms (end to end 4.58645 ms, enqueue 0.729126 ms)
[03/24/2023-12:57:42] [I] Average on 10 runs - GPU latency: 2.36489 ms - Host latency: 4.18555 ms (end to end 4.58181 ms, enqueue 0.735547 ms)
[03/24/2023-12:57:42] [I] Average on 10 runs - GPU latency: 2.36455 ms - Host latency: 4.18884 ms (end to end 4.59187 ms, enqueue 0.724487 ms)
[03/24/2023-12:57:42] [I] Average on 10 runs - GPU latency: 2.34397 ms - Host latency: 4.16628 ms (end to end 4.54756 ms, enqueue 0.720239 ms)
[03/24/2023-12:57:42] [I] Average on 10 runs - GPU latency: 2.34568 ms - Host latency: 4.1658 ms (end to end 4.55491 ms, enqueue 0.705078 ms)
[03/24/2023-12:57:42] [I] Average on 10 runs - GPU latency: 2.36416 ms - Host latency: 4.18542 ms (end to end 4.5801 ms, enqueue 0.738086 ms)
[03/24/2023-12:57:42] [I] Average on 10 runs - GPU latency: 2.36409 ms - Host latency: 4.18479 ms (end to end 4.59851 ms, enqueue 0.721875 ms)
[03/24/2023-12:57:42] [I] Average on 10 runs - GPU latency: 2.36345 ms - Host latency: 4.18503 ms (end to end 4.58833 ms, enqueue 0.734204 ms)
[03/24/2023-12:57:42] [I] Average on 10 runs - GPU latency: 2.36423 ms - Host latency: 4.18621 ms (end to end 4.59546 ms, enqueue 0.722217 ms)
[03/24/2023-12:57:42] [I] Average on 10 runs - GPU latency: 2.36465 ms - Host latency: 4.18835 ms (end to end 4.59182 ms, enqueue 0.731738 ms)
[03/24/2023-12:57:42] [I] Average on 10 runs - GPU latency: 2.36575 ms - Host latency: 4.18977 ms (end to end 4.58418 ms, enqueue 0.736035 ms)
[03/24/2023-12:57:42] [I] Average on 10 runs - GPU latency: 2.36494 ms - Host latency: 4.18865 ms (end to end 4.58823 ms, enqueue 0.726221 ms)
[03/24/2023-12:57:42] [I] Average on 10 runs - GPU latency: 2.36277 ms - Host latency: 4.18442 ms (end to end 4.58237 ms, enqueue 0.726245 ms)
[03/24/2023-12:57:42] [I] Average on 10 runs - GPU latency: 2.36624 ms - Host latency: 4.19028 ms (end to end 4.58293 ms, enqueue 0.733252 ms)
[03/24/2023-12:57:42] [I] Average on 10 runs - GPU latency: 2.3655 ms - Host latency: 4.18604 ms (end to end 4.58599 ms, enqueue 0.712012 ms)
[03/24/2023-12:57:42] [I] Average on 10 runs - GPU latency: 2.36436 ms - Host latency: 4.18345 ms (end to end 4.58765 ms, enqueue 0.734888 ms)
[03/24/2023-12:57:42] [I] Average on 10 runs - GPU latency: 2.36519 ms - Host latency: 4.18972 ms (end to end 4.58455 ms, enqueue 0.747314 ms)
[03/24/2023-12:57:42] [I] Average on 10 runs - GPU latency: 2.36545 ms - Host latency: 4.18682 ms (end to end 4.58003 ms, enqueue 0.738159 ms)
[03/24/2023-12:57:42] [I] Average on 10 runs - GPU latency: 2.36504 ms - Host latency: 4.18127 ms (end to end 4.61733 ms, enqueue 0.775415 ms)
[03/24/2023-12:57:42] [I] Average on 10 runs - GPU latency: 2.35041 ms - Host latency: 4.17258 ms (end to end 4.55786 ms, enqueue 0.721338 ms)
[03/24/2023-12:57:42] [I] Average on 10 runs - GPU latency: 2.3428 ms - Host latency: 4.16243 ms (end to end 4.54412 ms, enqueue 0.72749 ms)
[03/24/2023-12:57:42] [I] Average on 10 runs - GPU latency: 2.36501 ms - Host latency: 4.18943 ms (end to end 4.58879 ms, enqueue 0.729858 ms)
[03/24/2023-12:57:42] [I] 
[03/24/2023-12:57:42] [I] === Performance summary ===
[03/24/2023-12:57:42] [I] Throughput: 424.281 qps
[03/24/2023-12:57:42] [I] Latency: min = 4.13727 ms, max = 4.20911 ms, mean = 4.1715 ms, median = 4.17139 ms, percentile(99%) = 4.20166 ms
[03/24/2023-12:57:42] [I] End-to-End Host Latency: min = 4.47382 ms, max = 4.68054 ms, mean = 4.56716 ms, median = 4.5686 ms, percentile(99%) = 4.6543 ms
[03/24/2023-12:57:42] [I] Enqueue Time: min = 0.489014 ms, max = 0.995026 ms, mean = 0.718707 ms, median = 0.719482 ms, percentile(99%) = 0.856201 ms
[03/24/2023-12:57:42] [I] H2D Latency: min = 1.35498 ms, max = 1.39429 ms, mean = 1.37039 ms, median = 1.37 ms, percentile(99%) = 1.38586 ms
[03/24/2023-12:57:42] [I] GPU Compute Time: min = 2.33167 ms, max = 2.38287 ms, mean = 2.35166 ms, median = 2.35217 ms, percentile(99%) = 2.37775 ms
[03/24/2023-12:57:42] [I] D2H Latency: min = 0.43335 ms, max = 0.462341 ms, mean = 0.449453 ms, median = 0.449219 ms, percentile(99%) = 0.458435 ms
[03/24/2023-12:57:42] [I] Total Host Walltime: 3.00508 s
[03/24/2023-12:57:42] [I] Total GPU Compute Time: 2.99837 s
[03/24/2023-12:57:42] [I] Explanations of the performance metrics are printed in the verbose logs.
[03/24/2023-12:57:42] [V] 
[03/24/2023-12:57:42] [V] === Explanations of the performance metrics ===
[03/24/2023-12:57:42] [V] Total Host Walltime: the host walltime from when the first query (after warmups) is enqueued to when the last query is completed.
[03/24/2023-12:57:42] [V] GPU Compute Time: the GPU latency to execute the kernels for a query.
[03/24/2023-12:57:42] [V] Total GPU Compute Time: the summation of the GPU Compute Time of all the queries. If this is significantly shorter than Total Host Walltime, the GPU may be under-utilized because of host-side overheads or data transfers.
[03/24/2023-12:57:42] [V] Throughput: the observed throughput computed by dividing the number of queries by the Total Host Walltime. If this is significantly lower than the reciprocal of GPU Compute Time, the GPU may be under-utilized because of host-side overheads or data transfers.
[03/24/2023-12:57:42] [V] Enqueue Time: the host latency to enqueue a query. If this is longer than GPU Compute Time, the GPU may be under-utilized.
[03/24/2023-12:57:42] [V] H2D Latency: the latency for host-to-device data transfers for input tensors of a single query.
[03/24/2023-12:57:42] [V] D2H Latency: the latency for device-to-host data transfers for output tensors of a single query.
[03/24/2023-12:57:42] [V] Latency: the summation of H2D Latency, GPU Compute Time, and D2H Latency. This is the latency to infer a single query.
[03/24/2023-12:57:42] [V] End-to-End Host Latency: the duration from when the H2D of a query is called to when the D2H of the same query is completed, which includes the latency to wait for the completion of the previous query. This is the latency of a query if multiple queries are enqueued consecutively.
[03/24/2023-12:57:42] [I] 
[03/24/2023-12:57:45] [I] 
[03/24/2023-12:57:45] [I] === Profile (781 iterations ) ===
[03/24/2023-12:57:45] [I]                                                                                                                                                                                 Layer   Time (ms)   Avg. Time (ms)   Time %
[03/24/2023-12:57:45] [I]                                                                                                                         Reformatting CopyNode for Input Tensor 0 to Conv_15 + Relu_16       30.57           0.0391      1.5
[03/24/2023-12:57:45] [I]                                                                                                                                                                     Conv_15 + Relu_16       83.17           0.1065      4.1
[03/24/2023-12:57:45] [I]                                                                                                                                                                     Conv_17 + Relu_18       45.19           0.0579      2.2
[03/24/2023-12:57:45] [I]                                                                                                                                                                     Conv_19 + Relu_20       44.84           0.0574      2.2
[03/24/2023-12:57:45] [I]                                                                                                                                                                     Conv_21 + Relu_22       45.41           0.0581      2.3
[03/24/2023-12:57:45] [I]                                                                                                                                                                     Conv_23 + Relu_24       44.74           0.0573      2.2
[03/24/2023-12:57:45] [I]                                                                                                                                                                     Conv_25 + Relu_26       44.95           0.0576      2.2
[03/24/2023-12:57:45] [I]                                                                                                                                                                     Conv_27 + Relu_28       22.31           0.0286      1.1
[03/24/2023-12:57:45] [I]                                                                                                                                                                     Conv_44 + Relu_45       32.48           0.0416      1.6
[03/24/2023-12:57:45] [I]                                                                                                                                                                     Conv_46 + Relu_47       51.37           0.0658      2.5
[03/24/2023-12:57:45] [I]                                                                                                                                                                     Conv_48 + Relu_49       50.93           0.0652      2.5
[03/24/2023-12:57:45] [I]                                                                                                                                                                     Conv_50 + Relu_51       51.40           0.0658      2.6
[03/24/2023-12:57:45] [I]                                                                                                                                                                     Conv_52 + Relu_53       52.35           0.0670      2.6
[03/24/2023-12:57:45] [I]                                                                                                                                                                     Conv_54 + Relu_55       51.49           0.0659      2.6
[03/24/2023-12:57:45] [I]                                                                                                                                    ConvTranspose_56 + BatchNormalization_57 + Relu_58       47.75           0.0611      2.4
[03/24/2023-12:57:45] [I]                                                                                                                                                                 onnx::Concat_647 copy       31.93           0.0409      1.6
[03/24/2023-12:57:45] [I]                                                                                                                                                                     Conv_60 + Relu_61       93.25           0.1194      4.6
[03/24/2023-12:57:45] [I]                  Conv_62 + Relu_63 || Conv_65 + Relu_66 || Conv_68 + Relu_69 || Conv_71 + Relu_72 || Conv_74 + Relu_75 || Conv_77 + Relu_78 || Conv_80 + Relu_81 || Conv_83 + Relu_84       79.43           0.1017      3.9
[03/24/2023-12:57:45] [I]                                                                                                                                                                               Conv_64       17.87           0.0229      0.9
[03/24/2023-12:57:45] [I]                                                                                                                                  Reformatting CopyNode for Output Tensor 0 to Conv_64        5.70           0.0073      0.3
[03/24/2023-12:57:45] [I]                                                                                                                                                                               Conv_67       16.33           0.0209      0.8
[03/24/2023-12:57:45] [I]                                                                                                                                  Reformatting CopyNode for Output Tensor 0 to Conv_67        5.66           0.0072      0.3
[03/24/2023-12:57:45] [I]                                                                                                                                                                               Conv_70       16.77           0.0215      0.8
[03/24/2023-12:57:45] [I]                                                                                                                                  Reformatting CopyNode for Output Tensor 0 to Conv_70        5.69           0.0073      0.3
[03/24/2023-12:57:45] [I]                                                                                                                                                                               Conv_73       17.33           0.0222      0.9
[03/24/2023-12:57:45] [I]                                                                                                                                  Reformatting CopyNode for Output Tensor 0 to Conv_73        5.69           0.0073      0.3
[03/24/2023-12:57:45] [I]                                                                                                                                                                               Conv_76       18.07           0.0231      0.9
[03/24/2023-12:57:45] [I]                                                                                                                                  Reformatting CopyNode for Output Tensor 0 to Conv_76        5.70           0.0073      0.3
[03/24/2023-12:57:45] [I]                                                                                                                                                                               Conv_79       17.75           0.0227      0.9
[03/24/2023-12:57:45] [I]                                                                                                                                  Reformatting CopyNode for Output Tensor 0 to Conv_79        5.66           0.0072      0.3
[03/24/2023-12:57:45] [I]                                                                                                                                                                               Conv_82       18.01           0.0231      0.9
[03/24/2023-12:57:45] [I]                                                                                                                                  Reformatting CopyNode for Output Tensor 0 to Conv_82        5.66           0.0072      0.3
[03/24/2023-12:57:45] [I]                                                                                                                                                                               Conv_85       18.21           0.0233      0.9
[03/24/2023-12:57:45] [I]                                                                                                                                  Reformatting CopyNode for Output Tensor 0 to Conv_85        5.67           0.0073      0.3
[03/24/2023-12:57:45] [I]            Conv_86 + Relu_87 || Conv_89 + Relu_90 || Conv_92 + Relu_93 || Conv_95 + Relu_96 || Conv_98 + Relu_99 || Conv_101 + Relu_102 || Conv_104 + Relu_105 || Conv_107 + Relu_108       79.92           0.1023      4.0
[03/24/2023-12:57:45] [I]                                                                                                                                                                               Conv_88       16.53           0.0212      0.8
[03/24/2023-12:57:45] [I]                                                                                                                                  Reformatting CopyNode for Output Tensor 0 to Conv_88        5.70           0.0073      0.3
[03/24/2023-12:57:45] [I]                                                                                                                                                                               Conv_91       16.58           0.0212      0.8
[03/24/2023-12:57:45] [I]                                                                                                                                  Reformatting CopyNode for Output Tensor 0 to Conv_91        6.00           0.0077      0.3
[03/24/2023-12:57:45] [I]                                                                                                                                                                               Conv_94       16.69           0.0214      0.8
[03/24/2023-12:57:45] [I]                                                                                                                                  Reformatting CopyNode for Output Tensor 0 to Conv_94        5.67           0.0073      0.3
[03/24/2023-12:57:45] [I]                                                                                                                                                                               Conv_97       17.23           0.0221      0.9
[03/24/2023-12:57:45] [I]                                                                                                                                  Reformatting CopyNode for Output Tensor 0 to Conv_97        5.99           0.0077      0.3
[03/24/2023-12:57:45] [I]                                                                                                                                                                              Conv_100       17.61           0.0225      0.9
[03/24/2023-12:57:45] [I]                                                                                                                                 Reformatting CopyNode for Output Tensor 0 to Conv_100        5.68           0.0073      0.3
[03/24/2023-12:57:45] [I]                                                                                                                                                                              Conv_103       18.35           0.0235      0.9
[03/24/2023-12:57:45] [I]                                                                                                                                 Reformatting CopyNode for Output Tensor 0 to Conv_103        5.96           0.0076      0.3
[03/24/2023-12:57:45] [I]                                                                                                                                                                              Conv_106       17.84           0.0228      0.9
[03/24/2023-12:57:45] [I]                                                                                                                                 Reformatting CopyNode for Output Tensor 0 to Conv_106        5.70           0.0073      0.3
[03/24/2023-12:57:45] [I]                                                                                                                                                                              Conv_109       17.53           0.0225      0.9
[03/24/2023-12:57:45] [I]                                                                                                                                 Reformatting CopyNode for Output Tensor 0 to Conv_109        5.95           0.0076      0.3
[03/24/2023-12:57:45] [I]  Conv_110 + Relu_111 || Conv_113 + Relu_114 || Conv_116 + Relu_117 || Conv_119 + Relu_120 || Conv_122 + Relu_123 || Conv_125 + Relu_126 || Conv_128 + Relu_129 || Conv_131 + Relu_132       79.39           0.1016      3.9
[03/24/2023-12:57:45] [I]                                                                                                                                                                              Conv_112       16.59           0.0212      0.8
[03/24/2023-12:57:45] [I]                                                                                                                                 Reformatting CopyNode for Output Tensor 0 to Conv_112        5.71           0.0073      0.3
[03/24/2023-12:57:45] [I]                                                                                                                                                                              Conv_115       16.99           0.0218      0.8
[03/24/2023-12:57:45] [I]                                                                                                                                 Reformatting CopyNode for Output Tensor 0 to Conv_115        5.69           0.0073      0.3
[03/24/2023-12:57:45] [I]                                                                                                                                                                              Conv_118       16.85           0.0216      0.8
[03/24/2023-12:57:45] [I]                                                                                                                                 Reformatting CopyNode for Output Tensor 0 to Conv_118        5.66           0.0072      0.3
[03/24/2023-12:57:45] [I]                                                                                                                                                                              Conv_121       17.60           0.0225      0.9
[03/24/2023-12:57:45] [I]                                                                                                                                 Reformatting CopyNode for Output Tensor 0 to Conv_121        5.69           0.0073      0.3
[03/24/2023-12:57:45] [I]                                                                                                                                                                              Conv_124       18.02           0.0231      0.9
[03/24/2023-12:57:45] [I]                                                                                                                                 Reformatting CopyNode for Output Tensor 0 to Conv_124        5.64           0.0072      0.3
[03/24/2023-12:57:45] [I]                                                                                                                                                                              Conv_127       18.07           0.0231      0.9
[03/24/2023-12:57:45] [I]                                                                                                                                 Reformatting CopyNode for Output Tensor 0 to Conv_127        5.70           0.0073      0.3
[03/24/2023-12:57:45] [I]                                                                                                                                                                              Conv_130       17.69           0.0227      0.9
[03/24/2023-12:57:45] [I]                                                                                                                                 Reformatting CopyNode for Output Tensor 0 to Conv_130        5.70           0.0073      0.3
[03/24/2023-12:57:45] [I]                                                                                                                                                                              Conv_133       18.74           0.0240      0.9
[03/24/2023-12:57:45] [I]                                                                                                                                 Reformatting CopyNode for Output Tensor 0 to Conv_133        5.69           0.0073      0.3
[03/24/2023-12:57:45] [I]  Conv_134 + Relu_135 || Conv_137 + Relu_138 || Conv_140 + Relu_141 || Conv_143 + Relu_144 || Conv_146 + Relu_147 || Conv_149 + Relu_150 || Conv_152 + Relu_153 || Conv_155 + Relu_156       79.45           0.1017      3.9
[03/24/2023-12:57:45] [I]                                                                                                                                                                              Conv_136       16.50           0.0211      0.8
[03/24/2023-12:57:45] [I]                                                                                                                                 Reformatting CopyNode for Output Tensor 0 to Conv_136        6.10           0.0078      0.3
[03/24/2023-12:57:45] [I]                                                                                                                                                                              Conv_139       16.43           0.0210      0.8
[03/24/2023-12:57:45] [I]                                                                                                                                 Reformatting CopyNode for Output Tensor 0 to Conv_139        5.69           0.0073      0.3
[03/24/2023-12:57:45] [I]                                                                                                                                                                              Conv_142       17.10           0.0219      0.8
[03/24/2023-12:57:45] [I]                                                                                                                                 Reformatting CopyNode for Output Tensor 0 to Conv_142        5.95           0.0076      0.3
[03/24/2023-12:57:45] [I]                                                                                                                                                                              Conv_145       17.00           0.0218      0.8
[03/24/2023-12:57:45] [I]                                                                                                                                 Reformatting CopyNode for Output Tensor 0 to Conv_145        5.70           0.0073      0.3
[03/24/2023-12:57:45] [I]                                                                                                                                                                              Conv_148       17.62           0.0226      0.9
[03/24/2023-12:57:45] [I]                                                                                                                                 Reformatting CopyNode for Output Tensor 0 to Conv_148        5.92           0.0076      0.3
[03/24/2023-12:57:45] [I]                                                                                                                                                                              Conv_151       17.56           0.0225      0.9
[03/24/2023-12:57:45] [I]                                                                                                                                 Reformatting CopyNode for Output Tensor 0 to Conv_151        5.65           0.0072      0.3
[03/24/2023-12:57:45] [I]                                                                                                                                                                              Conv_154       17.69           0.0226      0.9
[03/24/2023-12:57:45] [I]                                                                                                                                 Reformatting CopyNode for Output Tensor 0 to Conv_154        5.89           0.0075      0.3
[03/24/2023-12:57:45] [I]                                                                                                                                                                              Conv_157       17.63           0.0226      0.9
[03/24/2023-12:57:45] [I]                                                                                                                                 Reformatting CopyNode for Output Tensor 0 to Conv_157        5.66           0.0073      0.3
[03/24/2023-12:57:45] [I]                                                                                              Conv_158 + Relu_159 || Conv_161 + Relu_162 || Conv_164 + Relu_165 || Conv_167 + Relu_168       43.92           0.0562      2.2
[03/24/2023-12:57:45] [I]                                                                                                                                                                              Conv_160       16.46           0.0211      0.8
[03/24/2023-12:57:45] [I]                                                                                                                                 Reformatting CopyNode for Output Tensor 0 to Conv_160        5.63           0.0072      0.3
[03/24/2023-12:57:45] [I]                                                                                                                                                                              Conv_163       16.54           0.0212      0.8
[03/24/2023-12:57:45] [I]                                                                                                                                 Reformatting CopyNode for Output Tensor 0 to Conv_163        5.70           0.0073      0.3
[03/24/2023-12:57:45] [I]                                                                                                                                                                              Conv_166       16.05           0.0205      0.8
[03/24/2023-12:57:45] [I]                                                                                                                                 Reformatting CopyNode for Output Tensor 0 to Conv_166        5.68           0.0073      0.3
[03/24/2023-12:57:45] [I]                                                                                                                                                                              Conv_169       16.31           0.0209      0.8
[03/24/2023-12:57:45] [I]                                                                                                                                 Reformatting CopyNode for Output Tensor 0 to Conv_169        5.68           0.0073      0.3
[03/24/2023-12:57:45] [I]                                                                                                                                                                                 Total     2015.23           2.5803    100.0
[03/24/2023-12:57:45] [I] 
&&&& PASSED TensorRT.trtexec [TensorRT v8203] # trtexec --onnx=model/rpn_centerhead_sim.onnx --saveEngine=model/rpn_centerhead_sim.plan.8503 --workspace=4096 --fp16 --outputIOFormats=fp16:chw --inputIOFormats=fp16:chw --verbose --dumpLayerInfo --dumpProfile --separateProfileRun --profilingVerbosity=detailed
